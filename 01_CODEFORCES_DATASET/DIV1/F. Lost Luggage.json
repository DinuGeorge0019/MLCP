{
    "link": "https://codeforces.com//contest/2097/problem/F",
    "problemId": "3353170",
    "problem_idx": "F",
    "shortId": "2097F",
    "contest_number": "2097",
    "problem_submissions": {
        "F": [
            317307318,
            317309525,
            317309102,
            317312383,
            317316279,
            317325883,
            317416247,
            317580233,
            317579495,
            317578954,
            317578471,
            317578170,
            317576401,
            317575526,
            317574565,
            317326012
        ],
        "C": [
            317301103,
            317292740,
            317292086,
            317292797,
            317292557,
            317300448,
            317293184,
            317293569,
            317295891,
            317295305,
            317293328,
            317304181,
            317299563,
            317305951,
            317296495,
            317302226,
            317306136,
            317302946
        ],
        "E": [
            317299854,
            317301108,
            317299586,
            317304189,
            317304951,
            317308313,
            317313597,
            317305664,
            317317246,
            317322289,
            317316806,
            317319809,
            317318900,
            317321182,
            317406068,
            317321088,
            317322736,
            317322644
        ],
        "D": [
            317296567,
            317296050,
            317297072,
            317301213,
            317322631,
            317315490,
            317304532,
            317321371,
            317306823,
            317303050,
            317304957,
            317310591,
            317315906,
            317313581,
            317306990,
            317307372,
            317315011,
            317317721
        ],
        "B": [
            317283633,
            317287516,
            317287207,
            317285769,
            317289590,
            317285943,
            317288249,
            317285819,
            317286523,
            317288061,
            317290152,
            317289644,
            317297031,
            317288240,
            317297080,
            317298214,
            317294941
        ],
        "A": [
            317279828,
            317283931,
            317284029,
            317281512,
            317283570,
            317281675,
            317282711,
            317280805,
            317280621,
            317281741,
            317281827,
            317282878,
            317285451,
            317282463,
            317280852,
            317282823,
            317324194
        ]
    },
    "editorial_link": "https://codeforces.com//blog/entry/142316",
    "editorial": "It is clear that the problem can be solved using flows. We will\r\nintroduce a dummy source and vertices (, ), and the following edges will\r\nbe added to the network: For all (), edges from to with capacity . For\r\nall pairs , (, ), edges from to with capacity . For all pairs , (, ),\r\nedges from to with capacity . For all pairs , (, ), edges from to with\r\ncapacity . To each layer (), we will connect edges to the sink (for all\r\n, edges from to will have capacity ). Thus, the answer to the problem is\r\nthe values of the maximum flows from to , respectively.Unfortunately for\r\nthe participants, the maximum flows ( is the maximum flow from to ) can\r\ndiffer significantly from each other. This causes algorithms based on\r\nthe Ford-Fulkerson method to work unjustifiably slowly, specifically in\r\ntime . If we are wrong, and you managed to squeeze your solution, please\r\nshare it in the comments :)The values of the maximum flows can be found\r\nusing the Ford-Fulkerson theorem with the help of dynamic programming.\r\nSpecifically, let be the minimum -cut on the subgraph , where the vertex\r\nis in the part of the cut if and only if the -th bit of the mask is\r\nequal to .This dynamic can be easily computed in time , but again, this\r\nis too slow. The author’s solution is to speed up the recalculation of\r\nthe next layer of dynamics to time .Let be the already computed layer of\r\ndynamics, and be the layer of dynamics that we want to compute. Instead\r\nof indexing by the mask in the forms, we will index these arrays by sets\r\nof vertices of the corresponding layer that are in the part of the cut.A\r\ncouple of clarifications: is simply the weights of the edges between\r\nlayers and in a convenient order. It is very difficult for me to keep\r\ntrack of the indices accurately, and this is just a technical detail, so\r\nreconstruct how to form from the arrays , , and from the context.\r\nactually means . Here is the Iverson bracket. when the predicate is\r\nsatisfied, and otherwise. The main difficulty of the recalculation lies\r\nin the fact that the set determines which summands will participate in\r\nthe sum and which will not. For a fixed , each zero bit in the mask is\r\nassigned its own penalty; in other words, we define , then:To\r\nefficiently recalculate, we will build a segment tree. Formally, it will\r\nbe defined as follows: The segment tree contains layers numbered . The\r\nindices of the vertices of the -th layer are subsets , and the two\r\nchildren of the vertex of the -th layer are the vertices and from the\r\n-th layer. The value at the vertex from the -th layer is equal to ,\r\nwhere: It is clear that the value can be easily computed as . This\r\nstructure is good because when changing , we only need to recalculate\r\nthe constructed tree up to the last layer where the weight function\r\nchanged.Now we will iterate over in the order of Gray codes\r\napproximately in the following order:The essence of this process is that\r\nwe will iterate through all possible sets , where the 2nd bit will\r\nchange times, the 3rd bit will change times, and so on, the -th bit will\r\nchange times, while the 1st bit will change only once. When changing the\r\n-th bit in , the function will change at points , , and , thus: If ,\r\nonly the first layers of the segment tree will change, and it will take\r\noperations to recalculate them, which will happen times. If or , the\r\nentire tree will need to be rebuilt, but this will only happen times.\r\nThe total number of affected vertices when iterating over will be:Here\r\nthe constant is not very good and the time constraints are strict, so we\r\nwill also have to put effort into the implementation. I think it is\r\nworth mentioning that using a segment tree on pointers is not a very\r\ngood idea, and one should write the segment tree in the same indexing as\r\na regular segment tree.\r\n",
    "name": "F. Lost Luggage",
    "statement": "As is known, the airline \"Trouble\" often loses luggage, and concerned\r\njournalists decided to calculate the maximum number of luggage pieces\r\nthat may not return to travelers.The airline \"Trouble\" operates flights\r\nbetween n airports, numbered from 1 to n. The journalists’ experiment\r\nwill last for m days. It is known that at midnight before the first day\r\nof the experiment, there were s_j lost pieces of luggage in the j-th\r\nairport. On the i-th day, the following occurs: , 2n flights take off\r\nsimultaneously, including n flights of the and n flights of the . The\r\nj-th flight of the first type flies from airport j to airport (((j-2)\r\nbmod n )+ 1) (the previous airport, with the first airport being the\r\nlast), and it can carry no more than a_{i,j} lost pieces of luggage. The\r\nj-th flight of the second type flies from airport j to airport ((j\r\nbmod n) + 1) (the next airport, with the last airport being the first),\r\nand it can carry no more than c_{i,j} lost pieces of luggage. , a check\r\nof lost luggage is conducted at the airports. If after the flights have\r\ndeparted on that day, there are x pieces of luggage remaining in the\r\nj-th airport and x\r\nge b_{i, j}, then at least x - b_{i, j} pieces of luggage are found, and\r\nthey . , all 2n flights conclude, and the lost luggage transported that\r\nday arrives at the corresponding airports. For each k from 1 to m, the\r\njournalists want to know the maximum number of lost pieces of luggage\r\nthat may be during the checks over the first k days. Note that for each\r\nk, these values are calculated independently.\r\n",
    "solutions": [],
    "input": "",
    "output": "",
    "tags": [
        "dp",
        "flows"
    ],
    "dificulty": "3500",
    "interactive": false,
    "file_name": "D:\\scoala\\RESEARCH\\MLCP\\01_CODEFORCES_DATASET\\DIV1\\F. Lost Luggage.json",
    "hint": []
}