{
    "link": "https://codeforces.com//contest/1383/problem/F",
    "problemId": "681332",
    "problem_idx": "F",
    "shortId": "1383F",
    "contest_number": "1383",
    "problem_submissions": {
        "F": [
            87911622,
            87901413,
            87908295,
            87909079,
            87912863,
            87912844,
            87913228,
            87920937
        ],
        "C": [
            87903412,
            87908609,
            87920945,
            87921225,
            87936073,
            87936017,
            87923661,
            87919633,
            87920208,
            87928476,
            88561363,
            87907584
        ],
        "D": [
            87893217,
            87920512,
            87917720,
            87900472,
            88564499,
            87905800,
            87942673,
            87934937,
            87934603,
            87934354,
            87926585,
            87907511,
            87916069,
            87908438,
            87914997,
            87918050,
            87919666,
            87904890,
            87912187,
            87897729,
            87922544,
            87918917
        ],
        "E": [
            87883167,
            87893057,
            87896267,
            87890928,
            88564562,
            87897262,
            87898365,
            87901088,
            87901845,
            87906849,
            87898532,
            87900480,
            87902921,
            87905469,
            87912176,
            87897358,
            87922285,
            87909673,
            87899729,
            87921664
        ],
        "B": [
            87873092,
            87873731,
            87878338,
            87871770,
            88564467,
            87883802,
            87879305,
            87891950,
            87885163,
            87888568,
            87878119,
            87882001,
            87878631,
            87875818,
            87883310,
            87903746,
            87887725,
            87881741,
            87892008,
            87886946
        ],
        "A": [
            87871300,
            87878540,
            87872599,
            87873455,
            88564441,
            87872862,
            87887205,
            87872116,
            87872818,
            87877345,
            87871429,
            87873700,
            87872797,
            87871844,
            87872683,
            87874942,
            87874295,
            87872122,
            87878303,
            87875696
        ]
    },
    "name": "F. Special Edges",
    "statement": "Koa the Koala has a graph G with n nodes and m edges. Each edge has a\r\ncapacity associated with it. Exactly k edges of the graph, numbered from\r\n1 to k, are special, such edges initially have a capacity equal to 0.Koa\r\nasks you q queries. In each query she gives you k integers w_1, w_2,\r\nldots, w_k. This means that capacity of the i-th special edge becomes\r\nw_i (and other capacities remain the same).Koa wonders: what is the\r\nmaximum flow that goes from node 1 to node n after each such query?Help\r\nher!\r\n",
    "solutions": [
        "/**\n *    author:  tourist\n *    created: 24.07.2020 18:51:48       \n**/\n#include <bits/stdc++.h>\n\nusing namespace std;\n\ntemplate <typename A, typename B>\nstring to_string(pair<A, B> p);\n\ntemplate <typename A, typename B, typename C>\nstring to_string(tuple<A, B, C> p);\n\ntemplate <typename A, typename B, typename C, typename D>\nstring to_string(tuple<A, B, C, D> p);\n\nstring to_string(const string& s) {\n  return '\"' + s + '\"';\n}\n\nstring to_string(const char* s) {\n  return to_string((string) s);\n}\n\nstring to_string(bool b) {\n  return (b ? \"true\" : \"false\");\n}\n\nstring to_string(vector<bool> v) {\n  bool first = true;\n  string res = \"{\";\n  for (int i = 0; i < static_cast<int>(v.size()); i++) {\n    if (!first) {\n      res += \", \";\n    }\n    first = false;\n    res += to_string(v[i]);\n  }\n  res += \"}\";\n  return res;\n}\n\ntemplate <size_t N>\nstring to_string(bitset<N> v) {\n  string res = \"\";\n  for (size_t i = 0; i < N; i++) {\n    res += static_cast<char>('0' + v[i]);\n  }\n  return res;\n}\n\ntemplate <typename A>\nstring to_string(A v) {\n  bool first = true;\n  string res = \"{\";\n  for (const auto &x : v) {\n    if (!first) {\n      res += \", \";\n    }\n    first = false;\n    res += to_string(x);\n  }\n  res += \"}\";\n  return res;\n}\n\ntemplate <typename A, typename B>\nstring to_string(pair<A, B> p) {\n  return \"(\" + to_string(p.first) + \", \" + to_string(p.second) + \")\";\n}\n\ntemplate <typename A, typename B, typename C>\nstring to_string(tuple<A, B, C> p) {\n  return \"(\" + to_string(get<0>(p)) + \", \" + to_string(get<1>(p)) + \", \" + to_string(get<2>(p)) + \")\";\n}\n\ntemplate <typename A, typename B, typename C, typename D>\nstring to_string(tuple<A, B, C, D> p) {\n  return \"(\" + to_string(get<0>(p)) + \", \" + to_string(get<1>(p)) + \", \" + to_string(get<2>(p)) + \", \" + to_string(get<3>(p)) + \")\";\n}\n\nvoid debug_out() { cerr << endl; }\n\ntemplate <typename Head, typename... Tail>\nvoid debug_out(Head H, Tail... T) {\n  cerr << \" \" << to_string(H);\n  debug_out(T...);\n}\n\n#ifdef LOCAL\n#define debug(...) cerr << \"[\" << #__VA_ARGS__ << \"]:\", debug_out(__VA_ARGS__)\n#else\n#define debug(...) 42\n#endif\n\ntemplate <typename T>\nclass flow_graph {\n public:\n  static constexpr T eps = (T) 1e-9;\n\n  struct edge {\n    int from;\n    int to;\n    T c;\n    T f;\n  };\n\n  vector<vector<int>> g;\n  vector<edge> edges;\n  int n;\n  int st;\n  int fin;\n  T flow;\n\n  flow_graph(int _n, int _st, int _fin) : n(_n), st(_st), fin(_fin) {\n    assert(0 <= st && st < n && 0 <= fin && fin < n && st != fin);\n    g.resize(n);\n    flow = 0;\n  }\n\n  void clear_flow() {\n    for (const edge &e : edges) {\n      e.f = 0;\n    }\n    flow = 0;\n  }\n   \n  int add(int from, int to, T forward_cap, T backward_cap) {\n    assert(0 <= from && from < n && 0 <= to && to < n);\n    int id = (int) edges.size();\n    g[from].push_back(id);\n    edges.push_back({from, to, forward_cap, 0});\n    g[to].push_back(id + 1);\n    edges.push_back({to, from, backward_cap, 0});\n    return id;\n  }\n};\n\ntemplate <typename T>\nclass dinic {\n public:\n  flow_graph<T> &g;\n\n  vector<int> ptr;\n  vector<int> d;\n  vector<int> q;\n\n  dinic(flow_graph<T> &_g) : g(_g) {\n    ptr.resize(g.n);\n    d.resize(g.n);\n    q.resize(g.n);\n  }\n\n  bool expath() {\n    fill(d.begin(), d.end(), -1);\n    q[0] = g.fin;\n    d[g.fin] = 0;\n    int beg = 0, end = 1;\n    while (beg < end) {\n      int i = q[beg++];\n      for (int id : g.g[i]) {\n        const auto &e = g.edges[id];\n        const auto &back = g.edges[id ^ 1];\n        if (back.c - back.f > g.eps && d[e.to] == -1) {\n          d[e.to] = d[i] + 1;\n          if (e.to == g.st) {\n            return true;\n          }\n          q[end++] = e.to;\n        }\n      }\n    }\n    return false;\n  }\n   \n  T dfs(int v, T w) {\n    if (v == g.fin) {\n      return w;\n    }\n    int &j = ptr[v];\n    while (j >= 0) {\n      int id = g.g[v][j];\n      const auto &e = g.edges[id];\n      if (e.c - e.f > g.eps && d[e.to] == d[v] - 1) {\n        T t = dfs(e.to, min(e.c - e.f, w));\n        if (t > g.eps) {\n          g.edges[id].f += t;\n          g.edges[id ^ 1].f -= t;\n          return t;\n        }\n      }\n      j--;\n    }\n    return 0;\n  }\n\n  T max_flow() {\n    while (expath()) {\n      for (int i = 0; i < g.n; i++) {\n        ptr[i] = (int) g.g[i].size() - 1;\n      }\n      T big_add = 0;\n      while (true) {\n        T add = dfs(g.st, numeric_limits<T>::max());\n        if (add <= g.eps) {\n          break;\n        }\n        big_add += add;\n      }\n      if (big_add <= g.eps) {\n        break;\n      }\n      g.flow += big_add;\n    }\n    return g.flow;\n  }\n\n  vector<bool> min_cut() {\n    max_flow();\n    vector<bool> ret(g.n);\n    for (int i = 0; i < g.n; i++) {\n      ret[i] = (d[i] != -1);\n    }\n    return ret;\n  }\n};\n\nconst int MAXC = 25;\n\nint main() {\n  ios::sync_with_stdio(false);\n  cin.tie(0);\n  int n, m, k, q;\n  cin >> n >> m >> k >> q;\n  flow_graph<int> g(n, 0, n - 1);\n  for (int i = 0; i < m; i++) {\n    int x, y, z;\n    cin >> x >> y >> z;\n    --x; --y;\n    g.add(x, y, z, 0);\n  }\n  dinic<int> d(g);\n  vector<vector<int>> backup(1 << k, vector<int>(2 * m));\n  vector<int> backup_flow(1 << k);\n  vector<int> without(1 << k, 0);\n  without.back() = d.max_flow();\n  for (int i = 0; i < 2 * m; i++) {\n    backup.back()[i] = g.edges[i].f;\n  }\n  backup_flow.back() = g.flow;\n  for (int t = (1 << k) - 2; t >= 0; t--) {\n//    debug(t);\n    for (int id = 0; id < k; id++) {\n      if (!(t & (1 << id))) {\n//        debug(id);\n        for (int i = 0; i < 2 * m; i++) {\n          g.edges[i].f = backup[t | (1 << id)][i];\n        }\n        for (int i = 0; i < k; i++) {\n          g.edges[2 * i].c = ((t & (1 << i)) ? 0 : MAXC);\n        }\n        g.flow = backup_flow[t | (1 << id)];\n//        for (int i = 0; i < 2 * m; i++) debug(g.edges[i].from, g.edges[i].to, g.edges[i].c, g.edges[i].f);\n        without[t] = d.max_flow();\n//        debug(t, without[t]);\n        for (int i = 0; i < 2 * m; i++) {\n          backup[t][i] = g.edges[i].f;\n        }\n        backup_flow[t] = g.flow;\n        break;\n      }\n    }\n  }\n//  debug(without);\n  vector<int> cap(k);\n  vector<int> sum(1 << k);\n  while (q--) {\n    for (int i = 0; i < k; i++) {\n      cin >> cap[i];\n    }\n    sum[0] = 0;\n    for (int t = 1; t < (1 << k); t++) {\n      int bit = __builtin_ctz(t);\n      sum[t] = sum[t ^ (1 << bit)] + cap[bit];\n    }\n    int ans = 787788789;\n    for (int t = 0; t < (1 << k); t++) {\n      ans = min(ans, sum[t] + without[t]);\n    }\n    cout << ans << '\\n';\n  }\n  return 0;\n}\n"
    ],
    "input": "",
    "output": "",
    "tags": [
        "flows",
        "graphs"
    ],
    "dificulty": "3200",
    "interactive": false,
    "file_name": "D:\\scoala\\RESEARCH\\MLCP\\01_CODEFORCES_DATASET\\DIV1\\F. Special Edges.json",
    "editorial_link": "https://codeforces.com//blog/entry/80562",
    "editorial": "Finding maximum flow from to is equivalent to find the minimum cut from\r\nto . Letâs use the later interpretation to solve the problem.Suppose\r\nthere is a single special edge (), on each query there are two options,\r\neither this edge belong to the minimum cut or it doesnât. If the edge\r\ndoesnât belong to the minimum cut, the value of the cut wonât change\r\neven if we increase the capacity of each edge arbitrarily (letâs say to\r\n). On the other hand, if the edge belong to the cut, then the value of\r\nthe cut will be equal to the capacity of the edge + the value of the cut\r\nif the capacity of the edge was . With this in mind we can compute each\r\nquery in O(1).Let be the value of the minimum cut if the capacity of the\r\nspecial edge is 0, and be the value of the minimum cut if the capacity\r\nof the special edge is . Then for each query the minimum cut will be\r\nequal to .We can generalize this ideas to multiple edges in the\r\nfollowing way. For each subset of special edges, they either belong to\r\nthe minimum cut, or they donât. If we fix a subset and say those are\r\namong the special edges the only ones that belong to the minimum cut,\r\nthen the value of the cut will be equal to the sum of the values of the\r\ncapacities of these edges plus the minimum cut in the graph were each of\r\nthese edges has capacity 0 and other special edges has capacity . In a\r\nsimilar way as we did for the case of we can pre-compute cuts, fixing as\r\neach possible set in , and then answer each query in . The overall\r\ncomplexity of this solution will be . However the preprocessing can be\r\ndone faster. If we have the maximum flow (and the residual network) for\r\na mask, we can compute the maximum flow adding one new edge in , doing\r\nat most steps of augmentation as done by Ford-Fulkerson algorithm. To\r\nremove an edge we just store the residual network before augmenting, in\r\nsuch a way that we can undo the last change. The time complexity of the\r\npreprocessing will be and since we need to be able to undo the last\r\noperation spatial complexity will be .It was possible to solve the\r\nproblem without the last trick, but it was not guaranteed that slow\r\nflows implementations would work in .\r\n",
    "hint": []
}