{
    "link": "https://codeforces.com//contest/1876/problem/G",
    "problemId": "2251951",
    "problem_idx": "G",
    "shortId": "1876G",
    "contest_number": "1876",
    "problem_submissions": {
        "F": [
            227177806,
            227207094,
            227205539,
            227205151
        ],
        "E": [
            227157151,
            227151734,
            227168660,
            227172380,
            227183052,
            227309041,
            227308704,
            227174767,
            227180790,
            227181408,
            227180728,
            227180621,
            227182335,
            227260713,
            227259829,
            227186766,
            227170474,
            227321208,
            227261014
        ],
        "D": [
            227143743,
            227138577,
            227308847,
            227146942,
            227140586,
            227141511,
            227160448,
            227153072,
            227151615,
            227160275,
            227166901,
            227141697,
            227262091,
            227163246,
            227151371,
            227141424,
            227141434,
            227152662,
            227155489,
            227148839,
            227151040,
            227154461
        ],
        "C": [
            227128643,
            227130062,
            227133604,
            227130971,
            227129714,
            227144982,
            227139072,
            227133756,
            227145578,
            227141605,
            227156976,
            227263099,
            227135346,
            227132471,
            227128506,
            227133146,
            227135885,
            227135604,
            227140440,
            227137265
        ],
        "B": [
            227120010,
            227119885,
            227123059,
            227119488,
            227120157,
            227125041,
            227123945,
            227122604,
            227124586,
            227123169,
            227160403,
            227263121,
            227124143,
            227123043,
            227120364,
            227120185,
            227120687,
            227125676,
            227123006,
            227129980,
            227122132
        ],
        "A": [
            227117267,
            227116977,
            227118151,
            227116487,
            227116831,
            227118490,
            227120408,
            227118388,
            227121296,
            227117209,
            227162962,
            227263136,
            227118862,
            227118193,
            227117199,
            227115769,
            227117422,
            227121537,
            227118512,
            227124495,
            227116510
        ],
        "G": [
            227270487,
            229852864,
            229527555
        ]
    },
    "name": "G. Clubstep",
    "statement": "There is an extremely hard video game that is one of Chaneka\u2019s favourite\r\nvideo games. One of the hardest levels in the game is called Clubstep.\r\nClubstep consists of n parts, numbered from 1 to n. Chaneka has\r\npractised the level a good amount, so currently, her familiarity value\r\nwith each part i is a_i.After this, Chaneka can do several (possibly\r\nzero) attempts on Clubstep. In each attempt, she dies on one of the n\r\nparts. If an attempt dies on part p, that means it only successfully\r\npasses through every part k for all 1\r\nleq k\r\nleq p-1 and it does not reach any part k for all p+1\r\nleq k\r\nleq n. An attempt that dies on part p takes p seconds.It is known that\r\nChaneka improves much more on the part she dies on than anything else.\r\nIt is also known that during an attempt, Chaneka does not get to\r\npractise that much on the parts she does not reach. So, the effect of an\r\nattempt that dies on part p is as follows: Chaneka\u2019s familiarity value\r\nwith part p increases by 2. Chaneka\u2019s familiarity value with each part k\r\nfor all 1\r\nleq k\r\nleq p-1 increases by 1. There will be q questions. For the j-th\r\nquestion, you are given three integers l_j, r_j, and x_j. Then, you are\r\nasked to find out the (in seconds) for Chaneka to make it such that the\r\nfamiliarity value for every part p (l_j\r\nleq p\r\nleq r_j) is at least x_j.Note that each question is independent, so the\r\nattempt Chaneka does on a question does not affect the familiarity\r\nvalues of any other questions.\r\n",
    "solutions": [
        "#include <bits/stdc++.h>\n\nusing i64 = long long;\n\nint main() {\n    std::ios::sync_with_stdio(false);\n    std::cin.tie(nullptr);\n    \n    int n;\n    std::cin >> n;\n    \n    std::vector<int> a(n);\n    for (int i = 0; i < n; i++) {\n        std::cin >> a[i];\n    }\n    \n    int q;\n    std::cin >> q;\n    \n    std::vector<int> f(2 * q);\n    std::vector<i64> val(2 * q);\n    int tot = q;\n    std::iota(f.begin(), f.end(), 0);\n    \n    std::vector<i64> ans(q);\n    std::vector<std::vector<std::pair<int, int>>> add(n);\n    std::vector<std::vector<int>> del(n);\n    for (int i = 0; i < q; i++) {\n        int l, r, x;\n        std::cin >> l >> r >> x;\n        l--, r--;\n        add[r].emplace_back(x, i);\n        del[l].push_back(i);\n    }\n    \n    auto find = [&](auto self, int x) -> int {\n        if (f[x] == f[f[x]]) {\n            return f[x];\n        }\n        auto y = self(self, f[x]);\n        val[x] += val[f[x]];\n        f[x] = y;\n        return f[x];\n    };\n    \n    auto get = [&](i64 x) {\n        find(find, x);\n        i64 ans = val[x];\n        if (x != f[x]) {\n            ans += val[f[x]];\n        }\n        return ans;\n    };\n    \n    auto merge = [&](int &x, int y) {\n        int z = tot++;\n        f[x] = z;\n        f[y] = z;\n        x = z;\n    };\n    \n    std::map<int, int> mp;\n    for (int i = n - 1; i >= 0; i--) {\n        for (auto [x, j] : add[i]) {\n            if (mp.contains(x)) {\n                merge(mp[x], j);\n            } else {\n                mp[x] = j;\n            }\n        }\n        for (auto it = mp.upper_bound(a[i]); it != mp.end(); it = mp.erase(it)) {\n            auto [x, j] = *it;\n            int y = (x + a[i]) / 2;\n            val[j] += 1LL * (i + 1) * (x - y);\n            if (mp.contains(y)) {\n                merge(mp[y], j);\n            } else {\n                mp[y] = j;\n            }\n        }\n        for (auto j : del[i]) {\n            ans[j] = get(j);\n        }\n    }\n    \n    for (int i = 0; i < q; i++) {\n        std::cout << ans[i] << \"\\n\";\n    }\n    \n    return 0;\n}\n"
    ],
    "input": "",
    "output": "",
    "tags": [
        "binary search",
        "brute force",
        "data structures",
        "greedy",
        "trees"
    ],
    "dificulty": "3500",
    "interactive": false,
    "file_name": "D:\\scoala\\RESEARCH\\MLCP\\01_CODEFORCES_DATASET\\DIV1\\G. Clubstep.json",
    "editorial_link": "https://codeforces.com//blog/entry/121200",
    "editorial": "Let\u00e2\u0080\u0099s try to solve a single query in . It is clear that in the optimal\r\nstrategy, we do not want to do any attempts that die on parts to the\r\nleft of or to the right of . There are two cases: If , then we can\r\nignore index and solve the query for . If , then it is optimal to do\r\nattempts that die on part . This takes seconds and will make all indices\r\nfrom to increase by . After doing that, it is equivalent to ignoring\r\nindex and solving the query for . For now, let\u00e2\u0080\u0099s ignore and focus on .\r\nFor some pair , there are two cases it can recurse into. We mainly care\r\nabout the second case since it is the only one that contributes to the\r\ntotal time. For some pair of a query, we can turn it into where () is\r\nthe rightmost index with . For some pair with , we can see it as the\r\npair recursing immediately to where () is the rightmost index with .We\r\nwant to maintain all important pairs that are needed to answer all\r\nqueries. Two pairs with the same values of and that comes from different\r\nqueries can be treated as the same pair.Let\u00e2\u0080\u0099s imagine a process to\r\ncalculate all important pairs . To do this, we iterate from to while\r\nmaintaining all of the current important values of , including the ones\r\nnot bigger than . Each iteration, we just modify the values of from the\r\nprevious iteration. For each , we first add new values of for all\r\nqueries with this current value of . Then, the important pairs for this\r\nvalue of are all current values of that are greater than . And those\r\nvalues of are the values of which will get updated (changed into ) for\r\nthe next iteration. If more than one value of updates into the same\r\nvalue, they merge and the number of values decreases.Using the logic of\r\nthe process above, it can be obtained that the total number of important\r\npairs is ..Notice that the number of important pairs is about equal to\r\nthe number of updates to the value of in all iterations. Let\u00e2\u0080\u0099s calculate\r\nthe total number of updates.Instead of looking at the values of that we\r\nmaintain, let\u00e2\u0080\u0099s sort those values and look at the gaps between adjacent\r\nvalues. For a value of , the value of lies in one of the gaps. Then,\r\nthat gap and all gaps located to the right of it in the number line will\r\nget updated. The gap that contains can change arbitrarily, but each gap\r\nthat is to the right of that gap will have its length divided by ,\r\neither floored or ceilinged.This means, each gap can only have updates\r\nbefore having a length of . Then, its length can get ceilinged multiple\r\ntimes before getting floored to . When its length becomes , the two\r\nvalues at the endpoints of the gap will merge.It may look like there can\r\nbe many updates because a length of can be ceilinged multiple times.\r\nHowever, for every gap having its length divided by in an iteration, the\r\ncase where a length of gets ceilinged cannot happen on two adjacent\r\ngaps, so if there are gaps updated, that particular case can only happen\r\non gaps. That means, the total number of updates is about two times the\r\ntotal number of times a gap gets its length decreased, plus the total\r\nnumber of gaps that contains .Therefore, the total number of important\r\npairs is . Knowing that, we can calculate all important pairs quickly\r\nusing a stack and a priority queue. The stack maintains the current\r\nvalues of that have already been updated at least once. The priority\r\nqueue only maintains new values of that have not been updated yet. In\r\neach iteration, we only process several values at the top of the stack\r\nand at the top of the priority queue, then each of those gets pushed\r\ninto the stack with their new values, without changes in their order.\r\nThe total number of operations in the stack is equal to the number of\r\nimportant pairs, but the total number of changes in the priority queue\r\nis only equal to the number of queries. So the total complexity of this\r\nis .While calculating all important pairs, we can simultaneously\r\nconstruct a tree of pairs where the parent of each pair is its\r\ncorresponding pair .We can solve each query using a simple binary\r\nlifting in the tree, but that would be too slow since there are\r\nvertices. Instead, we can do a DFS traversal from the root while\r\nmaintaining a stack of the values of in the DFS recursion. Solving a\r\nquery in a vertex is just doing a binary search in the stack. So the\r\ntotal complexity of answering all queries is .Time complexity:\r\n"
}