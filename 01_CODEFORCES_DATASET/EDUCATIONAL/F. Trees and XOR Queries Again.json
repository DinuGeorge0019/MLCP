{
    "link": "https://codeforces.com//contest/1902/problem/F",
    "problemId": "2362203",
    "problem_idx": "F",
    "shortId": "1902F",
    "contest_number": "1902",
    "problem_submissions": {
        "B": [
            235588094,
            235541813,
            235538695,
            235540200,
            235541986,
            235546581,
            235539624,
            235542221,
            235543196,
            235570763,
            235543003,
            235539161,
            235543236,
            235569611,
            235570026,
            235542153,
            235655407,
            235543168,
            235545066,
            235549273,
            235544565,
            235544393
        ],
        "D": [
            235587336,
            235552561,
            235553295,
            235563680,
            235553330,
            235555395,
            235568492,
            235559700,
            235568658,
            235567617,
            235560146,
            235561416,
            235554309,
            235551620,
            235562986,
            235561764,
            235586816,
            235566705,
            235566898,
            235564749,
            235564461
        ],
        "E": [
            235583583,
            235582606,
            235582050,
            235581289,
            235558586,
            235559098,
            235551541,
            235558190,
            235559848,
            235566108,
            235566192,
            235566094,
            235564789,
            235564113,
            235549751,
            235553064,
            235566369,
            235568437,
            235561807,
            235546129,
            235601857,
            235573551,
            235578412,
            235572635,
            235576054,
            235577219,
            235558759
        ],
        "F": [
            235562465,
            235568838,
            236129130,
            236129102,
            235556472,
            235565709,
            235569182,
            235561417,
            235572126,
            235555263,
            235543234,
            235574528,
            235579496,
            235582447,
            235591540,
            235554289,
            235597722,
            235587185,
            235557652,
            235580838,
            235744278,
            235581308,
            235591762,
            235592390
        ],
        "C": [
            235547363,
            235542973,
            235546654,
            235544681,
            235542274,
            235544554,
            235550388,
            235549932,
            235558653,
            235546403,
            235544913,
            235545913,
            235542697,
            235566604,
            235546411,
            235656040,
            235549867,
            235560184,
            235557908,
            235596779,
            235549641,
            235614612,
            235549186
        ],
        "A": [
            235534144,
            235534113,
            235534651,
            235534058,
            235534240,
            235534127,
            235534119,
            235534985,
            235553076,
            235538076,
            235534100,
            235534474,
            235534171,
            235570865,
            235534497,
            235654959,
            235535402,
            235534132,
            235535287,
            235538251,
            235534330
        ]
    },
    "name": "F. Trees and XOR Queries Again",
    "statement": "You are given a tree consisting of n vertices. There is an integer\r\nwritten on each vertex; the i-th vertex has integer a_i written on\r\nit.You have to process q queries. The i-th query consists of three\r\nintegers x_i, y_i and k_i. For this query, you have to answer if it is\r\npossible to choose a set of vertices v_1, v_2,\r\ndots, v_m (possibly empty) such that: every vertex v_j is on the simple\r\npath between x_i and y_i (endpoints can be used as well); a_{v_1}\r\noplus a_{v_2}\r\noplus\r\ndots\r\noplus a_{v_m} = k_i, where\r\noplus denotes the bitwise XOR operator.\r\n",
    "solutions": [
        "#include <algorithm>\n#include <array>\n#include <bitset>\n#include <cassert>\n#include <chrono>\n#include <cmath>\n#include <complex>\n#include <deque>\n#include <forward_list>\n#include <fstream>\n#include <functional>\n#include <iomanip>\n#include <ios>\n#include <iostream>\n#include <limits>\n#include <list>\n#include <map>\n#include <memory>\n#include <numeric>\n#include <optional>\n#include <queue>\n#include <random>\n#include <set>\n#include <sstream>\n#include <stack>\n#include <string>\n#include <tuple>\n#include <type_traits>\n#include <unordered_map>\n#include <unordered_set>\n#include <utility>\n#include <vector>\nusing namespace std;\nusing lint = long long;\nusing pint = pair<int, int>;\nusing plint = pair<lint, lint>;\nstruct fast_ios { fast_ios(){ cin.tie(nullptr), ios::sync_with_stdio(false), cout << fixed << setprecision(20); }; } fast_ios_;\n#define ALL(x) (x).begin(), (x).end()\n#define FOR(i, begin, end) for(int i=(begin),i##_end_=(end);i<i##_end_;i++)\n#define IFOR(i, begin, end) for(int i=(end)-1,i##_begin_=(begin);i>=i##_begin_;i--)\n#define REP(i, n) FOR(i,0,n)\n#define IREP(i, n) IFOR(i,0,n)\ntemplate <typename T> bool chmax(T &m, const T q) { return m < q ? (m = q, true) : false; }\ntemplate <typename T> bool chmin(T &m, const T q) { return m > q ? (m = q, true) : false; }\nconst std::vector<std::pair<int, int>> grid_dxs{{1, 0}, {-1, 0}, {0, 1}, {0, -1}};\nint floor_lg(long long x) { return x <= 0 ? -1 : 63 - __builtin_clzll(x); }\ntemplate <class T1, class T2> T1 floor_div(T1 num, T2 den) { return (num > 0 ? num / den : -((-num + den - 1) / den)); }\ntemplate <class T1, class T2> std::pair<T1, T2> operator+(const std::pair<T1, T2> &l, const std::pair<T1, T2> &r) { return std::make_pair(l.first + r.first, l.second + r.second); }\ntemplate <class T1, class T2> std::pair<T1, T2> operator-(const std::pair<T1, T2> &l, const std::pair<T1, T2> &r) { return std::make_pair(l.first - r.first, l.second - r.second); }\ntemplate <class T> std::vector<T> sort_unique(std::vector<T> vec) { sort(vec.begin(), vec.end()), vec.erase(unique(vec.begin(), vec.end()), vec.end()); return vec; }\ntemplate <class T> int arglb(const std::vector<T> &v, const T &x) { return std::distance(v.begin(), std::lower_bound(v.begin(), v.end(), x)); }\ntemplate <class T> int argub(const std::vector<T> &v, const T &x) { return std::distance(v.begin(), std::upper_bound(v.begin(), v.end(), x)); }\ntemplate <class IStream, class T> IStream &operator>>(IStream &is, std::vector<T> &vec) { for (auto &v : vec) is >> v; return is; }\n\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::vector<T> &vec);\ntemplate <class OStream, class T, size_t sz> OStream &operator<<(OStream &os, const std::array<T, sz> &arr);\ntemplate <class OStream, class T, class TH> OStream &operator<<(OStream &os, const std::unordered_set<T, TH> &vec);\ntemplate <class OStream, class T, class U> OStream &operator<<(OStream &os, const pair<T, U> &pa);\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::deque<T> &vec);\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::set<T> &vec);\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::multiset<T> &vec);\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::unordered_multiset<T> &vec);\ntemplate <class OStream, class T, class U> OStream &operator<<(OStream &os, const std::pair<T, U> &pa);\ntemplate <class OStream, class TK, class TV> OStream &operator<<(OStream &os, const std::map<TK, TV> &mp);\ntemplate <class OStream, class TK, class TV, class TH> OStream &operator<<(OStream &os, const std::unordered_map<TK, TV, TH> &mp);\ntemplate <class OStream, class... T> OStream &operator<<(OStream &os, const std::tuple<T...> &tpl);\n\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::vector<T> &vec) { os << '['; for (auto v : vec) os << v << ','; os << ']'; return os; }\ntemplate <class OStream, class T, size_t sz> OStream &operator<<(OStream &os, const std::array<T, sz> &arr) { os << '['; for (auto v : arr) os << v << ','; os << ']'; return os; }\ntemplate <class... T> std::istream &operator>>(std::istream &is, std::tuple<T...> &tpl) { std::apply([&is](auto &&... args) { ((is >> args), ...);}, tpl); return is; }\ntemplate <class OStream, class... T> OStream &operator<<(OStream &os, const std::tuple<T...> &tpl) { os << '('; std::apply([&os](auto &&... args) { ((os << args << ','), ...);}, tpl); return os << ')'; }\ntemplate <class OStream, class T, class TH> OStream &operator<<(OStream &os, const std::unordered_set<T, TH> &vec) { os << '{'; for (auto v : vec) os << v << ','; os << '}'; return os; }\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::deque<T> &vec) { os << \"deq[\"; for (auto v : vec) os << v << ','; os << ']'; return os; }\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::set<T> &vec) { os << '{'; for (auto v : vec) os << v << ','; os << '}'; return os; }\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::multiset<T> &vec) { os << '{'; for (auto v : vec) os << v << ','; os << '}'; return os; }\ntemplate <class OStream, class T> OStream &operator<<(OStream &os, const std::unordered_multiset<T> &vec) { os << '{'; for (auto v : vec) os << v << ','; os << '}'; return os; }\ntemplate <class OStream, class T, class U> OStream &operator<<(OStream &os, const std::pair<T, U> &pa) { return os << '(' << pa.first << ',' << pa.second << ')'; }\ntemplate <class OStream, class TK, class TV> OStream &operator<<(OStream &os, const std::map<TK, TV> &mp) { os << '{'; for (auto v : mp) os << v.first << \"=>\" << v.second << ','; os << '}'; return os; }\ntemplate <class OStream, class TK, class TV, class TH> OStream &operator<<(OStream &os, const std::unordered_map<TK, TV, TH> &mp) { os << '{'; for (auto v : mp) os << v.first << \"=>\" << v.second << ','; os << '}'; return os; }\n#ifdef HITONANODE_LOCAL\nconst string COLOR_RESET = \"\\033[0m\", BRIGHT_GREEN = \"\\033[1;32m\", BRIGHT_RED = \"\\033[1;31m\", BRIGHT_CYAN = \"\\033[1;36m\", NORMAL_CROSSED = \"\\033[0;9;37m\", RED_BACKGROUND = \"\\033[1;41m\", NORMAL_FAINT = \"\\033[0;2m\";\n#define dbg(x) std::cerr << BRIGHT_CYAN << #x << COLOR_RESET << \" = \" << (x) << NORMAL_FAINT << \" (L\" << __LINE__ << \") \" << __FILE__ << COLOR_RESET << std::endl\n#define dbgif(cond, x) ((cond) ? std::cerr << BRIGHT_CYAN << #x << COLOR_RESET << \" = \" << (x) << NORMAL_FAINT << \" (L\" << __LINE__ << \") \" << __FILE__ << COLOR_RESET << std::endl : std::cerr)\n#else\n#define dbg(x) ((void)0)\n#define dbgif(cond, x) ((void)0)\n#endif\n\n#include <algorithm>\n#include <cassert>\n#include <functional>\n#include <queue>\n#include <stack>\n#include <utility>\n#include <vector>\n\n// Heavy-Light Decomposition of trees\n// Based on http://beet-aizu.hatenablog.com/entry/2017/12/12/235950\nstruct HeavyLightDecomposition {\n    int V;\n    int k;\n    int nb_heavy_path;\n    std::vector<std::vector<int>> e;\n    std::vector<int> par;         // par[i] = parent of vertex i (Default: -1)\n    std::vector<int> depth;       // depth[i] = distance between root and vertex i\n    std::vector<int> subtree_sz;  // subtree_sz[i] = size of subtree whose root is i\n    std::vector<int> heavy_child; // heavy_child[i] = child of vertex i on heavy path (Default: -1)\n    std::vector<int> tree_id;     // tree_id[i] = id of tree vertex i belongs to\n    std::vector<int> aligned_id,\n        aligned_id_inv;    // aligned_id[i] =  aligned id for vertex i (consecutive on heavy edges)\n    std::vector<int> head; // head[i] = id of vertex on heavy path of vertex i, nearest to root\n    std::vector<int> head_ids;      // consist of head vertex id's\n    std::vector<int> heavy_path_id; // heavy_path_id[i] = heavy_path_id for vertex [i]\n\n    HeavyLightDecomposition(int sz = 0)\n        : V(sz), k(0), nb_heavy_path(0), e(sz), par(sz), depth(sz), subtree_sz(sz), heavy_child(sz),\n          tree_id(sz, -1), aligned_id(sz), aligned_id_inv(sz), head(sz), heavy_path_id(sz, -1) {}\n    void add_edge(int u, int v) {\n        e[u].emplace_back(v);\n        e[v].emplace_back(u);\n    }\n\n    void _build_dfs(int root) {\n        std::stack<std::pair<int, int>> st;\n        par[root] = -1;\n        depth[root] = 0;\n        st.emplace(root, 0);\n        while (!st.empty()) {\n            int now = st.top().first;\n            int &i = st.top().second;\n            if (i < (int)e[now].size()) {\n                int nxt = e[now][i++];\n                if (nxt == par[now]) continue;\n                par[nxt] = now;\n                depth[nxt] = depth[now] + 1;\n                st.emplace(nxt, 0);\n            } else {\n                st.pop();\n                int max_sub_sz = 0;\n                subtree_sz[now] = 1;\n                heavy_child[now] = -1;\n                for (auto nxt : e[now]) {\n                    if (nxt == par[now]) continue;\n                    subtree_sz[now] += subtree_sz[nxt];\n                    if (max_sub_sz < subtree_sz[nxt])\n                        max_sub_sz = subtree_sz[nxt], heavy_child[now] = nxt;\n                }\n            }\n        }\n    }\n\n    void _build_bfs(int root, int tree_id_now) {\n        std::queue<int> q({root});\n        while (!q.empty()) {\n            int h = q.front();\n            q.pop();\n            head_ids.emplace_back(h);\n            for (int now = h; now != -1; now = heavy_child[now]) {\n                tree_id[now] = tree_id_now;\n                aligned_id[now] = k++;\n                aligned_id_inv[aligned_id[now]] = now;\n                heavy_path_id[now] = nb_heavy_path;\n                head[now] = h;\n                for (int nxt : e[now])\n                    if (nxt != par[now] and nxt != heavy_child[now]) q.push(nxt);\n            }\n            nb_heavy_path++;\n        }\n    }\n\n    void build(std::vector<int> roots = {0}) {\n        int tree_id_now = 0;\n        for (auto r : roots) _build_dfs(r), _build_bfs(r, tree_id_now++);\n    }\n\n    template <class T> std::vector<T> segtree_rearrange(const std::vector<T> &data) const {\n        assert(int(data.size()) == V);\n        std::vector<T> ret;\n        ret.reserve(V);\n        for (int i = 0; i < V; i++) ret.emplace_back(data[aligned_id_inv[i]]);\n        return ret;\n    }\n\n    // query for vertices on path [u, v] (INCLUSIVE)\n    void\n    for_each_vertex(int u, int v, const std::function<void(int ancestor, int descendant)> &f) const {\n        while (true) {\n            if (aligned_id[u] > aligned_id[v]) std::swap(u, v);\n            f(std::max(aligned_id[head[v]], aligned_id[u]), aligned_id[v]);\n            if (head[u] == head[v]) break;\n            v = par[head[v]];\n        }\n    }\n\n    void for_each_vertex_noncommutative(\n        int from, int to, const std::function<void(int ancestor, int descendant)> &fup,\n        const std::function<void(int ancestor, int descendant)> &fdown) const {\n        int u = from, v = to;\n        const int lca = lowest_common_ancestor(u, v), dlca = depth[lca];\n        while (u >= 0 and depth[u] > dlca) {\n            const int p = (depth[head[u]] > dlca ? head[u] : lca);\n            fup(aligned_id[p] + (p == lca), aligned_id[u]), u = par[p];\n        }\n        static std::vector<std::pair<int, int>> lrs;\n        int sz = 0;\n        while (v >= 0 and depth[v] >= dlca) {\n            const int p = (depth[head[v]] >= dlca ? head[v] : lca);\n            if (int(lrs.size()) == sz) lrs.emplace_back(0, 0);\n            lrs.at(sz++) = {p, v}, v = par.at(p);\n        }\n        while (sz--) fdown(aligned_id[lrs.at(sz).first], aligned_id[lrs.at(sz).second]);\n    }\n\n    // query for edges on path [u, v]\n    void for_each_edge(int u, int v, const std::function<void(int, int)> &f) const {\n        while (true) {\n            if (aligned_id[u] > aligned_id[v]) std::swap(u, v);\n            if (head[u] != head[v]) {\n                f(aligned_id[head[v]], aligned_id[v]);\n                v = par[head[v]];\n            } else {\n                if (u != v) f(aligned_id[u] + 1, aligned_id[v]);\n                break;\n            }\n        }\n    }\n\n    // lowest_common_ancestor: O(log V)\n    int lowest_common_ancestor(int u, int v) const {\n        assert(tree_id[u] == tree_id[v] and tree_id[u] >= 0);\n        while (true) {\n            if (aligned_id[u] > aligned_id[v]) std::swap(u, v);\n            if (head[u] == head[v]) return u;\n            v = par[head[v]];\n        }\n    }\n\n    int distance(int u, int v) const {\n        assert(tree_id[u] == tree_id[v] and tree_id[u] >= 0);\n        return depth[u] + depth[v] - 2 * depth[lowest_common_ancestor(u, v)];\n    }\n\n    // Level ancestor, O(log V)\n    // if k-th parent is out of range, return -1\n    int kth_parent(int v, int k) const {\n        if (k < 0) return -1;\n        while (v >= 0) {\n            int h = head.at(v), len = depth.at(v) - depth.at(h);\n            if (k <= len) return aligned_id_inv.at(aligned_id.at(v) - k);\n            k -= len + 1, v = par.at(h);\n        }\n        return -1;\n    }\n\n    // Jump on tree, O(log V)\n    int s_to_t_by_k_steps(int s, int t, int k) const {\n        if (k < 0) return -1;\n        if (k == 0) return s;\n        int lca = lowest_common_ancestor(s, t);\n        if (k <= depth.at(s) - depth.at(lca)) return kth_parent(s, k);\n        return kth_parent(t, depth.at(s) + depth.at(t) - depth.at(lca) * 2 - k);\n    }\n};\n\n// Static sequence sparse table\n// Complexity: O(NlogN) for precalculation, O(1) per query\ntemplate <class S, S (*op)(S, S), S (*e)()> struct sparse_table {\n    int N, lgN;\n    std::vector<std::vector<S>> d;\n    std::vector<int> lgx_table;\n    sparse_table() {}\n    sparse_table(const std::vector<S> &sequence) : N(sequence.size()) {\n        lgx_table.resize(N + 1);\n        for (int i = 2; i < N + 1; ++i) lgx_table[i] = lgx_table[i >> 1] + 1;\n        lgN = lgx_table[N] + 1;\n        d.assign(lgN, std::vector<S>(N, e()));\n        d[0] = sequence;\n        for (int h = 1; h < lgN; ++h) {\n            for (int i = 0; i + (1 << h) <= N; ++i) {\n                d[h][i] = op(d[h - 1][i], d[h - 1][i + (1 << (h - 1))]);\n            }\n        }\n    }\n    S prod(int l, int r) const { // [l, r), 0-indexed\n        assert(l >= 0 and r <= N);\n        if (l >= r) return e();\n        int h = lgx_table[r - l];\n        return op(d[h][l], d[h][r - (1 << h)]);\n    }\n};\n\nconstexpr int D = 20;\n\nusing S = vector<int>;\n\nS op(S l, S r) {\n    for (int x : r) {\n        if ((int)l.size() == D) break;\n        for (int y : l) chmin(x, y ^ x);\n        if (x) l.push_back(x);\n    }\n    return l;\n}\n\nS e() { return {}; }\n\nint main() {\n\n    int N;\n    cin >> N;\n    vector<int> A(N);\n    cin >> A;\n\n    HeavyLightDecomposition hld(N);\n\n    REP(e, N - 1) {\n        int u, v;\n        cin >> u >> v;\n        --u, --v;\n        hld.add_edge(u, v);\n    }\n\n    hld.build();\n\n    vector<S> init;\n    for (int x : A) init.push_back(vector<int>{x});\n    dbg(init);\n    init = hld.segtree_rearrange(init);\n    sparse_table<S, op, e> st(init);\n\n    int Q;\n    cin >> Q;\n    while (Q--) {\n        int x, y, k;\n        cin >> x >> y >> k;\n        --x, --y;\n\n        S base;\n        hld.for_each_vertex(x, y, [&](int l, int r) { base = op(base, st.prod(l, r + 1)); });\n\n        for (int b : base) chmin(k, k ^ b);\n        cout << (k ? \"NO\" : \"YES\") << '\\n';\n    }\n}\n"
    ],
    "input": "",
    "output": "",
    "tags": [
        "data structures",
        "dfs and similar",
        "divide and conquer",
        "graphs",
        "implementation",
        "math",
        "trees"
    ],
    "dificulty": "2400",
    "interactive": false,
    "file_name": "D:\\scoala\\RESEARCH\\MLCP\\01_CODEFORCES_DATASET\\EDUCATIONAL\\F. Trees and XOR Queries Again.json",
    "editorial_link": "https://codeforces.com//blog/entry/122951",
    "editorial": "This problem requires working with XOR bases, so letâs have a primer on\r\nthem.Suppose you want to solve the following problem: given a set of\r\nintegers and another integer , check whether it is possible to choose\r\nseveral (maybe zero) integers from the set such that their XOR is . It\r\ncan be solved with Gauss elimination method for systems of linear\r\nequations, but there are easier and faster methods, and we will describe\r\none of them.For the given set of integers, letâs build an XOR base. An\r\nXOR base of a set of integers is another set of integers such that:\r\nevery integer that can be expressed as the XOR of some integers from the\r\nset can also be expressed as the XOR of some integers from , and vice\r\nversa; every integer in is non-redundant (i. e. if you remove any\r\ninteger from , the first property is no longer met). For example, one of\r\nthe XOR bases for is . is also an XOR base of , but is not since, for\r\nexample, can be deleted.Note that an XOR base is not necessarily a\r\nsubset of the original set. For example, for , is a valid XOR base.Due\r\nto the laws of linear algebra, an XOR base of size supports integers (i.\r\ne. integers can be expressed using XOR of some numbers from the base).\r\nThis means that since in our problem the integers are limited to bits,\r\nthe maximum size of an XOR base we need is .Now letâs talk about how we\r\nbuild, store and maintain the XOR base. We will use an array of\r\nintegers, initially filled with zeroes (an array of all zeroes\r\nrepresents an empty XOR base). Letâs call this array . If some integer\r\nin this array is non-zero, it has to meet the following constraints: the\r\n-th bit is set to in ; the -th bit is set to in every integer such that\r\n. This is kinda similar to how the Gauss elimination method transforms a\r\nmatrix representing the system of linear equations: it leaves only one\r\nrow with non-zero value in the first column and puts it as the first\r\nrow, then in the next non-zero column it leaves only one row with\r\nnon-zero value (except for maybe the first row) and puts it as the\r\nsecond row, and so on.Okay, we need to process two types of queries for\r\nXOR bases: add an integer and change the XOR base accordingly if needed;\r\ncheck that some integer is supported (i. e. can be represented) by the\r\nXOR base. For both of those queries, we will use a special reduction\r\nprocess. In the model solution, it is the function that takes an array\r\nrepresenting the XOR base and an integer , and tries to eliminate bits\r\nset to from . In this reduction process, we iterate on bits from (or the\r\nhighest bit the number can have set to ) to , and every time the bit\r\nweâre considering is set to , we try to make it by XORing with . It can\r\nbe easily seen that due to the properties of XOR base, XORing with is\r\nthe only way to do it: if we XOR with any other number such that , it\r\nwonât affect the -th bit; and if we XOR it with such that , it sets the\r\n-th bit to (and we have already ensured that it should be ).If\r\ntransforms to , then is supported by the XOR base, otherwise it is not.\r\nAnd if we want to try adding to the base, we can simply reduce , find\r\nthe highest non-zero bit in the resulting integer , (let it be ), and\r\nassign to (it is guaranteed that was zero, since otherwise we would have\r\neliminated the -th bit).So, thatâs how we can work with XOR bases and\r\nprocess every query to them in , where is the number of bits in each\r\ninteger.Now letâs go back to the original problem. Basically, for every\r\nquery, we have to build a XOR base on some path in the tree. We can root\r\nthe tree and then use LCA to split this path into two vertical paths,\r\nget XOR bases from those two paths, and merge them in . But how do we\r\nget an XOR base on a vertical path in something like ?To do this, for\r\neach vertex , letâs consider the following process. We go from to the\r\nroot, maintain the XOR base of the integers we met, and every time we\r\nadd something to the XOR base, we mark the current vertex as\r\n\"interesting\" for . Our goal is to build a list of \"interesting\"\r\nvertices for in order from to the root. Since the size of each XOR base\r\nis up to , the size of each such list is also up to , so we can get the\r\nXOR base for a vertical path by simply iterating on that interesting\r\nlist for the lower endpoint of the path.Okay, the last part of the\r\nproblem we have to solve is how to build these lists for all vertices in\r\nreasonable time. The key insight here is that if is the parent of , then\r\nthe list for will be very similar to the list for : if is not supported\r\nby the XOR base of the list for , then the list for is simply the list\r\nfor , with the vertex added; otherwise, eliminates one of the vertices\r\nfrom the list for . We can find which one by building the XOR base for\r\nand the list of ; we need to add first, and then the values from all\r\nvertices in the list of in order \"from bottom to top\", and when an\r\ninteresting vertex for adds nothing to the XOR base, it means that it is\r\nexactly the vertex we need to eliminate. Combining all of these, we can\r\nget a solution that works in for preprocessing and in to answer each\r\nquery.\r\n",
    "hint": []
}