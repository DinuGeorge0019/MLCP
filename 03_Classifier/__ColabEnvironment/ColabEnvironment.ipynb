{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20891,"status":"ok","timestamp":1740619245166,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"xe8Eih0hHc2-","outputId":"153fd8b7-606b-40aa-eb5a-6c616369125c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":543,"status":"ok","timestamp":1740619245711,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"YmNUmwcdHc3B","outputId":"9a5b3315-a629-4423-a2d1-200d2d9f7bba"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2617,"status":"ok","timestamp":1740619248330,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"qIIAqc0VIDm4","outputId":"dc76352d-3b11-498b-8eb1-b9ef67c061ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n","Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}],"source":["# install dependencies\n","\n","# !pip install catboost\n","!pip install scikit-multilearn\n","# !pip install --upgrade tensorflow-addons\n","# !pip install sentence-transformers\n","# !pip install --upgrade tensorflow-addons\n","# !pip install dask[dataframe]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1740619248342,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"T2lmJ49jGPJE","outputId":"88e71c0c-11f2-40fe-df0d-51ba92b56aa8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":782,"status":"ok","timestamp":1740619249124,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"7T7YDX_3GPJE","outputId":"490d519b-0006-49a2-ee38-c7d7ae1376f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRO_Vzk2MtcV","outputId":"876d6cb8-2e4f-452e-f627-55a3aea67625","executionInfo":{"status":"ok","timestamp":1740264162900,"user_tz":-120,"elapsed":300457,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (16, 768)\n","Positive Embeddings Shape: (16, 768)\n","Negative Embeddings Shape: (16, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model_4/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d33cc772bd0>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d33cc930190>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d34d71898d0>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model_4/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tfmp_net_model_4/mpnet/pooler/dense/kernel:0', 'tfmp_net_model_4/mpnet/pooler/dense/bias:0'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (16, 768)\n","Positive Embeddings Shape: (16, 768)\n","Negative Embeddings Shape: (16, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model_4/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d34bdf68d50>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d34d89df710>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7d3434168a10>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model_4/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model_4/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 496ms/step - loss: 0.5054\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335\n"]}],"source":["# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2') #\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'OUTSIDE_TOP_20_BASIC_NLI_TRAINING_DATASET_PATH'], # CONFIG[f'OUTSIDE_TOP_10_NLI_TRAINING_DATASET_PATH'], # CONFIG[f'TOP_10_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250215_191013')\n","  )\n","\n","# from google.colab import runtime\n","# runtime.unassign()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["ccf71ef69d6748cfb190d94c08b0e943","ed51bd66cf1b4546ba04628833d20a64","2ac743e5e1974dedb31ec490576209db","d407dd5647aa4f8fb39eb881c475a259","903a2b8ec24a42b6be27113ec19b5258","d63c34906561471f9092a63fd00b44db","6c204cb081be4ff4b0afee9dadb15818","2d14833d4a6b4e21ae10112821442f06","409c40de138e4829a444c564d4ed9e95","53e53d968510448ea13202bee35cf12d","d67df1b5f7694b748aacecc6e6855ed6","97998b89aeb5452d98b75564ce6b7119","cc245f3ac9c64e2bba768bd76cb1091b","e14d6036a56f4cc4b426f3e7a7a451ed","6418210dfa9f4212b59a7871ce1ab128","f1a71565f71548f0acf33a5f5a686440","aa24d582d8e845739837b2d709fdf152","902f3cd03acb4de78af96007e345bb4b","5d66d1aa8a4d4fefac3ec244a76871b0","f3b349dde8834c84919ce466f3f01f7c","124caf22a5d440f3891c7aba0ba02cff","0a8be40ed51d494280ad9705be8a7d3e","71e43115a5b5449ea4fe9e51fbdd7261","19e53d74ff22468294af8c30543bc238","f52fd95d126c4c599b13afa4d720704e","08b2c94852834d208a2f8b4767ea09e1","c4bf96e9504f4c0babb248d0ec527c13","e12372dceb1a4046a0679b2a633f7f84","46d2a2a16e20488f90d5ee3734f464c5","215f094c3695467eb2824631dcd4f704","ce0422ffd4524fa7b9c17402835c16cb","85fab071adef433ca1a8449567456063","a020cc480ebb45988d9a3b1e94a6e8f1","11e3df3c8e9d4b33b09db9348392b0ac","cf69768dd22d416d8b48742dc406029f","0ac1b540e4a24c20a934b7cbdac7128e","720f1a0b20bf490d8a1bc22f6ec95023","b63d17107709412bbcc1d3c1f597e2e0","675dad3b11254f38b78ca8bed50847eb","eb2aa37e56774c2e91056857373bc8af","36d793efae8f4943af934aaf6050315b","7a91e2e590e449658e0fb7b35edbab4d","46ad870cc07c470da97a4bd84fedfe51","9285033d142a4593bc50f52e7ac387a2"]},"executionInfo":{"elapsed":82649,"status":"ok","timestamp":1740607631145,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"ZxccKR9-LaVM","outputId":"90314dd5-126c-421f-947c-beb6a57fb88c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccf71ef69d6748cfb190d94c08b0e943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97998b89aeb5452d98b75564ce6b7119"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71e43115a5b5449ea4fe9e51fbdd7261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11e3df3c8e9d4b33b09db9348392b0ac"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250219_145342_base_top_20.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model from: /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250219_145342_base_top_20\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 160/160 [00:36<00:00,  4.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 45/45 [00:09<00:00,  4.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: GaussianNB\n"]}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","NUMBER_OF_TAGS = 20\n","\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20')\n","    # outside_dataset=True\n","    )"]},{"cell_type":"code","source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","# decisionTreeEvaluator.benchmark_model(\n","#     encoder_batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS1,\n","#     transformer_name='sentence-transformers/all-mpnet-base-v2'\n","#     )\n","\n","# decisionTreeEvaluator.benchmark_model(\n","#     encoder_batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS2,\n","#     transformer_name='sentence-transformers/all-mpnet-base-v2'\n","#     )\n","\n","# decisionTreeEvaluator.benchmark_model(\n","#     encoder_batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS3,\n","#     transformer_name='sentence-transformers/all-mpnet-base-v2'\n","#     )\n","\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_5_basic_nli'),\n","    outside_dataset=True\n","    )\n","\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_10_basic_nli'),\n","    outside_dataset=True\n","    )\n","\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_20_basic_nli'),\n","    outside_dataset=True\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["32f52b6a83ea4ba99c4f8d9c8590a726","53c8cbdf1f1148d8b2971af121eb37cf","878e698ab10d46bca44cced3b3b41c2c","de99a826e5d0410cbb639ab46bc6abdc","33a5eaa1d7e04b2c83f60df6031838bd","a46450e51004458b934330d5bd68e82d","a66bfe8c6d154a1c88ac707e66f5b66b","6b5130f7849a422db7fdfb53a0530011","7ed283d5d1944333a1615b7b1884c17b","ccda8d4ff7ba47afa95091a1ba72284f","ccde2fe05af44e0aa1e8e2fd5d5da9ce","48d0b0faeaf64cdfae04f38beac5412e","b4055beb83ba46e399c12f80feca7f81","24a3abe28a114be386115806b189890c","3f3d32c96ad4426180c47246f76a4769","8808a7380cdb43c59ef7239304884796","3439462dd99f4312a625bae2a11f11bf","a5bf869229474863997b775dc94fef57","daa539eba5564410bfea46d706928b18","2d90729579c94168933eace4ad6cf720","990bf27b7b7d4843b6116ca03799e88c","e1531324da624a1fa307ee31574778a4","7b986cfb4af14955ad7343095b862e0c","045049a775bc491a9c362f1630660168","a23af30131fe4878a4f5a7552c7ad0f5","55d1e8c1600949489da8c6d99ea52bc3","f2c9325977584b8aaa927cc4d34c9bfe","8316ce21976342888667843df597bccf","41b4c6e096914ec0a2966b8b0e3db8fb","0585c666e1d943ad85feffa59112b837","7d68f092c06247c58d7810b1e0a8bb97","ad4a7c80c5c84c07842b1ef8eec334b4","f0267e009e7c472aba0abcb847be5382","23120690c8484281892bd7aeb2082cae","309c3931c7bb4273a6c56e4245913c72","529f5b6a0f6040aea6f8ed6644284be3","5bd1d21486d24f38995defbd718d3fe8","c44a36a04e7b4943a48f30c01d76dcbc","4b901fecc98b4d0bb241b91ee5849bb2","3eaf364182ff46d9b04ca464ebc9f488","eff3085396524665ae11da6d09df5b34","5933a75716d54a80a8d22967c76004fc","d5d0081f0dea4cfbb1570ac5140a0149","5f75cdfb90204a858050c53e0f8820cb","d51a750a2afa44d49c89a582feefcf72","31028bc5abfd4980baef9636fe0e32ad","e7eb765a0fdf4903a72da7ddc28e495d","6909eafd62f9423b8958f9ffbe692335","ae3fbfd0d9c44687a416e417dab20381","40c247d4fa6941ccab3f9f47cf221c39","459c582527ba4780809a80b8d1f5c0de","19e6a80598214fd49843bc3144a94d9d","caa523233fbb4c3d9c4409e3f4d1d999","2951e5954b194544a9dfd69f8ec05b17","ed24eebedccf437d967141a162b3bb94","cfc85653913e47578a4f568afa91a607","3193d84e1e424203ba5676ace433d780","210fcaa9b4aa4f269bdbeb0b389da125","20f646d4b3ee45fb93c58f8c01b4b892","51880c0fd5044725b733749340b869e1","5e405b575c3341da9f60da8e30a4f20a","84b85b3357874ce9a60b11dd7df70ea4","4c9a7d0a4d1d446e8a98f48a74562776","e708d45825994489a2471743a896bc0a","df19808adbc14a82ac974a48d129f159","7e1bea3b62aa4026a1f600c436c818b5"]},"id":"K7YQYNvdPp32","executionInfo":{"status":"error","timestamp":1740619322315,"user_tz":-120,"elapsed":73190,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"82e27552-997b-499a-d9fa-b9ccee11c71f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f52b6a83ea4ba99c4f8d9c8590a726"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d0b0faeaf64cdfae04f38beac5412e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b986cfb4af14955ad7343095b862e0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23120690c8484281892bd7aeb2082cae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51a750a2afa44d49c89a582feefcf72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfc85653913e47578a4f568afa91a607"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 141/141 [00:32<00:00,  4.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 34/34 [00:07<00:00,  4.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: GaussianNB\n"]},{"output_type":"error","ename":"NotFittedError","evalue":"This Classifier Chain has not been fit yet","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36m_order\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ClassifierChain' object has no attribute '_label_count'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-81954e0649e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#     )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m decisionTreeEvaluator.benchmark_model(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mencoder_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUMBER_OF_TAGS1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/DecisionTreeEvaluator.py\u001b[0m in \u001b[0;36mbenchmark_model\u001b[0;34m(self, encoder_batch_size, number_of_tags, validation, transformer_name, transformer_model_path, outside_dataset, base_model_evaluation)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__save_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/ClassifierChainWrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_problem_statements_embeddings, test_tags)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Make predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_problem_statements_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Transform from sparce array to dense array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpredictions_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    175\u001b[0m             X, sparse_format='csc', enforce_sparse=True)\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             prediction = self.classifiers_[label].predict(\n\u001b[1;32m    179\u001b[0m                 self._ensure_input_format(X_extended))\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36m_order\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This Classifier Chain has not been fit yet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m: This Classifier Chain has not been fit yet"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":360829,"status":"error","timestamp":1739480038019,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"E67PUmrfEy0H","outputId":"3b4acbc5-02ea-4672-e5ee-0e92ecf8180b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_203348.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - auc: 0.5006 - binary_accuracy: 0.5191 - f1: 0.6830 - loss: 0.6949 - prc_auc: 0.5194 - precision: 0.5191 - recall: 1.0000\n","Epoch 1: Validation Metrics:\n","loss: 0.6989742517471313\n","val_binary_accuracy: 0.40248963236808777\n","val_precision: 0.40248963236808777\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.4024896025657654\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 460ms/step - auc: 0.5007 - binary_accuracy: 0.5189 - f1: 0.6828 - loss: 0.6950 - prc_auc: 0.5193 - precision: 0.5189 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.4025 - val_f1: 0.5740 - val_loss: 0.7187 - val_prc_auc: 0.4025 - val_precision: 0.4025 - val_recall: 1.0000\n","Epoch 2/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5016 - binary_accuracy: 0.5191 - f1: 0.6830 - loss: 0.6943 - prc_auc: 0.5200 - precision: 0.5191 - recall: 1.0000\n","Epoch 2: Validation Metrics:\n","loss: 0.6977320909500122\n","val_binary_accuracy: 0.40248963236808777\n","val_precision: 0.40248963236808777\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.4024896025657654\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.5016 - binary_accuracy: 0.5189 - f1: 0.6828 - loss: 0.6943 - prc_auc: 0.5198 - precision: 0.5189 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.4025 - val_f1: 0.5740 - val_loss: 0.7137 - val_prc_auc: 0.4025 - val_precision: 0.4025 - val_recall: 1.0000\n","Epoch 3/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4883 - binary_accuracy: 0.5191 - f1: 0.6830 - loss: 0.6933 - prc_auc: 0.5094 - precision: 0.5191 - recall: 1.0000\n","Epoch 3: Validation Metrics:\n","loss: 0.695991575717926\n","val_binary_accuracy: 0.40248963236808777\n","val_precision: 0.40248963236808777\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.4024896025657654\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.4884 - binary_accuracy: 0.5189 - f1: 0.6828 - loss: 0.6933 - prc_auc: 0.5094 - precision: 0.5189 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.4025 - val_f1: 0.5740 - val_loss: 0.7075 - val_prc_auc: 0.4025 - val_precision: 0.4025 - val_recall: 1.0000\n","Epoch 4/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5023 - binary_accuracy: 0.5191 - f1: 0.6830 - loss: 0.6926 - prc_auc: 0.5204 - precision: 0.5191 - recall: 1.0000\n","Epoch 4: Validation Metrics:\n","loss: 0.6946596503257751\n","val_binary_accuracy: 0.40248963236808777\n","val_precision: 0.40248963236808777\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.4024896025657654\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - auc: 0.5023 - binary_accuracy: 0.5189 - f1: 0.6828 - loss: 0.6926 - prc_auc: 0.5202 - precision: 0.5189 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.4025 - val_f1: 0.5740 - val_loss: 0.7030 - val_prc_auc: 0.4025 - val_precision: 0.4025 - val_recall: 1.0000\n","Starting training for label: 1\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_203348.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - auc: 0.5020 - binary_accuracy: 0.5051 - f1: 0.6709 - loss: 0.6957 - prc_auc: 0.5110 - precision: 0.5051 - recall: 1.0000\n","Epoch 1: Validation Metrics:\n","loss: 0.6965370774269104\n","val_binary_accuracy: 0.37551867961883545\n","val_precision: 0.37551867961883545\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.37551867961883545\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 392ms/step - auc: 0.5020 - binary_accuracy: 0.5050 - f1: 0.6709 - loss: 0.6957 - prc_auc: 0.5110 - precision: 0.5050 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.3755 - val_f1: 0.5460 - val_loss: 0.7160 - val_prc_auc: 0.3755 - val_precision: 0.3755 - val_recall: 1.0000\n","Epoch 2/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.4984 - binary_accuracy: 0.5051 - f1: 0.6709 - loss: 0.6952 - prc_auc: 0.5077 - precision: 0.5051 - recall: 1.0000\n","Epoch 2: Validation Metrics:\n","loss: 0.6958320140838623\n","val_binary_accuracy: 0.37551867961883545\n","val_precision: 0.37551867961883545\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.37551867961883545\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.4984 - binary_accuracy: 0.5050 - f1: 0.6709 - loss: 0.6952 - prc_auc: 0.5076 - precision: 0.5050 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.3755 - val_f1: 0.5460 - val_loss: 0.7118 - val_prc_auc: 0.3755 - val_precision: 0.3755 - val_recall: 1.0000\n","Epoch 3/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5041 - binary_accuracy: 0.5051 - f1: 0.6709 - loss: 0.6944 - prc_auc: 0.5129 - precision: 0.5051 - recall: 1.0000\n","Epoch 3: Validation Metrics:\n","loss: 0.6948112845420837\n","val_binary_accuracy: 0.37551867961883545\n","val_precision: 0.37551867961883545\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.37551867961883545\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.5041 - binary_accuracy: 0.5050 - f1: 0.6709 - loss: 0.6944 - prc_auc: 0.5128 - precision: 0.5050 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.3755 - val_f1: 0.5460 - val_loss: 0.7065 - val_prc_auc: 0.3755 - val_precision: 0.3755 - val_recall: 1.0000\n","Epoch 4/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.4992 - binary_accuracy: 0.5051 - f1: 0.6709 - loss: 0.6936 - prc_auc: 0.5078 - precision: 0.5051 - recall: 1.0000\n","Epoch 4: Validation Metrics:\n","loss: 0.6940034031867981\n","val_binary_accuracy: 0.37551867961883545\n","val_precision: 0.37551867961883545\n","val_recall: 1.0\n","val_auc: 0.5\n","val_prc_auc: 0.37551867961883545\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.4993 - binary_accuracy: 0.5050 - f1: 0.6709 - loss: 0.6936 - prc_auc: 0.5077 - precision: 0.5050 - recall: 1.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.3755 - val_f1: 0.5460 - val_loss: 0.7023 - val_prc_auc: 0.3755 - val_precision: 0.3755 - val_recall: 1.0000\n","Starting training for label: 2\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_203348.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - auc: 0.5007 - binary_accuracy: 0.5167 - f1: 0.0000e+00 - loss: 0.6927 - prc_auc: 0.4859 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 1: Validation Metrics:\n","loss: 0.6943050026893616\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.32987552881240845\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 407ms/step - auc: 0.5007 - binary_accuracy: 0.5165 - f1: 0.0000e+00 - loss: 0.6927 - prc_auc: 0.4861 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6701 - val_f1: 0.0000e+00 - val_loss: 0.6786 - val_prc_auc: 0.3299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4897 - binary_accuracy: 0.5169 - f1: 0.0000e+00 - loss: 0.6926 - prc_auc: 0.4764 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 2: Validation Metrics:\n","loss: 0.6940585970878601\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.32987552881240845\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.4899 - binary_accuracy: 0.5165 - f1: 0.0000e+00 - loss: 0.6927 - prc_auc: 0.4769 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6701 - val_f1: 0.0000e+00 - val_loss: 0.6808 - val_prc_auc: 0.3299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5046 - binary_accuracy: 0.5169 - f1: 0.0000e+00 - loss: 0.6926 - prc_auc: 0.4923 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 3: Validation Metrics:\n","loss: 0.6937268972396851\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.32987552881240845\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.5049 - binary_accuracy: 0.5165 - f1: 0.0000e+00 - loss: 0.6926 - prc_auc: 0.4928 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6701 - val_f1: 0.0000e+00 - val_loss: 0.6840 - val_prc_auc: 0.3299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 4/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5022 - binary_accuracy: 0.5169 - f1: 0.0000e+00 - loss: 0.6926 - prc_auc: 0.4877 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 4: Validation Metrics:\n","loss: 0.6934719085693359\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.32987552881240845\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.5024 - binary_accuracy: 0.5165 - f1: 0.0000e+00 - loss: 0.6926 - prc_auc: 0.4883 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6701 - val_f1: 0.0000e+00 - val_loss: 0.6867 - val_prc_auc: 0.3299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Starting training for label: 3\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_203348.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - auc: 0.5017 - binary_accuracy: 0.5101 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4916 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 1: Validation Metrics:\n","loss: 0.6937404274940491\n","val_binary_accuracy: 0.6867219805717468\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.3132780194282532\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 513ms/step - auc: 0.5018 - binary_accuracy: 0.5100 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4918 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6867 - val_f1: 0.0000e+00 - val_loss: 0.6810 - val_prc_auc: 0.3133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.5026 - binary_accuracy: 0.5101 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4912 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 2: Validation Metrics:\n","loss: 0.6936624050140381\n","val_binary_accuracy: 0.6867219805717468\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.3132780194282532\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - auc: 0.5026 - binary_accuracy: 0.5100 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4913 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6867 - val_f1: 0.0000e+00 - val_loss: 0.6823 - val_prc_auc: 0.3133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 3/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5001 - binary_accuracy: 0.5101 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4900 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 3: Validation Metrics:\n","loss: 0.6935387849807739\n","val_binary_accuracy: 0.6867219805717468\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.3132780194282532\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.5001 - binary_accuracy: 0.5100 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4901 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6867 - val_f1: 0.0000e+00 - val_loss: 0.6841 - val_prc_auc: 0.3133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Epoch 4/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5025 - binary_accuracy: 0.5101 - f1: 0.0000e+00 - loss: 0.6929 - prc_auc: 0.4913 - precision: 0.0000e+00 - recall: 0.0000e+00\n","Epoch 4: Validation Metrics:\n","loss: 0.6934121251106262\n","val_binary_accuracy: 0.6867219805717468\n","val_precision: 0.0\n","val_recall: 0.0\n","val_auc: 0.5\n","val_prc_auc: 0.3132780194282532\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - auc: 0.5024 - binary_accuracy: 0.5100 - f1: 0.0000e+00 - loss: 0.6930 - prc_auc: 0.4914 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_auc: 0.5000 - val_binary_accuracy: 0.6867 - val_f1: 0.0000e+00 - val_loss: 0.6861 - val_prc_auc: 0.3133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n","Starting training for label: 4\n"]},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_203348.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e5daf55fef3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtransformer_evaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsAllTransformerEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m transformer_evaluator.evaluate_models(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/OneVsAllTransformerEvaluator.py\u001b[0m in \u001b[0;36mevaluate_models\u001b[0;34m(self, epochs, batch_size, number_of_tags, train_model, threshold, transformer_model_path, train_dataset_path, val_dataset_path, test_dataset_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training and evaluating model: {model}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtransformer_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsAllSentenceTransformerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             transformer_wrapper.train_model(\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mtrain_dataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#CONFIG[f'TOP_{number_of_tags}_TRAINING_DATASET_PATH'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mval_dataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# CONFIG[f'TOP_{number_of_tags}_VALIDATION_DATASET_PATH'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/OneVsAllSentenceTransformerWrapper.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_dataset_path, val_dataset_path, epochs, batch_size, train_model, threshold, transformer_model_path)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             history = encoder_model.fit(\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0msingle_label_train_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msingle_label_val_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   function = trace_function(\n\u001b[0m\u001b[1;32m    133\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    115\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             loss = self._compute_loss(\n\u001b[1;32m     61\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/SentenceTransformerEncoderModel.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Get the transformer outputs. The first element is usually the last hidden states.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mtransformer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Extract the last hidden states (batch_size, seq_len, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 ):\n\u001b[0;32m-> 1142\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mpnet/modeling_tf_mpnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     ) -> Union[TFBaseModelOutput, Tuple[tf.Tensor]]:\n\u001b[0;32m--> 777\u001b[0;31m         outputs = self.mpnet(\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 ):\n\u001b[0;32m-> 1142\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mpnet/modeling_tf_mpnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 ):\n\u001b[0;32m-> 1142\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mpnet/modeling_tf_mpnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     ):\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mposition_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_position_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mall_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mpnet/modeling_tf_mpnet.py\u001b[0m in \u001b[0;36mcompute_position_bias\u001b[0;34m(self, x, position_ids)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mrelative_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_position\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext_position\u001b[0m  \u001b[0;31m# shape (qlen, klen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         rp_bucket = self._relative_position_bucket(\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0mrelative_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mnum_buckets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention_num_buckets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/mpnet/modeling_tf_mpnet.py\u001b[0m in \u001b[0;36m_relative_position_bucket\u001b[0;34m(relative_position, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         val_if_large = max_exact + tf.cast(\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_exact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_distance\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_exact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_buckets\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_exact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   5717\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5718\u001b[0m     \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attr_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5719\u001b[0;31m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5720\u001b[0m     _execute.record_gradient(\n\u001b[1;32m   5721\u001b[0m         \"Log\", _inputs_flat, _attrs, _result)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       self._inputs_val = tuple(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           for i in pywrap_tf_session.GetOperationInputs(self._c_op))\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       self._inputs_val = tuple(\n\u001b[0;32m-> 1487\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m           for i in pywrap_tf_session.GetOperationInputs(self._c_op))\n\u001b[1;32m   1489\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_tensor_by_tf_output\u001b[0;34m(self, tf_output)\u001b[0m\n\u001b[1;32m   3057\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m     \"\"\"Returns the `Tensor` representing `tf_output`.\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 20\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_163804_outside_top_20'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n","\n","from google.colab import runtime\n","runtime.unassign()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ab75f67eb42b4a1ca21d6468049a3a2c","a0b2bf7c41854086a868c6425482130a","8316f4f113cc448bb3499124c39f211a","035b31cd9a8d4ea6919b7b86f6d0b615","7943ae8731234fa0836a59cf7e4244f3","d2240f0013694f07bed47fe75a5a1641","11589f1d66dd451d970c79ce42cb7171","fdab0baa964e4b2fb906b35a20902ddc","bb3894688cd04c88bdf92501441b60e2","b178e852a15e46228594ced4cf8aa27e","cd5c5e3f4508453ea82ff0fc16e27296","3055ea4e48cb4418b8f6504cc8c08467","d4183705c5384ce88d098138701ff430","3ac81fc0f037454f85d5ba838e4af86f","d48be92e49844ca28a2e8043cafdb115","1545bbd1a8464908a0965b541726955e","9676e2ff41fb4b5c85b5c2d0c1456140","ea3aa6ac78be4c39b7f66a55c4e5428f","42ec6beaa68b438f9d4b61c149d49e2f","206b60fa24504fed99b79cc57951fe41","c168639624c64cc6a23227abf2815f5f","d769cfc2ebb4448cb81d84604ce35c00","1fd716c8298246818220c3d03d4c85d4","4de9a757f6e74d0195bf319c2e893c36","f5d816e9a3834a7fadcea9e7aedacf93","c738430dec2240eeb761b21b7540a45d","df694098c89a49cd99732b52466278f3","3d66a179586f459bbb47a32de58f1a38","2af30a8b517c4171826296b82bf11db0","5d8d7d944c644e81a74c4d2b5284855f","887b10734cf54c93a3a753e9cba86175","6acba668429e440ebfeed86b1b991f68","07c9d7d2cf994ab09fe1985b3d611041","3c7ef7385dc642e28088fbc953bcc1a6","44c836770f0846c698f9a02023b2a7f1","5b317a4e47554fd1a2e18bde011a140a","f08e2bb04ca04bea92daee838df0c279","b609d99de499468c89dba07fbe8d5fdb","3385ae4046c74d02b71def42296972e2","6f26c09acb93419aa497867f971a6a13","fdb80f290b664a3b84225de50ac57131","2e7751f1290c46a395562b059e337444","a104ffe21dfb4fc2863c6955e258337b","d50e75c126ee46f2af3197950fe4feb4"]},"executionInfo":{"elapsed":1104754,"status":"ok","timestamp":1740236096500,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"1NV-8lk7Q1b0","outputId":"86a5d096-0525-4302-f381-a4f72ee81a1c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-MiniLM-L12-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab75f67eb42b4a1ca21d6468049a3a2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3055ea4e48cb4418b8f6504cc8c08467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fd716c8298246818220c3d03d4c85d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7ef7385dc642e28088fbc953bcc1a6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - auc: 0.7428 - binary_accuracy: 0.6618 - f1: 0.5532 - loss: 0.6082 - prc_auc: 0.7443 - precision: 0.7103 - recall: 0.4776\n","Epoch 1: Validation Metrics:\n","loss: 0.5319944024085999\n","val_binary_accuracy: 0.727623462677002\n","val_precision: 0.3814432919025421\n","val_recall: 0.5670498013496399\n","val_auc: 0.7169137597084045\n","val_prc_auc: 0.4208998680114746\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 403ms/step - auc: 0.7441 - binary_accuracy: 0.6630 - f1: 0.5557 - loss: 0.6071 - prc_auc: 0.7455 - precision: 0.7113 - recall: 0.4805 - val_auc: 0.7169 - val_binary_accuracy: 0.7276 - val_f1: 0.4561 - val_loss: 0.5722 - val_prc_auc: 0.4209 - val_precision: 0.3814 - val_recall: 0.5670\n","Epoch 2/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8674 - binary_accuracy: 0.7971 - f1: 0.7954 - loss: 0.4574 - prc_auc: 0.8649 - precision: 0.8113 - recall: 0.7804\n","Epoch 2: Validation Metrics:\n","loss: 0.43866032361984253\n","val_binary_accuracy: 0.7253086566925049\n","val_precision: 0.37851661443710327\n","val_recall: 0.5670498013496399\n","val_auc: 0.7208858132362366\n","val_prc_auc: 0.4228777289390564\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - auc: 0.8678 - binary_accuracy: 0.7973 - f1: 0.7955 - loss: 0.4569 - prc_auc: 0.8653 - precision: 0.8113 - recall: 0.7805 - val_auc: 0.7209 - val_binary_accuracy: 0.7253 - val_f1: 0.4540 - val_loss: 0.5850 - val_prc_auc: 0.4229 - val_precision: 0.3785 - val_recall: 0.5670\n","Epoch 3/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8738 - binary_accuracy: 0.7974 - f1: 0.7957 - loss: 0.4449 - prc_auc: 0.8677 - precision: 0.8116 - recall: 0.7805\n","Epoch 3: Validation Metrics:\n","loss: 0.4270778298377991\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.38167938590049744\n","val_recall: 0.5747126340866089\n","val_auc: 0.7221760153770447\n","val_prc_auc: 0.42847418785095215\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8741 - binary_accuracy: 0.7976 - f1: 0.7958 - loss: 0.4444 - prc_auc: 0.8682 - precision: 0.8117 - recall: 0.7806 - val_auc: 0.7222 - val_binary_accuracy: 0.7269 - val_f1: 0.4587 - val_loss: 0.5866 - val_prc_auc: 0.4285 - val_precision: 0.3817 - val_recall: 0.5747\n","Epoch 4/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8786 - binary_accuracy: 0.8003 - f1: 0.7981 - loss: 0.4372 - prc_auc: 0.8736 - precision: 0.8158 - recall: 0.7813\n","Epoch 4: Validation Metrics:\n","loss: 0.42037177085876465\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.3834586441516876\n","val_recall: 0.5862069129943848\n","val_auc: 0.722912609577179\n","val_prc_auc: 0.43246906995773315\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8790 - binary_accuracy: 0.8005 - f1: 0.7983 - loss: 0.4367 - prc_auc: 0.8740 - precision: 0.8159 - recall: 0.7816 - val_auc: 0.7229 - val_binary_accuracy: 0.7269 - val_f1: 0.4636 - val_loss: 0.5872 - val_prc_auc: 0.4325 - val_precision: 0.3835 - val_recall: 0.5862\n","Epoch 5/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8818 - binary_accuracy: 0.8020 - f1: 0.8001 - loss: 0.4319 - prc_auc: 0.8759 - precision: 0.8170 - recall: 0.7839\n","Epoch 5: Validation Metrics:\n","loss: 0.4157518148422241\n","val_binary_accuracy: 0.7245370149612427\n","val_precision: 0.38118812441825867\n","val_recall: 0.5900382995605469\n","val_auc: 0.723495602607727\n","val_prc_auc: 0.4362243115901947\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8821 - binary_accuracy: 0.8022 - f1: 0.8002 - loss: 0.4314 - prc_auc: 0.8764 - precision: 0.8172 - recall: 0.7841 - val_auc: 0.7235 - val_binary_accuracy: 0.7245 - val_f1: 0.4632 - val_loss: 0.5879 - val_prc_auc: 0.4362 - val_precision: 0.3812 - val_recall: 0.5900\n","Epoch 6/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8840 - binary_accuracy: 0.8052 - f1: 0.8040 - loss: 0.4281 - prc_auc: 0.8797 - precision: 0.8175 - recall: 0.7910\n","Epoch 6: Validation Metrics:\n","loss: 0.4124157130718231\n","val_binary_accuracy: 0.7237654328346252\n","val_precision: 0.3808353841304779\n","val_recall: 0.5938697457313538\n","val_auc: 0.7237270474433899\n","val_prc_auc: 0.4374217987060547\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8843 - binary_accuracy: 0.8054 - f1: 0.8041 - loss: 0.4276 - prc_auc: 0.8801 - precision: 0.8176 - recall: 0.7912 - val_auc: 0.7237 - val_binary_accuracy: 0.7238 - val_f1: 0.4641 - val_loss: 0.5884 - val_prc_auc: 0.4374 - val_precision: 0.3808 - val_recall: 0.5939\n","Epoch 7/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8858 - binary_accuracy: 0.8055 - f1: 0.8040 - loss: 0.4251 - prc_auc: 0.8811 - precision: 0.8193 - recall: 0.7893\n","Epoch 7: Validation Metrics:\n","loss: 0.4098336398601532\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.3857493996620178\n","val_recall: 0.6015325784683228\n","val_auc: 0.7240398526191711\n","val_prc_auc: 0.4400779604911804\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8860 - binary_accuracy: 0.8058 - f1: 0.8041 - loss: 0.4247 - prc_auc: 0.8815 - precision: 0.8193 - recall: 0.7896 - val_auc: 0.7240 - val_binary_accuracy: 0.7269 - val_f1: 0.4701 - val_loss: 0.5890 - val_prc_auc: 0.4401 - val_precision: 0.3857 - val_recall: 0.6015\n","Epoch 8/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8874 - binary_accuracy: 0.8062 - f1: 0.8047 - loss: 0.4227 - prc_auc: 0.8833 - precision: 0.8195 - recall: 0.7906\n","Epoch 8: Validation Metrics:\n","loss: 0.40776532888412476\n","val_binary_accuracy: 0.7245370149612427\n","val_precision: 0.3829268217086792\n","val_recall: 0.6015325784683228\n","val_auc: 0.7241916060447693\n","val_prc_auc: 0.4393038749694824\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8876 - binary_accuracy: 0.8064 - f1: 0.8049 - loss: 0.4223 - prc_auc: 0.8836 - precision: 0.8196 - recall: 0.7908 - val_auc: 0.7242 - val_binary_accuracy: 0.7245 - val_f1: 0.4680 - val_loss: 0.5896 - val_prc_auc: 0.4393 - val_precision: 0.3829 - val_recall: 0.6015\n","Epoch 9/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8883 - binary_accuracy: 0.8088 - f1: 0.8067 - loss: 0.4208 - prc_auc: 0.8832 - precision: 0.8238 - recall: 0.7906\n","Epoch 9: Validation Metrics:\n","loss: 0.4060831665992737\n","val_binary_accuracy: 0.7229938507080078\n","val_precision: 0.3810679614543915\n","val_recall: 0.6015325784683228\n","val_auc: 0.7242027521133423\n","val_prc_auc: 0.4415770173072815\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8886 - binary_accuracy: 0.8089 - f1: 0.8069 - loss: 0.4203 - prc_auc: 0.8836 - precision: 0.8238 - recall: 0.7908 - val_auc: 0.7242 - val_binary_accuracy: 0.7230 - val_f1: 0.4666 - val_loss: 0.5903 - val_prc_auc: 0.4416 - val_precision: 0.3811 - val_recall: 0.6015\n","Epoch 10/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8892 - binary_accuracy: 0.8094 - f1: 0.8074 - loss: 0.4191 - prc_auc: 0.8848 - precision: 0.8246 - recall: 0.7911\n","Epoch 10: Validation Metrics:\n","loss: 0.404632031917572\n","val_binary_accuracy: 0.7245370149612427\n","val_precision: 0.38349515199661255\n","val_recall: 0.6053639650344849\n","val_auc: 0.7240564823150635\n","val_prc_auc: 0.4425528943538666\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8895 - binary_accuracy: 0.8096 - f1: 0.8075 - loss: 0.4187 - prc_auc: 0.8851 - precision: 0.8246 - recall: 0.7914 - val_auc: 0.7241 - val_binary_accuracy: 0.7245 - val_f1: 0.4695 - val_loss: 0.5907 - val_prc_auc: 0.4426 - val_precision: 0.3835 - val_recall: 0.6054\n","Epoch 11/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8902 - binary_accuracy: 0.8094 - f1: 0.8075 - loss: 0.4176 - prc_auc: 0.8864 - precision: 0.8242 - recall: 0.7916\n","Epoch 11: Validation Metrics:\n","loss: 0.4033387303352356\n","val_binary_accuracy: 0.7260802388191223\n","val_precision: 0.38701921701431274\n","val_recall: 0.6168582439422607\n","val_auc: 0.7242174744606018\n","val_prc_auc: 0.442825585603714\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8904 - binary_accuracy: 0.8095 - f1: 0.8076 - loss: 0.4172 - prc_auc: 0.8868 - precision: 0.8242 - recall: 0.7919 - val_auc: 0.7242 - val_binary_accuracy: 0.7261 - val_f1: 0.4756 - val_loss: 0.5913 - val_prc_auc: 0.4428 - val_precision: 0.3870 - val_recall: 0.6169\n","Epoch 12/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8909 - binary_accuracy: 0.8093 - f1: 0.8075 - loss: 0.4163 - prc_auc: 0.8866 - precision: 0.8237 - recall: 0.7921\n","Epoch 12: Validation Metrics:\n","loss: 0.4022026062011719\n","val_binary_accuracy: 0.7260802388191223\n","val_precision: 0.38701921701431274\n","val_recall: 0.6168582439422607\n","val_auc: 0.7241082787513733\n","val_prc_auc: 0.44187673926353455\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8911 - binary_accuracy: 0.8094 - f1: 0.8076 - loss: 0.4159 - prc_auc: 0.8870 - precision: 0.8236 - recall: 0.7924 - val_auc: 0.7241 - val_binary_accuracy: 0.7261 - val_f1: 0.4756 - val_loss: 0.5916 - val_prc_auc: 0.4419 - val_precision: 0.3870 - val_recall: 0.6169\n","Epoch 13/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8913 - binary_accuracy: 0.8098 - f1: 0.8080 - loss: 0.4151 - prc_auc: 0.8865 - precision: 0.8243 - recall: 0.7926\n","Epoch 13: Validation Metrics:\n","loss: 0.4011569023132324\n","val_binary_accuracy: 0.7260802388191223\n","val_precision: 0.38701921701431274\n","val_recall: 0.6168582439422607\n","val_auc: 0.7243674397468567\n","val_prc_auc: 0.4431726336479187\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8916 - binary_accuracy: 0.8100 - f1: 0.8081 - loss: 0.4147 - prc_auc: 0.8869 - precision: 0.8243 - recall: 0.7929 - val_auc: 0.7244 - val_binary_accuracy: 0.7261 - val_f1: 0.4756 - val_loss: 0.5919 - val_prc_auc: 0.4432 - val_precision: 0.3870 - val_recall: 0.6169\n","Epoch 14/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8920 - binary_accuracy: 0.8111 - f1: 0.8092 - loss: 0.4140 - prc_auc: 0.8877 - precision: 0.8258 - recall: 0.7935\n","Epoch 14: Validation Metrics:\n","loss: 0.4001893401145935\n","val_binary_accuracy: 0.7260802388191223\n","val_precision: 0.38701921701431274\n","val_recall: 0.6168582439422607\n","val_auc: 0.7246080636978149\n","val_prc_auc: 0.44418880343437195\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - auc: 0.8923 - binary_accuracy: 0.8113 - f1: 0.8094 - loss: 0.4136 - prc_auc: 0.8881 - precision: 0.8258 - recall: 0.7938 - val_auc: 0.7246 - val_binary_accuracy: 0.7261 - val_f1: 0.4756 - val_loss: 0.5923 - val_prc_auc: 0.4442 - val_precision: 0.3870 - val_recall: 0.6169\n","Epoch 15/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8926 - binary_accuracy: 0.8111 - f1: 0.8092 - loss: 0.4130 - prc_auc: 0.8887 - precision: 0.8258 - recall: 0.7936\n","Epoch 15: Validation Metrics:\n","loss: 0.39930304884910583\n","val_binary_accuracy: 0.727623462677002\n","val_precision: 0.389952152967453\n","val_recall: 0.6245210766792297\n","val_auc: 0.7247061133384705\n","val_prc_auc: 0.44418877363204956\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8929 - binary_accuracy: 0.8113 - f1: 0.8094 - loss: 0.4126 - prc_auc: 0.8890 - precision: 0.8258 - recall: 0.7939 - val_auc: 0.7247 - val_binary_accuracy: 0.7276 - val_f1: 0.4801 - val_loss: 0.5925 - val_prc_auc: 0.4442 - val_precision: 0.3900 - val_recall: 0.6245\n","Epoch 16/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8934 - binary_accuracy: 0.8134 - f1: 0.8110 - loss: 0.4120 - prc_auc: 0.8898 - precision: 0.8298 - recall: 0.7936\n","Epoch 16: Validation Metrics:\n","loss: 0.39844247698783875\n","val_binary_accuracy: 0.7291666865348816\n","val_precision: 0.39182692766189575\n","val_recall: 0.6245210766792297\n","val_auc: 0.7247709035873413\n","val_prc_auc: 0.4449303150177002\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8936 - binary_accuracy: 0.8135 - f1: 0.8112 - loss: 0.4116 - prc_auc: 0.8901 - precision: 0.8297 - recall: 0.7939 - val_auc: 0.7248 - val_binary_accuracy: 0.7292 - val_f1: 0.4815 - val_loss: 0.5928 - val_prc_auc: 0.4449 - val_precision: 0.3918 - val_recall: 0.6245\n","Epoch 17/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8940 - binary_accuracy: 0.8141 - f1: 0.8119 - loss: 0.4110 - prc_auc: 0.8905 - precision: 0.8299 - recall: 0.7952\n","Epoch 17: Validation Metrics:\n","loss: 0.397616982460022\n","val_binary_accuracy: 0.7291666865348816\n","val_precision: 0.39182692766189575\n","val_recall: 0.6245210766792297\n","val_auc: 0.7247375845909119\n","val_prc_auc: 0.44423288106918335\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - auc: 0.8942 - binary_accuracy: 0.8142 - f1: 0.8120 - loss: 0.4106 - prc_auc: 0.8908 - precision: 0.8297 - recall: 0.7955 - val_auc: 0.7247 - val_binary_accuracy: 0.7292 - val_f1: 0.4815 - val_loss: 0.5930 - val_prc_auc: 0.4442 - val_precision: 0.3918 - val_recall: 0.6245\n","Epoch 18/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8946 - binary_accuracy: 0.8144 - f1: 0.8122 - loss: 0.4101 - prc_auc: 0.8912 - precision: 0.8303 - recall: 0.7952\n","Epoch 18: Validation Metrics:\n","loss: 0.39683645963668823\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.38902148604393005\n","val_recall: 0.6245210766792297\n","val_auc: 0.7249486446380615\n","val_prc_auc: 0.44543248414993286\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8949 - binary_accuracy: 0.8145 - f1: 0.8123 - loss: 0.4097 - prc_auc: 0.8915 - precision: 0.8302 - recall: 0.7955 - val_auc: 0.7249 - val_binary_accuracy: 0.7269 - val_f1: 0.4794 - val_loss: 0.5932 - val_prc_auc: 0.4454 - val_precision: 0.3890 - val_recall: 0.6245\n","Epoch 19/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8951 - binary_accuracy: 0.8144 - f1: 0.8122 - loss: 0.4093 - prc_auc: 0.8919 - precision: 0.8303 - recall: 0.7952\n","Epoch 19: Validation Metrics:\n","loss: 0.3960956931114197\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.3895486891269684\n","val_recall: 0.6283524632453918\n","val_auc: 0.7250874638557434\n","val_prc_auc: 0.4470147490501404\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - auc: 0.8954 - binary_accuracy: 0.8145 - f1: 0.8123 - loss: 0.4089 - prc_auc: 0.8922 - precision: 0.8302 - recall: 0.7955 - val_auc: 0.7251 - val_binary_accuracy: 0.7269 - val_f1: 0.4809 - val_loss: 0.5935 - val_prc_auc: 0.4470 - val_precision: 0.3895 - val_recall: 0.6284\n","Epoch 20/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8955 - binary_accuracy: 0.8166 - f1: 0.8139 - loss: 0.4085 - prc_auc: 0.8926 - precision: 0.8346 - recall: 0.7946\n","Epoch 20: Validation Metrics:\n","loss: 0.39540648460388184\n","val_binary_accuracy: 0.7268518805503845\n","val_precision: 0.3895486891269684\n","val_recall: 0.6283524632453918\n","val_auc: 0.7252355813980103\n","val_prc_auc: 0.44780272245407104\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8958 - binary_accuracy: 0.8166 - f1: 0.8139 - loss: 0.4081 - prc_auc: 0.8929 - precision: 0.8344 - recall: 0.7948 - val_auc: 0.7252 - val_binary_accuracy: 0.7269 - val_f1: 0.4809 - val_loss: 0.5936 - val_prc_auc: 0.4478 - val_precision: 0.3895 - val_recall: 0.6284\n","Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - auc: 0.7420 - binary_accuracy: 0.6818 - f1: 0.7279 - loss: 0.6130 - prc_auc: 0.7436 - precision: 0.6555 - recall: 0.8214\n","Epoch 1: Validation Metrics:\n","loss: 0.5772278308868408\n","val_binary_accuracy: 0.595678985118866\n","val_precision: 0.4372881352901459\n","val_recall: 0.5733333230018616\n","val_auc: 0.6506592631340027\n","val_prc_auc: 0.4887133240699768\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 183ms/step - auc: 0.7423 - binary_accuracy: 0.6821 - f1: 0.7279 - loss: 0.6127 - prc_auc: 0.7439 - precision: 0.6557 - recall: 0.8210 - val_auc: 0.6507 - val_binary_accuracy: 0.5957 - val_f1: 0.4962 - val_loss: 0.6787 - val_prc_auc: 0.4887 - val_precision: 0.4373 - val_recall: 0.5733\n","Epoch 2/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8058 - binary_accuracy: 0.7257 - f1: 0.7341 - loss: 0.5390 - prc_auc: 0.8190 - precision: 0.7366 - recall: 0.7321\n","Epoch 2: Validation Metrics:\n","loss: 0.5410758852958679\n","val_binary_accuracy: 0.6064814925193787\n","val_precision: 0.4475524425506592\n","val_recall: 0.5688889026641846\n","val_auc: 0.6552101373672485\n","val_prc_auc: 0.4935489892959595\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8058 - binary_accuracy: 0.7257 - f1: 0.7341 - loss: 0.5390 - prc_auc: 0.8188 - precision: 0.7366 - recall: 0.7321 - val_auc: 0.6552 - val_binary_accuracy: 0.6065 - val_f1: 0.5010 - val_loss: 0.6846 - val_prc_auc: 0.4935 - val_precision: 0.4476 - val_recall: 0.5689\n","Epoch 3/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8111 - binary_accuracy: 0.7287 - f1: 0.7324 - loss: 0.5306 - prc_auc: 0.8248 - precision: 0.7484 - recall: 0.7176\n","Epoch 3: Validation Metrics:\n","loss: 0.5345017910003662\n","val_binary_accuracy: 0.6180555820465088\n","val_precision: 0.45945945382118225\n","val_recall: 0.5666666626930237\n","val_auc: 0.6570212841033936\n","val_prc_auc: 0.4950043559074402\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8111 - binary_accuracy: 0.7288 - f1: 0.7324 - loss: 0.5306 - prc_auc: 0.8247 - precision: 0.7483 - recall: 0.7176 - val_auc: 0.6570 - val_binary_accuracy: 0.6181 - val_f1: 0.5075 - val_loss: 0.6880 - val_prc_auc: 0.4950 - val_precision: 0.4595 - val_recall: 0.5667\n","Epoch 4/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8143 - binary_accuracy: 0.7329 - f1: 0.7352 - loss: 0.5261 - prc_auc: 0.8280 - precision: 0.7551 - recall: 0.7168\n","Epoch 4: Validation Metrics:\n","loss: 0.5307313203811646\n","val_binary_accuracy: 0.6195987462997437\n","val_precision: 0.46098002791404724\n","val_recall: 0.5644444227218628\n","val_auc: 0.6581180095672607\n","val_prc_auc: 0.4954998791217804\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8142 - binary_accuracy: 0.7329 - f1: 0.7351 - loss: 0.5262 - prc_auc: 0.8279 - precision: 0.7551 - recall: 0.7167 - val_auc: 0.6581 - val_binary_accuracy: 0.6196 - val_f1: 0.5075 - val_loss: 0.6905 - val_prc_auc: 0.4955 - val_precision: 0.4610 - val_recall: 0.5644\n","Epoch 5/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8165 - binary_accuracy: 0.7348 - f1: 0.7360 - loss: 0.5233 - prc_auc: 0.8300 - precision: 0.7594 - recall: 0.7145\n","Epoch 5: Validation Metrics:\n","loss: 0.5281888246536255\n","val_binary_accuracy: 0.6242284178733826\n","val_precision: 0.4660550355911255\n","val_recall: 0.5644444227218628\n","val_auc: 0.6587076187133789\n","val_prc_auc: 0.49772804975509644\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8164 - binary_accuracy: 0.7349 - f1: 0.7359 - loss: 0.5233 - prc_auc: 0.8299 - precision: 0.7593 - recall: 0.7145 - val_auc: 0.6587 - val_binary_accuracy: 0.6242 - val_f1: 0.5106 - val_loss: 0.6918 - val_prc_auc: 0.4977 - val_precision: 0.4661 - val_recall: 0.5644\n","Epoch 6/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8182 - binary_accuracy: 0.7358 - f1: 0.7364 - loss: 0.5211 - prc_auc: 0.8313 - precision: 0.7616 - recall: 0.7133\n","Epoch 6: Validation Metrics:\n","loss: 0.5261879563331604\n","val_binary_accuracy: 0.6257715821266174\n","val_precision: 0.46777164936065674\n","val_recall: 0.5644444227218628\n","val_auc: 0.6592185497283936\n","val_prc_auc: 0.49833574891090393\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8181 - binary_accuracy: 0.7358 - f1: 0.7364 - loss: 0.5212 - prc_auc: 0.8312 - precision: 0.7616 - recall: 0.7132 - val_auc: 0.6592 - val_binary_accuracy: 0.6258 - val_f1: 0.5116 - val_loss: 0.6927 - val_prc_auc: 0.4983 - val_precision: 0.4678 - val_recall: 0.5644\n","Epoch 7/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8196 - binary_accuracy: 0.7350 - f1: 0.7348 - loss: 0.5194 - prc_auc: 0.8326 - precision: 0.7625 - recall: 0.7097\n","Epoch 7: Validation Metrics:\n","loss: 0.524522602558136\n","val_binary_accuracy: 0.6257715821266174\n","val_precision: 0.46765249967575073\n","val_recall: 0.5622222423553467\n","val_auc: 0.659482479095459\n","val_prc_auc: 0.49905359745025635\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8196 - binary_accuracy: 0.7350 - f1: 0.7348 - loss: 0.5194 - prc_auc: 0.8324 - precision: 0.7625 - recall: 0.7096 - val_auc: 0.6595 - val_binary_accuracy: 0.6258 - val_f1: 0.5106 - val_loss: 0.6934 - val_prc_auc: 0.4991 - val_precision: 0.4677 - val_recall: 0.5622\n","Epoch 8/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8209 - binary_accuracy: 0.7348 - f1: 0.7342 - loss: 0.5179 - prc_auc: 0.8340 - precision: 0.7632 - recall: 0.7079\n","Epoch 8: Validation Metrics:\n","loss: 0.5230559706687927\n","val_binary_accuracy: 0.6280864477157593\n","val_precision: 0.47026023268699646\n","val_recall: 0.5622222423553467\n","val_auc: 0.659847617149353\n","val_prc_auc: 0.4992790222167969\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8209 - binary_accuracy: 0.7348 - f1: 0.7341 - loss: 0.5179 - prc_auc: 0.8339 - precision: 0.7632 - recall: 0.7079 - val_auc: 0.6598 - val_binary_accuracy: 0.6281 - val_f1: 0.5121 - val_loss: 0.6939 - val_prc_auc: 0.4993 - val_precision: 0.4703 - val_recall: 0.5622\n","Epoch 9/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8221 - binary_accuracy: 0.7364 - f1: 0.7355 - loss: 0.5166 - prc_auc: 0.8351 - precision: 0.7655 - recall: 0.7083\n","Epoch 9: Validation Metrics:\n","loss: 0.5217414498329163\n","val_binary_accuracy: 0.6273148059844971\n","val_precision: 0.46927374601364136\n","val_recall: 0.5600000023841858\n","val_auc: 0.6600262522697449\n","val_prc_auc: 0.498907208442688\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - auc: 0.8221 - binary_accuracy: 0.7364 - f1: 0.7354 - loss: 0.5166 - prc_auc: 0.8350 - precision: 0.7654 - recall: 0.7083 - val_auc: 0.6600 - val_binary_accuracy: 0.6273 - val_f1: 0.5106 - val_loss: 0.6944 - val_prc_auc: 0.4989 - val_precision: 0.4693 - val_recall: 0.5600\n","Epoch 10/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8231 - binary_accuracy: 0.7360 - f1: 0.7348 - loss: 0.5153 - prc_auc: 0.8360 - precision: 0.7654 - recall: 0.7072\n","Epoch 10: Validation Metrics:\n","loss: 0.520526647567749\n","val_binary_accuracy: 0.6257715821266174\n","val_precision: 0.4675324559211731\n","val_recall: 0.5600000023841858\n","val_auc: 0.6602981090545654\n","val_prc_auc: 0.5011765956878662\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8231 - binary_accuracy: 0.7360 - f1: 0.7348 - loss: 0.5154 - prc_auc: 0.8359 - precision: 0.7654 - recall: 0.7072 - val_auc: 0.6603 - val_binary_accuracy: 0.6258 - val_f1: 0.5096 - val_loss: 0.6947 - val_prc_auc: 0.5012 - val_precision: 0.4675 - val_recall: 0.5600\n","Epoch 11/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8244 - binary_accuracy: 0.7359 - f1: 0.7346 - loss: 0.5142 - prc_auc: 0.8374 - precision: 0.7656 - recall: 0.7067\n","Epoch 11: Validation Metrics:\n","loss: 0.519406259059906\n","val_binary_accuracy: 0.6257715821266174\n","val_precision: 0.4675324559211731\n","val_recall: 0.5600000023841858\n","val_auc: 0.6603598594665527\n","val_prc_auc: 0.5008726119995117\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - auc: 0.8243 - binary_accuracy: 0.7359 - f1: 0.7346 - loss: 0.5142 - prc_auc: 0.8373 - precision: 0.7655 - recall: 0.7067 - val_auc: 0.6604 - val_binary_accuracy: 0.6258 - val_f1: 0.5096 - val_loss: 0.6952 - val_prc_auc: 0.5009 - val_precision: 0.4675 - val_recall: 0.5600\n","Epoch 12/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8252 - binary_accuracy: 0.7362 - f1: 0.7349 - loss: 0.5131 - prc_auc: 0.8380 - precision: 0.7660 - recall: 0.7067\n","Epoch 12: Validation Metrics:\n","loss: 0.5183473825454712\n","val_binary_accuracy: 0.625\n","val_precision: 0.4665427505970001\n","val_recall: 0.5577777624130249\n","val_auc: 0.6607263088226318\n","val_prc_auc: 0.5024290680885315\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8252 - binary_accuracy: 0.7362 - f1: 0.7348 - loss: 0.5132 - prc_auc: 0.8379 - precision: 0.7660 - recall: 0.7066 - val_auc: 0.6607 - val_binary_accuracy: 0.6250 - val_f1: 0.5081 - val_loss: 0.6957 - val_prc_auc: 0.5024 - val_precision: 0.4665 - val_recall: 0.5578\n","Epoch 13/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8261 - binary_accuracy: 0.7378 - f1: 0.7365 - loss: 0.5121 - prc_auc: 0.8388 - precision: 0.7679 - recall: 0.7081\n","Epoch 13: Validation Metrics:\n","loss: 0.5173768401145935\n","val_binary_accuracy: 0.6257715821266174\n","val_precision: 0.4674115478992462\n","val_recall: 0.5577777624130249\n","val_auc: 0.660907506942749\n","val_prc_auc: 0.5026165246963501\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - auc: 0.8260 - binary_accuracy: 0.7379 - f1: 0.7364 - loss: 0.5122 - prc_auc: 0.8387 - precision: 0.7678 - recall: 0.7081 - val_auc: 0.6609 - val_binary_accuracy: 0.6258 - val_f1: 0.5086 - val_loss: 0.6959 - val_prc_auc: 0.5026 - val_precision: 0.4674 - val_recall: 0.5578\n","Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - auc: 0.7805 - binary_accuracy: 0.6802 - f1: 0.7483 - loss: 0.6049 - prc_auc: 0.7933 - precision: 0.6459 - recall: 0.8948\n","Epoch 1: Validation Metrics:\n","loss: 0.5450809597969055\n","val_binary_accuracy: 0.7569444179534912\n","val_precision: 0.41566264629364014\n","val_recall: 0.5328185558319092\n","val_auc: 0.7267473936080933\n","val_prc_auc: 0.4309345483779907\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 308ms/step - auc: 0.7814 - binary_accuracy: 0.6813 - f1: 0.7486 - loss: 0.6040 - prc_auc: 0.7940 - precision: 0.6468 - recall: 0.8941 - val_auc: 0.7267 - val_binary_accuracy: 0.7569 - val_f1: 0.4670 - val_loss: 0.5482 - val_prc_auc: 0.4309 - val_precision: 0.4157 - val_recall: 0.5328\n","Epoch 2/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8705 - binary_accuracy: 0.7945 - f1: 0.7947 - loss: 0.4624 - prc_auc: 0.8847 - precision: 0.8361 - recall: 0.7585\n","Epoch 2: Validation Metrics:\n","loss: 0.45177021622657776\n","val_binary_accuracy: 0.7623456716537476\n","val_precision: 0.42172524333000183\n","val_recall: 0.5096524953842163\n","val_auc: 0.728586733341217\n","val_prc_auc: 0.4354109466075897\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - auc: 0.8705 - binary_accuracy: 0.7946 - f1: 0.7947 - loss: 0.4623 - prc_auc: 0.8846 - precision: 0.8357 - recall: 0.7588 - val_auc: 0.7286 - val_binary_accuracy: 0.7623 - val_f1: 0.4615 - val_loss: 0.5425 - val_prc_auc: 0.4354 - val_precision: 0.4217 - val_recall: 0.5097\n","Epoch 3/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.8765 - binary_accuracy: 0.7933 - f1: 0.7914 - loss: 0.4463 - prc_auc: 0.8901 - precision: 0.8420 - recall: 0.7480\n","Epoch 3: Validation Metrics:\n","loss: 0.43782177567481995\n","val_binary_accuracy: 0.7646604776382446\n","val_precision: 0.4253246784210205\n","val_recall: 0.5057914853096008\n","val_auc: 0.7294039726257324\n","val_prc_auc: 0.4434288442134857\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8766 - binary_accuracy: 0.7934 - f1: 0.7914 - loss: 0.4461 - prc_auc: 0.8900 - precision: 0.8416 - recall: 0.7483 - val_auc: 0.7294 - val_binary_accuracy: 0.7647 - val_f1: 0.4621 - val_loss: 0.5462 - val_prc_auc: 0.4434 - val_precision: 0.4253 - val_recall: 0.5058\n","Epoch 4/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8813 - binary_accuracy: 0.8034 - f1: 0.8021 - loss: 0.4384 - prc_auc: 0.8933 - precision: 0.8502 - recall: 0.7601\n","Epoch 4: Validation Metrics:\n","loss: 0.43037328124046326\n","val_binary_accuracy: 0.7638888955116272\n","val_precision: 0.4239482283592224\n","val_recall: 0.5057914853096008\n","val_auc: 0.7298339605331421\n","val_prc_auc: 0.4435994327068329\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.8813 - binary_accuracy: 0.8034 - f1: 0.8021 - loss: 0.4383 - prc_auc: 0.8933 - precision: 0.8499 - recall: 0.7603 - val_auc: 0.7298 - val_binary_accuracy: 0.7639 - val_f1: 0.4613 - val_loss: 0.5500 - val_prc_auc: 0.4436 - val_precision: 0.4239 - val_recall: 0.5058\n","Epoch 5/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8848 - binary_accuracy: 0.8124 - f1: 0.8114 - loss: 0.4329 - prc_auc: 0.8960 - precision: 0.8590 - recall: 0.7697\n","Epoch 5: Validation Metrics:\n","loss: 0.4250941276550293\n","val_binary_accuracy: 0.7592592835426331\n","val_precision: 0.4158730208873749\n","val_recall: 0.5057914853096008\n","val_auc: 0.7301820516586304\n","val_prc_auc: 0.44655993580818176\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - auc: 0.8848 - binary_accuracy: 0.8124 - f1: 0.8114 - loss: 0.4327 - prc_auc: 0.8960 - precision: 0.8587 - recall: 0.7698 - val_auc: 0.7302 - val_binary_accuracy: 0.7593 - val_f1: 0.4564 - val_loss: 0.5538 - val_prc_auc: 0.4466 - val_precision: 0.4159 - val_recall: 0.5058\n","Epoch 6/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8871 - binary_accuracy: 0.8117 - f1: 0.8103 - loss: 0.4288 - prc_auc: 0.8975 - precision: 0.8597 - recall: 0.7670\n","Epoch 6: Validation Metrics:\n","loss: 0.42121434211730957\n","val_binary_accuracy: 0.7584876418113708\n","val_precision: 0.4150943458080292\n","val_recall: 0.5096524953842163\n","val_auc: 0.7301020622253418\n","val_prc_auc: 0.4439963400363922\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - auc: 0.8871 - binary_accuracy: 0.8117 - f1: 0.8102 - loss: 0.4287 - prc_auc: 0.8974 - precision: 0.8594 - recall: 0.7671 - val_auc: 0.7301 - val_binary_accuracy: 0.7585 - val_f1: 0.4575 - val_loss: 0.5570 - val_prc_auc: 0.4440 - val_precision: 0.4151 - val_recall: 0.5097\n","Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - auc: 0.8949 - binary_accuracy: 0.8340 - f1: 0.8413 - loss: 0.5926 - prc_auc: 0.8802 - precision: 0.8135 - recall: 0.8769\n","Epoch 1: Validation Metrics:\n","loss: 0.5177960991859436\n","val_binary_accuracy: 0.9243826866149902\n","val_precision: 0.5095541477203369\n","val_recall: 0.7920792102813721\n","val_auc: 0.929056704044342\n","val_prc_auc: 0.5519742965698242\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 612ms/step - auc: 0.8971 - binary_accuracy: 0.8364 - f1: 0.8434 - loss: 0.5898 - prc_auc: 0.8830 - precision: 0.8170 - recall: 0.8774 - val_auc: 0.9291 - val_binary_accuracy: 0.9244 - val_f1: 0.6202 - val_loss: 0.4417 - val_prc_auc: 0.5520 - val_precision: 0.5096 - val_recall: 0.7921\n","Epoch 2/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.9748 - binary_accuracy: 0.9350 - f1: 0.9308 - loss: 0.3451 - prc_auc: 0.9791 - precision: 0.9759 - recall: 0.8900\n","Epoch 2: Validation Metrics:\n","loss: 0.3097214996814728\n","val_binary_accuracy: 0.9228395223617554\n","val_precision: 0.5031446814537048\n","val_recall: 0.7920792102813721\n","val_auc: 0.9280874133110046\n","val_prc_auc: 0.5416415929794312\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9750 - binary_accuracy: 0.9353 - f1: 0.9312 - loss: 0.3425 - prc_auc: 0.9791 - precision: 0.9757 - recall: 0.8908 - val_auc: 0.9281 - val_binary_accuracy: 0.9228 - val_f1: 0.6154 - val_loss: 0.3349 - val_prc_auc: 0.5416 - val_precision: 0.5031 - val_recall: 0.7921\n","Epoch 3/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - auc: 0.9752 - binary_accuracy: 0.9350 - f1: 0.9308 - loss: 0.2489 - prc_auc: 0.9802 - precision: 0.9759 - recall: 0.8900\n","Epoch 3: Validation Metrics:\n","loss: 0.22996361553668976\n","val_binary_accuracy: 0.9205247163772583\n","val_precision: 0.4938271641731262\n","val_recall: 0.7920792102813721\n","val_auc: 0.9295910596847534\n","val_prc_auc: 0.5433320999145508\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - auc: 0.9755 - binary_accuracy: 0.9353 - f1: 0.9312 - loss: 0.2475 - prc_auc: 0.9804 - precision: 0.9757 - recall: 0.8908 - val_auc: 0.9296 - val_binary_accuracy: 0.9205 - val_f1: 0.6084 - val_loss: 0.2986 - val_prc_auc: 0.5433 - val_precision: 0.4938 - val_recall: 0.7921\n","Epoch 4/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9763 - binary_accuracy: 0.9372 - f1: 0.9332 - loss: 0.2096 - prc_auc: 0.9816 - precision: 0.9760 - recall: 0.8943\n","Epoch 4: Validation Metrics:\n","loss: 0.1966371238231659\n","val_binary_accuracy: 0.9189814925193787\n","val_precision: 0.4878048896789551\n","val_recall: 0.7920792102813721\n","val_auc: 0.9301462173461914\n","val_prc_auc: 0.5253262519836426\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - auc: 0.9765 - binary_accuracy: 0.9374 - f1: 0.9337 - loss: 0.2087 - prc_auc: 0.9817 - precision: 0.9758 - recall: 0.8952 - val_auc: 0.9301 - val_binary_accuracy: 0.9190 - val_f1: 0.6038 - val_loss: 0.2902 - val_prc_auc: 0.5253 - val_precision: 0.4878 - val_recall: 0.7921\n","Epoch 5/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9765 - binary_accuracy: 0.9408 - f1: 0.9373 - loss: 0.1910 - prc_auc: 0.9818 - precision: 0.9762 - recall: 0.9017\n","Epoch 5: Validation Metrics:\n","loss: 0.1804872751235962\n","val_binary_accuracy: 0.9166666865348816\n","val_precision: 0.4792899489402771\n","val_recall: 0.801980197429657\n","val_auc: 0.9314802289009094\n","val_prc_auc: 0.5298898220062256\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9768 - binary_accuracy: 0.9413 - f1: 0.9379 - loss: 0.1902 - prc_auc: 0.9819 - precision: 0.9760 - recall: 0.9029 - val_auc: 0.9315 - val_binary_accuracy: 0.9167 - val_f1: 0.6000 - val_loss: 0.2914 - val_prc_auc: 0.5299 - val_precision: 0.4793 - val_recall: 0.8020\n","Epoch 6/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.9768 - binary_accuracy: 0.9393 - f1: 0.9358 - loss: 0.1808 - prc_auc: 0.9819 - precision: 0.9730 - recall: 0.9017\n","Epoch 6: Validation Metrics:\n","loss: 0.17147667706012726\n","val_binary_accuracy: 0.9158950448036194\n","val_precision: 0.4767441749572754\n","val_recall: 0.8118811845779419\n","val_auc: 0.9315341114997864\n","val_prc_auc: 0.52631676197052\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - auc: 0.9770 - binary_accuracy: 0.9397 - f1: 0.9363 - loss: 0.1801 - prc_auc: 0.9820 - precision: 0.9727 - recall: 0.9029 - val_auc: 0.9315 - val_binary_accuracy: 0.9159 - val_f1: 0.6007 - val_loss: 0.2952 - val_prc_auc: 0.5263 - val_precision: 0.4767 - val_recall: 0.8119\n","Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - auc: 0.7392 - binary_accuracy: 0.6766 - f1: 0.7035 - loss: 0.6068 - prc_auc: 0.7498 - precision: 0.6689 - recall: 0.7435\n","Epoch 1: Validation Metrics:\n","loss: 0.5412088632583618\n","val_binary_accuracy: 0.7175925970077515\n","val_precision: 0.44501277804374695\n","val_recall: 0.5386996865272522\n","val_auc: 0.7039700150489807\n","val_prc_auc: 0.4924551546573639\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 283ms/step - auc: 0.7402 - binary_accuracy: 0.6775 - f1: 0.7042 - loss: 0.6060 - prc_auc: 0.7507 - precision: 0.6696 - recall: 0.7442 - val_auc: 0.7040 - val_binary_accuracy: 0.7176 - val_f1: 0.4874 - val_loss: 0.5745 - val_prc_auc: 0.4925 - val_precision: 0.4450 - val_recall: 0.5387\n","Epoch 2/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8722 - binary_accuracy: 0.7957 - f1: 0.7983 - loss: 0.4548 - prc_auc: 0.8770 - precision: 0.8131 - recall: 0.7843\n","Epoch 2: Validation Metrics:\n","loss: 0.45680806040763855\n","val_binary_accuracy: 0.7199074029922485\n","val_precision: 0.44736841320991516\n","val_recall: 0.5263158082962036\n","val_auc: 0.7068113684654236\n","val_prc_auc: 0.4965518116950989\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8722 - binary_accuracy: 0.7958 - f1: 0.7983 - loss: 0.4548 - prc_auc: 0.8769 - precision: 0.8130 - recall: 0.7844 - val_auc: 0.7068 - val_binary_accuracy: 0.7199 - val_f1: 0.4836 - val_loss: 0.5843 - val_prc_auc: 0.4966 - val_precision: 0.4474 - val_recall: 0.5263\n","Epoch 3/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8765 - binary_accuracy: 0.7976 - f1: 0.7994 - loss: 0.4427 - prc_auc: 0.8822 - precision: 0.8175 - recall: 0.7822\n","Epoch 3: Validation Metrics:\n","loss: 0.4479844272136688\n","val_binary_accuracy: 0.720678985118866\n","val_precision: 0.448548823595047\n","val_recall: 0.5263158082962036\n","val_auc: 0.7087189555168152\n","val_prc_auc: 0.49944964051246643\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8765 - binary_accuracy: 0.7976 - f1: 0.7994 - loss: 0.4428 - prc_auc: 0.8820 - precision: 0.8174 - recall: 0.7823 - val_auc: 0.7087 - val_binary_accuracy: 0.7207 - val_f1: 0.4843 - val_loss: 0.5874 - val_prc_auc: 0.4994 - val_precision: 0.4485 - val_recall: 0.5263\n","Epoch 4/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8788 - binary_accuracy: 0.8015 - f1: 0.8024 - loss: 0.4379 - prc_auc: 0.8842 - precision: 0.8247 - recall: 0.7814\n","Epoch 4: Validation Metrics:\n","loss: 0.443526029586792\n","val_binary_accuracy: 0.7222222089767456\n","val_precision: 0.45092839002609253\n","val_recall: 0.5263158082962036\n","val_auc: 0.7102224230766296\n","val_prc_auc: 0.4978533685207367\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8788 - binary_accuracy: 0.8016 - f1: 0.8024 - loss: 0.4380 - prc_auc: 0.8841 - precision: 0.8245 - recall: 0.7815 - val_auc: 0.7102 - val_binary_accuracy: 0.7222 - val_f1: 0.4857 - val_loss: 0.5886 - val_prc_auc: 0.4979 - val_precision: 0.4509 - val_recall: 0.5263\n","Epoch 5/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8805 - binary_accuracy: 0.8029 - f1: 0.8035 - loss: 0.4348 - prc_auc: 0.8859 - precision: 0.8269 - recall: 0.7814\n","Epoch 5: Validation Metrics:\n","loss: 0.4402940273284912\n","val_binary_accuracy: 0.7214506268501282\n","val_precision: 0.44946807622909546\n","val_recall: 0.5232198238372803\n","val_auc: 0.7112788558006287\n","val_prc_auc: 0.49483850598335266\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8805 - binary_accuracy: 0.8029 - f1: 0.8034 - loss: 0.4348 - prc_auc: 0.8857 - precision: 0.8268 - recall: 0.7815 - val_auc: 0.7113 - val_binary_accuracy: 0.7215 - val_f1: 0.4835 - val_loss: 0.5894 - val_prc_auc: 0.4948 - val_precision: 0.4495 - val_recall: 0.5232\n","Epoch 6/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8820 - binary_accuracy: 0.8033 - f1: 0.8035 - loss: 0.4324 - prc_auc: 0.8868 - precision: 0.8282 - recall: 0.7804\n","Epoch 6: Validation Metrics:\n","loss: 0.43772152066230774\n","val_binary_accuracy: 0.7214506268501282\n","val_precision: 0.4505208432674408\n","val_recall: 0.5356037020683289\n","val_auc: 0.7115142941474915\n","val_prc_auc: 0.49582234025001526\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8820 - binary_accuracy: 0.8033 - f1: 0.8035 - loss: 0.4324 - prc_auc: 0.8866 - precision: 0.8281 - recall: 0.7806 - val_auc: 0.7115 - val_binary_accuracy: 0.7215 - val_f1: 0.4894 - val_loss: 0.5905 - val_prc_auc: 0.4958 - val_precision: 0.4505 - val_recall: 0.5356\n","Epoch 7/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8831 - binary_accuracy: 0.8062 - f1: 0.8063 - loss: 0.4304 - prc_auc: 0.8867 - precision: 0.8313 - recall: 0.7828\n","Epoch 7: Validation Metrics:\n","loss: 0.4355829656124115\n","val_binary_accuracy: 0.7222222089767456\n","val_precision: 0.45169714093208313\n","val_recall: 0.5356037020683289\n","val_auc: 0.7129826545715332\n","val_prc_auc: 0.49526458978652954\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8831 - binary_accuracy: 0.8062 - f1: 0.8063 - loss: 0.4305 - prc_auc: 0.8865 - precision: 0.8311 - recall: 0.7829 - val_auc: 0.7130 - val_binary_accuracy: 0.7222 - val_f1: 0.4901 - val_loss: 0.5913 - val_prc_auc: 0.4953 - val_precision: 0.4517 - val_recall: 0.5356\n","Epoch 8/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8841 - binary_accuracy: 0.8070 - f1: 0.8073 - loss: 0.4287 - prc_auc: 0.8878 - precision: 0.8317 - recall: 0.7845\n","Epoch 8: Validation Metrics:\n","loss: 0.4337124228477478\n","val_binary_accuracy: 0.720678985118866\n","val_precision: 0.44935065507888794\n","val_recall: 0.5356037020683289\n","val_auc: 0.7129016518592834\n","val_prc_auc: 0.4947734773159027\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8840 - binary_accuracy: 0.8071 - f1: 0.8073 - loss: 0.4288 - prc_auc: 0.8877 - precision: 0.8315 - recall: 0.7846 - val_auc: 0.7129 - val_binary_accuracy: 0.7207 - val_f1: 0.4887 - val_loss: 0.5919 - val_prc_auc: 0.4948 - val_precision: 0.4494 - val_recall: 0.5356\n","Epoch 9/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8849 - binary_accuracy: 0.8066 - f1: 0.8068 - loss: 0.4272 - prc_auc: 0.8889 - precision: 0.8315 - recall: 0.7836\n","Epoch 9: Validation Metrics:\n","loss: 0.4320935010910034\n","val_binary_accuracy: 0.7199074029922485\n","val_precision: 0.4481865167617798\n","val_recall: 0.5356037020683289\n","val_auc: 0.7135921120643616\n","val_prc_auc: 0.4937936067581177\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8849 - binary_accuracy: 0.8066 - f1: 0.8068 - loss: 0.4273 - prc_auc: 0.8887 - precision: 0.8314 - recall: 0.7837 - val_auc: 0.7136 - val_binary_accuracy: 0.7199 - val_f1: 0.4880 - val_loss: 0.5927 - val_prc_auc: 0.4938 - val_precision: 0.4482 - val_recall: 0.5356\n","Epoch 10/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8857 - binary_accuracy: 0.8071 - f1: 0.8073 - loss: 0.4259 - prc_auc: 0.8900 - precision: 0.8321 - recall: 0.7840\n","Epoch 10: Validation Metrics:\n","loss: 0.4306437075138092\n","val_binary_accuracy: 0.7214506268501282\n","val_precision: 0.45077720284461975\n","val_recall: 0.5386996865272522\n","val_auc: 0.7137161493301392\n","val_prc_auc: 0.49432358145713806\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8856 - binary_accuracy: 0.8071 - f1: 0.8073 - loss: 0.4260 - prc_auc: 0.8899 - precision: 0.8320 - recall: 0.7841 - val_auc: 0.7137 - val_binary_accuracy: 0.7215 - val_f1: 0.4908 - val_loss: 0.5934 - val_prc_auc: 0.4943 - val_precision: 0.4508 - val_recall: 0.5387\n","Epoch 11/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8863 - binary_accuracy: 0.8089 - f1: 0.8093 - loss: 0.4248 - prc_auc: 0.8898 - precision: 0.8327 - recall: 0.7874\n","Epoch 11: Validation Metrics:\n","loss: 0.4293310344219208\n","val_binary_accuracy: 0.7214506268501282\n","val_precision: 0.4505208432674408\n","val_recall: 0.5356037020683289\n","val_auc: 0.7141919136047363\n","val_prc_auc: 0.4931974709033966\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8863 - binary_accuracy: 0.8089 - f1: 0.8093 - loss: 0.4248 - prc_auc: 0.8897 - precision: 0.8326 - recall: 0.7875 - val_auc: 0.7142 - val_binary_accuracy: 0.7215 - val_f1: 0.4894 - val_loss: 0.5940 - val_prc_auc: 0.4932 - val_precision: 0.4505 - val_recall: 0.5356\n","Epoch 12/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8869 - binary_accuracy: 0.8106 - f1: 0.8109 - loss: 0.4237 - prc_auc: 0.8904 - precision: 0.8355 - recall: 0.7877\n","Epoch 12: Validation Metrics:\n","loss: 0.4281308650970459\n","val_binary_accuracy: 0.7199074029922485\n","val_precision: 0.4479166567325592\n","val_recall: 0.5325077176094055\n","val_auc: 0.7144719362258911\n","val_prc_auc: 0.4925658106803894\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8869 - binary_accuracy: 0.8107 - f1: 0.8109 - loss: 0.4238 - prc_auc: 0.8903 - precision: 0.8354 - recall: 0.7878 - val_auc: 0.7145 - val_binary_accuracy: 0.7199 - val_f1: 0.4866 - val_loss: 0.5946 - val_prc_auc: 0.4926 - val_precision: 0.4479 - val_recall: 0.5325\n","Epoch 13/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8875 - binary_accuracy: 0.8133 - f1: 0.8134 - loss: 0.4227 - prc_auc: 0.8911 - precision: 0.8388 - recall: 0.7895\n","Epoch 13: Validation Metrics:\n","loss: 0.4270217716693878\n","val_binary_accuracy: 0.7199074029922485\n","val_precision: 0.4479166567325592\n","val_recall: 0.5325077176094055\n","val_auc: 0.7145593166351318\n","val_prc_auc: 0.49295055866241455\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8875 - binary_accuracy: 0.8133 - f1: 0.8133 - loss: 0.4228 - prc_auc: 0.8910 - precision: 0.8387 - recall: 0.7896 - val_auc: 0.7146 - val_binary_accuracy: 0.7199 - val_f1: 0.4866 - val_loss: 0.5954 - val_prc_auc: 0.4930 - val_precision: 0.4479 - val_recall: 0.5325\n","Epoch 14/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8881 - binary_accuracy: 0.8166 - f1: 0.8163 - loss: 0.4218 - prc_auc: 0.8921 - precision: 0.8433 - recall: 0.7909\n","Epoch 14: Validation Metrics:\n","loss: 0.426006942987442\n","val_binary_accuracy: 0.7191358208656311\n","val_precision: 0.44675323367118835\n","val_recall: 0.5325077176094055\n","val_auc: 0.7146787047386169\n","val_prc_auc: 0.49233007431030273\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - auc: 0.8881 - binary_accuracy: 0.8166 - f1: 0.8162 - loss: 0.4218 - prc_auc: 0.8919 - precision: 0.8432 - recall: 0.7910 - val_auc: 0.7147 - val_binary_accuracy: 0.7191 - val_f1: 0.4859 - val_loss: 0.5960 - val_prc_auc: 0.4923 - val_precision: 0.4468 - val_recall: 0.5325\n","Epoch 15/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8886 - binary_accuracy: 0.8188 - f1: 0.8187 - loss: 0.4209 - prc_auc: 0.8926 - precision: 0.8440 - recall: 0.7949\n","Epoch 15: Validation Metrics:\n","loss: 0.42507404088974\n","val_binary_accuracy: 0.7191358208656311\n","val_precision: 0.44675323367118835\n","val_recall: 0.5325077176094055\n","val_auc: 0.7146086692810059\n","val_prc_auc: 0.491630494594574\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - auc: 0.8885 - binary_accuracy: 0.8188 - f1: 0.8186 - loss: 0.4210 - prc_auc: 0.8925 - precision: 0.8438 - recall: 0.7950 - val_auc: 0.7146 - val_binary_accuracy: 0.7191 - val_f1: 0.4859 - val_loss: 0.5966 - val_prc_auc: 0.4916 - val_precision: 0.4468 - val_recall: 0.5325\n","Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - auc: 0.6838 - binary_accuracy: 0.6412 - f1: 0.6609 - loss: 0.6416 - prc_auc: 0.6921 - precision: 0.6306 - recall: 0.6965\n","Epoch 1: Validation Metrics:\n","loss: 0.5603649020195007\n","val_binary_accuracy: 0.8873456716537476\n","val_precision: 0.4644808769226074\n","val_recall: 0.6390977501869202\n","val_auc: 0.8159704804420471\n","val_prc_auc: 0.4306296408176422\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 620ms/step - auc: 0.6892 - binary_accuracy: 0.6455 - f1: 0.6647 - loss: 0.6393 - prc_auc: 0.6978 - precision: 0.6350 - recall: 0.6996 - val_auc: 0.8160 - val_binary_accuracy: 0.8873 - val_f1: 0.5380 - val_loss: 0.4548 - val_prc_auc: 0.4306 - val_precision: 0.4645 - val_recall: 0.6391\n","Epoch 2/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9279 - binary_accuracy: 0.8820 - f1: 0.8733 - loss: 0.3952 - prc_auc: 0.9439 - precision: 0.9229 - recall: 0.8289\n","Epoch 2: Validation Metrics:\n","loss: 0.36730313301086426\n","val_binary_accuracy: 0.8935185074806213\n","val_precision: 0.48554912209510803\n","val_recall: 0.6315789222717285\n","val_auc: 0.8171277642250061\n","val_prc_auc: 0.4235188066959381\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - auc: 0.9281 - binary_accuracy: 0.8822 - f1: 0.8737 - loss: 0.3936 - prc_auc: 0.9440 - precision: 0.9230 - recall: 0.8296 - val_auc: 0.8171 - val_binary_accuracy: 0.8935 - val_f1: 0.5490 - val_loss: 0.3714 - val_prc_auc: 0.4235 - val_precision: 0.4855 - val_recall: 0.6316\n","Epoch 3/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9336 - binary_accuracy: 0.8786 - f1: 0.8704 - loss: 0.3254 - prc_auc: 0.9485 - precision: 0.9143 - recall: 0.8306\n","Epoch 3: Validation Metrics:\n","loss: 0.31248870491981506\n","val_binary_accuracy: 0.8935185074806213\n","val_precision: 0.48554912209510803\n","val_recall: 0.6315789222717285\n","val_auc: 0.8173443078994751\n","val_prc_auc: 0.4253678321838379\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc: 0.9337 - binary_accuracy: 0.8791 - f1: 0.8710 - loss: 0.3247 - prc_auc: 0.9485 - precision: 0.9149 - recall: 0.8311 - val_auc: 0.8173 - val_binary_accuracy: 0.8935 - val_f1: 0.5490 - val_loss: 0.3539 - val_prc_auc: 0.4254 - val_precision: 0.4855 - val_recall: 0.6316\n","Epoch 4/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9372 - binary_accuracy: 0.8825 - f1: 0.8745 - loss: 0.3037 - prc_auc: 0.9504 - precision: 0.9182 - recall: 0.8348\n","Epoch 4: Validation Metrics:\n","loss: 0.29439738392829895\n","val_binary_accuracy: 0.8927469253540039\n","val_precision: 0.48275861144065857\n","val_recall: 0.6315789222717285\n","val_auc: 0.8156925439834595\n","val_prc_auc: 0.41981014609336853\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - auc: 0.9373 - binary_accuracy: 0.8828 - f1: 0.8750 - loss: 0.3032 - prc_auc: 0.9504 - precision: 0.9187 - recall: 0.8353 - val_auc: 0.8157 - val_binary_accuracy: 0.8927 - val_f1: 0.5472 - val_loss: 0.3536 - val_prc_auc: 0.4198 - val_precision: 0.4828 - val_recall: 0.6316\n","Epoch 5/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9405 - binary_accuracy: 0.8827 - f1: 0.8747 - loss: 0.2951 - prc_auc: 0.9526 - precision: 0.9187 - recall: 0.8348\n","Epoch 5: Validation Metrics:\n","loss: 0.286624938249588\n","val_binary_accuracy: 0.8927469253540039\n","val_precision: 0.48275861144065857\n","val_recall: 0.6315789222717285\n","val_auc: 0.8133844137191772\n","val_prc_auc: 0.42505374550819397\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - auc: 0.9405 - binary_accuracy: 0.8831 - f1: 0.8753 - loss: 0.2946 - prc_auc: 0.9526 - precision: 0.9193 - recall: 0.8353 - val_auc: 0.8134 - val_binary_accuracy: 0.8927 - val_f1: 0.5472 - val_loss: 0.3568 - val_prc_auc: 0.4251 - val_precision: 0.4828 - val_recall: 0.6316\n","Epoch 6/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9424 - binary_accuracy: 0.8876 - f1: 0.8793 - loss: 0.2907 - prc_auc: 0.9536 - precision: 0.9290 - recall: 0.8348\n","Epoch 6: Validation Metrics:\n","loss: 0.28235408663749695\n","val_binary_accuracy: 0.8935185074806213\n","val_precision: 0.48554912209510803\n","val_recall: 0.6315789222717285\n","val_auc: 0.8123889565467834\n","val_prc_auc: 0.4274159371852875\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc: 0.9423 - binary_accuracy: 0.8879 - f1: 0.8798 - loss: 0.2902 - prc_auc: 0.9536 - precision: 0.9294 - recall: 0.8353 - val_auc: 0.8124 - val_binary_accuracy: 0.8935 - val_f1: 0.5490 - val_loss: 0.3603 - val_prc_auc: 0.4274 - val_precision: 0.4855 - val_recall: 0.6316\n","Epoch 7/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9432 - binary_accuracy: 0.8876 - f1: 0.8793 - loss: 0.2879 - prc_auc: 0.9542 - precision: 0.9290 - recall: 0.8348\n","Epoch 7: Validation Metrics:\n","loss: 0.2795218825340271\n","val_binary_accuracy: 0.8935185074806213\n","val_precision: 0.48554912209510803\n","val_recall: 0.6315789222717285\n","val_auc: 0.8116486072540283\n","val_prc_auc: 0.41824471950531006\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - auc: 0.9431 - binary_accuracy: 0.8879 - f1: 0.8798 - loss: 0.2874 - prc_auc: 0.9543 - precision: 0.9294 - recall: 0.8353 - val_auc: 0.8116 - val_binary_accuracy: 0.8935 - val_f1: 0.5490 - val_loss: 0.3632 - val_prc_auc: 0.4182 - val_precision: 0.4855 - val_recall: 0.6316\n","Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - auc: 0.7192 - binary_accuracy: 0.6582 - f1: 0.6359 - loss: 0.6191 - prc_auc: 0.7015 - precision: 0.6498 - recall: 0.6297\n","Epoch 1: Validation Metrics:\n","loss: 0.5736820101737976\n","val_binary_accuracy: 0.6851851940155029\n","val_precision: 0.5341726541519165\n","val_recall: 0.665919303894043\n","val_auc: 0.739506721496582\n","val_prc_auc: 0.5901496410369873\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 216ms/step - auc: 0.7198 - binary_accuracy: 0.6587 - f1: 0.6366 - loss: 0.6187 - prc_auc: 0.7021 - precision: 0.6504 - recall: 0.6304 - val_auc: 0.7395 - val_binary_accuracy: 0.6852 - val_f1: 0.5928 - val_loss: 0.6044 - val_prc_auc: 0.5901 - val_precision: 0.5342 - val_recall: 0.6659\n","Epoch 2/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8153 - binary_accuracy: 0.7541 - f1: 0.7488 - loss: 0.5277 - prc_auc: 0.8033 - precision: 0.7496 - recall: 0.7483\n","Epoch 2: Validation Metrics:\n","loss: 0.5266647338867188\n","val_binary_accuracy: 0.6851851940155029\n","val_precision: 0.5345454812049866\n","val_recall: 0.6591928005218506\n","val_auc: 0.7471010088920593\n","val_prc_auc: 0.6036263108253479\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - auc: 0.8153 - binary_accuracy: 0.7541 - f1: 0.7489 - loss: 0.5277 - prc_auc: 0.8034 - precision: 0.7497 - recall: 0.7482 - val_auc: 0.7471 - val_binary_accuracy: 0.6852 - val_f1: 0.5904 - val_loss: 0.6009 - val_prc_auc: 0.6036 - val_precision: 0.5345 - val_recall: 0.6592\n","Epoch 3/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8251 - binary_accuracy: 0.7592 - f1: 0.7533 - loss: 0.5154 - prc_auc: 0.8184 - precision: 0.7560 - recall: 0.7507\n","Epoch 3: Validation Metrics:\n","loss: 0.5168542265892029\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5419707894325256\n","val_recall: 0.665919303894043\n","val_auc: 0.7497625946998596\n","val_prc_auc: 0.607602596282959\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8251 - binary_accuracy: 0.7591 - f1: 0.7533 - loss: 0.5154 - prc_auc: 0.8184 - precision: 0.7561 - recall: 0.7506 - val_auc: 0.7498 - val_binary_accuracy: 0.6914 - val_f1: 0.5976 - val_loss: 0.6012 - val_prc_auc: 0.6076 - val_precision: 0.5420 - val_recall: 0.6659\n","Epoch 4/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8305 - binary_accuracy: 0.7628 - f1: 0.7558 - loss: 0.5085 - prc_auc: 0.8257 - precision: 0.7621 - recall: 0.7497\n","Epoch 4: Validation Metrics:\n","loss: 0.5109900832176208\n","val_binary_accuracy: 0.6944444179534912\n","val_precision: 0.5461254715919495\n","val_recall: 0.6636771559715271\n","val_auc: 0.7513479590415955\n","val_prc_auc: 0.6096601486206055\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8305 - binary_accuracy: 0.7627 - f1: 0.7558 - loss: 0.5086 - prc_auc: 0.8257 - precision: 0.7622 - recall: 0.7497 - val_auc: 0.7513 - val_binary_accuracy: 0.6944 - val_f1: 0.5992 - val_loss: 0.6024 - val_prc_auc: 0.6097 - val_precision: 0.5461 - val_recall: 0.6637\n","Epoch 5/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8342 - binary_accuracy: 0.7645 - f1: 0.7578 - loss: 0.5039 - prc_auc: 0.8312 - precision: 0.7636 - recall: 0.7522\n","Epoch 5: Validation Metrics:\n","loss: 0.506904661655426\n","val_binary_accuracy: 0.6921296119689941\n","val_precision: 0.5432780981063843\n","val_recall: 0.6614349484443665\n","val_auc: 0.7517739534378052\n","val_prc_auc: 0.6103227734565735\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - auc: 0.8341 - binary_accuracy: 0.7645 - f1: 0.7578 - loss: 0.5040 - prc_auc: 0.8312 - precision: 0.7637 - recall: 0.7521 - val_auc: 0.7518 - val_binary_accuracy: 0.6921 - val_f1: 0.5966 - val_loss: 0.6037 - val_prc_auc: 0.6103 - val_precision: 0.5433 - val_recall: 0.6614\n","Epoch 6/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8366 - binary_accuracy: 0.7650 - f1: 0.7571 - loss: 0.5006 - prc_auc: 0.8341 - precision: 0.7668 - recall: 0.7478\n","Epoch 6: Validation Metrics:\n","loss: 0.5038343667984009\n","val_binary_accuracy: 0.6921296119689941\n","val_precision: 0.5432780981063843\n","val_recall: 0.6614349484443665\n","val_auc: 0.7525626420974731\n","val_prc_auc: 0.6113123893737793\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8365 - binary_accuracy: 0.7650 - f1: 0.7572 - loss: 0.5006 - prc_auc: 0.8341 - precision: 0.7669 - recall: 0.7478 - val_auc: 0.7526 - val_binary_accuracy: 0.6921 - val_f1: 0.5966 - val_loss: 0.6051 - val_prc_auc: 0.6113 - val_precision: 0.5433 - val_recall: 0.6614\n","Epoch 7/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8385 - binary_accuracy: 0.7658 - f1: 0.7580 - loss: 0.4979 - prc_auc: 0.8367 - precision: 0.7677 - recall: 0.7487\n","Epoch 7: Validation Metrics:\n","loss: 0.5013909339904785\n","val_binary_accuracy: 0.6929012537002563\n","val_precision: 0.544280469417572\n","val_recall: 0.6614349484443665\n","val_auc: 0.7531706690788269\n","val_prc_auc: 0.6093206405639648\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - auc: 0.8384 - binary_accuracy: 0.7658 - f1: 0.7581 - loss: 0.4980 - prc_auc: 0.8367 - precision: 0.7678 - recall: 0.7487 - val_auc: 0.7532 - val_binary_accuracy: 0.6929 - val_f1: 0.5972 - val_loss: 0.6062 - val_prc_auc: 0.6093 - val_precision: 0.5443 - val_recall: 0.6614\n","Epoch 8/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8403 - binary_accuracy: 0.7666 - f1: 0.7588 - loss: 0.4957 - prc_auc: 0.8389 - precision: 0.7687 - recall: 0.7492\n","Epoch 8: Validation Metrics:\n","loss: 0.4993109107017517\n","val_binary_accuracy: 0.6959876418113708\n","val_precision: 0.5485074520111084\n","val_recall: 0.6591928005218506\n","val_auc: 0.75330650806427\n","val_prc_auc: 0.6098039150238037\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8403 - binary_accuracy: 0.7666 - f1: 0.7588 - loss: 0.4958 - prc_auc: 0.8389 - precision: 0.7688 - recall: 0.7492 - val_auc: 0.7533 - val_binary_accuracy: 0.6960 - val_f1: 0.5988 - val_loss: 0.6073 - val_prc_auc: 0.6098 - val_precision: 0.5485 - val_recall: 0.6592\n","Epoch 9/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8418 - binary_accuracy: 0.7672 - f1: 0.7593 - loss: 0.4938 - prc_auc: 0.8407 - precision: 0.7694 - recall: 0.7497\n","Epoch 9: Validation Metrics:\n","loss: 0.4975110590457916\n","val_binary_accuracy: 0.6952160596847534\n","val_precision: 0.5473098158836365\n","val_recall: 0.6614349484443665\n","val_auc: 0.7533724308013916\n","val_prc_auc: 0.6098070740699768\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - auc: 0.8417 - binary_accuracy: 0.7672 - f1: 0.7594 - loss: 0.4938 - prc_auc: 0.8407 - precision: 0.7695 - recall: 0.7497 - val_auc: 0.7534 - val_binary_accuracy: 0.6952 - val_f1: 0.5990 - val_loss: 0.6085 - val_prc_auc: 0.6098 - val_precision: 0.5473 - val_recall: 0.6614\n","Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - auc: 0.3874 - binary_accuracy: 0.3753 - f1: 0.3258 - loss: 0.7071 - prc_auc: 0.4617 - precision: 0.3332 - recall: 0.3189\n","Epoch 1: Validation Metrics:\n","loss: 0.6535711884498596\n","val_binary_accuracy: 0.9552469253540039\n","val_precision: 0.4193548262119293\n","val_recall: 0.5416666865348816\n","val_auc: 0.8307541608810425\n","val_prc_auc: 0.4360606372356415\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - auc: 0.4143 - binary_accuracy: 0.3950 - f1: 0.3490 - loss: 0.7030 - prc_auc: 0.4850 - precision: 0.3564 - recall: 0.3421 - val_auc: 0.8308 - val_binary_accuracy: 0.9552 - val_f1: 0.4727 - val_loss: 0.5575 - val_prc_auc: 0.4361 - val_precision: 0.4194 - val_recall: 0.5417\n","Epoch 2/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.9634 - binary_accuracy: 0.9573 - f1: 0.9544 - loss: 0.5108 - prc_auc: 0.9657 - precision: 0.9826 - recall: 0.9278\n","Epoch 2: Validation Metrics:\n","loss: 0.4728429317474365\n","val_binary_accuracy: 0.9660493731498718\n","val_precision: 0.5416666865348816\n","val_recall: 0.5416666865348816\n","val_auc: 0.8170989751815796\n","val_prc_auc: 0.49972373247146606\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - auc: 0.9642 - binary_accuracy: 0.9562 - f1: 0.9535 - loss: 0.5050 - prc_auc: 0.9673 - precision: 0.9818 - recall: 0.9267 - val_auc: 0.8171 - val_binary_accuracy: 0.9660 - val_f1: 0.5417 - val_loss: 0.4324 - val_prc_auc: 0.4997 - val_precision: 0.5417 - val_recall: 0.5417\n","Epoch 3/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.9737 - binary_accuracy: 0.9565 - f1: 0.9534 - loss: 0.3792 - prc_auc: 0.9765 - precision: 0.9825 - recall: 0.9260\n","Epoch 3: Validation Metrics:\n","loss: 0.3571641147136688\n","val_binary_accuracy: 0.966821014881134\n","val_precision: 0.5531914830207825\n","val_recall: 0.5416666865348816\n","val_auc: 0.8065904974937439\n","val_prc_auc: 0.5059360861778259\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - auc: 0.9736 - binary_accuracy: 0.9551 - f1: 0.9522 - loss: 0.3758 - prc_auc: 0.9771 - precision: 0.9817 - recall: 0.9245 - val_auc: 0.8066 - val_binary_accuracy: 0.9668 - val_f1: 0.5474 - val_loss: 0.3455 - val_prc_auc: 0.5059 - val_precision: 0.5532 - val_recall: 0.5417\n","Epoch 4/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9771 - binary_accuracy: 0.9562 - f1: 0.9531 - loss: 0.2968 - prc_auc: 0.9806 - precision: 0.9825 - recall: 0.9255\n","Epoch 4: Validation Metrics:\n","loss: 0.28610023856163025\n","val_binary_accuracy: 0.966821014881134\n","val_precision: 0.5531914830207825\n","val_recall: 0.5416666865348816\n","val_auc: 0.800706148147583\n","val_prc_auc: 0.5050375461578369\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - auc: 0.9767 - binary_accuracy: 0.9544 - f1: 0.9515 - loss: 0.2951 - prc_auc: 0.9807 - precision: 0.9817 - recall: 0.9232 - val_auc: 0.8007 - val_binary_accuracy: 0.9668 - val_f1: 0.5474 - val_loss: 0.2871 - val_prc_auc: 0.5050 - val_precision: 0.5532 - val_recall: 0.5417\n","Epoch 5/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9786 - binary_accuracy: 0.9562 - f1: 0.9531 - loss: 0.2456 - prc_auc: 0.9830 - precision: 0.9825 - recall: 0.9255\n","Epoch 5: Validation Metrics:\n","loss: 0.2424650937318802\n","val_binary_accuracy: 0.966821014881134\n","val_precision: 0.5531914830207825\n","val_recall: 0.5416666865348816\n","val_auc: 0.793461263179779\n","val_prc_auc: 0.5027640461921692\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - auc: 0.9782 - binary_accuracy: 0.9544 - f1: 0.9515 - loss: 0.2452 - prc_auc: 0.9829 - precision: 0.9817 - recall: 0.9232 - val_auc: 0.7935 - val_binary_accuracy: 0.9668 - val_f1: 0.5474 - val_loss: 0.2485 - val_prc_auc: 0.5028 - val_precision: 0.5532 - val_recall: 0.5417\n","Epoch 6/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9796 - binary_accuracy: 0.9562 - f1: 0.9531 - loss: 0.2132 - prc_auc: 0.9837 - precision: 0.9825 - recall: 0.9255\n","Epoch 6: Validation Metrics:\n","loss: 0.21488338708877563\n","val_binary_accuracy: 0.966821014881134\n","val_precision: 0.5531914830207825\n","val_recall: 0.5416666865348816\n","val_auc: 0.7911158204078674\n","val_prc_auc: 0.5096386671066284\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - auc: 0.9792 - binary_accuracy: 0.9544 - f1: 0.9515 - loss: 0.2135 - prc_auc: 0.9836 - precision: 0.9817 - recall: 0.9232 - val_auc: 0.7911 - val_binary_accuracy: 0.9668 - val_f1: 0.5474 - val_loss: 0.2229 - val_prc_auc: 0.5096 - val_precision: 0.5532 - val_recall: 0.5417\n","Epoch 7/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9804 - binary_accuracy: 0.9565 - f1: 0.9534 - loss: 0.1921 - prc_auc: 0.9843 - precision: 0.9825 - recall: 0.9260\n","Epoch 7: Validation Metrics:\n","loss: 0.19686537981033325\n","val_binary_accuracy: 0.9660493731498718\n","val_precision: 0.5416666865348816\n","val_recall: 0.5416666865348816\n","val_auc: 0.7871344089508057\n","val_prc_auc: 0.508266270160675\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - auc: 0.9801 - binary_accuracy: 0.9551 - f1: 0.9522 - loss: 0.1928 - prc_auc: 0.9842 - precision: 0.9817 - recall: 0.9245 - val_auc: 0.7871 - val_binary_accuracy: 0.9660 - val_f1: 0.5417 - val_loss: 0.2059 - val_prc_auc: 0.5083 - val_precision: 0.5417 - val_recall: 0.5417\n","Epoch 8/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.9812 - binary_accuracy: 0.9570 - f1: 0.9540 - loss: 0.1778 - prc_auc: 0.9846 - precision: 0.9825 - recall: 0.9271\n","Epoch 8: Validation Metrics:\n","loss: 0.1845748871564865\n","val_binary_accuracy: 0.9660493731498718\n","val_precision: 0.5416666865348816\n","val_recall: 0.5416666865348816\n","val_auc: 0.7792134284973145\n","val_prc_auc: 0.5083752870559692\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - auc: 0.9809 - binary_accuracy: 0.9559 - f1: 0.9532 - loss: 0.1788 - prc_auc: 0.9845 - precision: 0.9818 - recall: 0.9262 - val_auc: 0.7792 - val_binary_accuracy: 0.9660 - val_f1: 0.5417 - val_loss: 0.1944 - val_prc_auc: 0.5084 - val_precision: 0.5417 - val_recall: 0.5417\n","Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - auc: 0.7415 - binary_accuracy: 0.6778 - f1: 0.6353 - loss: 0.6203 - prc_auc: 0.7260 - precision: 0.7204 - recall: 0.5730\n","Epoch 1: Validation Metrics:\n","loss: 0.582736611366272\n","val_binary_accuracy: 0.6288580298423767\n","val_precision: 0.46393442153930664\n","val_recall: 0.6475972533226013\n","val_auc: 0.6926538944244385\n","val_prc_auc: 0.49857693910598755\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 211ms/step - auc: 0.7418 - binary_accuracy: 0.6781 - f1: 0.6358 - loss: 0.6200 - prc_auc: 0.7264 - precision: 0.7205 - recall: 0.5737 - val_auc: 0.6927 - val_binary_accuracy: 0.6289 - val_f1: 0.5406 - val_loss: 0.6771 - val_prc_auc: 0.4986 - val_precision: 0.4639 - val_recall: 0.6476\n","Epoch 2/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8020 - binary_accuracy: 0.7259 - f1: 0.7046 - loss: 0.5454 - prc_auc: 0.7932 - precision: 0.7582 - recall: 0.6587\n","Epoch 2: Validation Metrics:\n","loss: 0.5380746126174927\n","val_binary_accuracy: 0.6211419701576233\n","val_precision: 0.45768025517463684\n","val_recall: 0.6681922078132629\n","val_auc: 0.6983055472373962\n","val_prc_auc: 0.49980273842811584\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8021 - binary_accuracy: 0.7260 - f1: 0.7048 - loss: 0.5453 - prc_auc: 0.7934 - precision: 0.7582 - recall: 0.6591 - val_auc: 0.6983 - val_binary_accuracy: 0.6211 - val_f1: 0.5433 - val_loss: 0.6937 - val_prc_auc: 0.4998 - val_precision: 0.4577 - val_recall: 0.6682\n","Epoch 3/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8133 - binary_accuracy: 0.7307 - f1: 0.7114 - loss: 0.5311 - prc_auc: 0.8043 - precision: 0.7610 - recall: 0.6683\n","Epoch 3: Validation Metrics:\n","loss: 0.5264645218849182\n","val_binary_accuracy: 0.6172839403152466\n","val_precision: 0.45550528168678284\n","val_recall: 0.6910755038261414\n","val_auc: 0.7002634406089783\n","val_prc_auc: 0.5034500956535339\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8134 - binary_accuracy: 0.7309 - f1: 0.7117 - loss: 0.5310 - prc_auc: 0.8044 - precision: 0.7611 - recall: 0.6688 - val_auc: 0.7003 - val_binary_accuracy: 0.6173 - val_f1: 0.5491 - val_loss: 0.7033 - val_prc_auc: 0.5035 - val_precision: 0.4555 - val_recall: 0.6911\n","Epoch 4/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8191 - binary_accuracy: 0.7388 - f1: 0.7224 - loss: 0.5237 - prc_auc: 0.8112 - precision: 0.7653 - recall: 0.6846\n","Epoch 4: Validation Metrics:\n","loss: 0.5201971530914307\n","val_binary_accuracy: 0.6165123581886292\n","val_precision: 0.4552238881587982\n","val_recall: 0.6979405283927917\n","val_auc: 0.7009161114692688\n","val_prc_auc: 0.5049306154251099\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8191 - binary_accuracy: 0.7389 - f1: 0.7226 - loss: 0.5236 - prc_auc: 0.8113 - precision: 0.7653 - recall: 0.6850 - val_auc: 0.7009 - val_binary_accuracy: 0.6165 - val_f1: 0.5510 - val_loss: 0.7086 - val_prc_auc: 0.5049 - val_precision: 0.4552 - val_recall: 0.6979\n","Epoch 5/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8228 - binary_accuracy: 0.7430 - f1: 0.7289 - loss: 0.5187 - prc_auc: 0.8167 - precision: 0.7661 - recall: 0.6956\n","Epoch 5: Validation Metrics:\n","loss: 0.5159826278686523\n","val_binary_accuracy: 0.6134259104728699\n","val_precision: 0.4528023600578308\n","val_recall: 0.7025171518325806\n","val_auc: 0.7015674710273743\n","val_prc_auc: 0.5046399235725403\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8228 - binary_accuracy: 0.7430 - f1: 0.7290 - loss: 0.5187 - prc_auc: 0.8168 - precision: 0.7660 - recall: 0.6959 - val_auc: 0.7016 - val_binary_accuracy: 0.6134 - val_f1: 0.5507 - val_loss: 0.7124 - val_prc_auc: 0.5046 - val_precision: 0.4528 - val_recall: 0.7025\n","Epoch 6/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.8255 - binary_accuracy: 0.7429 - f1: 0.7299 - loss: 0.5150 - prc_auc: 0.8214 - precision: 0.7640 - recall: 0.6991\n","Epoch 6: Validation Metrics:\n","loss: 0.5128545165061951\n","val_binary_accuracy: 0.6095678806304932\n","val_precision: 0.449487566947937\n","val_recall: 0.7025171518325806\n","val_auc: 0.7024386525154114\n","val_prc_auc: 0.5066330432891846\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8256 - binary_accuracy: 0.7430 - f1: 0.7301 - loss: 0.5150 - prc_auc: 0.8214 - precision: 0.7640 - recall: 0.6994 - val_auc: 0.7024 - val_binary_accuracy: 0.6096 - val_f1: 0.5482 - val_loss: 0.7150 - val_prc_auc: 0.5066 - val_precision: 0.4495 - val_recall: 0.7025\n","Epoch 7/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8279 - binary_accuracy: 0.7448 - f1: 0.7338 - loss: 0.5121 - prc_auc: 0.8251 - precision: 0.7624 - recall: 0.7076\n","Epoch 7: Validation Metrics:\n","loss: 0.5103947520256042\n","val_binary_accuracy: 0.6141975522041321\n","val_precision: 0.4540145993232727\n","val_recall: 0.711670458316803\n","val_auc: 0.7030072808265686\n","val_prc_auc: 0.5055923461914062\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8280 - binary_accuracy: 0.7449 - f1: 0.7339 - loss: 0.5120 - prc_auc: 0.8251 - precision: 0.7623 - recall: 0.7079 - val_auc: 0.7030 - val_binary_accuracy: 0.6142 - val_f1: 0.5544 - val_loss: 0.7171 - val_prc_auc: 0.5056 - val_precision: 0.4540 - val_recall: 0.7117\n","Epoch 8/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8298 - binary_accuracy: 0.7455 - f1: 0.7353 - loss: 0.5097 - prc_auc: 0.8283 - precision: 0.7615 - recall: 0.7111\n","Epoch 8: Validation Metrics:\n","loss: 0.5083491802215576\n","val_binary_accuracy: 0.6141975522041321\n","val_precision: 0.4542815685272217\n","val_recall: 0.7162471413612366\n","val_auc: 0.7033588886260986\n","val_prc_auc: 0.5054067373275757\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8298 - binary_accuracy: 0.7455 - f1: 0.7354 - loss: 0.5096 - prc_auc: 0.8283 - precision: 0.7614 - recall: 0.7114 - val_auc: 0.7034 - val_binary_accuracy: 0.6142 - val_f1: 0.5560 - val_loss: 0.7185 - val_prc_auc: 0.5054 - val_precision: 0.4543 - val_recall: 0.7162\n","Epoch 9/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8313 - binary_accuracy: 0.7458 - f1: 0.7359 - loss: 0.5076 - prc_auc: 0.8309 - precision: 0.7613 - recall: 0.7124\n","Epoch 9: Validation Metrics:\n","loss: 0.5066177248954773\n","val_binary_accuracy: 0.6141975522041321\n","val_precision: 0.45441389083862305\n","val_recall: 0.7185354828834534\n","val_auc: 0.7041088342666626\n","val_prc_auc: 0.5061188340187073\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8314 - binary_accuracy: 0.7458 - f1: 0.7360 - loss: 0.5076 - prc_auc: 0.8309 - precision: 0.7612 - recall: 0.7126 - val_auc: 0.7041 - val_binary_accuracy: 0.6142 - val_f1: 0.5567 - val_loss: 0.7197 - val_prc_auc: 0.5061 - val_precision: 0.4544 - val_recall: 0.7185\n","Epoch 10/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8327 - binary_accuracy: 0.7469 - f1: 0.7374 - loss: 0.5058 - prc_auc: 0.8330 - precision: 0.7616 - recall: 0.7150\n","Epoch 10: Validation Metrics:\n","loss: 0.5050445199012756\n","val_binary_accuracy: 0.6134259104728699\n","val_precision: 0.45375722646713257\n","val_recall: 0.7185354828834534\n","val_auc: 0.7045363783836365\n","val_prc_auc: 0.5057016611099243\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8327 - binary_accuracy: 0.7469 - f1: 0.7375 - loss: 0.5058 - prc_auc: 0.8330 - precision: 0.7616 - recall: 0.7151 - val_auc: 0.7045 - val_binary_accuracy: 0.6134 - val_f1: 0.5562 - val_loss: 0.7208 - val_prc_auc: 0.5057 - val_precision: 0.4538 - val_recall: 0.7185\n","Epoch 11/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8341 - binary_accuracy: 0.7467 - f1: 0.7379 - loss: 0.5042 - prc_auc: 0.8348 - precision: 0.7601 - recall: 0.7171\n","Epoch 11: Validation Metrics:\n","loss: 0.5036520957946777\n","val_binary_accuracy: 0.6149691343307495\n","val_precision: 0.455331414937973\n","val_recall: 0.7231121063232422\n","val_auc: 0.7047695517539978\n","val_prc_auc: 0.5061649084091187\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8341 - binary_accuracy: 0.7468 - f1: 0.7380 - loss: 0.5042 - prc_auc: 0.8347 - precision: 0.7601 - recall: 0.7173 - val_auc: 0.7048 - val_binary_accuracy: 0.6150 - val_f1: 0.5588 - val_loss: 0.7218 - val_prc_auc: 0.5062 - val_precision: 0.4553 - val_recall: 0.7231\n","Epoch 12/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8351 - binary_accuracy: 0.7471 - f1: 0.7385 - loss: 0.5027 - prc_auc: 0.8359 - precision: 0.7601 - recall: 0.7183\n","Epoch 12: Validation Metrics:\n","loss: 0.5023635625839233\n","val_binary_accuracy: 0.6149691343307495\n","val_precision: 0.455331414937973\n","val_recall: 0.7231121063232422\n","val_auc: 0.7049559354782104\n","val_prc_auc: 0.5039083957672119\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8351 - binary_accuracy: 0.7472 - f1: 0.7386 - loss: 0.5027 - prc_auc: 0.8358 - precision: 0.7601 - recall: 0.7185 - val_auc: 0.7050 - val_binary_accuracy: 0.6150 - val_f1: 0.5588 - val_loss: 0.7223 - val_prc_auc: 0.5039 - val_precision: 0.4553 - val_recall: 0.7231\n","Epoch 13/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8363 - binary_accuracy: 0.7478 - f1: 0.7394 - loss: 0.5014 - prc_auc: 0.8380 - precision: 0.7603 - recall: 0.7198\n","Epoch 13: Validation Metrics:\n","loss: 0.5012032985687256\n","val_binary_accuracy: 0.6149691343307495\n","val_precision: 0.45558738708496094\n","val_recall: 0.7276887893676758\n","val_auc: 0.7052596807479858\n","val_prc_auc: 0.5034760236740112\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8363 - binary_accuracy: 0.7478 - f1: 0.7395 - loss: 0.5014 - prc_auc: 0.8380 - precision: 0.7603 - recall: 0.7200 - val_auc: 0.7053 - val_binary_accuracy: 0.6150 - val_f1: 0.5604 - val_loss: 0.7228 - val_prc_auc: 0.5035 - val_precision: 0.4556 - val_recall: 0.7277\n","Epoch 14/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8371 - binary_accuracy: 0.7471 - f1: 0.7387 - loss: 0.5001 - prc_auc: 0.8391 - precision: 0.7596 - recall: 0.7192\n","Epoch 14: Validation Metrics:\n","loss: 0.5000847578048706\n","val_binary_accuracy: 0.6149691343307495\n","val_precision: 0.45558738708496094\n","val_recall: 0.7276887893676758\n","val_auc: 0.7056939005851746\n","val_prc_auc: 0.5025716423988342\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8371 - binary_accuracy: 0.7472 - f1: 0.7389 - loss: 0.5001 - prc_auc: 0.8390 - precision: 0.7597 - recall: 0.7194 - val_auc: 0.7057 - val_binary_accuracy: 0.6150 - val_f1: 0.5604 - val_loss: 0.7232 - val_prc_auc: 0.5026 - val_precision: 0.4556 - val_recall: 0.7277\n","Epoch 15/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8381 - binary_accuracy: 0.7484 - f1: 0.7400 - loss: 0.4989 - prc_auc: 0.8402 - precision: 0.7609 - recall: 0.7205\n","Epoch 15: Validation Metrics:\n","loss: 0.49901577830314636\n","val_binary_accuracy: 0.6165123581886292\n","val_precision: 0.4568965435028076\n","val_recall: 0.7276887893676758\n","val_auc: 0.7059496641159058\n","val_prc_auc: 0.5033342242240906\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8381 - binary_accuracy: 0.7484 - f1: 0.7401 - loss: 0.4989 - prc_auc: 0.8401 - precision: 0.7609 - recall: 0.7206 - val_auc: 0.7059 - val_binary_accuracy: 0.6165 - val_f1: 0.5613 - val_loss: 0.7231 - val_prc_auc: 0.5033 - val_precision: 0.4569 - val_recall: 0.7277\n","Epoch 16/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8387 - binary_accuracy: 0.7482 - f1: 0.7399 - loss: 0.4979 - prc_auc: 0.8408 - precision: 0.7604 - recall: 0.7208\n","Epoch 16: Validation Metrics:\n","loss: 0.4980252981185913\n","val_binary_accuracy: 0.6180555820465088\n","val_precision: 0.4583333432674408\n","val_recall: 0.7299771308898926\n","val_auc: 0.706750214099884\n","val_prc_auc: 0.50375896692276\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8387 - binary_accuracy: 0.7482 - f1: 0.7401 - loss: 0.4979 - prc_auc: 0.8407 - precision: 0.7605 - recall: 0.7209 - val_auc: 0.7068 - val_binary_accuracy: 0.6181 - val_f1: 0.5631 - val_loss: 0.7233 - val_prc_auc: 0.5038 - val_precision: 0.4583 - val_recall: 0.7300\n","Epoch 17/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8396 - binary_accuracy: 0.7486 - f1: 0.7406 - loss: 0.4968 - prc_auc: 0.8419 - precision: 0.7607 - recall: 0.7217\n","Epoch 17: Validation Metrics:\n","loss: 0.497057169675827\n","val_binary_accuracy: 0.6211419701576233\n","val_precision: 0.46098265051841736\n","val_recall: 0.7299771308898926\n","val_auc: 0.707179069519043\n","val_prc_auc: 0.502578854560852\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8396 - binary_accuracy: 0.7487 - f1: 0.7407 - loss: 0.4968 - prc_auc: 0.8419 - precision: 0.7608 - recall: 0.7218 - val_auc: 0.7072 - val_binary_accuracy: 0.6211 - val_f1: 0.5651 - val_loss: 0.7234 - val_prc_auc: 0.5026 - val_precision: 0.4610 - val_recall: 0.7300\n","Epoch 18/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8405 - binary_accuracy: 0.7485 - f1: 0.7403 - loss: 0.4958 - prc_auc: 0.8432 - precision: 0.7608 - recall: 0.7211\n","Epoch 18: Validation Metrics:\n","loss: 0.49611008167266846\n","val_binary_accuracy: 0.6203703880310059\n","val_precision: 0.4602026045322418\n","val_recall: 0.7276887893676758\n","val_auc: 0.7075480222702026\n","val_prc_auc: 0.5031845569610596\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - auc: 0.8405 - binary_accuracy: 0.7485 - f1: 0.7404 - loss: 0.4958 - prc_auc: 0.8431 - precision: 0.7608 - recall: 0.7212 - val_auc: 0.7075 - val_binary_accuracy: 0.6204 - val_f1: 0.5638 - val_loss: 0.7235 - val_prc_auc: 0.5032 - val_precision: 0.4602 - val_recall: 0.7277\n","Epoch 19/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8411 - binary_accuracy: 0.7475 - f1: 0.7392 - loss: 0.4948 - prc_auc: 0.8437 - precision: 0.7599 - recall: 0.7199\n","Epoch 19: Validation Metrics:\n","loss: 0.4952057898044586\n","val_binary_accuracy: 0.6226851940155029\n","val_precision: 0.4623188376426697\n","val_recall: 0.7299771308898926\n","val_auc: 0.7080888152122498\n","val_prc_auc: 0.5057510137557983\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8411 - binary_accuracy: 0.7476 - f1: 0.7393 - loss: 0.4948 - prc_auc: 0.8436 - precision: 0.7599 - recall: 0.7200 - val_auc: 0.7081 - val_binary_accuracy: 0.6227 - val_f1: 0.5661 - val_loss: 0.7236 - val_prc_auc: 0.5058 - val_precision: 0.4623 - val_recall: 0.7300\n","Epoch 20/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.8417 - binary_accuracy: 0.7498 - f1: 0.7416 - loss: 0.4939 - prc_auc: 0.8444 - precision: 0.7623 - recall: 0.7222\n","Epoch 20: Validation Metrics:\n","loss: 0.4943450391292572\n","val_binary_accuracy: 0.6265432238578796\n","val_precision: 0.4660894572734833\n","val_recall: 0.739130437374115\n","val_auc: 0.7085763216018677\n","val_prc_auc: 0.5060980319976807\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - auc: 0.8417 - binary_accuracy: 0.7498 - f1: 0.7417 - loss: 0.4939 - prc_auc: 0.8443 - precision: 0.7623 - recall: 0.7224 - val_auc: 0.7086 - val_binary_accuracy: 0.6265 - val_f1: 0.5717 - val_loss: 0.7236 - val_prc_auc: 0.5061 - val_precision: 0.4661 - val_recall: 0.7391\n","Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_135555.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - auc: 0.6243 - binary_accuracy: 0.5838 - f1: 0.6645 - loss: 0.6704 - prc_auc: 0.6050 - precision: 0.5622 - recall: 0.8224\n","Epoch 1: Validation Metrics:\n","loss: 0.6417456269264221\n","val_binary_accuracy: 0.6072530746459961\n","val_precision: 0.2556818127632141\n","val_recall: 0.5378485918045044\n","val_auc: 0.5944604277610779\n","val_prc_auc: 0.2365441620349884\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 300ms/step - auc: 0.6253 - binary_accuracy: 0.5846 - f1: 0.6647 - loss: 0.6699 - prc_auc: 0.6058 - precision: 0.5630 - recall: 0.8214 - val_auc: 0.5945 - val_binary_accuracy: 0.6073 - val_f1: 0.3466 - val_loss: 0.6642 - val_prc_auc: 0.2365 - val_precision: 0.2557 - val_recall: 0.5378\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7429 - binary_accuracy: 0.6877 - f1: 0.6851 - loss: 0.6006 - prc_auc: 0.7094 - precision: 0.6890 - recall: 0.6816\n","Epoch 2: Validation Metrics:\n","loss: 0.6041865944862366\n","val_binary_accuracy: 0.5995370149612427\n","val_precision: 0.25276753306388855\n","val_recall: 0.5458167195320129\n","val_auc: 0.5958253145217896\n","val_prc_auc: 0.23920616507530212\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7428 - binary_accuracy: 0.6877 - f1: 0.6852 - loss: 0.6007 - prc_auc: 0.7091 - precision: 0.6889 - recall: 0.6818 - val_auc: 0.5958 - val_binary_accuracy: 0.5995 - val_f1: 0.3455 - val_loss: 0.6666 - val_prc_auc: 0.2392 - val_precision: 0.2528 - val_recall: 0.5458\n","Epoch 3/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7506 - binary_accuracy: 0.6945 - f1: 0.6953 - loss: 0.5930 - prc_auc: 0.7221 - precision: 0.6918 - recall: 0.6990\n","Epoch 3: Validation Metrics:\n","loss: 0.597557544708252\n","val_binary_accuracy: 0.5895061492919922\n","val_precision: 0.24684683978557587\n","val_recall: 0.5458167195320129\n","val_auc: 0.5966888070106506\n","val_prc_auc: 0.24277561902999878\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7504 - binary_accuracy: 0.6945 - f1: 0.6953 - loss: 0.5931 - prc_auc: 0.7218 - precision: 0.6917 - recall: 0.6992 - val_auc: 0.5967 - val_binary_accuracy: 0.5895 - val_f1: 0.3400 - val_loss: 0.6703 - val_prc_auc: 0.2428 - val_precision: 0.2468 - val_recall: 0.5458\n","Epoch 4/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7559 - binary_accuracy: 0.6997 - f1: 0.7024 - loss: 0.5889 - prc_auc: 0.7303 - precision: 0.6942 - recall: 0.7112\n","Epoch 4: Validation Metrics:\n","loss: 0.5932689309120178\n","val_binary_accuracy: 0.5817901492118835\n","val_precision: 0.24695652723312378\n","val_recall: 0.5657370686531067\n","val_auc: 0.5969386100769043\n","val_prc_auc: 0.24499927461147308\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - auc: 0.7557 - binary_accuracy: 0.6996 - f1: 0.7025 - loss: 0.5890 - prc_auc: 0.7300 - precision: 0.6940 - recall: 0.7114 - val_auc: 0.5969 - val_binary_accuracy: 0.5818 - val_f1: 0.3438 - val_loss: 0.6734 - val_prc_auc: 0.2450 - val_precision: 0.2470 - val_recall: 0.5657\n","Epoch 5/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7585 - binary_accuracy: 0.7017 - f1: 0.7076 - loss: 0.5862 - prc_auc: 0.7347 - precision: 0.6922 - recall: 0.7239\n","Epoch 5: Validation Metrics:\n","loss: 0.5901644229888916\n","val_binary_accuracy: 0.5817901492118835\n","val_precision: 0.24870465695858002\n","val_recall: 0.5737051963806152\n","val_auc: 0.5970300436019897\n","val_prc_auc: 0.24796368181705475\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7584 - binary_accuracy: 0.7017 - f1: 0.7076 - loss: 0.5862 - prc_auc: 0.7344 - precision: 0.6921 - recall: 0.7241 - val_auc: 0.5970 - val_binary_accuracy: 0.5818 - val_f1: 0.3470 - val_loss: 0.6757 - val_prc_auc: 0.2480 - val_precision: 0.2487 - val_recall: 0.5737\n","Epoch 6/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7612 - binary_accuracy: 0.7044 - f1: 0.7134 - loss: 0.5841 - prc_auc: 0.7394 - precision: 0.6905 - recall: 0.7381\n","Epoch 6: Validation Metrics:\n","loss: 0.587676465511322\n","val_binary_accuracy: 0.5802469253540039\n","val_precision: 0.24957264959812164\n","val_recall: 0.5816733241081238\n","val_auc: 0.5966469049453735\n","val_prc_auc: 0.2518744170665741\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7611 - binary_accuracy: 0.7043 - f1: 0.7134 - loss: 0.5842 - prc_auc: 0.7392 - precision: 0.6905 - recall: 0.7382 - val_auc: 0.5966 - val_binary_accuracy: 0.5802 - val_f1: 0.3493 - val_loss: 0.6774 - val_prc_auc: 0.2519 - val_precision: 0.2496 - val_recall: 0.5817\n","Epoch 7/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7629 - binary_accuracy: 0.7066 - f1: 0.7170 - loss: 0.5825 - prc_auc: 0.7409 - precision: 0.6908 - recall: 0.7456\n","Epoch 7: Validation Metrics:\n","loss: 0.5856472253799438\n","val_binary_accuracy: 0.5756173133850098\n","val_precision: 0.24703891575336456\n","val_recall: 0.5816733241081238\n","val_auc: 0.5966182947158813\n","val_prc_auc: 0.2538459300994873\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7627 - binary_accuracy: 0.7066 - f1: 0.7170 - loss: 0.5825 - prc_auc: 0.7406 - precision: 0.6907 - recall: 0.7457 - val_auc: 0.5966 - val_binary_accuracy: 0.5756 - val_f1: 0.3468 - val_loss: 0.6789 - val_prc_auc: 0.2538 - val_precision: 0.2470 - val_recall: 0.5817\n","Epoch 8/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7647 - binary_accuracy: 0.7091 - f1: 0.7207 - loss: 0.5811 - prc_auc: 0.7436 - precision: 0.6912 - recall: 0.7532\n","Epoch 8: Validation Metrics:\n","loss: 0.58392333984375\n","val_binary_accuracy: 0.5733024477958679\n","val_precision: 0.2457912415266037\n","val_recall: 0.5816733241081238\n","val_auc: 0.5962141752243042\n","val_prc_auc: 0.25419124960899353\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - auc: 0.7646 - binary_accuracy: 0.7091 - f1: 0.7207 - loss: 0.5811 - prc_auc: 0.7433 - precision: 0.6911 - recall: 0.7532 - val_auc: 0.5962 - val_binary_accuracy: 0.5733 - val_f1: 0.3456 - val_loss: 0.6800 - val_prc_auc: 0.2542 - val_precision: 0.2458 - val_recall: 0.5817\n","Epoch 9/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7660 - binary_accuracy: 0.7101 - f1: 0.7221 - loss: 0.5798 - prc_auc: 0.7441 - precision: 0.6916 - recall: 0.7557\n","Epoch 9: Validation Metrics:\n","loss: 0.5823643207550049\n","val_binary_accuracy: 0.5733024477958679\n","val_precision: 0.2466442883014679\n","val_recall: 0.5856573581695557\n","val_auc: 0.5958901047706604\n","val_prc_auc: 0.25590500235557556\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7659 - binary_accuracy: 0.7100 - f1: 0.7220 - loss: 0.5798 - prc_auc: 0.7439 - precision: 0.6915 - recall: 0.7558 - val_auc: 0.5959 - val_binary_accuracy: 0.5733 - val_f1: 0.3471 - val_loss: 0.6809 - val_prc_auc: 0.2559 - val_precision: 0.2466 - val_recall: 0.5857\n","Epoch 10/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - auc: 0.7676 - binary_accuracy: 0.7095 - f1: 0.7217 - loss: 0.5786 - prc_auc: 0.7467 - precision: 0.6908 - recall: 0.7557\n","Epoch 10: Validation Metrics:\n","loss: 0.5809786915779114\n","val_binary_accuracy: 0.5740740895271301\n","val_precision: 0.24705882370471954\n","val_recall: 0.5856573581695557\n","val_auc: 0.5960902571678162\n","val_prc_auc: 0.2564743757247925\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - auc: 0.7675 - binary_accuracy: 0.7094 - f1: 0.7216 - loss: 0.5787 - prc_auc: 0.7465 - precision: 0.6907 - recall: 0.7558 - val_auc: 0.5961 - val_binary_accuracy: 0.5741 - val_f1: 0.3475 - val_loss: 0.6819 - val_prc_auc: 0.2565 - val_precision: 0.2471 - val_recall: 0.5857\n","Epoch 11/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - auc: 0.7692 - binary_accuracy: 0.7114 - f1: 0.7250 - loss: 0.5776 - prc_auc: 0.7482 - precision: 0.6906 - recall: 0.7633\n","Epoch 11: Validation Metrics:\n","loss: 0.5797096490859985\n","val_binary_accuracy: 0.5733024477958679\n","val_precision: 0.2466442883014679\n","val_recall: 0.5856573581695557\n","val_auc: 0.5959683060646057\n","val_prc_auc: 0.2565155029296875\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - auc: 0.7691 - binary_accuracy: 0.7114 - f1: 0.7249 - loss: 0.5776 - prc_auc: 0.7480 - precision: 0.6905 - recall: 0.7633 - val_auc: 0.5960 - val_binary_accuracy: 0.5733 - val_f1: 0.3471 - val_loss: 0.6828 - val_prc_auc: 0.2565 - val_precision: 0.2466 - val_recall: 0.5857\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 208ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 210ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 209ms/step\n","[[1 0 0 ... 0 1 0]\n"," [1 0 0 ... 0 1 0]\n"," [0 0 1 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 1]\n"," [0 1 0 ... 0 1 1]\n"," [0 1 1 ... 0 0 1]]\n"]}],"source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 10\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_135555'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n","\n","from google.colab import runtime\n","runtime.unassign()\n"]},{"cell_type":"markdown","source":["RUN BASIC MODELS ON OUR / OUTSIDE DATASET"],"metadata":{"id":"WcQG86Mbh9gB"}},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","# #####################################################################################################################################################\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_model=True,\n","    threshold=0.5,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","\n","from google.colab import runtime\n","runtime.unassign()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c0b8871e38c44ee08f79919ecf2d4a59","25b01b07c03e4b1fb67f83f2572831bc","47afe335d23542c8ba9d24f5511b95e3","b185cc64f5814d8588c3d0c7e5973b9d","b877e913bc2b4a878b65fc89f71f79bf","0326e04166894e91b65de74a355bd6bb","2d28ebfb09be4445bd8876c386b4a08f","526cd94d7b6745338a677a35ec71267a","ce8c054496504d8cace349f2808f6177","97727e59cc754dd9a0caa86724397204","7ab4b2019cec467c94c8345a5b0d483c","2bdd1c45ba35483eb7ffc9be26bd2cbb","e6686d1800aa4c0eac2ce3119b03f9ad","dad8bf8d257047eaad0a259a59cb8e65","47ad0a3fe8b84694b315c96ff6ea7272","61f3da3002e84c8eb47446cb32d8643d","ef0e77bd67bd4b318f49c5bfc2f2044c","e109930020a8413fac4029584f7645a7","c8977af5eabc4fb5aca438b480224fd2","cc200d368bfd4485b05d28df01875927","9208c58128cb4d65897b6f1f3b47f6f4","c0fe27c84eb6404f91cf62250364387d","7ff02d35d2044f798525c220a5da720e","74771f365e464c16939d72c95fb25092","45481bd363f24744a8c4a99746144051","a3599526d1fc44ebad1328dc9b06ccf7","ec14629366fe4c5bb18cdd300df4ada0","94254415e22247d7b3abb092fcf8c3f3","3343db48619d469bbb23a355af1de335","268322c174bc4aa6bdbfe5dc99ee6f46","54612f124d23411e86a053b4212b2b78","67bdf0d99eb5425c8825344b1371c06f","7b8a38f18cf74604bd4fe71a764e2fa7","98f4727015544075b51249ec17574341","8fbb0a51f33e4391b542e6dde45ce263","79c8e244a34b4e438cfeaecb8ba06482","4a8c51ad59ef4373bd4710e554adab6a","9d0d770bfeec4f20abe88cc05f15cca4","540f2a8ea1c04c458240e87afe4eeab1","d6d9c7356f8143e2b927b5089a6d2a0e","2212afac6cdc4e35ae3a3c2de35b35de","391f10a76c1a4859a06f7541b85b5aea","f8cf696f82f84c8abdb09a694016f5d5","bd4ede6526eb4392b10e6967dba2dbea","f48aa799028f45deac82474f037542c1","e50b43d63bc84f199942409c2f379918","1e4d76a58a694e648c1d11a0ffccff4e","b75d6bfcb8674253ada5db33deae5cfc","69f9649a66f943d584d713392bdf6987","ea595275a75843ea8673881c59f4be6f","ee42fa6cf7084a7aade563f562e3408c","7ec2ddf240bb423ebbd032613bf6ddce","1380749860c2431e987d14be76d36765","c382fcb3372249528d23772146672044","a5b57911e7834bc4967bb7eec9aadcf3","a69a26a2c5bf42b29634fb52df795b0a","cc6c522d33a24af28956ce964b1f4c39","a910f41247834518986fc052aa950129","7255e31b9f0c4d5d8e4c66f168ac4614","86044863b4b6435d9e9dc7f0b631dbb6","2ad4eb12cf40492aa9f54ed8708080fd","f1e9944e249b4acd99dfd2c68da78c1d","933990dbd74b45bba720bfd96009b772","febc9be8b02340ba9a74e7a1af347a83","4e59669e37824834a1cceea83509eb1f","f18274d74cec49708999fe4d3043779a","2cd105141f3a4c92995f2748abda07e6","854f1811f5e8401aa668b123db75f502","0a7cdb4546044deebd24ed57e5161dd5","ff98d952924547dc984a6adf1ed86eac","2305cdbccec84568aa4637acc011d4bb","998a6234106c43728f6260e6dba7bbb0","01931057bc2c49c18fe13e0056f154fd","80b8b549ea984dc9b8945d1346a39751","d8b6764ff11b4c49b414d2be8e1be055","5ab2ca99f2334dc787c2d6a1980bdb5a","3339e8654acf40ff854295e6a1fb71c5","798c6b5b49ec4db78d2a9e668b8dd43f","7b4232f269534253ab0667e14705b4e8","b724ee576f084dbfb176245c7e5e437c","bc3035798d1341f4a96a689c0f9ae9df","8d641cee244b4d9280b655887e9487f7","6ed1c143f8944f0e8d466ac82b7cf105","d135cb720f4e49f19b6bc405b1a47b0f","c1620f24b0854c8daadd0b17393034a5","2044dac6d9e6424f9e7fe44fb30c8210","edbe0dd553ed47c3a058c11d643b6ca6","79f85022cf0043d584c253130bc74738","01712d5da64b4670aa00b4a2bf1ba1cd","287b2c996ad14a2cbbc9424ace66ed1a","fc6b1578cd9a43c89aaef26cc1409d34","d04ade88a3534b02b253b70a37d74fff","ac3ca46ebaf143aaa859ef9aaa0b9e4a","7e01e0ce35a0406b853d45821128f444","ddb34a307bbb48c8adda9af468aac073","310357abc60649f0b2fdbe77d02b29c3","ed8373e0ad20462481c3285eceb7f871","2bd71294ce8c47cfa09ad1cbc0d896e8","db90aecf04ce4f9484735601b59a52ea","59165906e52d403c91e53abe84c1d365","fff31088d2f14627ae4263556082b1dd","d746e14f65424ac09f0d692372f5dadf","184f548b04fe4bb1b273e9e809280f5d","54e4a35d2a0043f78653e4c67f6a76ee","7b90916f3d604f5b83d69497eba9541d","1e1284ddc4ea40eab285856936a5cf7e","bf07e155ff88460587f3edc915e4675a","f84b00b2de024bb9b1388d79067299e8","faa2081e6efb49f88ae920a0b363d7b8","95ebcab5cb5841bd8dbb8411448982fc","96f9aa37ca694fd9992cd1024de6f6b1","b6cd518dd4b44bf38a088b9c5b5a79ec","6feb1997aca147bdb54e19676868da21","5ff415eb2c68464b9956074f19405183","a2b54a1ea2e64ea8b5eb5e3a74dc34fb","c42a4083736a4d86a160c4b909ab3fdd","0762eb75d257410bae92b06d762c5d7e","3d4b4e0404ab416eadd9ef58a4e364b6","55f7c63a59aa48adb88e2ad83463c57b","db4c98d48f8845e789257dc7236a9735","5af9b995fb3f4dc0a04e945aa1c58a46","eac512bda6154776a8109fc232899da0","b3609920b4b24812a19f02ad0321ab3d","b4fe9376518245fabfc677bddb2d7b91","8e7a013c3cd14d288c6d9535402237bb","b5f4de06db9f4e3589ccd4e5bfeee133","49dfd6587845450b9b056cb964d52067","0bc32a7d8dc64117b481fe2913c5d9f8","0264eea6db314003ba01170255ee011d","7805bd5803d64537b9b71beaf4a3aa10","07be0479b7f04da9b58c7feb3333b051","26c0852bdcf34941ae1952f362c827c8","88fe10f7f4514619925f29c5f4bc0056","bc23d38bdc8c420b8133992cba025009","e937614c182d4428abeb49181d6c106c","1229dccd6ade4c318c09db8f8d6e788e","cec11d9dde1241eebcefd15812fa47b7","ea8d804ef87945be9572abd96cb41e7c","5f4fce1b1911448ea6307bd8dddad907","0bc92f40f0b0443f9360594412835a0f","643a25a747e34b7fab35e07d39303728","2bde52327dec4867824277d6bb6d6e75","57fbb0ab064d4d178cbb0692982b3304","24a8f7d8508a429e88701579131fdd23","1f7aca5dd6c04ffc87d4ea48347e92b5","804cd4aa0bf74386bdea2a64d4f65c25","7929e641f57b4270b5e446291c9c6e27","6f8a7f6de2dd4567a0a84b5b68266262","d44814f03dbb4d359b3a89774a2fdc42","3d02e2de40464b079d6dac68a89a7bef","9168191ee8d642c59046ca6ed9870785","e599eb973fac4c0b976bcc412c37c25c","9acb1eae03ec4ed2a9182d6638bba073","31a6d5d7bbe8470b96bf65e1f42a0fd6","53b3ba65207745c58ab2eba361dc4b44","56e69be7468548389ce31294ce315852","bdf0bb0eac1446fb97a04987b5166e3d","86ddc002aba24c69b7de81503bee50d2","963363422aa74f5a8c0cb44e42300f61","d4cb34edcd464a7aab02396229693941","2e2be76cd92a461895c245561d60f48b","42dca08b3dea4bd0ba8a55c527c53a5b","de1be903fb7b481eab5d7f71444122f2","e1422593cc954303afa5598b4ff732bd","00e35c0ffb0c4f72a6b91aa311684e06","1079a862500d441489b8cf140d252dff","b69f5c04ae0f40bcbfad917351ab0911","6a912585fe584e2a9209c8f799b06993","f91a8f9caee8488f8e27810c800ae16d","fe1c4364b3804aa299649a55618fdc1f","5c60844e982d4f6e8cbe0cd43fc64521","d9ad7b02e1014c7aa321f0992bc7739a","475d93e9403e43d38fd2e61c4ff6a615","99f5e06a4657402283734d69188b5705","ccd11dffad9c439ea753b05ca65e6cff","cb1f430691b64773baec1e442174497e","5088c41b183b420aa7f9f85013f307f0","5fd8df306b154448a03e4910ad251790","226aefc7a6644defa11a23f820a57bd1","1b3e48f019e74c79880c5b5c2dabee66","098acf3459ea443ab370b8d712b32051","2ca313da1ee14994a1cf833f289bdab8","aa7eef12a821406995e928e5be1d021e","65784d78cf4f4355a0621017c41b9150","302c3e61c1c64835b9ee4ffeadb82b78","c4962e5f9ddd4486a703401fcf7a0011","d25300245563454f9da8421223121ae3","a776c4c9bfcf4035a226d4fa59ab84a0","d9c8ccd8645d4779ae6551f13c8dd91a","77ecfde5ef8e4415991ee7c22c897a8d","ccb654fa5c7a4b5597c97748465987d8","7afe1e29a71742bcb0546734d43222a5","a59447422f21493187bd466fec1f7434","63ad1b8925ce426585a7be65afd0d181","47030b44a04e49ed9fd70f71708ddef1","5981410e444f42a4b329ead0103ee5ae","bee7ec2196804e619d9fe79eb31c9cfa","b35bf1dc125c441888c3fddc1bcfbc38","98818d3839124f1ca94c9bcab601de27","35daa5097c884e14be6b54f804f7e694","2679206ed8ed4e6b8b5386429eb94b35","7a199b81decd4a3ca33915d38e30a736","a0ab81481d05461c87e5197e6775e38d","a8f60699ecfd4f7fb1b3a5298ec6a0ce","a7de6e638d31463b977532111f8c97be","c6e666f8f2ea4070a273fa37f925a08b","01e71a0ff1664d5e8f889e2fbc799ca0","a1a9b380891b43a0a498f6150033bd1d","76ba34fa5c0b48d8bbcc883dd24f394c","61892bf08f94477da0a0862661dfcdae","4adf4fc9c2554977bdddb4100a765711","cf45015451fa4c309bb74608e474a56c","01973213b96c45809112c0ae952f1bbe","47f3fbbf834e41f2aae954d6df9213b2","8f59b9cb8ee5480ab844777141de107c","1b0cff0f8ecd47a5bb7087300ff351c1","1cc36989b9cf400ba2d721ee4a0b81a1","a050577d4f544bd1ae3eed36b685589c","9d355646d13f442d83f93aaf3c375bc1","dc41424fe7824c2d8ae5aefc8aed27ee","4d626bf001024415bf4189a9fa9e6790","6bf2ceb8aed54fb2a9a2892774d926d1","e0400db9defb4ad185891c476292849a","486f5df6ac2a40c1a21bf77aa411826a","a91305fa2d9046cea835c43d0df072eb","221761596386442eaab1c9d09ef6b5b1","5a53856c33db411893d9abfbad1386c1","c510d0728532493d8916462c2e6c5fa1","a732e74cf5294d78bea1060aaea8156e","069b1f4277b5474ca492e41efc897073","b2bafd52d6dd4c37a6139e2cae6c0c13","ec1768ff11484d66b7f02c0249ea3ca4","c05825335fc94912a240c179377c0cea","2b36f1a3e17c42ecb746b47b4e239926","4801ea97081949b28903007442a5ce10","2bf381be28af42b9a9cda1b08019cf25","5fa8fbb6ca1e471c836692f47c9b71e0","9fcbb1fa9bec4aa78e0c5a6bdb461f04","b2e217b77d4245f5b57e84d68b099413","1fc95ecf3244494ea9fe291de4eb7953","1e745e4364a948cab227d0fb64e8af0c","b3041f0182034fbc9007a67635868d71","dc7f0b12d75a422d9888bff6809c58f6","e4e61a59a8784f159af36d36fa20dbd1","38392ae43f98448fbed95ca14f96a020","6cdc2fb7087f47de9ca8a1c52f71e4c5","fdb7cc93046a43e8911665b53295b6af","83c6961cee4c4acea51bf19676be1592","28dfd04ab6234a8284cdfabecc89e158","06b2e228d8144385b1bbe58b8e89c1c5","8f5ac612a7d84a4cb095623763e27565","1a4f5921061d476499f4377be4cf5050","9d9ec7e67e1f40aeae1e34346b7df37c","3f4af2ac4fe64a5bb2b98be2b7273099","c02b98aa2d3e4abba60b90e9029b56f9","b96cf3e807234ee7834f0a7ccc517f20","0a207549c763442f861bec46972bd033","b4eea5cdd66946209bf29b41ed8c20d9","0d098f60c1964aa6925ac44348a50af1","324d00ae92e3448b85e59ab65ecf4dd0","f55e18ac927c46b580f4497814bb976c","3599d78ffe7b4e1aad1fc05e7178a453","fd7bab52d2ff4e9ea0c3ee6d98bf425c","aafbdf937b134f10bdf4b554b70c7a2f","f87337dd2f78448887eac6c6cf33a5ca","691ddef57c5848fd883c5d9012c94045","7d8b16dd68664ce5879de4e5f6370f79","d07052827bc643789dd44d98470f8515","1195af52e396464f9925c37528b923ea","f697625c7eb446538788d0da12dda7eb","cfe71caf9ef34fffb338f8b912aaf86e","67962942e6a74c4aacf084c4a6b94e30","0015edfaae9b4b4a80dd8af43d23d826","4a3e757b96524f1b924562641594454d","f1975dc3ba7a4cfeab0f30e83879de20","92a4f2c303d942b6819d095a9be59a49","5a19035c4645491ba2455967081f0fb0","8a3a36a54a9447989728d5565c6b83f8","bf0bc230a5d145ad8583a0394c46d74a","33202e426d50459bacdd863c19ddb436","7b31f6154c2147fb9bd90345a9a086fa","a4ea297b38d5434baf34caff05f9b154","c3202bea3ff64c6f9732ef65e2e17762","6d098fc73ae14aa791bc37ca14118596","983f18692b2f44288555c879ca9453aa","fac935b2c8f54124ae476bebbe279d7b","426fc031ad2741779d60e3b01f49fbe4","1732faff578745bfafb5cd26e5ae54bd","cdb4993f65c94f1d8d890488da593ecd","eeb06d6ebb2f4fc48ba3e8ca37a15d37","97547fe7b54a4470b2d5878ed92bbf16","7ea6d2c66f64452a8a077a4e488f1c5e","02bc3344e8264c03a676f85387bc37c0","82e9ed2db6ab45179831d3397a37ee75","68456052447f456fa519c2d6a45f56e2","b61a248802124cbe9b80f4a9855b533a","66ec20af59b94dbb9b4cf76943230cdd","f53188c89a304ab19cdddd98031c9325","a715726a9133486fb9d3956667dc7b83","ffa46ad9f0f240d9ac31f129134c3cc2","0279ed93c980420786bd46ba2b62982c","019a20cc526d44618f8364f97d39e56f","27d05e2328a14edc9134b739e314ada8","a2c5c6b7daab481589759aefbce19082","8f161165b6e54a4abf04a181e7e6cf50","91a312ea81394f318907f0d0b584172d","1549ecc63bf14c03bb37b9c170f4b796","fa8f5c63ffd14c50adfd833ebcfe3cfe","95a2e13b5b3b4bd283f82f91275588a2","059d7fb551484eb4a89c6cfb4a851541","6267dbd8f6b0457380b0b0acf11709d0","b5bcb7940d494bc6975cf65a8138b1ab","dfd748f2131f4e7ba0e9e3309e1a339d","3e57fd859a6340e397017f4aba4c67d9","593a612ab5c64f8bab67b1a279228a0b","3a1f8d64920a47fa99d0771f6f9e598c","8e01af936e794f029f8a0ebeb36e98b4","e00f859c149840e09f0ee528f8af484b","8990c63160144a78831bde90f9ac5258","bfb5ed39808342c5b41d340e19005093","38c438c37fd640808d5a027ddbad0592","62b40c42df3e407c9a3b9906bf0b6c0f","097d11cbc613496190677afe4af3526c","7daf1551f39d471284d69d234899f40b","03ea6fbd1ab04a81a58f5b0fb818021c","c2690fa39b7b4abd8c99b2795a0c2965","dea5be60a56c4356a90111e91b3a2525","c315a5dab8d94ea6b3462bf86e69e9dc","1b1e414feec347fd810f2990bfdb5987","9e79a778ebf444d09ebbdcd8ed290361","c69cd9f647be4989af2e5e5e21dad780","36be5d5e34e24fd8b7f6bfdf3f14dc76","26f42fda6d9344a48933ea892cefb87c","1500fd4e94114aa98454678e5baa9549","77c9306848444db69dbf21da9370346f","c0bc765d0a3442a2b162fa4d17d31445","356525a630dd4bfdae8586bc76851afe","1e7e91a702624226a3d661f443ab6f17","1c6b764048ea4fd8ad2e1f07a535e312","c6d73282cde34f99ae5f99945d6a088c","d2f8c8ef24ee4231a343100267982773","39b55ca016714c03a60208cc49a6b396","c55f7d403a9a4178a3a09c330f36073b","40e590fcfacb44f184fb3cd0f491ea9e","be99005858d04039a77226609ce02cef","8476f4bb395a4d9291dfc960c0d25eff","03381d7aaf704d87b77cb05a0245d38a","695ab68d6d4b468a9091c8951204fdbe","bf738f2a9bc94964a7f5df221799460a","fbeb7fad69b2491dbed805204ab99cb2","8a2a07225ea447c9961fccc7ddf2ee04","0fbcd8b716094fc695fed86b260bb31f","50207a2fa0df4436aec3d7912d7df478","daabbcfd808449a4bc475ac5f3be2073","4a57292903334f428fb67d4e0a650762","ed3aa274e0d04b78b9aaa7c36565ebca","fe3bf2799e7048ec94b7249cd91b83a8","79686f4b88a6492bb814d97b50a1b320","cfe34636ffa944a38e779ffd67d70202","9eca35fdcf014c7caa0f63a6ff883a81","55e9ede5c8bb40819b8419db4007d16a","cd8df956048e4434af88ac15707e29f4","3c8debd45b734adab462ede4906417ae","4b111be4b34d42f9801daba9c9f623da","b2a76dff60d14298a421ce02442b1b33","2acdc4ed71494aa089ec9a07338e6285","644929d279554c2a96845f1889d641d5","bd958e3fa9184817bef65705651e2dc8","2eaf6bef3704419a9020bc509f87820d","7b3fbaf24a144488826a44065494f936","24f07f5dd3674985978748f8bf933f12","ebaf365a3d56441790253b466fab3248","2044447e6c8e4168923b28397023707b","b65c4198c4764fe9bc7ebe63723ada15","04487fa1f01e4344b49b378b0ea1068b","a7596a0c7b45490dad136b5e35b8022a","a1fc78e8817344668c89951b468e28f1","98482eb4d6bf42b99f043fed56d7ac37","2b92b3226122412ab509330c3bb8a18f","5e72c7ff66c645de8efb7b53ec7aa728","d7fb298d23f24f3998ef5f51fcaf0108","695d8e0800854d05a608bc689c9a4c2e","8c9d4d83656241dab02b7d65d2dffdd8","a080a4c972f64410bf624fbd6c9864d1","0da75f1e8afd447ea1b207307933d5fc","2447b53235034c03807e8bd43f20f1b8","d48a1d744f7740fdaf15a8ac1c054463","1f7d8a47612240508578cba9501b08cf","0f41432ecb6040379f446a42113720e1","19db576129eb4752a4601ba62ca5d601","fa1a6494f0fb4df3a8cce0736263a0bf","a10a4c55f07647eeb8f91eec5d4ef226","f30e2f2c78e34d84b9f5da6d695667e0","b9f7ee718bab4a658e628f060f483bbd","f5bdd392a6824ac0827c0dd0d0302232","688081eb31b243ab9bbe8a6880b68dff","08cc6cfe7ef742649b32a9e566ba88df","3bdd2dd51b02451c9aaf33a2d0a6e88e","ec5c165a12e740f39d59c4fdf93f8d86","ea02449d51984b71812661d0479f9f53","4bd6f27cf90d4ffcaa47925e76e075bd","0000a6aca5c84282ad7b99671c6a1020","64dd84f91c0e4baa8fce6d28edd58b9c","8378a358a8494e5aa7efdf278db009b7","eec8b201e41d4186b95bbfc99b0a4093","f4b5121b6d2b48fdbcd78479008639a1","40060699111049008928788aa359047b","7b637cf671654876a55ff106e9b5898b","e0b52c6fc2af4588843ef512ff3aa58e","3dcf5f8e0e6f4e859eac98fac47c040e","3ca5cb8e536c469c9ea8b724bb763860","7a4c56c79cde4763b96559ef295f0cb3","7d6644394e854f77a6d1895486ea98ff","783aba3f2a6341ddbd7cb553eb2a7d8f","a9cd81cce7fe4eaeab4ffdd48e7108c1","29b17ffe3df2470993eaba0a39185972","062836e2f98c40219a67e93418828e27","bee5cebc3cdd4504ac957d8407c935c8","de9c7c9c64c44b11a9dacf9b3ed4c85d","9f4a6dfc0ff3425786a6424e70118483","3cf1d799731944519809bebe36a261d4","e0b030a5f3264c6dac7ac1ebdf37ef0b","bc3c4407af8a4c3c9012ca37e207e028","fda57c5c3f004243896a6e96e8e9e08b","ce252ed598a6400aa3adbce4bb510fa3","631a7284a2f04db984c123dc22b8e1b8","dce9516fefd44411ae2285cd4bf307f2","263ae3e60a50431493e3e76e542ded69","f374834a454049949030d74a9188d7a9","91d0c46761a04f9c8682e209cde8677d","c0298515569d4f119c65d2792ef61d46","e0b806a6fb8c438982db4bce42146c40","e946433235d14eaeb95a0ff6e45b0b6f","1e3db13b9e2e437ba0db3a9da668cb7f","7c38874fa9ff476e84ac5e476d4502e5","7d02c5d968d14b169e4f6250b990a8bd","96293be43a7645f8b41e10157ce721e5","62ce42d0db5c4d24a6598b534ce4b733","8f35cd4b1be94269947394252eeac2cf","2cb73954dc8f4c03896727e6fda88b7d","4a4786a9bb174c7f865503e7c6b3f230","123cabf26e574aa59d90751e274a3309","f56cf122ee4d4ea09aa434307a3045fe","7b05dfe01b974e81b6b7a12db849b496","e2985ed87f5a4d8dbd7ac4486031468d","996e073194aa45439737189625a51f30","21bfda79719f4e618c3ea6e9c9dc4daf","8f1dd1f9edb64c2083d55d3191e7bf77","a9fc15d4836b4bed9cabe5d8a077cf8c","de7f3e06c0a54953a66d2a98465b5b9e","3b7be91ae5a34caea33e9fd5f5a168dc","683bc661987a4a37948a02fd1fdd69f1","2abb463e89de4a60b5956ab8b84d2001","9273dad39ce0474ba0cf9305f6dfe2b5","d10317949d584624a7c08d650f54910b","71893c7fe5a747689d64a34f7d520399","2318a8a90855429ab8e64572208fc542","9a16a551d08247f9ac66c6858df119f6","2a49593ef439418da70ab539b9c2cbce","b58c4391b86f469fb40a6fb912ed5344","677a5ce4d5a640b1865c35dc1b57bdbc","52a7b96979e64177a090a689b60382ee","ef8d492f1c4c4c6eb4c0e9f1f51e65eb","d53c806655db481bae284b8ce3fdf66e","7a78d831ea1d4507b998e64e704ce228","a37b432669a44ce8abe78e558e88ac47","eeb0feb7060342e3aaeba65003ba6701","fb0f313379c443afb683ba83dddcd090","a4a93869373540799ddbb423a8607132","31dd5f31c15b48bf8bf8fa803a9d8198","f7c5b29010334053ae97504c0ec2bea6","874dc4d016734036a185b38d0f90ea9c","4e324e5f4ab64bb88499f8dda37c6a13","31fe981882744d24a5554ec5817c7ffd","975c0a75bf6a4ba089c73588cd3ef2b3","15546706885f4399b3747a44a06f7c9f","29d1ca90bdbe424fb2d14df70cd9bcf4","ff59f70f151341bca7daec7d1a312859","6a29b2105df848209878d3ebad476d94","dfc8e2dd74564dc4b61f30cac5fcb639","a93c58088fbf4a478d5b4374c5c9ecc5","2056590dbf4a4889a4cf369549daf83c","c0a70d23cfd043c2814b693de7be42f5","1b56873534e74de8975c244c086209b3","342eb4641c944d42831d398807f604cf","bbf0bc0e3688433e842fbff5d6e9a329","0374eefd7beb46e9b0add7200a0e4548","815df6123d0c45768774f29dfb76c088","362b9f5e1bdd459ab8c912cc122b1329","3c453b958cd04539b13c779296f35193","ae73f4d5939c47a789096103ae6924fc","4f7cce27c93d4ef5931c0211fcce37d4","6af32093626c490eafa01d3760cead4e","d472dff3249749ac8c276dd85b86bf6a","75815ed83a364ee1a3f4eb80c0b4eb93","3335f3ee56314a9db856b6d090e7d9d0","7266d11bdef146c8b88bc7c252f6ba04","afaa2b9cce49479f90772adff9312a7a","3773d466ecf7492289936bc498fce64c","d134c8afb3384dd78b4872dd3313c2df","bc8ca40596bf4957a98c2e9e5081306c","35eb1dbbce204108af528bfdc1bfd341","547ff1c3454846db89aa451eeac06da7","5ef0ff3fbbb7455a9fef85302e8a934a","69c9894005fb4761a6e72bc07544fb44","8f18860c6ccb46b6b8e2afa3eb9722d4"]},"id":"E_tDkwyuQ3kR","outputId":"d60df88c-a9db-47e0-a404-acd9d081451a","executionInfo":{"status":"ok","timestamp":1740255624452,"user_tz":-120,"elapsed":2237113,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b8871e38c44ee08f79919ecf2d4a59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bdd1c45ba35483eb7ffc9be26bd2cbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ff02d35d2044f798525c220a5da720e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f4727015544075b51249ec17574341"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48aa799028f45deac82474f037542c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a69a26a2c5bf42b29634fb52df795b0a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 315ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","[[0 1 1 ... 1 0 0]\n"," [0 0 1 ... 1 0 1]\n"," [1 1 1 ... 1 0 0]\n"," ...\n"," [1 1 0 ... 1 1 0]\n"," [0 1 1 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","Training and evaluating model: sentence-transformers/multi-qa-mpnet-base-dot-v1\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd105141f3a4c92995f2748abda07e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"798c6b5b49ec4db78d2a9e668b8dd43f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01712d5da64b4670aa00b4a2bf1ba1cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59165906e52d403c91e53abe84c1d365"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f9aa37ca694fd9992cd1024de6f6b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac512bda6154776a8109fc232899da0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 282ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 273ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 293ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","[[0 1 1 ... 0 0 0]\n"," [0 1 1 ... 1 0 1]\n"," [1 1 0 ... 1 0 1]\n"," ...\n"," [1 1 1 ... 1 0 0]\n"," [1 1 1 ... 0 0 1]\n"," [0 0 0 ... 1 0 1]]\n","Training and evaluating model: sentence-transformers/multi-qa-distilbert-cos-v1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88fe10f7f4514619925f29c5f4bc0056"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a8f7d8508a429e88701579131fdd23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b3ba65207745c58ab2eba361dc4b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1079a862500d441489b8cf140d252dff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/523 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5088c41b183b420aa7f9f85013f307f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a776c4c9bfcf4035a226d4fa59ab84a0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFDistilBertModel.\n","\n","All the weights of TFDistilBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 131ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 129ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 127ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 127ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step\n","[[0 0 0 ... 1 1 0]\n"," [0 0 1 ... 1 1 0]\n"," [0 0 0 ... 1 1 0]\n"," ...\n"," [0 0 0 ... 1 1 0]\n"," [1 0 1 ... 1 1 0]\n"," [0 0 1 ... 1 1 0]]\n","Training and evaluating model: sentence-transformers/all-distilroberta-v1\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98818d3839124f1ca94c9bcab601de27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61892bf08f94477da0a0862661dfcdae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d626bf001024415bf4189a9fa9e6790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1768ff11484d66b7f02c0249ea3ca4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc7f0b12d75a422d9888bff6809c58f6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4af2ac4fe64a5bb2b98be2b7273099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87337dd2f78448887eac6c6cf33a5ca"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 157ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 156ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step\n","[[0 0 1 ... 0 0 0]\n"," [1 1 0 ... 0 1 1]\n"," [1 0 1 ... 0 0 1]\n"," ...\n"," [1 0 1 ... 1 1 0]\n"," [1 0 1 ... 1 0 0]\n"," [1 0 0 ... 0 0 0]]\n","Training and evaluating model: sentence-transformers/all-MiniLM-L12-v2\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a4f2c303d942b6819d095a9be59a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426fc031ad2741779d60e3b01f49fbe4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f53188c89a304ab19cdddd98031c9325"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a2e13b5b3b4bd283f82f91275588a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb5ed39808342c5b41d340e19005093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69cd9f647be4989af2e5e5e21dad780"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 326ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 218ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 208ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step\n","[[1 1 0 ... 0 1 1]\n"," [0 0 1 ... 0 1 0]\n"," [1 0 0 ... 1 0 0]\n"," ...\n"," [0 0 1 ... 1 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 0 0 ... 1 0 0]]\n","Training and evaluating model: microsoft/deberta-v3-base\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39b55ca016714c03a60208cc49a6b396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50207a2fa0df4436aec3d7912d7df478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b111be4b34d42f9801daba9c9f623da"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/736M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04487fa1f01e4344b49b378b0ea1068b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 563ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 471ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 457ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 477ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 449ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 439ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 474ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 432ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 479ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 438ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 445ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 439ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 442ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 438ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 440ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 440ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 439ms/step\n","[[0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]]\n","Training and evaluating model: microsoft/codebert-base\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2447b53235034c03807e8bd43f20f1b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08cc6cfe7ef742649b32a9e566ba88df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b637cf671654876a55ff106e9b5898b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de9c7c9c64c44b11a9dacf9b3ed4c85d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91d0c46761a04f9c8682e209cde8677d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4786a9bb174c7f865503e7c6b3f230"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 304ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 279ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 297ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 269ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 266ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 263ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 262ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 262ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 256ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","[[0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," ...\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]]\n","Training and evaluating model: bert-base-uncased\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"683bc661987a4a37948a02fd1fdd69f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef8d492f1c4c4c6eb4c0e9f1f51e65eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fe981882744d24a5554ec5817c7ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342eb4641c944d42831d398807f604cf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3335f3ee56314a9db856b6d090e7d9d0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 255ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 253ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 251ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 245ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 239ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 239ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 239ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step\n","[[1 0 0 ... 1 1 0]\n"," [1 1 0 ... 0 1 0]\n"," [1 1 0 ... 1 1 0]\n"," ...\n"," [1 1 1 ... 0 1 0]\n"," [1 0 0 ... 0 1 0]\n"," [1 1 1 ... 0 1 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_220718_base_top_5_basic_nli'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_base_top_10_basic_nli'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_base_top_20_basic_nli'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","# #####################################################################################################################################################\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_5_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_10_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_20_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","\n","from google.colab import runtime\n","runtime.unassign()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["89d8676581c84452ac3dca8197bf8075","b148f28a3fa941d585c58e217fd8be55","cbbd9ea9340741cd8c75e56882c59c96","8018582abd9e46028458e2f0bb49aa68","2457de4035074edb8d0e0e896339e451","334d7b554cc949b3ad8c278b612436c5","16709891f78d4330aa30f2c0d0f25e36","61e07a8840dd400ea300bbc47db1c2bb","ea48c26823364ca7ad93c7f9c6a7a9ab","145f74f8151244d8a9abe6f19702207e","e016f2983060497bbb8305d29030fd29","c453bca1feef4d7e995ed8927f0616d4","85c394a305a746a48f34c9152bce8f8b","97125525c4ad4f4195170b5473e6ce8e","8f7f3e164fe54a028d6ef8cefadb5357","f7b92639bc654a498a16cb1acf1f0eae","b6099387574d4a3db8199c2acca3773c","758fc2ead5914fc2811493979aa40485","3e938feae4874204bf9e75f606345222","eba78b635e594ebbacb48c503cd70f1a","1834f02ecb774d68bf9a4a47024884f5","73f1e3bb31034f49a76974d29c9d6e5d","c0b65940a5844185b6df13eda7833dad","90c4667efcaf4ec89289b230b4405b82","3583ca230f714d7e96acb6d8c2adf855","35f0425bd9254cff94ea80a3a87f424f","6621eb88a44644149e243ed3d5119f77","2075f23cfe5040c7923c7cec1d5919e4","f399ac2dcd894eb4a597f41aa2c53d00","c3d202f9ab7546489f4c824659e5d4e2","cefbe97b8a7b4aa3a1ca4ebf9f0848a4","db16a08b51054e129f338cf28dc12860","2e59e220e1eb47f5b47f033e291f54a1","7c4b01afb14d430fa7c09a72937714ed","98fe94ba97b242b0beb0a9ae5d9482d3","b5f527456a9f4340825447e0160aba94","b34d57acb8f44571990d23b4659fd955","7e6f497b5d76441083d645d65bc11a28","08cd1cb859794c818af4095d42c0aa2e","2d959ea2063540268ad377ed5cfcf156","39f3a7d89dcd4b8db0d525d9140530fd","963eb1c547234cb5af99abe810857c48","f63a81bba30944b58096c5c6365dd596","9fdabb13d6e544ff9debc66cdd3aae35"]},"id":"7A1gnUKT1Nhy","outputId":"efd5f13c-21df-4aca-c9f4-d4ac86ea4acb","executionInfo":{"status":"ok","timestamp":1740274801400,"user_tz":-120,"elapsed":747113,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89d8676581c84452ac3dca8197bf8075","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c453bca1feef4d7e995ed8927f0616d4","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0b65940a5844185b6df13eda7833dad","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c4b01afb14d430fa7c09a72937714ed","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_220718_base_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - auc: 0.6680 - binary_accuracy: 0.6185 - f1: 0.6213 - loss: 0.6602 - prc_auc: 0.6460 - precision: 0.6139 - recall: 0.6554\n","Epoch 1: Validation Metrics:\n","loss: 0.6310290694236755\n","val_binary_accuracy: 0.682572603225708\n","val_precision: 0.5767790079116821\n","val_recall: 0.7938144207000732\n","val_auc: 0.751413881778717\n","val_prc_auc: 0.599454402923584\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 483ms/step - auc: 0.6685 - binary_accuracy: 0.6190 - f1: 0.6220 - loss: 0.6599 - prc_auc: 0.6464 - precision: 0.6142 - recall: 0.6566 - val_auc: 0.7514 - val_binary_accuracy: 0.6826 - val_f1: 0.6681 - val_loss: 0.5939 - val_prc_auc: 0.5995 - val_precision: 0.5768 - val_recall: 0.7938\n","Epoch 2/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7609 - binary_accuracy: 0.7232 - f1: 0.7557 - loss: 0.5767 - prc_auc: 0.7164 - precision: 0.6970 - recall: 0.8265\n","Epoch 2: Validation Metrics:\n","loss: 0.5744242668151855\n","val_binary_accuracy: 0.6867219805717468\n","val_precision: 0.586345374584198\n","val_recall: 0.7525773048400879\n","val_auc: 0.7586805820465088\n","val_prc_auc: 0.6053452491760254\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.7610 - binary_accuracy: 0.7231 - f1: 0.7555 - loss: 0.5767 - prc_auc: 0.7164 - precision: 0.6968 - recall: 0.8264 - val_auc: 0.7587 - val_binary_accuracy: 0.6867 - val_f1: 0.6591 - val_loss: 0.5725 - val_prc_auc: 0.6053 - val_precision: 0.5863 - val_recall: 0.7526\n","Epoch 3/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7716 - binary_accuracy: 0.7170 - f1: 0.7473 - loss: 0.5616 - prc_auc: 0.7308 - precision: 0.6959 - recall: 0.8082\n","Epoch 3: Validation Metrics:\n","loss: 0.5629900693893433\n","val_binary_accuracy: 0.6908713579177856\n","val_precision: 0.5903614163398743\n","val_recall: 0.7577319741249084\n","val_auc: 0.7618485689163208\n","val_prc_auc: 0.6093336343765259\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7716 - binary_accuracy: 0.7169 - f1: 0.7472 - loss: 0.5616 - prc_auc: 0.7308 - precision: 0.6957 - recall: 0.8081 - val_auc: 0.7618 - val_binary_accuracy: 0.6909 - val_f1: 0.6637 - val_loss: 0.5684 - val_prc_auc: 0.6093 - val_precision: 0.5904 - val_recall: 0.7577\n","Epoch 4/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7769 - binary_accuracy: 0.7220 - f1: 0.7500 - loss: 0.5568 - prc_auc: 0.7383 - precision: 0.7028 - recall: 0.8053\n","Epoch 4: Validation Metrics:\n","loss: 0.5585014224052429\n","val_binary_accuracy: 0.6887966990470886\n","val_precision: 0.5879999995231628\n","val_recall: 0.7577319741249084\n","val_auc: 0.7645511627197266\n","val_prc_auc: 0.6116563677787781\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7770 - binary_accuracy: 0.7219 - f1: 0.7499 - loss: 0.5568 - prc_auc: 0.7383 - precision: 0.7026 - recall: 0.8053 - val_auc: 0.7646 - val_binary_accuracy: 0.6888 - val_f1: 0.6622 - val_loss: 0.5667 - val_prc_auc: 0.6117 - val_precision: 0.5880 - val_recall: 0.7577\n","Epoch 5/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7804 - binary_accuracy: 0.7199 - f1: 0.7472 - loss: 0.5535 - prc_auc: 0.7421 - precision: 0.7023 - recall: 0.7995\n","Epoch 5: Validation Metrics:\n","loss: 0.5551414489746094\n","val_binary_accuracy: 0.6950207352638245\n","val_precision: 0.5936254858970642\n","val_recall: 0.7680412530899048\n","val_auc: 0.7670926451683044\n","val_prc_auc: 0.6152887344360352\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7805 - binary_accuracy: 0.7199 - f1: 0.7471 - loss: 0.5535 - prc_auc: 0.7421 - precision: 0.7021 - recall: 0.7995 - val_auc: 0.7671 - val_binary_accuracy: 0.6950 - val_f1: 0.6697 - val_loss: 0.5653 - val_prc_auc: 0.6153 - val_precision: 0.5936 - val_recall: 0.7680\n","Epoch 6/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7831 - binary_accuracy: 0.7236 - f1: 0.7511 - loss: 0.5507 - prc_auc: 0.7454 - precision: 0.7045 - recall: 0.8053\n","Epoch 6: Validation Metrics:\n","loss: 0.5521249175071716\n","val_binary_accuracy: 0.6950207352638245\n","val_precision: 0.5936254858970642\n","val_recall: 0.7680412530899048\n","val_auc: 0.7686856389045715\n","val_prc_auc: 0.6177217960357666\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7832 - binary_accuracy: 0.7236 - f1: 0.7510 - loss: 0.5507 - prc_auc: 0.7454 - precision: 0.7043 - recall: 0.8053 - val_auc: 0.7687 - val_binary_accuracy: 0.6950 - val_f1: 0.6697 - val_loss: 0.5643 - val_prc_auc: 0.6177 - val_precision: 0.5936 - val_recall: 0.7680\n","Epoch 7/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7860 - binary_accuracy: 0.7236 - f1: 0.7510 - loss: 0.5481 - prc_auc: 0.7483 - precision: 0.7046 - recall: 0.8049\n","Epoch 7: Validation Metrics:\n","loss: 0.5493305921554565\n","val_binary_accuracy: 0.6950207352638245\n","val_precision: 0.5936254858970642\n","val_recall: 0.7680412530899048\n","val_auc: 0.7708423137664795\n","val_prc_auc: 0.622574508190155\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7860 - binary_accuracy: 0.7236 - f1: 0.7509 - loss: 0.5481 - prc_auc: 0.7483 - precision: 0.7045 - recall: 0.8049 - val_auc: 0.7708 - val_binary_accuracy: 0.6950 - val_f1: 0.6697 - val_loss: 0.5634 - val_prc_auc: 0.6226 - val_precision: 0.5936 - val_recall: 0.7680\n","Epoch 8/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7882 - binary_accuracy: 0.7245 - f1: 0.7515 - loss: 0.5458 - prc_auc: 0.7503 - precision: 0.7056 - recall: 0.8048\n","Epoch 8: Validation Metrics:\n","loss: 0.5467423796653748\n","val_binary_accuracy: 0.6970954537391663\n","val_precision: 0.5952380895614624\n","val_recall: 0.7731958627700806\n","val_auc: 0.771987795829773\n","val_prc_auc: 0.6256494522094727\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7882 - binary_accuracy: 0.7245 - f1: 0.7514 - loss: 0.5458 - prc_auc: 0.7503 - precision: 0.7055 - recall: 0.8048 - val_auc: 0.7720 - val_binary_accuracy: 0.6971 - val_f1: 0.6726 - val_loss: 0.5625 - val_prc_auc: 0.6256 - val_precision: 0.5952 - val_recall: 0.7732\n","Epoch 9/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7903 - binary_accuracy: 0.7251 - f1: 0.7523 - loss: 0.5436 - prc_auc: 0.7521 - precision: 0.7059 - recall: 0.8062\n","Epoch 9: Validation Metrics:\n","loss: 0.544297993183136\n","val_binary_accuracy: 0.6970954537391663\n","val_precision: 0.5952380895614624\n","val_recall: 0.7731958627700806\n","val_auc: 0.7735269665718079\n","val_prc_auc: 0.6282385587692261\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7904 - binary_accuracy: 0.7251 - f1: 0.7522 - loss: 0.5436 - prc_auc: 0.7521 - precision: 0.7058 - recall: 0.8062 - val_auc: 0.7735 - val_binary_accuracy: 0.6971 - val_f1: 0.6726 - val_loss: 0.5618 - val_prc_auc: 0.6282 - val_precision: 0.5952 - val_recall: 0.7732\n","Epoch 10/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7923 - binary_accuracy: 0.7255 - f1: 0.7524 - loss: 0.5414 - prc_auc: 0.7540 - precision: 0.7065 - recall: 0.8056\n","Epoch 10: Validation Metrics:\n","loss: 0.5419356822967529\n","val_binary_accuracy: 0.6991701126098633\n","val_precision: 0.5968379378318787\n","val_recall: 0.7783505320549011\n","val_auc: 0.774663507938385\n","val_prc_auc: 0.6288787126541138\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7924 - binary_accuracy: 0.7254 - f1: 0.7523 - loss: 0.5414 - prc_auc: 0.7541 - precision: 0.7064 - recall: 0.8056 - val_auc: 0.7747 - val_binary_accuracy: 0.6992 - val_f1: 0.6756 - val_loss: 0.5610 - val_prc_auc: 0.6289 - val_precision: 0.5968 - val_recall: 0.7784\n","Epoch 11/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7942 - binary_accuracy: 0.7248 - f1: 0.7514 - loss: 0.5393 - prc_auc: 0.7558 - precision: 0.7062 - recall: 0.8038\n","Epoch 11: Validation Metrics:\n","loss: 0.5396285653114319\n","val_binary_accuracy: 0.7053942084312439\n","val_precision: 0.60317462682724\n","val_recall: 0.7835051417350769\n","val_auc: 0.7761759161949158\n","val_prc_auc: 0.6286181807518005\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7942 - binary_accuracy: 0.7248 - f1: 0.7514 - loss: 0.5393 - prc_auc: 0.7558 - precision: 0.7061 - recall: 0.8038 - val_auc: 0.7762 - val_binary_accuracy: 0.7054 - val_f1: 0.6816 - val_loss: 0.5603 - val_prc_auc: 0.6286 - val_precision: 0.6032 - val_recall: 0.7835\n","Epoch 12/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7961 - binary_accuracy: 0.7278 - f1: 0.7543 - loss: 0.5373 - prc_auc: 0.7570 - precision: 0.7086 - recall: 0.8072\n","Epoch 12: Validation Metrics:\n","loss: 0.5373905897140503\n","val_binary_accuracy: 0.7074688673019409\n","val_precision: 0.6055777072906494\n","val_recall: 0.7835051417350769\n","val_auc: 0.7777241468429565\n","val_prc_auc: 0.6360180377960205\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - auc: 0.7961 - binary_accuracy: 0.7278 - f1: 0.7542 - loss: 0.5373 - prc_auc: 0.7570 - precision: 0.7085 - recall: 0.8072 - val_auc: 0.7777 - val_binary_accuracy: 0.7075 - val_f1: 0.6831 - val_loss: 0.5597 - val_prc_auc: 0.6360 - val_precision: 0.6056 - val_recall: 0.7835\n","Epoch 13/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7977 - binary_accuracy: 0.7313 - f1: 0.7571 - loss: 0.5354 - prc_auc: 0.7595 - precision: 0.7121 - recall: 0.8089\n","Epoch 13: Validation Metrics:\n","loss: 0.5352452993392944\n","val_binary_accuracy: 0.7095435857772827\n","val_precision: 0.6071428656578064\n","val_recall: 0.7886598110198975\n","val_auc: 0.7784757614135742\n","val_prc_auc: 0.635395884513855\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7977 - binary_accuracy: 0.7314 - f1: 0.7570 - loss: 0.5354 - prc_auc: 0.7595 - precision: 0.7121 - recall: 0.8089 - val_auc: 0.7785 - val_binary_accuracy: 0.7095 - val_f1: 0.6861 - val_loss: 0.5591 - val_prc_auc: 0.6354 - val_precision: 0.6071 - val_recall: 0.7887\n","Epoch 14/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7991 - binary_accuracy: 0.7328 - f1: 0.7580 - loss: 0.5335 - prc_auc: 0.7606 - precision: 0.7140 - recall: 0.8085\n","Epoch 14: Validation Metrics:\n","loss: 0.5331520438194275\n","val_binary_accuracy: 0.7053942084312439\n","val_precision: 0.6023622155189514\n","val_recall: 0.7886598110198975\n","val_auc: 0.7791648507118225\n","val_prc_auc: 0.6360786557197571\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.7992 - binary_accuracy: 0.7328 - f1: 0.7579 - loss: 0.5335 - prc_auc: 0.7607 - precision: 0.7139 - recall: 0.8085 - val_auc: 0.7792 - val_binary_accuracy: 0.7054 - val_f1: 0.6830 - val_loss: 0.5585 - val_prc_auc: 0.6361 - val_precision: 0.6024 - val_recall: 0.7887\n","Epoch 15/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8008 - binary_accuracy: 0.7358 - f1: 0.7603 - loss: 0.5316 - prc_auc: 0.7619 - precision: 0.7172 - recall: 0.8097\n","Epoch 15: Validation Metrics:\n","loss: 0.5310959219932556\n","val_binary_accuracy: 0.7033194899559021\n","val_precision: 0.6000000238418579\n","val_recall: 0.7886598110198975\n","val_auc: 0.7804445624351501\n","val_prc_auc: 0.6394569873809814\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.8009 - binary_accuracy: 0.7358 - f1: 0.7603 - loss: 0.5316 - prc_auc: 0.7620 - precision: 0.7171 - recall: 0.8097 - val_auc: 0.7804 - val_binary_accuracy: 0.7033 - val_f1: 0.6815 - val_loss: 0.5581 - val_prc_auc: 0.6395 - val_precision: 0.6000 - val_recall: 0.7887\n","Epoch 16/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8021 - binary_accuracy: 0.7403 - f1: 0.7640 - loss: 0.5298 - prc_auc: 0.7630 - precision: 0.7219 - recall: 0.8122\n","Epoch 16: Validation Metrics:\n","loss: 0.5290588736534119\n","val_binary_accuracy: 0.7053942084312439\n","val_precision: 0.6023622155189514\n","val_recall: 0.7886598110198975\n","val_auc: 0.7808025479316711\n","val_prc_auc: 0.6362494230270386\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.8022 - binary_accuracy: 0.7403 - f1: 0.7640 - loss: 0.5298 - prc_auc: 0.7631 - precision: 0.7218 - recall: 0.8122 - val_auc: 0.7808 - val_binary_accuracy: 0.7054 - val_f1: 0.6830 - val_loss: 0.5576 - val_prc_auc: 0.6362 - val_precision: 0.6024 - val_recall: 0.7887\n","Epoch 17/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8038 - binary_accuracy: 0.7407 - f1: 0.7640 - loss: 0.5279 - prc_auc: 0.7646 - precision: 0.7229 - recall: 0.8107\n","Epoch 17: Validation Metrics:\n","loss: 0.5270484089851379\n","val_binary_accuracy: 0.7053942084312439\n","val_precision: 0.6015625\n","val_recall: 0.7938144207000732\n","val_auc: 0.7814289331436157\n","val_prc_auc: 0.6406058073043823\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.8039 - binary_accuracy: 0.7407 - f1: 0.7639 - loss: 0.5279 - prc_auc: 0.7646 - precision: 0.7229 - recall: 0.8107 - val_auc: 0.7814 - val_binary_accuracy: 0.7054 - val_f1: 0.6844 - val_loss: 0.5573 - val_prc_auc: 0.6406 - val_precision: 0.6016 - val_recall: 0.7938\n","Epoch 18/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8055 - binary_accuracy: 0.7442 - f1: 0.7666 - loss: 0.5261 - prc_auc: 0.7674 - precision: 0.7271 - recall: 0.8115\n","Epoch 18: Validation Metrics:\n","loss: 0.525048017501831\n","val_binary_accuracy: 0.7053942084312439\n","val_precision: 0.6015625\n","val_recall: 0.7938144207000732\n","val_auc: 0.7815274596214294\n","val_prc_auc: 0.6378704309463501\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - auc: 0.8056 - binary_accuracy: 0.7442 - f1: 0.7666 - loss: 0.5261 - prc_auc: 0.7675 - precision: 0.7270 - recall: 0.8116 - val_auc: 0.7815 - val_binary_accuracy: 0.7054 - val_f1: 0.6844 - val_loss: 0.5570 - val_prc_auc: 0.6379 - val_precision: 0.6016 - val_recall: 0.7938\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_220718_base_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - auc: 0.7405 - binary_accuracy: 0.6867 - f1: 0.7005 - loss: 0.6429 - prc_auc: 0.7353 - precision: 0.6832 - recall: 0.7225\n","Epoch 1: Validation Metrics:\n","loss: 0.6110967993736267\n","val_binary_accuracy: 0.7095435857772827\n","val_precision: 0.5962441563606262\n","val_recall: 0.7016574740409851\n","val_auc: 0.7466731071472168\n","val_prc_auc: 0.6253145933151245\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 415ms/step - auc: 0.7407 - binary_accuracy: 0.6869 - f1: 0.7006 - loss: 0.6426 - prc_auc: 0.7354 - precision: 0.6835 - recall: 0.7224 - val_auc: 0.7467 - val_binary_accuracy: 0.7095 - val_f1: 0.6447 - val_loss: 0.6131 - val_prc_auc: 0.6253 - val_precision: 0.5962 - val_recall: 0.7017\n","Epoch 2/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8092 - binary_accuracy: 0.7335 - f1: 0.7316 - loss: 0.5473 - prc_auc: 0.8041 - precision: 0.7437 - recall: 0.7200\n","Epoch 2: Validation Metrics:\n","loss: 0.5504069924354553\n","val_binary_accuracy: 0.6950207352638245\n","val_precision: 0.5787037014961243\n","val_recall: 0.6906077265739441\n","val_auc: 0.7519960999488831\n","val_prc_auc: 0.6241555213928223\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.8091 - binary_accuracy: 0.7335 - f1: 0.7316 - loss: 0.5473 - prc_auc: 0.8039 - precision: 0.7436 - recall: 0.7200 - val_auc: 0.7520 - val_binary_accuracy: 0.6950 - val_f1: 0.6297 - val_loss: 0.6061 - val_prc_auc: 0.6242 - val_precision: 0.5787 - val_recall: 0.6906\n","Epoch 3/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8156 - binary_accuracy: 0.7376 - f1: 0.7379 - loss: 0.5338 - prc_auc: 0.8136 - precision: 0.7442 - recall: 0.7318\n","Epoch 3: Validation Metrics:\n","loss: 0.539663553237915\n","val_binary_accuracy: 0.6887966990470886\n","val_precision: 0.5707762837409973\n","val_recall: 0.6906077265739441\n","val_auc: 0.7540794014930725\n","val_prc_auc: 0.6238327026367188\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.8155 - binary_accuracy: 0.7376 - f1: 0.7378 - loss: 0.5339 - prc_auc: 0.8134 - precision: 0.7441 - recall: 0.7318 - val_auc: 0.7541 - val_binary_accuracy: 0.6888 - val_f1: 0.6250 - val_loss: 0.6023 - val_prc_auc: 0.6238 - val_precision: 0.5708 - val_recall: 0.6906\n","Epoch 4/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8182 - binary_accuracy: 0.7430 - f1: 0.7439 - loss: 0.5289 - prc_auc: 0.8165 - precision: 0.7483 - recall: 0.7398\n","Epoch 4: Validation Metrics:\n","loss: 0.5347416996955872\n","val_binary_accuracy: 0.6887966990470886\n","val_precision: 0.570135772228241\n","val_recall: 0.6961326003074646\n","val_auc: 0.7548410892486572\n","val_prc_auc: 0.625240683555603\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.8181 - binary_accuracy: 0.7430 - f1: 0.7439 - loss: 0.5289 - prc_auc: 0.8163 - precision: 0.7483 - recall: 0.7397 - val_auc: 0.7548 - val_binary_accuracy: 0.6888 - val_f1: 0.6269 - val_loss: 0.6002 - val_prc_auc: 0.6252 - val_precision: 0.5701 - val_recall: 0.6961\n","Epoch 5/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8208 - binary_accuracy: 0.7440 - f1: 0.7461 - loss: 0.5252 - prc_auc: 0.8205 - precision: 0.7472 - recall: 0.7451\n","Epoch 5: Validation Metrics:\n","loss: 0.5310463309288025\n","val_binary_accuracy: 0.6970954537391663\n","val_precision: 0.5799086689949036\n","val_recall: 0.7016574740409851\n","val_auc: 0.7557314038276672\n","val_prc_auc: 0.6266422271728516\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.8208 - binary_accuracy: 0.7440 - f1: 0.7460 - loss: 0.5253 - prc_auc: 0.8204 - precision: 0.7471 - recall: 0.7451 - val_auc: 0.7557 - val_binary_accuracy: 0.6971 - val_f1: 0.6350 - val_loss: 0.5984 - val_prc_auc: 0.6266 - val_precision: 0.5799 - val_recall: 0.7017\n","Epoch 6/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8231 - binary_accuracy: 0.7468 - f1: 0.7480 - loss: 0.5220 - prc_auc: 0.8224 - precision: 0.7515 - recall: 0.7446\n","Epoch 6: Validation Metrics:\n","loss: 0.5278527736663818\n","val_binary_accuracy: 0.7012448310852051\n","val_precision: 0.5844748616218567\n","val_recall: 0.7071823477745056\n","val_auc: 0.7576861381530762\n","val_prc_auc: 0.6296684741973877\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.8230 - binary_accuracy: 0.7467 - f1: 0.7479 - loss: 0.5220 - prc_auc: 0.8223 - precision: 0.7514 - recall: 0.7445 - val_auc: 0.7577 - val_binary_accuracy: 0.7012 - val_f1: 0.6400 - val_loss: 0.5968 - val_prc_auc: 0.6297 - val_precision: 0.5845 - val_recall: 0.7072\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_220718_base_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - auc: 0.6630 - binary_accuracy: 0.6016 - f1: 0.6345 - loss: 0.6716 - prc_auc: 0.6486 - precision: 0.5749 - recall: 0.7172\n","Epoch 1: Validation Metrics:\n","loss: 0.6574938297271729\n","val_binary_accuracy: 0.6244813203811646\n","val_precision: 0.44954127073287964\n","val_recall: 0.6163522005081177\n","val_auc: 0.6757014989852905\n","val_prc_auc: 0.4934806227684021\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 428ms/step - auc: 0.6632 - binary_accuracy: 0.6018 - f1: 0.6345 - loss: 0.6715 - prc_auc: 0.6489 - precision: 0.5753 - recall: 0.7165 - val_auc: 0.6757 - val_binary_accuracy: 0.6245 - val_f1: 0.5199 - val_loss: 0.6558 - val_prc_auc: 0.4935 - val_precision: 0.4495 - val_recall: 0.6164\n","Epoch 2/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7139 - binary_accuracy: 0.6593 - f1: 0.6396 - loss: 0.6274 - prc_auc: 0.7096 - precision: 0.6543 - recall: 0.6260\n","Epoch 2: Validation Metrics:\n","loss: 0.6252872943878174\n","val_binary_accuracy: 0.634854793548584\n","val_precision: 0.45728641748428345\n","val_recall: 0.5723270177841187\n","val_auc: 0.6747764945030212\n","val_prc_auc: 0.4917238652706146\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.7138 - binary_accuracy: 0.6591 - f1: 0.6395 - loss: 0.6274 - prc_auc: 0.7096 - precision: 0.6545 - recall: 0.6256 - val_auc: 0.6748 - val_binary_accuracy: 0.6349 - val_f1: 0.5084 - val_loss: 0.6504 - val_prc_auc: 0.4917 - val_precision: 0.4573 - val_recall: 0.5723\n","Epoch 3/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7229 - binary_accuracy: 0.6636 - f1: 0.6334 - loss: 0.6148 - prc_auc: 0.7198 - precision: 0.6686 - recall: 0.6018\n","Epoch 3: Validation Metrics:\n","loss: 0.6162808537483215\n","val_binary_accuracy: 0.634854793548584\n","val_precision: 0.45728641748428345\n","val_recall: 0.5723270177841187\n","val_auc: 0.6776096820831299\n","val_prc_auc: 0.49426746368408203\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7228 - binary_accuracy: 0.6634 - f1: 0.6334 - loss: 0.6148 - prc_auc: 0.7198 - precision: 0.6687 - recall: 0.6018 - val_auc: 0.6776 - val_binary_accuracy: 0.6349 - val_f1: 0.5084 - val_loss: 0.6493 - val_prc_auc: 0.4943 - val_precision: 0.4573 - val_recall: 0.5723\n","Epoch 4/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7282 - binary_accuracy: 0.6649 - f1: 0.6339 - loss: 0.6095 - prc_auc: 0.7253 - precision: 0.6707 - recall: 0.6011\n","Epoch 4: Validation Metrics:\n","loss: 0.6119864583015442\n","val_binary_accuracy: 0.634854793548584\n","val_precision: 0.4568527936935425\n","val_recall: 0.5660377144813538\n","val_auc: 0.678739070892334\n","val_prc_auc: 0.49487969279289246\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.7281 - binary_accuracy: 0.6646 - f1: 0.6339 - loss: 0.6096 - prc_auc: 0.7254 - precision: 0.6707 - recall: 0.6011 - val_auc: 0.6787 - val_binary_accuracy: 0.6349 - val_f1: 0.5056 - val_loss: 0.6484 - val_prc_auc: 0.4949 - val_precision: 0.4569 - val_recall: 0.5660\n","Epoch 5/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7319 - binary_accuracy: 0.6679 - f1: 0.6377 - loss: 0.6060 - prc_auc: 0.7294 - precision: 0.6737 - recall: 0.6056\n","Epoch 5: Validation Metrics:\n","loss: 0.6088253259658813\n","val_binary_accuracy: 0.6390041708946228\n","val_precision: 0.4615384638309479\n","val_recall: 0.5660377144813538\n","val_auc: 0.6799268126487732\n","val_prc_auc: 0.49605101346969604\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7318 - binary_accuracy: 0.6676 - f1: 0.6378 - loss: 0.6060 - prc_auc: 0.7295 - precision: 0.6737 - recall: 0.6056 - val_auc: 0.6799 - val_binary_accuracy: 0.6390 - val_f1: 0.5085 - val_loss: 0.6479 - val_prc_auc: 0.4961 - val_precision: 0.4615 - val_recall: 0.5660\n","Epoch 6/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7352 - binary_accuracy: 0.6695 - f1: 0.6412 - loss: 0.6031 - prc_auc: 0.7323 - precision: 0.6737 - recall: 0.6120\n","Epoch 6: Validation Metrics:\n","loss: 0.6060876250267029\n","val_binary_accuracy: 0.6493775844573975\n","val_precision: 0.47422680258750916\n","val_recall: 0.5786163806915283\n","val_auc: 0.681036651134491\n","val_prc_auc: 0.4947909116744995\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7351 - binary_accuracy: 0.6693 - f1: 0.6412 - loss: 0.6031 - prc_auc: 0.7324 - precision: 0.6737 - recall: 0.6119 - val_auc: 0.6810 - val_binary_accuracy: 0.6494 - val_f1: 0.5212 - val_loss: 0.6476 - val_prc_auc: 0.4948 - val_precision: 0.4742 - val_recall: 0.5786\n","Epoch 7/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7384 - binary_accuracy: 0.6706 - f1: 0.6426 - loss: 0.6005 - prc_auc: 0.7353 - precision: 0.6748 - recall: 0.6134\n","Epoch 7: Validation Metrics:\n","loss: 0.6035824418067932\n","val_binary_accuracy: 0.6452282071113586\n","val_precision: 0.46875\n","val_recall: 0.5660377144813538\n","val_auc: 0.6814748048782349\n","val_prc_auc: 0.49606814980506897\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7383 - binary_accuracy: 0.6704 - f1: 0.6426 - loss: 0.6005 - prc_auc: 0.7354 - precision: 0.6748 - recall: 0.6135 - val_auc: 0.6815 - val_binary_accuracy: 0.6452 - val_f1: 0.5128 - val_loss: 0.6475 - val_prc_auc: 0.4961 - val_precision: 0.4688 - val_recall: 0.5660\n","Epoch 8/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7410 - binary_accuracy: 0.6730 - f1: 0.6465 - loss: 0.5980 - prc_auc: 0.7382 - precision: 0.6759 - recall: 0.6197\n","Epoch 8: Validation Metrics:\n","loss: 0.6012001037597656\n","val_binary_accuracy: 0.6431535482406616\n","val_precision: 0.4663212299346924\n","val_recall: 0.5660377144813538\n","val_auc: 0.6820589303970337\n","val_prc_auc: 0.4966723322868347\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7409 - binary_accuracy: 0.6728 - f1: 0.6465 - loss: 0.5981 - prc_auc: 0.7383 - precision: 0.6760 - recall: 0.6197 - val_auc: 0.6821 - val_binary_accuracy: 0.6432 - val_f1: 0.5114 - val_loss: 0.6475 - val_prc_auc: 0.4967 - val_precision: 0.4663 - val_recall: 0.5660\n","Epoch 9/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7437 - binary_accuracy: 0.6748 - f1: 0.6486 - loss: 0.5957 - prc_auc: 0.7407 - precision: 0.6779 - recall: 0.6220\n","Epoch 9: Validation Metrics:\n","loss: 0.598905086517334\n","val_binary_accuracy: 0.6452282071113586\n","val_precision: 0.4693877696990967\n","val_recall: 0.5786163806915283\n","val_auc: 0.6827307343482971\n","val_prc_auc: 0.4963591396808624\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7435 - binary_accuracy: 0.6746 - f1: 0.6487 - loss: 0.5957 - prc_auc: 0.7408 - precision: 0.6780 - recall: 0.6221 - val_auc: 0.6827 - val_binary_accuracy: 0.6452 - val_f1: 0.5183 - val_loss: 0.6476 - val_prc_auc: 0.4964 - val_precision: 0.4694 - val_recall: 0.5786\n","Epoch 10/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7464 - binary_accuracy: 0.6735 - f1: 0.6484 - loss: 0.5934 - prc_auc: 0.7437 - precision: 0.6753 - recall: 0.6239\n","Epoch 10: Validation Metrics:\n","loss: 0.5966383218765259\n","val_binary_accuracy: 0.6473029255867004\n","val_precision: 0.4720812141895294\n","val_recall: 0.5849056839942932\n","val_auc: 0.6838892698287964\n","val_prc_auc: 0.4990566670894623\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7463 - binary_accuracy: 0.6734 - f1: 0.6486 - loss: 0.5934 - prc_auc: 0.7438 - precision: 0.6754 - recall: 0.6240 - val_auc: 0.6839 - val_binary_accuracy: 0.6473 - val_f1: 0.5225 - val_loss: 0.6476 - val_prc_auc: 0.4991 - val_precision: 0.4721 - val_recall: 0.5849\n","Epoch 11/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7489 - binary_accuracy: 0.6747 - f1: 0.6508 - loss: 0.5911 - prc_auc: 0.7464 - precision: 0.6755 - recall: 0.6282\n","Epoch 11: Validation Metrics:\n","loss: 0.5943961143493652\n","val_binary_accuracy: 0.6493775844573975\n","val_precision: 0.47448980808258057\n","val_recall: 0.5849056839942932\n","val_auc: 0.6842495203018188\n","val_prc_auc: 0.4988973140716553\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7488 - binary_accuracy: 0.6746 - f1: 0.6510 - loss: 0.5912 - prc_auc: 0.7465 - precision: 0.6757 - recall: 0.6283 - val_auc: 0.6842 - val_binary_accuracy: 0.6494 - val_f1: 0.5239 - val_loss: 0.6476 - val_prc_auc: 0.4989 - val_precision: 0.4745 - val_recall: 0.5849\n","Epoch 12/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7518 - binary_accuracy: 0.6761 - f1: 0.6530 - loss: 0.5888 - prc_auc: 0.7490 - precision: 0.6765 - recall: 0.6313\n","Epoch 12: Validation Metrics:\n","loss: 0.5921694040298462\n","val_binary_accuracy: 0.6493775844573975\n","val_precision: 0.47448980808258057\n","val_recall: 0.5849056839942932\n","val_auc: 0.6847265362739563\n","val_prc_auc: 0.5004882216453552\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7517 - binary_accuracy: 0.6760 - f1: 0.6531 - loss: 0.5889 - prc_auc: 0.7491 - precision: 0.6767 - recall: 0.6314 - val_auc: 0.6847 - val_binary_accuracy: 0.6494 - val_f1: 0.5239 - val_loss: 0.6475 - val_prc_auc: 0.5005 - val_precision: 0.4745 - val_recall: 0.5849\n","Epoch 13/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7545 - binary_accuracy: 0.6797 - f1: 0.6556 - loss: 0.5866 - prc_auc: 0.7521 - precision: 0.6820 - recall: 0.6314\n","Epoch 13: Validation Metrics:\n","loss: 0.5899147987365723\n","val_binary_accuracy: 0.6493775844573975\n","val_precision: 0.47448980808258057\n","val_recall: 0.5849056839942932\n","val_auc: 0.6859337687492371\n","val_prc_auc: 0.5013118386268616\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7544 - binary_accuracy: 0.6796 - f1: 0.6557 - loss: 0.5866 - prc_auc: 0.7522 - precision: 0.6822 - recall: 0.6315 - val_auc: 0.6859 - val_binary_accuracy: 0.6494 - val_f1: 0.5239 - val_loss: 0.6475 - val_prc_auc: 0.5013 - val_precision: 0.4745 - val_recall: 0.5849\n","Epoch 14/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7573 - binary_accuracy: 0.6821 - f1: 0.6571 - loss: 0.5842 - prc_auc: 0.7547 - precision: 0.6857 - recall: 0.6310\n","Epoch 14: Validation Metrics:\n","loss: 0.587628960609436\n","val_binary_accuracy: 0.6514523029327393\n","val_precision: 0.4769230782985687\n","val_recall: 0.5849056839942932\n","val_auc: 0.686741828918457\n","val_prc_auc: 0.5024886131286621\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7572 - binary_accuracy: 0.6820 - f1: 0.6573 - loss: 0.5843 - prc_auc: 0.7548 - precision: 0.6859 - recall: 0.6312 - val_auc: 0.6867 - val_binary_accuracy: 0.6515 - val_f1: 0.5254 - val_loss: 0.6475 - val_prc_auc: 0.5025 - val_precision: 0.4769 - val_recall: 0.5849\n","Epoch 15/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7597 - binary_accuracy: 0.6824 - f1: 0.6584 - loss: 0.5819 - prc_auc: 0.7575 - precision: 0.6853 - recall: 0.6338\n","Epoch 15: Validation Metrics:\n","loss: 0.5853447318077087\n","val_binary_accuracy: 0.6493775844573975\n","val_precision: 0.4747474789619446\n","val_recall: 0.5911949872970581\n","val_auc: 0.6871020197868347\n","val_prc_auc: 0.502692461013794\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7596 - binary_accuracy: 0.6823 - f1: 0.6586 - loss: 0.5820 - prc_auc: 0.7576 - precision: 0.6854 - recall: 0.6340 - val_auc: 0.6871 - val_binary_accuracy: 0.6494 - val_f1: 0.5266 - val_loss: 0.6473 - val_prc_auc: 0.5027 - val_precision: 0.4747 - val_recall: 0.5912\n","Epoch 16/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7624 - binary_accuracy: 0.6870 - f1: 0.6642 - loss: 0.5796 - prc_auc: 0.7602 - precision: 0.6896 - recall: 0.6409\n","Epoch 16: Validation Metrics:\n","loss: 0.583024263381958\n","val_binary_accuracy: 0.6535269618034363\n","val_precision: 0.47979798913002014\n","val_recall: 0.597484290599823\n","val_auc: 0.6875498294830322\n","val_prc_auc: 0.5048449039459229\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7623 - binary_accuracy: 0.6868 - f1: 0.6643 - loss: 0.5796 - prc_auc: 0.7603 - precision: 0.6897 - recall: 0.6410 - val_auc: 0.6875 - val_binary_accuracy: 0.6535 - val_f1: 0.5322 - val_loss: 0.6472 - val_prc_auc: 0.5048 - val_precision: 0.4798 - val_recall: 0.5975\n","Epoch 17/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7656 - binary_accuracy: 0.6898 - f1: 0.6674 - loss: 0.5772 - prc_auc: 0.7634 - precision: 0.6927 - recall: 0.6443\n","Epoch 17: Validation Metrics:\n","loss: 0.5806968212127686\n","val_binary_accuracy: 0.6576763391494751\n","val_precision: 0.48469388484954834\n","val_recall: 0.597484290599823\n","val_auc: 0.688640296459198\n","val_prc_auc: 0.5047067403793335\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7655 - binary_accuracy: 0.6897 - f1: 0.6674 - loss: 0.5773 - prc_auc: 0.7635 - precision: 0.6927 - recall: 0.6445 - val_auc: 0.6886 - val_binary_accuracy: 0.6577 - val_f1: 0.5352 - val_loss: 0.6471 - val_prc_auc: 0.5047 - val_precision: 0.4847 - val_recall: 0.5975\n","Epoch 18/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7685 - binary_accuracy: 0.6936 - f1: 0.6719 - loss: 0.5748 - prc_auc: 0.7666 - precision: 0.6964 - recall: 0.6496\n","Epoch 18: Validation Metrics:\n","loss: 0.5783373713493347\n","val_binary_accuracy: 0.6576763391494751\n","val_precision: 0.4848484992980957\n","val_recall: 0.6037735939025879\n","val_auc: 0.6889810562133789\n","val_prc_auc: 0.5073655843734741\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7684 - binary_accuracy: 0.6935 - f1: 0.6720 - loss: 0.5749 - prc_auc: 0.7667 - precision: 0.6964 - recall: 0.6498 - val_auc: 0.6890 - val_binary_accuracy: 0.6577 - val_f1: 0.5378 - val_loss: 0.6470 - val_prc_auc: 0.5074 - val_precision: 0.4848 - val_recall: 0.6038\n","Epoch 19/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7716 - binary_accuracy: 0.6958 - f1: 0.6749 - loss: 0.5724 - prc_auc: 0.7697 - precision: 0.6978 - recall: 0.6540\n","Epoch 19: Validation Metrics:\n","loss: 0.5759515762329102\n","val_binary_accuracy: 0.6618257164955139\n","val_precision: 0.49000000953674316\n","val_recall: 0.6163522005081177\n","val_auc: 0.6890395283699036\n","val_prc_auc: 0.5045251250267029\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - auc: 0.7715 - binary_accuracy: 0.6957 - f1: 0.6750 - loss: 0.5724 - prc_auc: 0.7698 - precision: 0.6978 - recall: 0.6542 - val_auc: 0.6890 - val_binary_accuracy: 0.6618 - val_f1: 0.5460 - val_loss: 0.6469 - val_prc_auc: 0.5045 - val_precision: 0.4900 - val_recall: 0.6164\n","Epoch 20/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7748 - binary_accuracy: 0.7003 - f1: 0.6795 - loss: 0.5699 - prc_auc: 0.7729 - precision: 0.7030 - recall: 0.6581\n","Epoch 20: Validation Metrics:\n","loss: 0.573560893535614\n","val_binary_accuracy: 0.6576763391494751\n","val_precision: 0.48514851927757263\n","val_recall: 0.6163522005081177\n","val_auc: 0.6897891163825989\n","val_prc_auc: 0.5072915554046631\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7747 - binary_accuracy: 0.7001 - f1: 0.6796 - loss: 0.5700 - prc_auc: 0.7729 - precision: 0.7030 - recall: 0.6583 - val_auc: 0.6898 - val_binary_accuracy: 0.6577 - val_f1: 0.5429 - val_loss: 0.6467 - val_prc_auc: 0.5073 - val_precision: 0.4851 - val_recall: 0.6164\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_220718_base_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - auc: 0.6928 - binary_accuracy: 0.6427 - f1: 0.5630 - loss: 0.6703 - prc_auc: 0.6764 - precision: 0.6947 - recall: 0.4787\n","Epoch 1: Validation Metrics:\n","loss: 0.659109354019165\n","val_binary_accuracy: 0.6597510576248169\n","val_precision: 0.4682926833629608\n","val_recall: 0.6357616186141968\n","val_auc: 0.7158520221710205\n","val_prc_auc: 0.5790383815765381\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 540ms/step - auc: 0.6929 - binary_accuracy: 0.6428 - f1: 0.5636 - loss: 0.6701 - prc_auc: 0.6766 - precision: 0.6947 - recall: 0.4795 - val_auc: 0.7159 - val_binary_accuracy: 0.6598 - val_f1: 0.5393 - val_loss: 0.6363 - val_prc_auc: 0.5790 - val_precision: 0.4683 - val_recall: 0.6358\n","Epoch 2/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7342 - binary_accuracy: 0.6663 - f1: 0.6552 - loss: 0.6244 - prc_auc: 0.7246 - precision: 0.6627 - recall: 0.6484\n","Epoch 2: Validation Metrics:\n","loss: 0.6238831877708435\n","val_binary_accuracy: 0.6618257164955139\n","val_precision: 0.4711538553237915\n","val_recall: 0.6490066051483154\n","val_auc: 0.7221543788909912\n","val_prc_auc: 0.5901399850845337\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7341 - binary_accuracy: 0.6662 - f1: 0.6552 - loss: 0.6244 - prc_auc: 0.7246 - precision: 0.6628 - recall: 0.6483 - val_auc: 0.7222 - val_binary_accuracy: 0.6618 - val_f1: 0.5460 - val_loss: 0.6168 - val_prc_auc: 0.5901 - val_precision: 0.4712 - val_recall: 0.6490\n","Epoch 3/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7416 - binary_accuracy: 0.6797 - f1: 0.6691 - loss: 0.6056 - prc_auc: 0.7333 - precision: 0.6770 - recall: 0.6616\n","Epoch 3: Validation Metrics:\n","loss: 0.609100341796875\n","val_binary_accuracy: 0.6618257164955139\n","val_precision: 0.4711538553237915\n","val_recall: 0.6490066051483154\n","val_auc: 0.7250155806541443\n","val_prc_auc: 0.5940935015678406\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7415 - binary_accuracy: 0.6796 - f1: 0.6690 - loss: 0.6057 - prc_auc: 0.7333 - precision: 0.6771 - recall: 0.6614 - val_auc: 0.7250 - val_binary_accuracy: 0.6618 - val_f1: 0.5460 - val_loss: 0.6103 - val_prc_auc: 0.5941 - val_precision: 0.4712 - val_recall: 0.6490\n","Epoch 4/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7474 - binary_accuracy: 0.6845 - f1: 0.6752 - loss: 0.5968 - prc_auc: 0.7395 - precision: 0.6810 - recall: 0.6698\n","Epoch 4: Validation Metrics:\n","loss: 0.6016029119491577\n","val_binary_accuracy: 0.6597510576248169\n","val_precision: 0.46889951825141907\n","val_recall: 0.6490066051483154\n","val_auc: 0.7254356741905212\n","val_prc_auc: 0.5943084359169006\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7473 - binary_accuracy: 0.6845 - f1: 0.6752 - loss: 0.5968 - prc_auc: 0.7395 - precision: 0.6811 - recall: 0.6696 - val_auc: 0.7254 - val_binary_accuracy: 0.6598 - val_f1: 0.5444 - val_loss: 0.6084 - val_prc_auc: 0.5943 - val_precision: 0.4689 - val_recall: 0.6490\n","Epoch 5/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7522 - binary_accuracy: 0.6823 - f1: 0.6734 - loss: 0.5912 - prc_auc: 0.7438 - precision: 0.6783 - recall: 0.6689\n","Epoch 5: Validation Metrics:\n","loss: 0.5965259671211243\n","val_binary_accuracy: 0.6639004349708557\n","val_precision: 0.4736842215061188\n","val_recall: 0.6556291580200195\n","val_auc: 0.7271362543106079\n","val_prc_auc: 0.5957384705543518\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7521 - binary_accuracy: 0.6823 - f1: 0.6734 - loss: 0.5913 - prc_auc: 0.7438 - precision: 0.6784 - recall: 0.6687 - val_auc: 0.7271 - val_binary_accuracy: 0.6639 - val_f1: 0.5500 - val_loss: 0.6081 - val_prc_auc: 0.5957 - val_precision: 0.4737 - val_recall: 0.6556\n","Epoch 6/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7566 - binary_accuracy: 0.6877 - f1: 0.6790 - loss: 0.5869 - prc_auc: 0.7480 - precision: 0.6839 - recall: 0.6744\n","Epoch 6: Validation Metrics:\n","loss: 0.5923967957496643\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.48076921701431274\n","val_recall: 0.6622516512870789\n","val_auc: 0.72764652967453\n","val_prc_auc: 0.5957745909690857\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7565 - binary_accuracy: 0.6878 - f1: 0.6790 - loss: 0.5870 - prc_auc: 0.7480 - precision: 0.6841 - recall: 0.6743 - val_auc: 0.7276 - val_binary_accuracy: 0.6701 - val_f1: 0.5571 - val_loss: 0.6084 - val_prc_auc: 0.5958 - val_precision: 0.4808 - val_recall: 0.6623\n","Epoch 7/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7603 - binary_accuracy: 0.6865 - f1: 0.6758 - loss: 0.5832 - prc_auc: 0.7509 - precision: 0.6845 - recall: 0.6678\n","Epoch 7: Validation Metrics:\n","loss: 0.5887895822525024\n","val_binary_accuracy: 0.6701244711875916\n","val_precision: 0.48076921701431274\n","val_recall: 0.6622516512870789\n","val_auc: 0.728106677532196\n","val_prc_auc: 0.5971099138259888\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7603 - binary_accuracy: 0.6865 - f1: 0.6759 - loss: 0.5833 - prc_auc: 0.7510 - precision: 0.6847 - recall: 0.6677 - val_auc: 0.7281 - val_binary_accuracy: 0.6701 - val_f1: 0.5571 - val_loss: 0.6089 - val_prc_auc: 0.5971 - val_precision: 0.4808 - val_recall: 0.6623\n","Epoch 8/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7643 - binary_accuracy: 0.6885 - f1: 0.6791 - loss: 0.5799 - prc_auc: 0.7536 - precision: 0.6856 - recall: 0.6731\n","Epoch 8: Validation Metrics:\n","loss: 0.585504412651062\n","val_binary_accuracy: 0.6659750938415527\n","val_precision: 0.4757281541824341\n","val_recall: 0.6490066051483154\n","val_auc: 0.7283167243003845\n","val_prc_auc: 0.5976588726043701\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7642 - binary_accuracy: 0.6885 - f1: 0.6791 - loss: 0.5800 - prc_auc: 0.7536 - precision: 0.6859 - recall: 0.6730 - val_auc: 0.7283 - val_binary_accuracy: 0.6660 - val_f1: 0.5490 - val_loss: 0.6097 - val_prc_auc: 0.5977 - val_precision: 0.4757 - val_recall: 0.6490\n","Epoch 9/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7677 - binary_accuracy: 0.6927 - f1: 0.6823 - loss: 0.5768 - prc_auc: 0.7569 - precision: 0.6912 - recall: 0.6741\n","Epoch 9: Validation Metrics:\n","loss: 0.5824498534202576\n","val_binary_accuracy: 0.6659750938415527\n","val_precision: 0.47641509771347046\n","val_recall: 0.6688741445541382\n","val_auc: 0.7281467318534851\n","val_prc_auc: 0.5954832434654236\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7676 - binary_accuracy: 0.6927 - f1: 0.6824 - loss: 0.5769 - prc_auc: 0.7570 - precision: 0.6914 - recall: 0.6741 - val_auc: 0.7281 - val_binary_accuracy: 0.6660 - val_f1: 0.5565 - val_loss: 0.6106 - val_prc_auc: 0.5955 - val_precision: 0.4764 - val_recall: 0.6689\n","Epoch 10/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7712 - binary_accuracy: 0.6962 - f1: 0.6856 - loss: 0.5739 - prc_auc: 0.7595 - precision: 0.6954 - recall: 0.6766\n","Epoch 10: Validation Metrics:\n","loss: 0.5795792937278748\n","val_binary_accuracy: 0.6576763391494751\n","val_precision: 0.46759259700775146\n","val_recall: 0.6688741445541382\n","val_auc: 0.7285768389701843\n","val_prc_auc: 0.5948561429977417\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7711 - binary_accuracy: 0.6962 - f1: 0.6856 - loss: 0.5739 - prc_auc: 0.7596 - precision: 0.6955 - recall: 0.6764 - val_auc: 0.7286 - val_binary_accuracy: 0.6577 - val_f1: 0.5504 - val_loss: 0.6115 - val_prc_auc: 0.5949 - val_precision: 0.4676 - val_recall: 0.6689\n","Epoch 11/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7745 - binary_accuracy: 0.6986 - f1: 0.6892 - loss: 0.5711 - prc_auc: 0.7615 - precision: 0.6964 - recall: 0.6826\n","Epoch 11: Validation Metrics:\n","loss: 0.5768601894378662\n","val_binary_accuracy: 0.6535269618034363\n","val_precision: 0.46330276131629944\n","val_recall: 0.6688741445541382\n","val_auc: 0.7284168004989624\n","val_prc_auc: 0.5936765670776367\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - auc: 0.7744 - binary_accuracy: 0.6986 - f1: 0.6892 - loss: 0.5712 - prc_auc: 0.7615 - precision: 0.6965 - recall: 0.6825 - val_auc: 0.7284 - val_binary_accuracy: 0.6535 - val_f1: 0.5474 - val_loss: 0.6122 - val_prc_auc: 0.5937 - val_precision: 0.4633 - val_recall: 0.6689\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_220718_base_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6664 - binary_accuracy: 0.6104 - f1: 0.4165 - loss: 0.6736 - prc_auc: 0.6875 - precision: 0.7795 - recall: 0.2853\n","Epoch 1: Validation Metrics:\n","loss: 0.6630294919013977\n","val_binary_accuracy: 0.7842323780059814\n","val_precision: 0.5199999809265137\n","val_recall: 0.3644859790802002\n","val_auc: 0.6990404725074768\n","val_prc_auc: 0.4988420009613037\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 491ms/step - auc: 0.6667 - binary_accuracy: 0.6105 - f1: 0.4172 - loss: 0.6734 - prc_auc: 0.6878 - precision: 0.7796 - recall: 0.2860 - val_auc: 0.6990 - val_binary_accuracy: 0.7842 - val_f1: 0.4286 - val_loss: 0.6100 - val_prc_auc: 0.4988 - val_precision: 0.5200 - val_recall: 0.3645\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7152 - binary_accuracy: 0.6304 - f1: 0.5116 - loss: 0.6336 - prc_auc: 0.7325 - precision: 0.7247 - recall: 0.3968\n","Epoch 2: Validation Metrics:\n","loss: 0.6304044723510742\n","val_binary_accuracy: 0.7510373592376709\n","val_precision: 0.4356435537338257\n","val_recall: 0.4112149477005005\n","val_auc: 0.7090092897415161\n","val_prc_auc: 0.5058812499046326\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7152 - binary_accuracy: 0.6305 - f1: 0.5120 - loss: 0.6335 - prc_auc: 0.7325 - precision: 0.7248 - recall: 0.3972 - val_auc: 0.7090 - val_binary_accuracy: 0.7510 - val_f1: 0.4231 - val_loss: 0.5929 - val_prc_auc: 0.5059 - val_precision: 0.4356 - val_recall: 0.4112\n","Epoch 3/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7234 - binary_accuracy: 0.6588 - f1: 0.5823 - loss: 0.6141 - prc_auc: 0.7399 - precision: 0.7271 - recall: 0.4873\n","Epoch 3: Validation Metrics:\n","loss: 0.6134533286094666\n","val_binary_accuracy: 0.7302904725074768\n","val_precision: 0.40336135029792786\n","val_recall: 0.44859811663627625\n","val_auc: 0.7213208675384521\n","val_prc_auc: 0.5134886503219604\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - auc: 0.7234 - binary_accuracy: 0.6588 - f1: 0.5825 - loss: 0.6141 - prc_auc: 0.7399 - precision: 0.7272 - recall: 0.4875 - val_auc: 0.7213 - val_binary_accuracy: 0.7303 - val_f1: 0.4248 - val_loss: 0.5872 - val_prc_auc: 0.5135 - val_precision: 0.4034 - val_recall: 0.4486\n","Epoch 4/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7309 - binary_accuracy: 0.6552 - f1: 0.5921 - loss: 0.6037 - prc_auc: 0.7455 - precision: 0.7038 - recall: 0.5125\n","Epoch 4: Validation Metrics:\n","loss: 0.6040709018707275\n","val_binary_accuracy: 0.7095435857772827\n","val_precision: 0.37593984603881836\n","val_recall: 0.4672897160053253\n","val_auc: 0.7290093302726746\n","val_prc_auc: 0.5191398859024048\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7309 - binary_accuracy: 0.6553 - f1: 0.5923 - loss: 0.6037 - prc_auc: 0.7455 - precision: 0.7039 - recall: 0.5128 - val_auc: 0.7290 - val_binary_accuracy: 0.7095 - val_f1: 0.4167 - val_loss: 0.5847 - val_prc_auc: 0.5191 - val_precision: 0.3759 - val_recall: 0.4673\n","Epoch 5/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7382 - binary_accuracy: 0.6606 - f1: 0.6059 - loss: 0.5974 - prc_auc: 0.7518 - precision: 0.7020 - recall: 0.5343\n","Epoch 5: Validation Metrics:\n","loss: 0.5979820489883423\n","val_binary_accuracy: 0.7178423404693604\n","val_precision: 0.3986014127731323\n","val_recall: 0.5327102541923523\n","val_auc: 0.7372709512710571\n","val_prc_auc: 0.5240558981895447\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - auc: 0.7382 - binary_accuracy: 0.6607 - f1: 0.6062 - loss: 0.5974 - prc_auc: 0.7519 - precision: 0.7021 - recall: 0.5346 - val_auc: 0.7373 - val_binary_accuracy: 0.7178 - val_f1: 0.4560 - val_loss: 0.5833 - val_prc_auc: 0.5241 - val_precision: 0.3986 - val_recall: 0.5327\n","Epoch 6/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7442 - binary_accuracy: 0.6624 - f1: 0.6128 - loss: 0.5925 - prc_auc: 0.7571 - precision: 0.6987 - recall: 0.5472\n","Epoch 6: Validation Metrics:\n","loss: 0.5931896567344666\n","val_binary_accuracy: 0.7199169993400574\n","val_precision: 0.4041095972061157\n","val_recall: 0.5514018535614014\n","val_auc: 0.744573175907135\n","val_prc_auc: 0.5299774408340454\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7442 - binary_accuracy: 0.6625 - f1: 0.6130 - loss: 0.5926 - prc_auc: 0.7572 - precision: 0.6988 - recall: 0.5475 - val_auc: 0.7446 - val_binary_accuracy: 0.7199 - val_f1: 0.4664 - val_loss: 0.5817 - val_prc_auc: 0.5300 - val_precision: 0.4041 - val_recall: 0.5514\n","Epoch 7/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7502 - binary_accuracy: 0.6698 - f1: 0.6238 - loss: 0.5883 - prc_auc: 0.7619 - precision: 0.7050 - recall: 0.5608\n","Epoch 7: Validation Metrics:\n","loss: 0.5890453457832336\n","val_binary_accuracy: 0.726141095161438\n","val_precision: 0.41721853613853455\n","val_recall: 0.5887850522994995\n","val_auc: 0.7479003071784973\n","val_prc_auc: 0.5339955687522888\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7502 - binary_accuracy: 0.6698 - f1: 0.6240 - loss: 0.5883 - prc_auc: 0.7620 - precision: 0.7051 - recall: 0.5611 - val_auc: 0.7479 - val_binary_accuracy: 0.7261 - val_f1: 0.4884 - val_loss: 0.5804 - val_prc_auc: 0.5340 - val_precision: 0.4172 - val_recall: 0.5888\n","Epoch 8/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7551 - binary_accuracy: 0.6749 - f1: 0.6343 - loss: 0.5843 - prc_auc: 0.7663 - precision: 0.7058 - recall: 0.5776\n","Epoch 8: Validation Metrics:\n","loss: 0.5852811932563782\n","val_binary_accuracy: 0.7302904725074768\n","val_precision: 0.42580646276474\n","val_recall: 0.6168224215507507\n","val_auc: 0.7518754005432129\n","val_prc_auc: 0.538049578666687\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7551 - binary_accuracy: 0.6750 - f1: 0.6344 - loss: 0.5843 - prc_auc: 0.7663 - precision: 0.7059 - recall: 0.5778 - val_auc: 0.7519 - val_binary_accuracy: 0.7303 - val_f1: 0.5038 - val_loss: 0.5795 - val_prc_auc: 0.5380 - val_precision: 0.4258 - val_recall: 0.6168\n","Epoch 9/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7596 - binary_accuracy: 0.6815 - f1: 0.6435 - loss: 0.5806 - prc_auc: 0.7698 - precision: 0.7119 - recall: 0.5888\n","Epoch 9: Validation Metrics:\n","loss: 0.5817710757255554\n","val_binary_accuracy: 0.7365145087242126\n","val_precision: 0.43589743971824646\n","val_recall: 0.6355140209197998\n","val_auc: 0.755688488483429\n","val_prc_auc: 0.5410549640655518\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7596 - binary_accuracy: 0.6815 - f1: 0.6436 - loss: 0.5806 - prc_auc: 0.7699 - precision: 0.7120 - recall: 0.5889 - val_auc: 0.7557 - val_binary_accuracy: 0.7365 - val_f1: 0.5171 - val_loss: 0.5787 - val_prc_auc: 0.5411 - val_precision: 0.4359 - val_recall: 0.6355\n","Epoch 10/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7648 - binary_accuracy: 0.6873 - f1: 0.6517 - loss: 0.5771 - prc_auc: 0.7745 - precision: 0.7166 - recall: 0.5993\n","Epoch 10: Validation Metrics:\n","loss: 0.5784720778465271\n","val_binary_accuracy: 0.7406638860702515\n","val_precision: 0.4423076808452606\n","val_recall: 0.644859790802002\n","val_auc: 0.7558255195617676\n","val_prc_auc: 0.5416498184204102\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7648 - binary_accuracy: 0.6872 - f1: 0.6518 - loss: 0.5771 - prc_auc: 0.7746 - precision: 0.7166 - recall: 0.5993 - val_auc: 0.7558 - val_binary_accuracy: 0.7407 - val_f1: 0.5247 - val_loss: 0.5783 - val_prc_auc: 0.5416 - val_precision: 0.4423 - val_recall: 0.6449\n","Epoch 11/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7688 - binary_accuracy: 0.6929 - f1: 0.6595 - loss: 0.5737 - prc_auc: 0.7781 - precision: 0.7215 - recall: 0.6089\n","Epoch 11: Validation Metrics:\n","loss: 0.5753417611122131\n","val_binary_accuracy: 0.7365145087242126\n","val_precision: 0.43670886754989624\n","val_recall: 0.644859790802002\n","val_auc: 0.7572460770606995\n","val_prc_auc: 0.5438442230224609\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - auc: 0.7688 - binary_accuracy: 0.6929 - f1: 0.6595 - loss: 0.5738 - prc_auc: 0.7781 - precision: 0.7215 - recall: 0.6090 - val_auc: 0.7572 - val_binary_accuracy: 0.7365 - val_f1: 0.5208 - val_loss: 0.5777 - val_prc_auc: 0.5438 - val_precision: 0.4367 - val_recall: 0.6449\n","Epoch 12/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7727 - binary_accuracy: 0.6982 - f1: 0.6650 - loss: 0.5705 - prc_auc: 0.7813 - precision: 0.7284 - recall: 0.6132\n","Epoch 12: Validation Metrics:\n","loss: 0.5723680853843689\n","val_binary_accuracy: 0.7385892271995544\n","val_precision: 0.4394904375076294\n","val_recall: 0.644859790802002\n","val_auc: 0.7581183910369873\n","val_prc_auc: 0.5434693098068237\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7727 - binary_accuracy: 0.6982 - f1: 0.6651 - loss: 0.5705 - prc_auc: 0.7813 - precision: 0.7285 - recall: 0.6133 - val_auc: 0.7581 - val_binary_accuracy: 0.7386 - val_f1: 0.5227 - val_loss: 0.5774 - val_prc_auc: 0.5435 - val_precision: 0.4395 - val_recall: 0.6449\n","Epoch 13/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7760 - binary_accuracy: 0.7055 - f1: 0.6734 - loss: 0.5674 - prc_auc: 0.7847 - precision: 0.7367 - recall: 0.6215\n","Epoch 13: Validation Metrics:\n","loss: 0.5695174336433411\n","val_binary_accuracy: 0.7385892271995544\n","val_precision: 0.44025155901908875\n","val_recall: 0.6542056202888489\n","val_auc: 0.7593644857406616\n","val_prc_auc: 0.5433847904205322\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7759 - binary_accuracy: 0.7054 - f1: 0.6734 - loss: 0.5674 - prc_auc: 0.7848 - precision: 0.7366 - recall: 0.6216 - val_auc: 0.7594 - val_binary_accuracy: 0.7386 - val_f1: 0.5263 - val_loss: 0.5772 - val_prc_auc: 0.5434 - val_precision: 0.4403 - val_recall: 0.6542\n","Epoch 14/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7797 - binary_accuracy: 0.7116 - f1: 0.6805 - loss: 0.5644 - prc_auc: 0.7882 - precision: 0.7438 - recall: 0.6284\n","Epoch 14: Validation Metrics:\n","loss: 0.5667833089828491\n","val_binary_accuracy: 0.7323651313781738\n","val_precision: 0.43209877610206604\n","val_recall: 0.6542056202888489\n","val_auc: 0.7599501609802246\n","val_prc_auc: 0.5435594320297241\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7796 - binary_accuracy: 0.7115 - f1: 0.6805 - loss: 0.5645 - prc_auc: 0.7882 - precision: 0.7437 - recall: 0.6285 - val_auc: 0.7600 - val_binary_accuracy: 0.7324 - val_f1: 0.5204 - val_loss: 0.5770 - val_prc_auc: 0.5436 - val_precision: 0.4321 - val_recall: 0.6542\n","Epoch 15/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7827 - binary_accuracy: 0.7099 - f1: 0.6793 - loss: 0.5615 - prc_auc: 0.7909 - precision: 0.7405 - recall: 0.6288\n","Epoch 15: Validation Metrics:\n","loss: 0.5641372203826904\n","val_binary_accuracy: 0.7323651313781738\n","val_precision: 0.43292683362960815\n","val_recall: 0.663551390171051\n","val_auc: 0.7604237794876099\n","val_prc_auc: 0.543765127658844\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7827 - binary_accuracy: 0.7098 - f1: 0.6793 - loss: 0.5616 - prc_auc: 0.7909 - precision: 0.7404 - recall: 0.6289 - val_auc: 0.7604 - val_binary_accuracy: 0.7324 - val_f1: 0.5240 - val_loss: 0.5770 - val_prc_auc: 0.5438 - val_precision: 0.4329 - val_recall: 0.6636\n","Epoch 16/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7857 - binary_accuracy: 0.7077 - f1: 0.6772 - loss: 0.5587 - prc_auc: 0.7939 - precision: 0.7372 - recall: 0.6277\n","Epoch 16: Validation Metrics:\n","loss: 0.5615770220756531\n","val_binary_accuracy: 0.7323651313781738\n","val_precision: 0.43292683362960815\n","val_recall: 0.663551390171051\n","val_auc: 0.7605980634689331\n","val_prc_auc: 0.5438380241394043\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - auc: 0.7856 - binary_accuracy: 0.7076 - f1: 0.6773 - loss: 0.5588 - prc_auc: 0.7939 - precision: 0.7371 - recall: 0.6279 - val_auc: 0.7606 - val_binary_accuracy: 0.7324 - val_f1: 0.5240 - val_loss: 0.5770 - val_prc_auc: 0.5438 - val_precision: 0.4329 - val_recall: 0.6636\n","Epoch 17/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7879 - binary_accuracy: 0.7083 - f1: 0.6784 - loss: 0.5560 - prc_auc: 0.7960 - precision: 0.7371 - recall: 0.6297\n","Epoch 17: Validation Metrics:\n","loss: 0.5590731501579285\n","val_binary_accuracy: 0.7365145087242126\n","val_precision: 0.4390243887901306\n","val_recall: 0.672897219657898\n","val_auc: 0.7611463665962219\n","val_prc_auc: 0.5440605282783508\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7879 - binary_accuracy: 0.7083 - f1: 0.6784 - loss: 0.5561 - prc_auc: 0.7960 - precision: 0.7371 - recall: 0.6299 - val_auc: 0.7611 - val_binary_accuracy: 0.7365 - val_f1: 0.5314 - val_loss: 0.5771 - val_prc_auc: 0.5441 - val_precision: 0.4390 - val_recall: 0.6729\n","Epoch 18/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7904 - binary_accuracy: 0.7110 - f1: 0.6831 - loss: 0.5534 - prc_auc: 0.7986 - precision: 0.7377 - recall: 0.6375\n","Epoch 18: Validation Metrics:\n","loss: 0.5566527843475342\n","val_binary_accuracy: 0.7323651313781738\n","val_precision: 0.4337349534034729\n","val_recall: 0.672897219657898\n","val_auc: 0.7614952921867371\n","val_prc_auc: 0.5444928407669067\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7903 - binary_accuracy: 0.7109 - f1: 0.6832 - loss: 0.5534 - prc_auc: 0.7986 - precision: 0.7376 - recall: 0.6375 - val_auc: 0.7615 - val_binary_accuracy: 0.7324 - val_f1: 0.5275 - val_loss: 0.5771 - val_prc_auc: 0.5445 - val_precision: 0.4337 - val_recall: 0.6729\n","Epoch 19/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7922 - binary_accuracy: 0.7127 - f1: 0.6858 - loss: 0.5508 - prc_auc: 0.8004 - precision: 0.7383 - recall: 0.6415\n","Epoch 19: Validation Metrics:\n","loss: 0.5542990565299988\n","val_binary_accuracy: 0.7302904725074768\n","val_precision: 0.43030303716659546\n","val_recall: 0.663551390171051\n","val_auc: 0.7620560526847839\n","val_prc_auc: 0.544944703578949\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7921 - binary_accuracy: 0.7126 - f1: 0.6858 - loss: 0.5509 - prc_auc: 0.8004 - precision: 0.7383 - recall: 0.6416 - val_auc: 0.7621 - val_binary_accuracy: 0.7303 - val_f1: 0.5221 - val_loss: 0.5771 - val_prc_auc: 0.5449 - val_precision: 0.4303 - val_recall: 0.6636\n","Epoch 20/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7944 - binary_accuracy: 0.7142 - f1: 0.6873 - loss: 0.5483 - prc_auc: 0.8026 - precision: 0.7405 - recall: 0.6425\n","Epoch 20: Validation Metrics:\n","loss: 0.5519869923591614\n","val_binary_accuracy: 0.7344398498535156\n","val_precision: 0.43558281660079956\n","val_recall: 0.663551390171051\n","val_auc: 0.7618816494941711\n","val_prc_auc: 0.5437213182449341\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7943 - binary_accuracy: 0.7141 - f1: 0.6873 - loss: 0.5483 - prc_auc: 0.8026 - precision: 0.7404 - recall: 0.6426 - val_auc: 0.7619 - val_binary_accuracy: 0.7344 - val_f1: 0.5259 - val_loss: 0.5771 - val_prc_auc: 0.5437 - val_precision: 0.4356 - val_recall: 0.6636\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 531ms/step\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 370ms/step\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 369ms/step\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 368ms/step\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 367ms/step\n","[[0 1 0 1 0]\n"," [1 0 1 1 1]\n"," [1 1 1 0 0]\n"," ...\n"," [1 0 1 0 0]\n"," [0 0 1 1 1]\n"," [1 1 0 0 0]]\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - auc: 0.6680 - binary_accuracy: 0.6147 - f1: 0.6200 - loss: 0.6678 - prc_auc: 0.6500 - precision: 0.6118 - recall: 0.6642\n","Epoch 1: Validation Metrics:\n","loss: 0.6455841064453125\n","val_binary_accuracy: 0.6672727465629578\n","val_precision: 0.5191637873649597\n","val_recall: 0.7680412530899048\n","val_auc: 0.7347387671470642\n","val_prc_auc: 0.526278555393219\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 289ms/step - auc: 0.6684 - binary_accuracy: 0.6151 - f1: 0.6207 - loss: 0.6676 - prc_auc: 0.6501 - precision: 0.6120 - recall: 0.6651 - val_auc: 0.7347 - val_binary_accuracy: 0.6673 - val_f1: 0.6195 - val_loss: 0.6155 - val_prc_auc: 0.5263 - val_precision: 0.5192 - val_recall: 0.7680\n","Epoch 2/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7466 - binary_accuracy: 0.7008 - f1: 0.7291 - loss: 0.5975 - prc_auc: 0.7112 - precision: 0.6867 - recall: 0.7779\n","Epoch 2: Validation Metrics:\n","loss: 0.5932484269142151\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.5283687710762024\n","val_recall: 0.7680412530899048\n","val_auc: 0.7377433180809021\n","val_prc_auc: 0.5326970815658569\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7465 - binary_accuracy: 0.7007 - f1: 0.7290 - loss: 0.5974 - prc_auc: 0.7110 - precision: 0.6864 - recall: 0.7779 - val_auc: 0.7377 - val_binary_accuracy: 0.6764 - val_f1: 0.6261 - val_loss: 0.5936 - val_prc_auc: 0.5327 - val_precision: 0.5284 - val_recall: 0.7680\n","Epoch 3/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7548 - binary_accuracy: 0.7053 - f1: 0.7318 - loss: 0.5807 - prc_auc: 0.7251 - precision: 0.6924 - recall: 0.7767\n","Epoch 3: Validation Metrics:\n","loss: 0.5814584493637085\n","val_binary_accuracy: 0.6727272868156433\n","val_precision: 0.5244755148887634\n","val_recall: 0.7731958627700806\n","val_auc: 0.7402482032775879\n","val_prc_auc: 0.5364048480987549\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7547 - binary_accuracy: 0.7052 - f1: 0.7316 - loss: 0.5807 - prc_auc: 0.7249 - precision: 0.6921 - recall: 0.7767 - val_auc: 0.7402 - val_binary_accuracy: 0.6727 - val_f1: 0.6250 - val_loss: 0.5883 - val_prc_auc: 0.5364 - val_precision: 0.5245 - val_recall: 0.7732\n","Epoch 4/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7608 - binary_accuracy: 0.7074 - f1: 0.7350 - loss: 0.5747 - prc_auc: 0.7345 - precision: 0.6927 - recall: 0.7837\n","Epoch 4: Validation Metrics:\n","loss: 0.5762760043144226\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.5279720425605774\n","val_recall: 0.7783505320549011\n","val_auc: 0.7426589727401733\n","val_prc_auc: 0.543045163154602\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7607 - binary_accuracy: 0.7073 - f1: 0.7349 - loss: 0.5747 - prc_auc: 0.7343 - precision: 0.6925 - recall: 0.7837 - val_auc: 0.7427 - val_binary_accuracy: 0.6764 - val_f1: 0.6292 - val_loss: 0.5851 - val_prc_auc: 0.5430 - val_precision: 0.5280 - val_recall: 0.7784\n","Epoch 5/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7666 - binary_accuracy: 0.7076 - f1: 0.7357 - loss: 0.5703 - prc_auc: 0.7430 - precision: 0.6922 - recall: 0.7859\n","Epoch 5: Validation Metrics:\n","loss: 0.57220858335495\n","val_binary_accuracy: 0.6709091067314148\n","val_precision: 0.5226480960845947\n","val_recall: 0.7731958627700806\n","val_auc: 0.745214581489563\n","val_prc_auc: 0.5534483194351196\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7666 - binary_accuracy: 0.7075 - f1: 0.7356 - loss: 0.5703 - prc_auc: 0.7428 - precision: 0.6920 - recall: 0.7860 - val_auc: 0.7452 - val_binary_accuracy: 0.6709 - val_f1: 0.6237 - val_loss: 0.5826 - val_prc_auc: 0.5534 - val_precision: 0.5226 - val_recall: 0.7732\n","Epoch 6/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7713 - binary_accuracy: 0.7075 - f1: 0.7360 - loss: 0.5663 - prc_auc: 0.7495 - precision: 0.6917 - recall: 0.7874\n","Epoch 6: Validation Metrics:\n","loss: 0.5685508847236633\n","val_binary_accuracy: 0.6690909266471863\n","val_precision: 0.5209790468215942\n","val_recall: 0.7680412530899048\n","val_auc: 0.7486389875411987\n","val_prc_auc: 0.5583759546279907\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7712 - binary_accuracy: 0.7074 - f1: 0.7359 - loss: 0.5664 - prc_auc: 0.7493 - precision: 0.6915 - recall: 0.7874 - val_auc: 0.7486 - val_binary_accuracy: 0.6691 - val_f1: 0.6208 - val_loss: 0.5805 - val_prc_auc: 0.5584 - val_precision: 0.5210 - val_recall: 0.7680\n","Epoch 7/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7757 - binary_accuracy: 0.7101 - f1: 0.7387 - loss: 0.5627 - prc_auc: 0.7555 - precision: 0.6933 - recall: 0.7914\n","Epoch 7: Validation Metrics:\n","loss: 0.5651399493217468\n","val_binary_accuracy: 0.6727272868156433\n","val_precision: 0.5246478915214539\n","val_recall: 0.7680412530899048\n","val_auc: 0.7503547668457031\n","val_prc_auc: 0.5649060606956482\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7757 - binary_accuracy: 0.7100 - f1: 0.7386 - loss: 0.5627 - prc_auc: 0.7552 - precision: 0.6931 - recall: 0.7915 - val_auc: 0.7504 - val_binary_accuracy: 0.6727 - val_f1: 0.6234 - val_loss: 0.5787 - val_prc_auc: 0.5649 - val_precision: 0.5246 - val_recall: 0.7680\n","Epoch 8/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7796 - binary_accuracy: 0.7150 - f1: 0.7430 - loss: 0.5593 - prc_auc: 0.7604 - precision: 0.6975 - recall: 0.7958\n","Epoch 8: Validation Metrics:\n","loss: 0.5619107484817505\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.5298245549201965\n","val_recall: 0.7783505320549011\n","val_auc: 0.7511728405952454\n","val_prc_auc: 0.5622455477714539\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7795 - binary_accuracy: 0.7150 - f1: 0.7429 - loss: 0.5594 - prc_auc: 0.7602 - precision: 0.6973 - recall: 0.7958 - val_auc: 0.7512 - val_binary_accuracy: 0.6782 - val_f1: 0.6305 - val_loss: 0.5771 - val_prc_auc: 0.5622 - val_precision: 0.5298 - val_recall: 0.7784\n","Epoch 9/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7830 - binary_accuracy: 0.7150 - f1: 0.7430 - loss: 0.5562 - prc_auc: 0.7643 - precision: 0.6977 - recall: 0.7955\n","Epoch 9: Validation Metrics:\n","loss: 0.5588415861129761\n","val_binary_accuracy: 0.6745454668998718\n","val_precision: 0.5263158082962036\n","val_recall: 0.7731958627700806\n","val_auc: 0.7525556087493896\n","val_prc_auc: 0.5627096891403198\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7829 - binary_accuracy: 0.7150 - f1: 0.7429 - loss: 0.5562 - prc_auc: 0.7641 - precision: 0.6975 - recall: 0.7955 - val_auc: 0.7526 - val_binary_accuracy: 0.6745 - val_f1: 0.6263 - val_loss: 0.5757 - val_prc_auc: 0.5627 - val_precision: 0.5263 - val_recall: 0.7732\n","Epoch 10/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7863 - binary_accuracy: 0.7179 - f1: 0.7460 - loss: 0.5531 - prc_auc: 0.7686 - precision: 0.6995 - recall: 0.8001\n","Epoch 10: Validation Metrics:\n","loss: 0.5559364557266235\n","val_binary_accuracy: 0.6745454668998718\n","val_precision: 0.5265017747879028\n","val_recall: 0.7680412530899048\n","val_auc: 0.7536488175392151\n","val_prc_auc: 0.564907968044281\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7862 - binary_accuracy: 0.7179 - f1: 0.7459 - loss: 0.5532 - prc_auc: 0.7683 - precision: 0.6993 - recall: 0.8002 - val_auc: 0.7536 - val_binary_accuracy: 0.6745 - val_f1: 0.6247 - val_loss: 0.5743 - val_prc_auc: 0.5649 - val_precision: 0.5265 - val_recall: 0.7680\n","Epoch 11/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7890 - binary_accuracy: 0.7203 - f1: 0.7478 - loss: 0.5503 - prc_auc: 0.7710 - precision: 0.7021 - recall: 0.8008\n","Epoch 11: Validation Metrics:\n","loss: 0.5531983971595764\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.5281690359115601\n","val_recall: 0.7731958627700806\n","val_auc: 0.7538442611694336\n","val_prc_auc: 0.5649169683456421\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7889 - binary_accuracy: 0.7202 - f1: 0.7477 - loss: 0.5504 - prc_auc: 0.7708 - precision: 0.7019 - recall: 0.8008 - val_auc: 0.7538 - val_binary_accuracy: 0.6764 - val_f1: 0.6276 - val_loss: 0.5733 - val_prc_auc: 0.5649 - val_precision: 0.5282 - val_recall: 0.7732\n","Epoch 12/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7917 - binary_accuracy: 0.7227 - f1: 0.7496 - loss: 0.5476 - prc_auc: 0.7740 - precision: 0.7043 - recall: 0.8021\n","Epoch 12: Validation Metrics:\n","loss: 0.5505457520484924\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.5300353169441223\n","val_recall: 0.7731958627700806\n","val_auc: 0.7547420263290405\n","val_prc_auc: 0.5662887096405029\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7916 - binary_accuracy: 0.7226 - f1: 0.7495 - loss: 0.5476 - prc_auc: 0.7738 - precision: 0.7041 - recall: 0.8021 - val_auc: 0.7547 - val_binary_accuracy: 0.6782 - val_f1: 0.6289 - val_loss: 0.5723 - val_prc_auc: 0.5663 - val_precision: 0.5300 - val_recall: 0.7732\n","Epoch 13/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7943 - binary_accuracy: 0.7266 - f1: 0.7536 - loss: 0.5450 - prc_auc: 0.7770 - precision: 0.7071 - recall: 0.8076\n","Epoch 13: Validation Metrics:\n","loss: 0.5479798316955566\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.5300353169441223\n","val_recall: 0.7731958627700806\n","val_auc: 0.7563202381134033\n","val_prc_auc: 0.5702306032180786\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7943 - binary_accuracy: 0.7265 - f1: 0.7534 - loss: 0.5450 - prc_auc: 0.7768 - precision: 0.7068 - recall: 0.8077 - val_auc: 0.7563 - val_binary_accuracy: 0.6782 - val_f1: 0.6289 - val_loss: 0.5715 - val_prc_auc: 0.5702 - val_precision: 0.5300 - val_recall: 0.7732\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - auc: 0.6432 - binary_accuracy: 0.5728 - f1: 0.6811 - loss: 0.6794 - prc_auc: 0.6404 - precision: 0.5486 - recall: 0.9025\n","Epoch 1: Validation Metrics:\n","loss: 0.6658607721328735\n","val_binary_accuracy: 0.6327272653579712\n","val_precision: 0.45783132314682007\n","val_recall: 0.6298342347145081\n","val_auc: 0.677139937877655\n","val_prc_auc: 0.5377185940742493\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 232ms/step - auc: 0.6437 - binary_accuracy: 0.5732 - f1: 0.6811 - loss: 0.6793 - prc_auc: 0.6407 - precision: 0.5490 - recall: 0.9018 - val_auc: 0.6771 - val_binary_accuracy: 0.6327 - val_f1: 0.5302 - val_loss: 0.6588 - val_prc_auc: 0.5377 - val_precision: 0.4578 - val_recall: 0.6298\n","Epoch 2/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7296 - binary_accuracy: 0.6720 - f1: 0.6685 - loss: 0.6317 - prc_auc: 0.7228 - precision: 0.6832 - recall: 0.6554\n","Epoch 2: Validation Metrics:\n","loss: 0.6251598000526428\n","val_binary_accuracy: 0.6563636660575867\n","val_precision: 0.4829059839248657\n","val_recall: 0.6243094205856323\n","val_auc: 0.6838626265525818\n","val_prc_auc: 0.5432471632957458\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7296 - binary_accuracy: 0.6720 - f1: 0.6686 - loss: 0.6316 - prc_auc: 0.7228 - precision: 0.6832 - recall: 0.6555 - val_auc: 0.6839 - val_binary_accuracy: 0.6564 - val_f1: 0.5446 - val_loss: 0.6359 - val_prc_auc: 0.5432 - val_precision: 0.4829 - val_recall: 0.6243\n","Epoch 3/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7394 - binary_accuracy: 0.6751 - f1: 0.6673 - loss: 0.6074 - prc_auc: 0.7360 - precision: 0.6914 - recall: 0.6459\n","Epoch 3: Validation Metrics:\n","loss: 0.6052596569061279\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.5065501928329468\n","val_recall: 0.6408839821815491\n","val_auc: 0.6920600533485413\n","val_prc_auc: 0.5481966733932495\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7394 - binary_accuracy: 0.6752 - f1: 0.6674 - loss: 0.6074 - prc_auc: 0.7360 - precision: 0.6914 - recall: 0.6461 - val_auc: 0.6921 - val_binary_accuracy: 0.6764 - val_f1: 0.5659 - val_loss: 0.6273 - val_prc_auc: 0.5482 - val_precision: 0.5066 - val_recall: 0.6409\n","Epoch 4/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7471 - binary_accuracy: 0.6762 - f1: 0.6689 - loss: 0.5962 - prc_auc: 0.7452 - precision: 0.6921 - recall: 0.6483\n","Epoch 4: Validation Metrics:\n","loss: 0.5956771969795227\n","val_binary_accuracy: 0.6709091067314148\n","val_precision: 0.5\n","val_recall: 0.6243094205856323\n","val_auc: 0.6985356211662292\n","val_prc_auc: 0.5534250736236572\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7471 - binary_accuracy: 0.6763 - f1: 0.6690 - loss: 0.5962 - prc_auc: 0.7452 - precision: 0.6920 - recall: 0.6484 - val_auc: 0.6985 - val_binary_accuracy: 0.6709 - val_f1: 0.5553 - val_loss: 0.6229 - val_prc_auc: 0.5534 - val_precision: 0.5000 - val_recall: 0.6243\n","Epoch 5/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7535 - binary_accuracy: 0.6823 - f1: 0.6761 - loss: 0.5894 - prc_auc: 0.7515 - precision: 0.6972 - recall: 0.6570\n","Epoch 5: Validation Metrics:\n","loss: 0.5894862413406372\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.5089285969734192\n","val_recall: 0.6298342347145081\n","val_auc: 0.7027729749679565\n","val_prc_auc: 0.5562531352043152\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7535 - binary_accuracy: 0.6823 - f1: 0.6761 - loss: 0.5894 - prc_auc: 0.7515 - precision: 0.6971 - recall: 0.6571 - val_auc: 0.7028 - val_binary_accuracy: 0.6782 - val_f1: 0.5630 - val_loss: 0.6195 - val_prc_auc: 0.5563 - val_precision: 0.5089 - val_recall: 0.6298\n","Epoch 6/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7583 - binary_accuracy: 0.6792 - f1: 0.6726 - loss: 0.5843 - prc_auc: 0.7564 - precision: 0.6946 - recall: 0.6532\n","Epoch 6: Validation Metrics:\n","loss: 0.5847328901290894\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.5090090036392212\n","val_recall: 0.6243094205856323\n","val_auc: 0.7070400714874268\n","val_prc_auc: 0.5600010752677917\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7583 - binary_accuracy: 0.6793 - f1: 0.6727 - loss: 0.5843 - prc_auc: 0.7564 - precision: 0.6946 - recall: 0.6534 - val_auc: 0.7070 - val_binary_accuracy: 0.6782 - val_f1: 0.5608 - val_loss: 0.6168 - val_prc_auc: 0.5600 - val_precision: 0.5090 - val_recall: 0.6243\n","Epoch 7/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7629 - binary_accuracy: 0.6845 - f1: 0.6777 - loss: 0.5802 - prc_auc: 0.7604 - precision: 0.7006 - recall: 0.6575\n","Epoch 7: Validation Metrics:\n","loss: 0.5807727575302124\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.5067873597145081\n","val_recall: 0.6187845468521118\n","val_auc: 0.7106709480285645\n","val_prc_auc: 0.5632855296134949\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.7628 - binary_accuracy: 0.6845 - f1: 0.6778 - loss: 0.5802 - prc_auc: 0.7604 - precision: 0.7006 - recall: 0.6576 - val_auc: 0.7107 - val_binary_accuracy: 0.6764 - val_f1: 0.5572 - val_loss: 0.6143 - val_prc_auc: 0.5633 - val_precision: 0.5068 - val_recall: 0.6188\n","Epoch 8/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7669 - binary_accuracy: 0.6870 - f1: 0.6800 - loss: 0.5766 - prc_auc: 0.7640 - precision: 0.7034 - recall: 0.6593\n","Epoch 8: Validation Metrics:\n","loss: 0.5772799253463745\n","val_binary_accuracy: 0.6800000071525574\n","val_precision: 0.5115207433700562\n","val_recall: 0.6132596731185913\n","val_auc: 0.7134857177734375\n","val_prc_auc: 0.5662205219268799\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7669 - binary_accuracy: 0.6871 - f1: 0.6801 - loss: 0.5766 - prc_auc: 0.7640 - precision: 0.7034 - recall: 0.6594 - val_auc: 0.7135 - val_binary_accuracy: 0.6800 - val_f1: 0.5578 - val_loss: 0.6122 - val_prc_auc: 0.5662 - val_precision: 0.5115 - val_recall: 0.6133\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - auc: 0.6488 - binary_accuracy: 0.6047 - f1: 0.6207 - loss: 0.6783 - prc_auc: 0.6347 - precision: 0.5853 - recall: 0.6741\n","Epoch 1: Validation Metrics:\n","loss: 0.6668866276741028\n","val_binary_accuracy: 0.5327273011207581\n","val_precision: 0.3583815097808838\n","val_recall: 0.7798742055892944\n","val_auc: 0.6712831258773804\n","val_prc_auc: 0.4396750330924988\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 242ms/step - auc: 0.6490 - binary_accuracy: 0.6049 - f1: 0.6207 - loss: 0.6782 - prc_auc: 0.6350 - precision: 0.5857 - recall: 0.6736 - val_auc: 0.6713 - val_binary_accuracy: 0.5327 - val_f1: 0.4911 - val_loss: 0.6890 - val_prc_auc: 0.4397 - val_precision: 0.3584 - val_recall: 0.7799\n","Epoch 2/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6859 - binary_accuracy: 0.6198 - f1: 0.6276 - loss: 0.6457 - prc_auc: 0.6781 - precision: 0.5979 - recall: 0.6646\n","Epoch 2: Validation Metrics:\n","loss: 0.6388196349143982\n","val_binary_accuracy: 0.578181803226471\n","val_precision: 0.38110747933387756\n","val_recall: 0.7358490824699402\n","val_auc: 0.6759397983551025\n","val_prc_auc: 0.4468343257904053\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6861 - binary_accuracy: 0.6200 - f1: 0.6278 - loss: 0.6456 - prc_auc: 0.6782 - precision: 0.5986 - recall: 0.6641 - val_auc: 0.6759 - val_binary_accuracy: 0.5782 - val_f1: 0.5021 - val_loss: 0.6801 - val_prc_auc: 0.4468 - val_precision: 0.3811 - val_recall: 0.7358\n","Epoch 3/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6940 - binary_accuracy: 0.6303 - f1: 0.6225 - loss: 0.6329 - prc_auc: 0.6873 - precision: 0.6160 - recall: 0.6314\n","Epoch 3: Validation Metrics:\n","loss: 0.6281850337982178\n","val_binary_accuracy: 0.5981818437576294\n","val_precision: 0.3931034505367279\n","val_recall: 0.7169811129570007\n","val_auc: 0.6808377504348755\n","val_prc_auc: 0.45333003997802734\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6942 - binary_accuracy: 0.6305 - f1: 0.6227 - loss: 0.6328 - prc_auc: 0.6875 - precision: 0.6166 - recall: 0.6313 - val_auc: 0.6808 - val_binary_accuracy: 0.5982 - val_f1: 0.5078 - val_loss: 0.6748 - val_prc_auc: 0.4533 - val_precision: 0.3931 - val_recall: 0.7170\n","Epoch 4/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7009 - binary_accuracy: 0.6424 - f1: 0.6283 - loss: 0.6270 - prc_auc: 0.6940 - precision: 0.6326 - recall: 0.6260\n","Epoch 4: Validation Metrics:\n","loss: 0.6232589483261108\n","val_binary_accuracy: 0.610909104347229\n","val_precision: 0.40072202682495117\n","val_recall: 0.698113203048706\n","val_auc: 0.6853496432304382\n","val_prc_auc: 0.45794257521629333\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7011 - binary_accuracy: 0.6426 - f1: 0.6286 - loss: 0.6269 - prc_auc: 0.6942 - precision: 0.6332 - recall: 0.6260 - val_auc: 0.6853 - val_binary_accuracy: 0.6109 - val_f1: 0.5092 - val_loss: 0.6713 - val_prc_auc: 0.4579 - val_precision: 0.4007 - val_recall: 0.6981\n","Epoch 5/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7064 - binary_accuracy: 0.6528 - f1: 0.6359 - loss: 0.6232 - prc_auc: 0.6984 - precision: 0.6456 - recall: 0.6280\n","Epoch 5: Validation Metrics:\n","loss: 0.6200057864189148\n","val_binary_accuracy: 0.610909104347229\n","val_precision: 0.4000000059604645\n","val_recall: 0.6918238997459412\n","val_auc: 0.6877623200416565\n","val_prc_auc: 0.4586572051048279\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7065 - binary_accuracy: 0.6528 - f1: 0.6361 - loss: 0.6231 - prc_auc: 0.6986 - precision: 0.6461 - recall: 0.6280 - val_auc: 0.6878 - val_binary_accuracy: 0.6109 - val_f1: 0.5069 - val_loss: 0.6692 - val_prc_auc: 0.4587 - val_precision: 0.4000 - val_recall: 0.6918\n","Epoch 6/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7104 - binary_accuracy: 0.6608 - f1: 0.6426 - loss: 0.6202 - prc_auc: 0.7026 - precision: 0.6555 - recall: 0.6316\n","Epoch 6: Validation Metrics:\n","loss: 0.617368757724762\n","val_binary_accuracy: 0.6127272844314575\n","val_precision: 0.4007352888584137\n","val_recall: 0.6855345964431763\n","val_auc: 0.6906818747520447\n","val_prc_auc: 0.46119797229766846\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7106 - binary_accuracy: 0.6608 - f1: 0.6427 - loss: 0.6201 - prc_auc: 0.7028 - precision: 0.6559 - recall: 0.6316 - val_auc: 0.6907 - val_binary_accuracy: 0.6127 - val_f1: 0.5058 - val_loss: 0.6677 - val_prc_auc: 0.4612 - val_precision: 0.4007 - val_recall: 0.6855\n","Epoch 7/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7143 - binary_accuracy: 0.6639 - f1: 0.6447 - loss: 0.6176 - prc_auc: 0.7060 - precision: 0.6602 - recall: 0.6311\n","Epoch 7: Validation Metrics:\n","loss: 0.6150270104408264\n","val_binary_accuracy: 0.6127272844314575\n","val_precision: 0.40145984292030334\n","val_recall: 0.6918238997459412\n","val_auc: 0.6927326917648315\n","val_prc_auc: 0.4637540280818939\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7144 - binary_accuracy: 0.6640 - f1: 0.6449 - loss: 0.6176 - prc_auc: 0.7062 - precision: 0.6606 - recall: 0.6312 - val_auc: 0.6927 - val_binary_accuracy: 0.6127 - val_f1: 0.5081 - val_loss: 0.6666 - val_prc_auc: 0.4638 - val_precision: 0.4015 - val_recall: 0.6918\n","Epoch 8/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7173 - binary_accuracy: 0.6660 - f1: 0.6464 - loss: 0.6153 - prc_auc: 0.7096 - precision: 0.6624 - recall: 0.6325\n","Epoch 8: Validation Metrics:\n","loss: 0.6128597855567932\n","val_binary_accuracy: 0.6163636445999146\n","val_precision: 0.4037036895751953\n","val_recall: 0.6855345964431763\n","val_auc: 0.6938265562057495\n","val_prc_auc: 0.4643811881542206\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7174 - binary_accuracy: 0.6660 - f1: 0.6466 - loss: 0.6153 - prc_auc: 0.7098 - precision: 0.6627 - recall: 0.6325 - val_auc: 0.6938 - val_binary_accuracy: 0.6164 - val_f1: 0.5082 - val_loss: 0.6656 - val_prc_auc: 0.4644 - val_precision: 0.4037 - val_recall: 0.6855\n","Epoch 9/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7202 - binary_accuracy: 0.6615 - f1: 0.6410 - loss: 0.6132 - prc_auc: 0.7118 - precision: 0.6583 - recall: 0.6258\n","Epoch 9: Validation Metrics:\n","loss: 0.6108343005180359\n","val_binary_accuracy: 0.6200000047683716\n","val_precision: 0.40671640634536743\n","val_recall: 0.6855345964431763\n","val_auc: 0.6954510807991028\n","val_prc_auc: 0.4668535590171814\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.7203 - binary_accuracy: 0.6616 - f1: 0.6412 - loss: 0.6131 - prc_auc: 0.7120 - precision: 0.6586 - recall: 0.6259 - val_auc: 0.6955 - val_binary_accuracy: 0.6200 - val_f1: 0.5105 - val_loss: 0.6648 - val_prc_auc: 0.4669 - val_precision: 0.4067 - val_recall: 0.6855\n","Epoch 10/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7229 - binary_accuracy: 0.6644 - f1: 0.6435 - loss: 0.6112 - prc_auc: 0.7144 - precision: 0.6618 - recall: 0.6275\n","Epoch 10: Validation Metrics:\n","loss: 0.6088799834251404\n","val_binary_accuracy: 0.614545464515686\n","val_precision: 0.40221402049064636\n","val_recall: 0.6855345964431763\n","val_auc: 0.6961668729782104\n","val_prc_auc: 0.46714797616004944\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7230 - binary_accuracy: 0.6644 - f1: 0.6438 - loss: 0.6111 - prc_auc: 0.7146 - precision: 0.6622 - recall: 0.6276 - val_auc: 0.6962 - val_binary_accuracy: 0.6145 - val_f1: 0.5070 - val_loss: 0.6640 - val_prc_auc: 0.4671 - val_precision: 0.4022 - val_recall: 0.6855\n","Epoch 11/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7258 - binary_accuracy: 0.6687 - f1: 0.6490 - loss: 0.6092 - prc_auc: 0.7167 - precision: 0.6655 - recall: 0.6346\n","Epoch 11: Validation Metrics:\n","loss: 0.6069645881652832\n","val_binary_accuracy: 0.614545464515686\n","val_precision: 0.40221402049064636\n","val_recall: 0.6855345964431763\n","val_auc: 0.6969550848007202\n","val_prc_auc: 0.46802276372909546\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7259 - binary_accuracy: 0.6687 - f1: 0.6492 - loss: 0.6092 - prc_auc: 0.7169 - precision: 0.6659 - recall: 0.6346 - val_auc: 0.6970 - val_binary_accuracy: 0.6145 - val_f1: 0.5070 - val_loss: 0.6634 - val_prc_auc: 0.4680 - val_precision: 0.4022 - val_recall: 0.6855\n","Epoch 12/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7278 - binary_accuracy: 0.6698 - f1: 0.6498 - loss: 0.6073 - prc_auc: 0.7193 - precision: 0.6669 - recall: 0.6347\n","Epoch 12: Validation Metrics:\n","loss: 0.6050778031349182\n","val_binary_accuracy: 0.6090909242630005\n","val_precision: 0.3978102207183838\n","val_recall: 0.6855345964431763\n","val_auc: 0.6975904703140259\n","val_prc_auc: 0.4704921543598175\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7279 - binary_accuracy: 0.6698 - f1: 0.6500 - loss: 0.6073 - prc_auc: 0.7195 - precision: 0.6672 - recall: 0.6348 - val_auc: 0.6976 - val_binary_accuracy: 0.6091 - val_f1: 0.5035 - val_loss: 0.6627 - val_prc_auc: 0.4705 - val_precision: 0.3978 - val_recall: 0.6855\n","Epoch 13/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7306 - binary_accuracy: 0.6672 - f1: 0.6463 - loss: 0.6054 - prc_auc: 0.7218 - precision: 0.6648 - recall: 0.6298\n","Epoch 13: Validation Metrics:\n","loss: 0.60322505235672\n","val_binary_accuracy: 0.607272744178772\n","val_precision: 0.39636364579200745\n","val_recall: 0.6855345964431763\n","val_auc: 0.6989255547523499\n","val_prc_auc: 0.4719020128250122\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.7307 - binary_accuracy: 0.6673 - f1: 0.6466 - loss: 0.6054 - prc_auc: 0.7220 - precision: 0.6652 - recall: 0.6300 - val_auc: 0.6989 - val_binary_accuracy: 0.6073 - val_f1: 0.5023 - val_loss: 0.6621 - val_prc_auc: 0.4719 - val_precision: 0.3964 - val_recall: 0.6855\n","Epoch 14/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7330 - binary_accuracy: 0.6706 - f1: 0.6493 - loss: 0.6036 - prc_auc: 0.7247 - precision: 0.6692 - recall: 0.6317\n","Epoch 14: Validation Metrics:\n","loss: 0.6013811230659485\n","val_binary_accuracy: 0.607272744178772\n","val_precision: 0.39636364579200745\n","val_recall: 0.6855345964431763\n","val_auc: 0.6994562745094299\n","val_prc_auc: 0.47066530585289\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7331 - binary_accuracy: 0.6707 - f1: 0.6496 - loss: 0.6035 - prc_auc: 0.7249 - precision: 0.6695 - recall: 0.6319 - val_auc: 0.6995 - val_binary_accuracy: 0.6073 - val_f1: 0.5023 - val_loss: 0.6619 - val_prc_auc: 0.4707 - val_precision: 0.3964 - val_recall: 0.6855\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - auc: 0.6890 - binary_accuracy: 0.6255 - f1: 0.5842 - loss: 0.6726 - prc_auc: 0.6608 - precision: 0.6330 - recall: 0.5532\n","Epoch 1: Validation Metrics:\n","loss: 0.6606597900390625\n","val_binary_accuracy: 0.6327272653579712\n","val_precision: 0.41355931758880615\n","val_recall: 0.807947039604187\n","val_auc: 0.7225015759468079\n","val_prc_auc: 0.5053560137748718\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 298ms/step - auc: 0.6891 - binary_accuracy: 0.6257 - f1: 0.5850 - loss: 0.6725 - prc_auc: 0.6613 - precision: 0.6331 - recall: 0.5545 - val_auc: 0.7225 - val_binary_accuracy: 0.6327 - val_f1: 0.5471 - val_loss: 0.6454 - val_prc_auc: 0.5054 - val_precision: 0.4136 - val_recall: 0.8079\n","Epoch 2/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7292 - binary_accuracy: 0.6753 - f1: 0.6991 - loss: 0.6307 - prc_auc: 0.7090 - precision: 0.6400 - recall: 0.7716\n","Epoch 2: Validation Metrics:\n","loss: 0.6260802149772644\n","val_binary_accuracy: 0.6363636255264282\n","val_precision: 0.41522490978240967\n","val_recall: 0.7947019934654236\n","val_auc: 0.7294893264770508\n","val_prc_auc: 0.5147233009338379\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7291 - binary_accuracy: 0.6752 - f1: 0.6990 - loss: 0.6306 - prc_auc: 0.7093 - precision: 0.6400 - recall: 0.7711 - val_auc: 0.7295 - val_binary_accuracy: 0.6364 - val_f1: 0.5455 - val_loss: 0.6271 - val_prc_auc: 0.5147 - val_precision: 0.4152 - val_recall: 0.7947\n","Epoch 3/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7346 - binary_accuracy: 0.6825 - f1: 0.7019 - loss: 0.6131 - prc_auc: 0.7152 - precision: 0.6498 - recall: 0.7641\n","Epoch 3: Validation Metrics:\n","loss: 0.6123371720314026\n","val_binary_accuracy: 0.6454545259475708\n","val_precision: 0.4225352108478546\n","val_recall: 0.7947019934654236\n","val_auc: 0.7321034669876099\n","val_prc_auc: 0.5203659534454346\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7345 - binary_accuracy: 0.6824 - f1: 0.7018 - loss: 0.6131 - prc_auc: 0.7154 - precision: 0.6498 - recall: 0.7638 - val_auc: 0.7321 - val_binary_accuracy: 0.6455 - val_f1: 0.5517 - val_loss: 0.6204 - val_prc_auc: 0.5204 - val_precision: 0.4225 - val_recall: 0.7947\n","Epoch 4/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7400 - binary_accuracy: 0.6862 - f1: 0.7020 - loss: 0.6056 - prc_auc: 0.7203 - precision: 0.6561 - recall: 0.7554\n","Epoch 4: Validation Metrics:\n","loss: 0.6063536405563354\n","val_binary_accuracy: 0.6454545259475708\n","val_precision: 0.42198580503463745\n","val_recall: 0.7880794405937195\n","val_auc: 0.7343109846115112\n","val_prc_auc: 0.5239965915679932\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7400 - binary_accuracy: 0.6861 - f1: 0.7019 - loss: 0.6056 - prc_auc: 0.7205 - precision: 0.6561 - recall: 0.7551 - val_auc: 0.7343 - val_binary_accuracy: 0.6455 - val_f1: 0.5497 - val_loss: 0.6171 - val_prc_auc: 0.5240 - val_precision: 0.4220 - val_recall: 0.7881\n","Epoch 5/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7444 - binary_accuracy: 0.6882 - f1: 0.7010 - loss: 0.6012 - prc_auc: 0.7234 - precision: 0.6607 - recall: 0.7471\n","Epoch 5: Validation Metrics:\n","loss: 0.6025724411010742\n","val_binary_accuracy: 0.6490908861160278\n","val_precision: 0.42446044087409973\n","val_recall: 0.7814569473266602\n","val_auc: 0.7363110184669495\n","val_prc_auc: 0.5265641212463379\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7444 - binary_accuracy: 0.6880 - f1: 0.7008 - loss: 0.6012 - prc_auc: 0.7236 - precision: 0.6607 - recall: 0.7468 - val_auc: 0.7363 - val_binary_accuracy: 0.6491 - val_f1: 0.5501 - val_loss: 0.6152 - val_prc_auc: 0.5266 - val_precision: 0.4245 - val_recall: 0.7815\n","Epoch 6/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7477 - binary_accuracy: 0.6894 - f1: 0.6993 - loss: 0.5981 - prc_auc: 0.7264 - precision: 0.6648 - recall: 0.7382\n","Epoch 6: Validation Metrics:\n","loss: 0.5996503233909607\n","val_binary_accuracy: 0.6527272462844849\n","val_precision: 0.4270072877407074\n","val_recall: 0.7748344540596008\n","val_auc: 0.7382279634475708\n","val_prc_auc: 0.5292654633522034\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7477 - binary_accuracy: 0.6892 - f1: 0.6991 - loss: 0.5981 - prc_auc: 0.7267 - precision: 0.6647 - recall: 0.7379 - val_auc: 0.7382 - val_binary_accuracy: 0.6527 - val_f1: 0.5506 - val_loss: 0.6140 - val_prc_auc: 0.5293 - val_precision: 0.4270 - val_recall: 0.7748\n","Epoch 7/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7506 - binary_accuracy: 0.6925 - f1: 0.6998 - loss: 0.5955 - prc_auc: 0.7295 - precision: 0.6702 - recall: 0.7327\n","Epoch 7: Validation Metrics:\n","loss: 0.5971762537956238\n","val_binary_accuracy: 0.6563636660575867\n","val_precision: 0.4296296238899231\n","val_recall: 0.7682119011878967\n","val_auc: 0.7390828132629395\n","val_prc_auc: 0.5293170213699341\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7505 - binary_accuracy: 0.6922 - f1: 0.6996 - loss: 0.5955 - prc_auc: 0.7297 - precision: 0.6700 - recall: 0.7324 - val_auc: 0.7391 - val_binary_accuracy: 0.6564 - val_f1: 0.5511 - val_loss: 0.6133 - val_prc_auc: 0.5293 - val_precision: 0.4296 - val_recall: 0.7682\n","Epoch 8/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7528 - binary_accuracy: 0.6940 - f1: 0.7004 - loss: 0.5933 - prc_auc: 0.7317 - precision: 0.6727 - recall: 0.7310\n","Epoch 8: Validation Metrics:\n","loss: 0.5949873924255371\n","val_binary_accuracy: 0.6600000262260437\n","val_precision: 0.43233081698417664\n","val_recall: 0.7615894079208374\n","val_auc: 0.7397467494010925\n","val_prc_auc: 0.5301758050918579\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - auc: 0.7527 - binary_accuracy: 0.6938 - f1: 0.7002 - loss: 0.5934 - prc_auc: 0.7320 - precision: 0.6726 - recall: 0.7307 - val_auc: 0.7397 - val_binary_accuracy: 0.6600 - val_f1: 0.5516 - val_loss: 0.6129 - val_prc_auc: 0.5302 - val_precision: 0.4323 - val_recall: 0.7616\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6237 - binary_accuracy: 0.5715 - f1: 0.3919 - loss: 0.6837 - prc_auc: 0.6301 - precision: 0.6503 - recall: 0.2854\n","Epoch 1: Validation Metrics:\n","loss: 0.6765210628509521\n","val_binary_accuracy: 0.721818208694458\n","val_precision: 0.3445945978164673\n","val_recall: 0.47663551568984985\n","val_auc: 0.6902492046356201\n","val_prc_auc: 0.3985167145729065\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 254ms/step - auc: 0.6241 - binary_accuracy: 0.5719 - f1: 0.3931 - loss: 0.6836 - prc_auc: 0.6306 - precision: 0.6509 - recall: 0.2864 - val_auc: 0.6902 - val_binary_accuracy: 0.7218 - val_f1: 0.4000 - val_loss: 0.6442 - val_prc_auc: 0.3985 - val_precision: 0.3446 - val_recall: 0.4766\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6658 - binary_accuracy: 0.6099 - f1: 0.5257 - loss: 0.6612 - prc_auc: 0.6668 - precision: 0.6470 - recall: 0.4432\n","Epoch 2: Validation Metrics:\n","loss: 0.6546227335929871\n","val_binary_accuracy: 0.6945454478263855\n","val_precision: 0.3296089470386505\n","val_recall: 0.5514018535614014\n","val_auc: 0.6957975625991821\n","val_prc_auc: 0.41221749782562256\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6660 - binary_accuracy: 0.6100 - f1: 0.5262 - loss: 0.6611 - prc_auc: 0.6672 - precision: 0.6472 - recall: 0.4438 - val_auc: 0.6958 - val_binary_accuracy: 0.6945 - val_f1: 0.4126 - val_loss: 0.6325 - val_prc_auc: 0.4122 - val_precision: 0.3296 - val_recall: 0.5514\n","Epoch 3/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6711 - binary_accuracy: 0.6119 - f1: 0.5511 - loss: 0.6488 - prc_auc: 0.6771 - precision: 0.6337 - recall: 0.4882\n","Epoch 3: Validation Metrics:\n","loss: 0.6408249139785767\n","val_binary_accuracy: 0.696363627910614\n","val_precision: 0.33695653080940247\n","val_recall: 0.5794392228126526\n","val_auc: 0.7029281854629517\n","val_prc_auc: 0.41751304268836975\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6713 - binary_accuracy: 0.6120 - f1: 0.5515 - loss: 0.6487 - prc_auc: 0.6775 - precision: 0.6340 - recall: 0.4886 - val_auc: 0.7029 - val_binary_accuracy: 0.6964 - val_f1: 0.4261 - val_loss: 0.6231 - val_prc_auc: 0.4175 - val_precision: 0.3370 - val_recall: 0.5794\n","Epoch 4/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6798 - binary_accuracy: 0.6129 - f1: 0.5565 - loss: 0.6402 - prc_auc: 0.6877 - precision: 0.6317 - recall: 0.4979\n","Epoch 4: Validation Metrics:\n","loss: 0.6309608221054077\n","val_binary_accuracy: 0.7018181681632996\n","val_precision: 0.3442623019218445\n","val_recall: 0.5887850522994995\n","val_auc: 0.7111770510673523\n","val_prc_auc: 0.42279863357543945\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6801 - binary_accuracy: 0.6131 - f1: 0.5570 - loss: 0.6400 - prc_auc: 0.6881 - precision: 0.6321 - recall: 0.4985 - val_auc: 0.7112 - val_binary_accuracy: 0.7018 - val_f1: 0.4345 - val_loss: 0.6144 - val_prc_auc: 0.4228 - val_precision: 0.3443 - val_recall: 0.5888\n","Epoch 5/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6894 - binary_accuracy: 0.6358 - f1: 0.5848 - loss: 0.6334 - prc_auc: 0.6965 - precision: 0.6600 - recall: 0.5257\n","Epoch 5: Validation Metrics:\n","loss: 0.6233596205711365\n","val_binary_accuracy: 0.7145454287528992\n","val_precision: 0.3579545319080353\n","val_recall: 0.5887850522994995\n","val_auc: 0.7179384827613831\n","val_prc_auc: 0.42789992690086365\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6897 - binary_accuracy: 0.6360 - f1: 0.5852 - loss: 0.6332 - prc_auc: 0.6969 - precision: 0.6603 - recall: 0.5262 - val_auc: 0.7179 - val_binary_accuracy: 0.7145 - val_f1: 0.4452 - val_loss: 0.6072 - val_prc_auc: 0.4279 - val_precision: 0.3580 - val_recall: 0.5888\n","Epoch 6/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6985 - binary_accuracy: 0.6456 - f1: 0.5956 - loss: 0.6276 - prc_auc: 0.7042 - precision: 0.6731 - recall: 0.5348\n","Epoch 6: Validation Metrics:\n","loss: 0.6171172261238098\n","val_binary_accuracy: 0.7236363887786865\n","val_precision: 0.36994218826293945\n","val_recall: 0.5981308221817017\n","val_auc: 0.7251850962638855\n","val_prc_auc: 0.4310416579246521\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6988 - binary_accuracy: 0.6457 - f1: 0.5959 - loss: 0.6275 - prc_auc: 0.7046 - precision: 0.6733 - recall: 0.5353 - val_auc: 0.7252 - val_binary_accuracy: 0.7236 - val_f1: 0.4571 - val_loss: 0.6003 - val_prc_auc: 0.4310 - val_precision: 0.3699 - val_recall: 0.5981\n","Epoch 7/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7075 - binary_accuracy: 0.6507 - f1: 0.5984 - loss: 0.6225 - prc_auc: 0.7124 - precision: 0.6821 - recall: 0.5340\n","Epoch 7: Validation Metrics:\n","loss: 0.6117540597915649\n","val_binary_accuracy: 0.7200000286102295\n","val_precision: 0.36094674468040466\n","val_recall: 0.5700934529304504\n","val_auc: 0.7297314405441284\n","val_prc_auc: 0.43414467573165894\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7078 - binary_accuracy: 0.6509 - f1: 0.5989 - loss: 0.6224 - prc_auc: 0.7128 - precision: 0.6824 - recall: 0.5346 - val_auc: 0.7297 - val_binary_accuracy: 0.7200 - val_f1: 0.4420 - val_loss: 0.5946 - val_prc_auc: 0.4341 - val_precision: 0.3609 - val_recall: 0.5701\n","Epoch 8/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7148 - binary_accuracy: 0.6542 - f1: 0.6032 - loss: 0.6179 - prc_auc: 0.7183 - precision: 0.6855 - recall: 0.5393\n","Epoch 8: Validation Metrics:\n","loss: 0.6070564985275269\n","val_binary_accuracy: 0.7200000286102295\n","val_precision: 0.359281450510025\n","val_recall: 0.5607476830482483\n","val_auc: 0.7345730662345886\n","val_prc_auc: 0.4395943582057953\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7151 - binary_accuracy: 0.6545 - f1: 0.6037 - loss: 0.6177 - prc_auc: 0.7187 - precision: 0.6858 - recall: 0.5400 - val_auc: 0.7346 - val_binary_accuracy: 0.7200 - val_f1: 0.4380 - val_loss: 0.5905 - val_prc_auc: 0.4396 - val_precision: 0.3593 - val_recall: 0.5607\n","Epoch 9/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7206 - binary_accuracy: 0.6522 - f1: 0.6042 - loss: 0.6137 - prc_auc: 0.7235 - precision: 0.6797 - recall: 0.5443\n","Epoch 9: Validation Metrics:\n","loss: 0.6029941439628601\n","val_binary_accuracy: 0.7236363887786865\n","val_precision: 0.3636363744735718\n","val_recall: 0.5607476830482483\n","val_auc: 0.739193320274353\n","val_prc_auc: 0.4449894428253174\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7208 - binary_accuracy: 0.6525 - f1: 0.6047 - loss: 0.6136 - prc_auc: 0.7239 - precision: 0.6801 - recall: 0.5450 - val_auc: 0.7392 - val_binary_accuracy: 0.7236 - val_f1: 0.4412 - val_loss: 0.5869 - val_prc_auc: 0.4450 - val_precision: 0.3636 - val_recall: 0.5607\n","Epoch 10/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7264 - binary_accuracy: 0.6538 - f1: 0.6059 - loss: 0.6099 - prc_auc: 0.7285 - precision: 0.6816 - recall: 0.5459\n","Epoch 10: Validation Metrics:\n","loss: 0.5992836356163025\n","val_binary_accuracy: 0.7272727489471436\n","val_precision: 0.3680981695652008\n","val_recall: 0.5607476830482483\n","val_auc: 0.7425687909126282\n","val_prc_auc: 0.4476752281188965\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7267 - binary_accuracy: 0.6541 - f1: 0.6065 - loss: 0.6097 - prc_auc: 0.7290 - precision: 0.6820 - recall: 0.5466 - val_auc: 0.7426 - val_binary_accuracy: 0.7273 - val_f1: 0.4444 - val_loss: 0.5839 - val_prc_auc: 0.4477 - val_precision: 0.3681 - val_recall: 0.5607\n","Epoch 11/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7316 - binary_accuracy: 0.6567 - f1: 0.6107 - loss: 0.6063 - prc_auc: 0.7328 - precision: 0.6835 - recall: 0.5525\n","Epoch 11: Validation Metrics:\n","loss: 0.5958561301231384\n","val_binary_accuracy: 0.7272727489471436\n","val_precision: 0.3696969747543335\n","val_recall: 0.5700934529304504\n","val_auc: 0.7454378008842468\n","val_prc_auc: 0.4498412609100342\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7318 - binary_accuracy: 0.6571 - f1: 0.6113 - loss: 0.6061 - prc_auc: 0.7332 - precision: 0.6840 - recall: 0.5531 - val_auc: 0.7454 - val_binary_accuracy: 0.7273 - val_f1: 0.4485 - val_loss: 0.5811 - val_prc_auc: 0.4498 - val_precision: 0.3697 - val_recall: 0.5701\n","Starting training for label: 5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5067 - binary_accuracy: 0.5070 - f1: 0.6265 - loss: 0.6930 - prc_auc: 0.5158 - precision: 0.5066 - recall: 0.8222\n","Epoch 1: Validation Metrics:\n","loss: 0.6912910342216492\n","val_binary_accuracy: 0.48181816935539246\n","val_precision: 0.25159236788749695\n","val_recall: 0.6124030947685242\n","val_auc: 0.5478005409240723\n","val_prc_auc: 0.2742428183555603\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 260ms/step - auc: 0.5072 - binary_accuracy: 0.5073 - f1: 0.6265 - loss: 0.6929 - prc_auc: 0.5162 - precision: 0.5068 - recall: 0.8219 - val_auc: 0.5478 - val_binary_accuracy: 0.4818 - val_f1: 0.3567 - val_loss: 0.6928 - val_prc_auc: 0.2742 - val_precision: 0.2516 - val_recall: 0.6124\n","Epoch 2/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6066 - binary_accuracy: 0.5618 - f1: 0.5913 - loss: 0.6845 - prc_auc: 0.6133 - precision: 0.5558 - recall: 0.6333\n","Epoch 2: Validation Metrics:\n","loss: 0.6848904490470886\n","val_binary_accuracy: 0.5181818008422852\n","val_precision: 0.2638888955116272\n","val_recall: 0.5891472697257996\n","val_auc: 0.5449004173278809\n","val_prc_auc: 0.26426956057548523\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6064 - binary_accuracy: 0.5617 - f1: 0.5915 - loss: 0.6845 - prc_auc: 0.6128 - precision: 0.5557 - recall: 0.6338 - val_auc: 0.5449 - val_binary_accuracy: 0.5182 - val_f1: 0.3645 - val_loss: 0.6887 - val_prc_auc: 0.2643 - val_precision: 0.2639 - val_recall: 0.5891\n","Epoch 3/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6226 - binary_accuracy: 0.5772 - f1: 0.5948 - loss: 0.6796 - prc_auc: 0.6302 - precision: 0.5737 - recall: 0.6187\n","Epoch 3: Validation Metrics:\n","loss: 0.6807101964950562\n","val_binary_accuracy: 0.5127272605895996\n","val_precision: 0.25441697239875793\n","val_recall: 0.5581395626068115\n","val_auc: 0.5459039807319641\n","val_prc_auc: 0.2683493494987488\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6224 - binary_accuracy: 0.5771 - f1: 0.5948 - loss: 0.6797 - prc_auc: 0.6297 - precision: 0.5735 - recall: 0.6190 - val_auc: 0.5459 - val_binary_accuracy: 0.5127 - val_f1: 0.3495 - val_loss: 0.6865 - val_prc_auc: 0.2683 - val_precision: 0.2544 - val_recall: 0.5581\n","Epoch 4/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6345 - binary_accuracy: 0.5959 - f1: 0.6042 - loss: 0.6756 - prc_auc: 0.6424 - precision: 0.5949 - recall: 0.6152\n","Epoch 4: Validation Metrics:\n","loss: 0.6772198677062988\n","val_binary_accuracy: 0.5218181610107422\n","val_precision: 0.2607142925262451\n","val_recall: 0.565891444683075\n","val_auc: 0.5473034381866455\n","val_prc_auc: 0.2617165744304657\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6343 - binary_accuracy: 0.5956 - f1: 0.6042 - loss: 0.6757 - prc_auc: 0.6419 - precision: 0.5946 - recall: 0.6154 - val_auc: 0.5473 - val_binary_accuracy: 0.5218 - val_f1: 0.3570 - val_loss: 0.6850 - val_prc_auc: 0.2617 - val_precision: 0.2607 - val_recall: 0.5659\n","Epoch 5/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6430 - binary_accuracy: 0.6071 - f1: 0.6081 - loss: 0.6722 - prc_auc: 0.6520 - precision: 0.6096 - recall: 0.6081\n","Epoch 5: Validation Metrics:\n","loss: 0.6741588711738586\n","val_binary_accuracy: 0.5345454812049866\n","val_precision: 0.26739928126335144\n","val_recall: 0.565891444683075\n","val_auc: 0.547975480556488\n","val_prc_auc: 0.26130998134613037\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6428 - binary_accuracy: 0.6068 - f1: 0.6080 - loss: 0.6722 - prc_auc: 0.6515 - precision: 0.6093 - recall: 0.6082 - val_auc: 0.5480 - val_binary_accuracy: 0.5345 - val_f1: 0.3632 - val_loss: 0.6832 - val_prc_auc: 0.2613 - val_precision: 0.2674 - val_recall: 0.5659\n","Epoch 6/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6491 - binary_accuracy: 0.6140 - f1: 0.6118 - loss: 0.6690 - prc_auc: 0.6568 - precision: 0.6185 - recall: 0.6068\n","Epoch 6: Validation Metrics:\n","loss: 0.6714251637458801\n","val_binary_accuracy: 0.5418182015419006\n","val_precision: 0.26966291666030884\n","val_recall: 0.5581395626068115\n","val_auc: 0.5504428148269653\n","val_prc_auc: 0.2633496820926666\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6489 - binary_accuracy: 0.6137 - f1: 0.6117 - loss: 0.6691 - prc_auc: 0.6563 - precision: 0.6181 - recall: 0.6069 - val_auc: 0.5504 - val_binary_accuracy: 0.5418 - val_f1: 0.3636 - val_loss: 0.6820 - val_prc_auc: 0.2633 - val_precision: 0.2697 - val_recall: 0.5581\n","Epoch 7/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6561 - binary_accuracy: 0.6124 - f1: 0.6071 - loss: 0.6661 - prc_auc: 0.6635 - precision: 0.6187 - recall: 0.5975\n","Epoch 7: Validation Metrics:\n","loss: 0.6688567996025085\n","val_binary_accuracy: 0.5381818413734436\n","val_precision: 0.2623574137687683\n","val_recall: 0.5348837375640869\n","val_auc: 0.5529193878173828\n","val_prc_auc: 0.26421207189559937\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6559 - binary_accuracy: 0.6122 - f1: 0.6070 - loss: 0.6662 - prc_auc: 0.6630 - precision: 0.6184 - recall: 0.5977 - val_auc: 0.5529 - val_binary_accuracy: 0.5382 - val_f1: 0.3520 - val_loss: 0.6808 - val_prc_auc: 0.2642 - val_precision: 0.2624 - val_recall: 0.5349\n","Starting training for label: 6\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - auc: 0.6186 - binary_accuracy: 0.5712 - f1: 0.4429 - loss: 0.6811 - prc_auc: 0.6176 - precision: 0.5984 - recall: 0.3535  \n","Epoch 1: Validation Metrics:\n","loss: 0.6656973361968994\n","val_binary_accuracy: 0.6836363673210144\n","val_precision: 0.3616071343421936\n","val_recall: 0.7232142686843872\n","val_auc: 0.755687415599823\n","val_prc_auc: 0.49313658475875854\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - auc: 0.6200 - binary_accuracy: 0.5722 - f1: 0.4448 - loss: 0.6808 - prc_auc: 0.6191 - precision: 0.6000 - recall: 0.3554 - val_auc: 0.7557 - val_binary_accuracy: 0.6836 - val_f1: 0.4821 - val_loss: 0.6494 - val_prc_auc: 0.4931 - val_precision: 0.3616 - val_recall: 0.7232\n","Epoch 2/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7863 - binary_accuracy: 0.7152 - f1: 0.7211 - loss: 0.6183 - prc_auc: 0.7899 - precision: 0.6906 - recall: 0.7559\n","Epoch 2: Validation Metrics:\n","loss: 0.6144234538078308\n","val_binary_accuracy: 0.6781818270683289\n","val_precision: 0.3568281829357147\n","val_recall: 0.7232142686843872\n","val_auc: 0.7572977542877197\n","val_prc_auc: 0.49829164147377014\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - auc: 0.7856 - binary_accuracy: 0.7147 - f1: 0.7204 - loss: 0.6181 - prc_auc: 0.7893 - precision: 0.6910 - recall: 0.7539 - val_auc: 0.7573 - val_binary_accuracy: 0.6782 - val_f1: 0.4779 - val_loss: 0.6252 - val_prc_auc: 0.4983 - val_precision: 0.3568 - val_recall: 0.7232\n","Epoch 3/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7920 - binary_accuracy: 0.7198 - f1: 0.7221 - loss: 0.5800 - prc_auc: 0.7993 - precision: 0.6995 - recall: 0.7475\n","Epoch 3: Validation Metrics:\n","loss: 0.5857095718383789\n","val_binary_accuracy: 0.6800000071525574\n","val_precision: 0.35840708017349243\n","val_recall: 0.7232142686843872\n","val_auc: 0.7563499212265015\n","val_prc_auc: 0.5008127689361572\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - auc: 0.7913 - binary_accuracy: 0.7192 - f1: 0.7213 - loss: 0.5802 - prc_auc: 0.7987 - precision: 0.6998 - recall: 0.7456 - val_auc: 0.7563 - val_binary_accuracy: 0.6800 - val_f1: 0.4793 - val_loss: 0.6163 - val_prc_auc: 0.5008 - val_precision: 0.3584 - val_recall: 0.7232\n","Epoch 4/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7962 - binary_accuracy: 0.7296 - f1: 0.7310 - loss: 0.5608 - prc_auc: 0.8055 - precision: 0.7103 - recall: 0.7542\n","Epoch 4: Validation Metrics:\n","loss: 0.5725224614143372\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.3539822995662689\n","val_recall: 0.7142857313156128\n","val_auc: 0.7573385238647461\n","val_prc_auc: 0.5084884762763977\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - auc: 0.7956 - binary_accuracy: 0.7290 - f1: 0.7301 - loss: 0.5612 - prc_auc: 0.8049 - precision: 0.7106 - recall: 0.7521 - val_auc: 0.7573 - val_binary_accuracy: 0.6764 - val_f1: 0.4734 - val_loss: 0.6141 - val_prc_auc: 0.5085 - val_precision: 0.3540 - val_recall: 0.7143\n","Epoch 5/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8002 - binary_accuracy: 0.7279 - f1: 0.7276 - loss: 0.5513 - prc_auc: 0.8101 - precision: 0.7118 - recall: 0.7452\n","Epoch 5: Validation Metrics:\n","loss: 0.5660397410392761\n","val_binary_accuracy: 0.6818181872367859\n","val_precision: 0.35746607184410095\n","val_recall: 0.7053571343421936\n","val_auc: 0.7586023807525635\n","val_prc_auc: 0.5171960592269897\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - auc: 0.7995 - binary_accuracy: 0.7273 - f1: 0.7269 - loss: 0.5518 - prc_auc: 0.8095 - precision: 0.7120 - recall: 0.7435 - val_auc: 0.7586 - val_binary_accuracy: 0.6818 - val_f1: 0.4745 - val_loss: 0.6132 - val_prc_auc: 0.5172 - val_precision: 0.3575 - val_recall: 0.7054\n","Epoch 6/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8031 - binary_accuracy: 0.7315 - f1: 0.7318 - loss: 0.5456 - prc_auc: 0.8135 - precision: 0.7144 - recall: 0.7512\n","Epoch 6: Validation Metrics:\n","loss: 0.5617914199829102\n","val_binary_accuracy: 0.6909090876579285\n","val_precision: 0.36574074625968933\n","val_recall: 0.7053571343421936\n","val_auc: 0.7588266730308533\n","val_prc_auc: 0.5221599340438843\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - auc: 0.8024 - binary_accuracy: 0.7310 - f1: 0.7311 - loss: 0.5461 - prc_auc: 0.8129 - precision: 0.7146 - recall: 0.7494 - val_auc: 0.7588 - val_binary_accuracy: 0.6909 - val_f1: 0.4817 - val_loss: 0.6123 - val_prc_auc: 0.5222 - val_precision: 0.3657 - val_recall: 0.7054\n","Starting training for label: 7\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - auc: 0.5194 - binary_accuracy: 0.5119 - f1: 0.5781 - loss: 0.6925 - prc_auc: 0.4901 - precision: 0.5049 - recall: 0.6886\n","Epoch 1: Validation Metrics:\n","loss: 0.6890382170677185\n","val_binary_accuracy: 0.48181816935539246\n","val_precision: 0.17133955657482147\n","val_recall: 0.7432432174682617\n","val_auc: 0.6066602468490601\n","val_prc_auc: 0.166425883769989\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 671ms/step - auc: 0.5209 - binary_accuracy: 0.5129 - f1: 0.5786 - loss: 0.6924 - prc_auc: 0.4916 - precision: 0.5059 - recall: 0.6880 - val_auc: 0.6067 - val_binary_accuracy: 0.4818 - val_f1: 0.2785 - val_loss: 0.7007 - val_prc_auc: 0.1664 - val_precision: 0.1713 - val_recall: 0.7432\n","Epoch 2/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6269 - binary_accuracy: 0.5987 - f1: 0.6200 - loss: 0.6817 - prc_auc: 0.5928 - precision: 0.5776 - recall: 0.6711\n","Epoch 2: Validation Metrics:\n","loss: 0.678860604763031\n","val_binary_accuracy: 0.5436363816261292\n","val_precision: 0.17818181216716766\n","val_recall: 0.662162184715271\n","val_auc: 0.6092862486839294\n","val_prc_auc: 0.17265471816062927\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6276 - binary_accuracy: 0.5990 - f1: 0.6204 - loss: 0.6816 - prc_auc: 0.5932 - precision: 0.5784 - recall: 0.6708 - val_auc: 0.6093 - val_binary_accuracy: 0.5436 - val_f1: 0.2808 - val_loss: 0.6883 - val_prc_auc: 0.1727 - val_precision: 0.1782 - val_recall: 0.6622\n","Epoch 3/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6437 - binary_accuracy: 0.5861 - f1: 0.5893 - loss: 0.6745 - prc_auc: 0.6178 - precision: 0.5719 - recall: 0.6088\n","Epoch 3: Validation Metrics:\n","loss: 0.6714905500411987\n","val_binary_accuracy: 0.5527272820472717\n","val_precision: 0.17669172585010529\n","val_recall: 0.6351351141929626\n","val_auc: 0.6099675893783569\n","val_prc_auc: 0.19023147225379944\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6442 - binary_accuracy: 0.5866 - f1: 0.5902 - loss: 0.6743 - prc_auc: 0.6178 - precision: 0.5729 - recall: 0.6096 - val_auc: 0.6100 - val_binary_accuracy: 0.5527 - val_f1: 0.2765 - val_loss: 0.6811 - val_prc_auc: 0.1902 - val_precision: 0.1767 - val_recall: 0.6351\n","Epoch 4/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6539 - binary_accuracy: 0.5908 - f1: 0.5898 - loss: 0.6684 - prc_auc: 0.6320 - precision: 0.5774 - recall: 0.6034\n","Epoch 4: Validation Metrics:\n","loss: 0.6651875376701355\n","val_binary_accuracy: 0.5545454621315002\n","val_precision: 0.1773584932088852\n","val_recall: 0.6351351141929626\n","val_auc: 0.6131330728530884\n","val_prc_auc: 0.18927565217018127\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6544 - binary_accuracy: 0.5914 - f1: 0.5909 - loss: 0.6682 - prc_auc: 0.6322 - precision: 0.5785 - recall: 0.6046 - val_auc: 0.6131 - val_binary_accuracy: 0.5545 - val_f1: 0.2773 - val_loss: 0.6760 - val_prc_auc: 0.1893 - val_precision: 0.1774 - val_recall: 0.6351\n","Epoch 5/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6633 - binary_accuracy: 0.5986 - f1: 0.5935 - loss: 0.6630 - prc_auc: 0.6490 - precision: 0.5859 - recall: 0.6015\n","Epoch 5: Validation Metrics:\n","loss: 0.659537672996521\n","val_binary_accuracy: 0.5527272820472717\n","val_precision: 0.17669172585010529\n","val_recall: 0.6351351141929626\n","val_auc: 0.6157733201980591\n","val_prc_auc: 0.18454977869987488\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6637 - binary_accuracy: 0.5990 - f1: 0.5946 - loss: 0.6628 - prc_auc: 0.6492 - precision: 0.5867 - recall: 0.6031 - val_auc: 0.6158 - val_binary_accuracy: 0.5527 - val_f1: 0.2765 - val_loss: 0.6721 - val_prc_auc: 0.1845 - val_precision: 0.1767 - val_recall: 0.6351\n","Epoch 6/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6679 - binary_accuracy: 0.6037 - f1: 0.5977 - loss: 0.6581 - prc_auc: 0.6563 - precision: 0.5912 - recall: 0.6046\n","Epoch 6: Validation Metrics:\n","loss: 0.6545129418373108\n","val_binary_accuracy: 0.5563636422157288\n","val_precision: 0.18045112490653992\n","val_recall: 0.6486486196517944\n","val_auc: 0.6184561252593994\n","val_prc_auc: 0.1870826929807663\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - auc: 0.6684 - binary_accuracy: 0.6041 - f1: 0.5989 - loss: 0.6579 - prc_auc: 0.6565 - precision: 0.5920 - recall: 0.6062 - val_auc: 0.6185 - val_binary_accuracy: 0.5564 - val_f1: 0.2824 - val_loss: 0.6698 - val_prc_auc: 0.1871 - val_precision: 0.1805 - val_recall: 0.6486\n","Epoch 7/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6726 - binary_accuracy: 0.6056 - f1: 0.6010 - loss: 0.6537 - prc_auc: 0.6598 - precision: 0.5924 - recall: 0.6101\n","Epoch 7: Validation Metrics:\n","loss: 0.6500046849250793\n","val_binary_accuracy: 0.5600000023841858\n","val_precision: 0.1818181872367859\n","val_recall: 0.6486486196517944\n","val_auc: 0.6182716488838196\n","val_prc_auc: 0.18393346667289734\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - auc: 0.6730 - binary_accuracy: 0.6062 - f1: 0.6023 - loss: 0.6535 - prc_auc: 0.6602 - precision: 0.5933 - recall: 0.6119 - val_auc: 0.6183 - val_binary_accuracy: 0.5600 - val_f1: 0.2840 - val_loss: 0.6684 - val_prc_auc: 0.1839 - val_precision: 0.1818 - val_recall: 0.6486\n","Epoch 8/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6771 - binary_accuracy: 0.6083 - f1: 0.6050 - loss: 0.6498 - prc_auc: 0.6646 - precision: 0.5944 - recall: 0.6162\n","Epoch 8: Validation Metrics:\n","loss: 0.6459416747093201\n","val_binary_accuracy: 0.5636363625526428\n","val_precision: 0.18560606241226196\n","val_recall: 0.662162184715271\n","val_auc: 0.6195776462554932\n","val_prc_auc: 0.1835535317659378\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6776 - binary_accuracy: 0.6088 - f1: 0.6063 - loss: 0.6496 - prc_auc: 0.6650 - precision: 0.5953 - recall: 0.6179 - val_auc: 0.6196 - val_binary_accuracy: 0.5636 - val_f1: 0.2899 - val_loss: 0.6669 - val_prc_auc: 0.1836 - val_precision: 0.1856 - val_recall: 0.6622\n","Epoch 9/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6810 - binary_accuracy: 0.6186 - f1: 0.6194 - loss: 0.6462 - prc_auc: 0.6669 - precision: 0.6027 - recall: 0.6374\n","Epoch 9: Validation Metrics:\n","loss: 0.6422929763793945\n","val_binary_accuracy: 0.5654545426368713\n","val_precision: 0.1863117814064026\n","val_recall: 0.662162184715271\n","val_auc: 0.6202731132507324\n","val_prc_auc: 0.18192331492900848\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6815 - binary_accuracy: 0.6191 - f1: 0.6206 - loss: 0.6460 - prc_auc: 0.6673 - precision: 0.6035 - recall: 0.6390 - val_auc: 0.6203 - val_binary_accuracy: 0.5655 - val_f1: 0.2908 - val_loss: 0.6657 - val_prc_auc: 0.1819 - val_precision: 0.1863 - val_recall: 0.6622\n","Epoch 10/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6849 - binary_accuracy: 0.6245 - f1: 0.6256 - loss: 0.6430 - prc_auc: 0.6713 - precision: 0.6085 - recall: 0.6440\n","Epoch 10: Validation Metrics:\n","loss: 0.638992965221405\n","val_binary_accuracy: 0.5654545426368713\n","val_precision: 0.1863117814064026\n","val_recall: 0.662162184715271\n","val_auc: 0.6228139996528625\n","val_prc_auc: 0.18383102118968964\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6853 - binary_accuracy: 0.6250 - f1: 0.6268 - loss: 0.6428 - prc_auc: 0.6718 - precision: 0.6093 - recall: 0.6456 - val_auc: 0.6228 - val_binary_accuracy: 0.5655 - val_f1: 0.2908 - val_loss: 0.6646 - val_prc_auc: 0.1838 - val_precision: 0.1863 - val_recall: 0.6622\n","Epoch 11/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6879 - binary_accuracy: 0.6244 - f1: 0.6276 - loss: 0.6400 - prc_auc: 0.6725 - precision: 0.6071 - recall: 0.6498\n","Epoch 11: Validation Metrics:\n","loss: 0.6359288096427917\n","val_binary_accuracy: 0.5636363625526428\n","val_precision: 0.18560606241226196\n","val_recall: 0.662162184715271\n","val_auc: 0.6239779591560364\n","val_prc_auc: 0.18351291120052338\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6884 - binary_accuracy: 0.6250 - f1: 0.6288 - loss: 0.6398 - prc_auc: 0.6731 - precision: 0.6080 - recall: 0.6514 - val_auc: 0.6240 - val_binary_accuracy: 0.5636 - val_f1: 0.2899 - val_loss: 0.6639 - val_prc_auc: 0.1835 - val_precision: 0.1856 - val_recall: 0.6622\n","Epoch 12/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6920 - binary_accuracy: 0.6256 - f1: 0.6304 - loss: 0.6372 - prc_auc: 0.6761 - precision: 0.6073 - recall: 0.6556\n","Epoch 12: Validation Metrics:\n","loss: 0.6330381631851196\n","val_binary_accuracy: 0.5600000023841858\n","val_precision: 0.18421052396297455\n","val_recall: 0.662162184715271\n","val_auc: 0.6256529092788696\n","val_prc_auc: 0.18380728363990784\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6924 - binary_accuracy: 0.6263 - f1: 0.6318 - loss: 0.6370 - prc_auc: 0.6766 - precision: 0.6083 - recall: 0.6574 - val_auc: 0.6257 - val_binary_accuracy: 0.5600 - val_f1: 0.2882 - val_loss: 0.6631 - val_prc_auc: 0.1838 - val_precision: 0.1842 - val_recall: 0.6622\n","Epoch 13/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6949 - binary_accuracy: 0.6274 - f1: 0.6355 - loss: 0.6345 - prc_auc: 0.6785 - precision: 0.6073 - recall: 0.6668\n","Epoch 13: Validation Metrics:\n","loss: 0.6303069591522217\n","val_binary_accuracy: 0.5618181824684143\n","val_precision: 0.19188192486763\n","val_recall: 0.7027027010917664\n","val_auc: 0.6272995471954346\n","val_prc_auc: 0.18555976450443268\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6954 - binary_accuracy: 0.6282 - f1: 0.6369 - loss: 0.6343 - prc_auc: 0.6791 - precision: 0.6084 - recall: 0.6686 - val_auc: 0.6273 - val_binary_accuracy: 0.5618 - val_f1: 0.3014 - val_loss: 0.6628 - val_prc_auc: 0.1856 - val_precision: 0.1919 - val_recall: 0.7027\n","Epoch 14/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6986 - binary_accuracy: 0.6294 - f1: 0.6366 - loss: 0.6321 - prc_auc: 0.6828 - precision: 0.6095 - recall: 0.6666\n","Epoch 14: Validation Metrics:\n","loss: 0.6276978850364685\n","val_binary_accuracy: 0.5563636422157288\n","val_precision: 0.1875\n","val_recall: 0.6891891956329346\n","val_auc: 0.6288610100746155\n","val_prc_auc: 0.18523430824279785\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6990 - binary_accuracy: 0.6302 - f1: 0.6381 - loss: 0.6318 - prc_auc: 0.6833 - precision: 0.6105 - recall: 0.6685 - val_auc: 0.6289 - val_binary_accuracy: 0.5564 - val_f1: 0.2948 - val_loss: 0.6622 - val_prc_auc: 0.1852 - val_precision: 0.1875 - val_recall: 0.6892\n","Epoch 15/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7023 - binary_accuracy: 0.6305 - f1: 0.6378 - loss: 0.6297 - prc_auc: 0.6860 - precision: 0.6104 - recall: 0.6681\n","Epoch 15: Validation Metrics:\n","loss: 0.6251891851425171\n","val_binary_accuracy: 0.5600000023841858\n","val_precision: 0.19117647409439087\n","val_recall: 0.7027027010917664\n","val_auc: 0.6304365992546082\n","val_prc_auc: 0.1857406347990036\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - auc: 0.7027 - binary_accuracy: 0.6314 - f1: 0.6394 - loss: 0.6295 - prc_auc: 0.6866 - precision: 0.6115 - recall: 0.6701 - val_auc: 0.6304 - val_binary_accuracy: 0.5600 - val_f1: 0.3006 - val_loss: 0.6620 - val_prc_auc: 0.1857 - val_precision: 0.1912 - val_recall: 0.7027\n","Epoch 16/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7053 - binary_accuracy: 0.6315 - f1: 0.6393 - loss: 0.6274 - prc_auc: 0.6888 - precision: 0.6113 - recall: 0.6705\n","Epoch 16: Validation Metrics:\n","loss: 0.6227368712425232\n","val_binary_accuracy: 0.5581818222999573\n","val_precision: 0.190476194024086\n","val_recall: 0.7027027010917664\n","val_auc: 0.6324523091316223\n","val_prc_auc: 0.18606019020080566\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - auc: 0.7058 - binary_accuracy: 0.6324 - f1: 0.6408 - loss: 0.6272 - prc_auc: 0.6894 - precision: 0.6124 - recall: 0.6724 - val_auc: 0.6325 - val_binary_accuracy: 0.5582 - val_f1: 0.2997 - val_loss: 0.6617 - val_prc_auc: 0.1861 - val_precision: 0.1905 - val_recall: 0.7027\n","Epoch 17/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7089 - binary_accuracy: 0.6381 - f1: 0.6478 - loss: 0.6251 - prc_auc: 0.6920 - precision: 0.6163 - recall: 0.6831\n","Epoch 17: Validation Metrics:\n","loss: 0.6203047633171082\n","val_binary_accuracy: 0.5618181824684143\n","val_precision: 0.19188192486763\n","val_recall: 0.7027027010917664\n","val_auc: 0.6358874440193176\n","val_prc_auc: 0.1884274184703827\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7094 - binary_accuracy: 0.6391 - f1: 0.6493 - loss: 0.6249 - prc_auc: 0.6926 - precision: 0.6174 - recall: 0.6852 - val_auc: 0.6359 - val_binary_accuracy: 0.5618 - val_f1: 0.3014 - val_loss: 0.6615 - val_prc_auc: 0.1884 - val_precision: 0.1919 - val_recall: 0.7027\n","Epoch 18/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7125 - binary_accuracy: 0.6464 - f1: 0.6560 - loss: 0.6230 - prc_auc: 0.6961 - precision: 0.6238 - recall: 0.6924\n","Epoch 18: Validation Metrics:\n","loss: 0.6179634928703308\n","val_binary_accuracy: 0.5563636422157288\n","val_precision: 0.1875\n","val_recall: 0.6891891956329346\n","val_auc: 0.6367675065994263\n","val_prc_auc: 0.18814608454704285\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7130 - binary_accuracy: 0.6471 - f1: 0.6573 - loss: 0.6227 - prc_auc: 0.6968 - precision: 0.6247 - recall: 0.6941 - val_auc: 0.6368 - val_binary_accuracy: 0.5564 - val_f1: 0.2948 - val_loss: 0.6614 - val_prc_auc: 0.1881 - val_precision: 0.1875 - val_recall: 0.6892\n","Starting training for label: 8\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - auc: 0.5477 - binary_accuracy: 0.5544 - f1: 0.4600 - loss: 0.6897 - prc_auc: 0.5491 - precision: 0.5831 - recall: 0.4023\n","Epoch 1: Validation Metrics:\n","loss: 0.6851415634155273\n","val_binary_accuracy: 0.41999998688697815\n","val_precision: 0.1532033383846283\n","val_recall: 0.7857142686843872\n","val_auc: 0.6115327477455139\n","val_prc_auc: 0.22568657994270325\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 488ms/step - auc: 0.5490 - binary_accuracy: 0.5548 - f1: 0.4628 - loss: 0.6896 - prc_auc: 0.5501 - precision: 0.5827 - recall: 0.4067 - val_auc: 0.6115 - val_binary_accuracy: 0.4200 - val_f1: 0.2564 - val_loss: 0.7016 - val_prc_auc: 0.2257 - val_precision: 0.1532 - val_recall: 0.7857\n","Epoch 2/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6446 - binary_accuracy: 0.5835 - f1: 0.6464 - loss: 0.6743 - prc_auc: 0.6472 - precision: 0.5593 - recall: 0.7663\n","Epoch 2: Validation Metrics:\n","loss: 0.670822024345398\n","val_binary_accuracy: 0.4909090995788574\n","val_precision: 0.16346153616905212\n","val_recall: 0.7285714149475098\n","val_auc: 0.622871994972229\n","val_prc_auc: 0.24719831347465515\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6448 - binary_accuracy: 0.5838 - f1: 0.6465 - loss: 0.6742 - prc_auc: 0.6472 - precision: 0.5596 - recall: 0.7661 - val_auc: 0.6229 - val_binary_accuracy: 0.4909 - val_f1: 0.2670 - val_loss: 0.6937 - val_prc_auc: 0.2472 - val_precision: 0.1635 - val_recall: 0.7286\n","Epoch 3/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6530 - binary_accuracy: 0.5969 - f1: 0.6416 - loss: 0.6651 - prc_auc: 0.6576 - precision: 0.5749 - recall: 0.7264\n","Epoch 3: Validation Metrics:\n","loss: 0.661685585975647\n","val_binary_accuracy: 0.5345454812049866\n","val_precision: 0.16546761989593506\n","val_recall: 0.6571428775787354\n","val_auc: 0.6331547498703003\n","val_prc_auc: 0.25883716344833374\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6532 - binary_accuracy: 0.5972 - f1: 0.6418 - loss: 0.6651 - prc_auc: 0.6577 - precision: 0.5753 - recall: 0.7261 - val_auc: 0.6332 - val_binary_accuracy: 0.5345 - val_f1: 0.2644 - val_loss: 0.6828 - val_prc_auc: 0.2588 - val_precision: 0.1655 - val_recall: 0.6571\n","Epoch 4/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6578 - binary_accuracy: 0.5986 - f1: 0.6260 - loss: 0.6586 - prc_auc: 0.6643 - precision: 0.5833 - recall: 0.6756\n","Epoch 4: Validation Metrics:\n","loss: 0.6551418304443359\n","val_binary_accuracy: 0.5581818222999573\n","val_precision: 0.17110265791416168\n","val_recall: 0.6428571343421936\n","val_auc: 0.6377975940704346\n","val_prc_auc: 0.264957457780838\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6580 - binary_accuracy: 0.5989 - f1: 0.6262 - loss: 0.6585 - prc_auc: 0.6644 - precision: 0.5837 - recall: 0.6758 - val_auc: 0.6378 - val_binary_accuracy: 0.5582 - val_f1: 0.2703 - val_loss: 0.6752 - val_prc_auc: 0.2650 - val_precision: 0.1711 - val_recall: 0.6429\n","Epoch 5/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6649 - binary_accuracy: 0.6050 - f1: 0.6268 - loss: 0.6535 - prc_auc: 0.6729 - precision: 0.5911 - recall: 0.6676\n","Epoch 5: Validation Metrics:\n","loss: 0.6501471400260925\n","val_binary_accuracy: 0.5672727227210999\n","val_precision: 0.1744185984134674\n","val_recall: 0.6428571343421936\n","val_auc: 0.6467113494873047\n","val_prc_auc: 0.28439781069755554\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6651 - binary_accuracy: 0.6053 - f1: 0.6271 - loss: 0.6534 - prc_auc: 0.6729 - precision: 0.5914 - recall: 0.6677 - val_auc: 0.6467 - val_binary_accuracy: 0.5673 - val_f1: 0.2744 - val_loss: 0.6691 - val_prc_auc: 0.2844 - val_precision: 0.1744 - val_recall: 0.6429\n","Epoch 6/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6718 - binary_accuracy: 0.5995 - f1: 0.6188 - loss: 0.6492 - prc_auc: 0.6798 - precision: 0.5874 - recall: 0.6539\n","Epoch 6: Validation Metrics:\n","loss: 0.6459864974021912\n","val_binary_accuracy: 0.5690909028053284\n","val_precision: 0.1725490242242813\n","val_recall: 0.6285714507102966\n","val_auc: 0.6527678966522217\n","val_prc_auc: 0.2967115640640259\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6720 - binary_accuracy: 0.5999 - f1: 0.6192 - loss: 0.6491 - prc_auc: 0.6798 - precision: 0.5878 - recall: 0.6543 - val_auc: 0.6528 - val_binary_accuracy: 0.5691 - val_f1: 0.2708 - val_loss: 0.6644 - val_prc_auc: 0.2967 - val_precision: 0.1725 - val_recall: 0.6286\n","Epoch 7/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6771 - binary_accuracy: 0.6028 - f1: 0.6219 - loss: 0.6453 - prc_auc: 0.6845 - precision: 0.5904 - recall: 0.6571\n","Epoch 7: Validation Metrics:\n","loss: 0.6422805786132812\n","val_binary_accuracy: 0.5745454430580139\n","val_precision: 0.17716535925865173\n","val_recall: 0.6428571343421936\n","val_auc: 0.6592559814453125\n","val_prc_auc: 0.3082250952720642\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6772 - binary_accuracy: 0.6032 - f1: 0.6223 - loss: 0.6452 - prc_auc: 0.6845 - precision: 0.5909 - recall: 0.6574 - val_auc: 0.6593 - val_binary_accuracy: 0.5745 - val_f1: 0.2778 - val_loss: 0.6610 - val_prc_auc: 0.3082 - val_precision: 0.1772 - val_recall: 0.6429\n","Epoch 8/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6822 - binary_accuracy: 0.6013 - f1: 0.6195 - loss: 0.6415 - prc_auc: 0.6895 - precision: 0.5895 - recall: 0.6530\n","Epoch 8: Validation Metrics:\n","loss: 0.638834536075592\n","val_binary_accuracy: 0.578181803226471\n","val_precision: 0.1785714328289032\n","val_recall: 0.6428571343421936\n","val_auc: 0.666398823261261\n","val_prc_auc: 0.3184705376625061\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6823 - binary_accuracy: 0.6018 - f1: 0.6199 - loss: 0.6415 - prc_auc: 0.6895 - precision: 0.5900 - recall: 0.6533 - val_auc: 0.6664 - val_binary_accuracy: 0.5782 - val_f1: 0.2795 - val_loss: 0.6575 - val_prc_auc: 0.3185 - val_precision: 0.1786 - val_recall: 0.6429\n","Epoch 9/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6870 - binary_accuracy: 0.6021 - f1: 0.6193 - loss: 0.6379 - prc_auc: 0.6941 - precision: 0.5906 - recall: 0.6512\n","Epoch 9: Validation Metrics:\n","loss: 0.6355807185173035\n","val_binary_accuracy: 0.5799999833106995\n","val_precision: 0.17928287386894226\n","val_recall: 0.6428571343421936\n","val_auc: 0.6713392734527588\n","val_prc_auc: 0.3346945345401764\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6872 - binary_accuracy: 0.6026 - f1: 0.6198 - loss: 0.6379 - prc_auc: 0.6941 - precision: 0.5911 - recall: 0.6515 - val_auc: 0.6713 - val_binary_accuracy: 0.5800 - val_f1: 0.2804 - val_loss: 0.6546 - val_prc_auc: 0.3347 - val_precision: 0.1793 - val_recall: 0.6429\n","Epoch 10/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6903 - binary_accuracy: 0.6065 - f1: 0.6262 - loss: 0.6345 - prc_auc: 0.6961 - precision: 0.5934 - recall: 0.6635\n","Epoch 10: Validation Metrics:\n","loss: 0.6324743628501892\n","val_binary_accuracy: 0.5872727036476135\n","val_precision: 0.18473894894123077\n","val_recall: 0.6571428775787354\n","val_auc: 0.6749404668807983\n","val_prc_auc: 0.33999207615852356\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6905 - binary_accuracy: 0.6070 - f1: 0.6266 - loss: 0.6345 - prc_auc: 0.6962 - precision: 0.5939 - recall: 0.6637 - val_auc: 0.6749 - val_binary_accuracy: 0.5873 - val_f1: 0.2884 - val_loss: 0.6517 - val_prc_auc: 0.3400 - val_precision: 0.1847 - val_recall: 0.6571\n","Epoch 11/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6943 - binary_accuracy: 0.6108 - f1: 0.6293 - loss: 0.6313 - prc_auc: 0.7001 - precision: 0.5977 - recall: 0.6649\n","Epoch 11: Validation Metrics:\n","loss: 0.6295069456100464\n","val_binary_accuracy: 0.5872727036476135\n","val_precision: 0.1872510015964508\n","val_recall: 0.6714285612106323\n","val_auc: 0.6796875\n","val_prc_auc: 0.34957003593444824\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6945 - binary_accuracy: 0.6113 - f1: 0.6297 - loss: 0.6312 - prc_auc: 0.7001 - precision: 0.5982 - recall: 0.6651 - val_auc: 0.6797 - val_binary_accuracy: 0.5873 - val_f1: 0.2928 - val_loss: 0.6494 - val_prc_auc: 0.3496 - val_precision: 0.1873 - val_recall: 0.6714\n","Epoch 12/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6987 - binary_accuracy: 0.6131 - f1: 0.6321 - loss: 0.6281 - prc_auc: 0.7030 - precision: 0.5994 - recall: 0.6691\n","Epoch 12: Validation Metrics:\n","loss: 0.6266381144523621\n","val_binary_accuracy: 0.5909090638160706\n","val_precision: 0.19123506546020508\n","val_recall: 0.6857143044471741\n","val_auc: 0.6835268139839172\n","val_prc_auc: 0.35595273971557617\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6989 - binary_accuracy: 0.6135 - f1: 0.6325 - loss: 0.6281 - prc_auc: 0.7030 - precision: 0.5999 - recall: 0.6694 - val_auc: 0.6835 - val_binary_accuracy: 0.5909 - val_f1: 0.2991 - val_loss: 0.6474 - val_prc_auc: 0.3560 - val_precision: 0.1912 - val_recall: 0.6857\n","Epoch 13/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7030 - binary_accuracy: 0.6138 - f1: 0.6338 - loss: 0.6251 - prc_auc: 0.7064 - precision: 0.5998 - recall: 0.6726\n","Epoch 13: Validation Metrics:\n","loss: 0.6238633990287781\n","val_binary_accuracy: 0.5836363434791565\n","val_precision: 0.1882352977991104\n","val_recall: 0.6857143044471741\n","val_auc: 0.6874107122421265\n","val_prc_auc: 0.3603232204914093\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7031 - binary_accuracy: 0.6143 - f1: 0.6342 - loss: 0.6251 - prc_auc: 0.7065 - precision: 0.6004 - recall: 0.6728 - val_auc: 0.6874 - val_binary_accuracy: 0.5836 - val_f1: 0.2954 - val_loss: 0.6451 - val_prc_auc: 0.3603 - val_precision: 0.1882 - val_recall: 0.6857\n","Epoch 14/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7075 - binary_accuracy: 0.6162 - f1: 0.6364 - loss: 0.6221 - prc_auc: 0.7093 - precision: 0.6018 - recall: 0.6758\n","Epoch 14: Validation Metrics:\n","loss: 0.6211692094802856\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.19599999487400055\n","val_recall: 0.699999988079071\n","val_auc: 0.6922470331192017\n","val_prc_auc: 0.3654669225215912\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7076 - binary_accuracy: 0.6168 - f1: 0.6368 - loss: 0.6221 - prc_auc: 0.7094 - precision: 0.6024 - recall: 0.6760 - val_auc: 0.6922 - val_binary_accuracy: 0.5964 - val_f1: 0.3062 - val_loss: 0.6432 - val_prc_auc: 0.3655 - val_precision: 0.1960 - val_recall: 0.7000\n","Epoch 15/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7109 - binary_accuracy: 0.6219 - f1: 0.6403 - loss: 0.6193 - prc_auc: 0.7119 - precision: 0.6078 - recall: 0.6772\n","Epoch 15: Validation Metrics:\n","loss: 0.6185809969902039\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.19599999487400055\n","val_recall: 0.699999988079071\n","val_auc: 0.6954314708709717\n","val_prc_auc: 0.3705560266971588\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7111 - binary_accuracy: 0.6224 - f1: 0.6407 - loss: 0.6193 - prc_auc: 0.7120 - precision: 0.6084 - recall: 0.6774 - val_auc: 0.6954 - val_binary_accuracy: 0.5964 - val_f1: 0.3062 - val_loss: 0.6418 - val_prc_auc: 0.3706 - val_precision: 0.1960 - val_recall: 0.7000\n","Epoch 16/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7138 - binary_accuracy: 0.6288 - f1: 0.6483 - loss: 0.6166 - prc_auc: 0.7140 - precision: 0.6133 - recall: 0.6882\n","Epoch 16: Validation Metrics:\n","loss: 0.6160712838172913\n","val_binary_accuracy: 0.6000000238418579\n","val_precision: 0.20000000298023224\n","val_recall: 0.7142857313156128\n","val_auc: 0.698244035243988\n","val_prc_auc: 0.37616798281669617\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7139 - binary_accuracy: 0.6292 - f1: 0.6486 - loss: 0.6166 - prc_auc: 0.7141 - precision: 0.6139 - recall: 0.6883 - val_auc: 0.6982 - val_binary_accuracy: 0.6000 - val_f1: 0.3125 - val_loss: 0.6400 - val_prc_auc: 0.3762 - val_precision: 0.2000 - val_recall: 0.7143\n","Epoch 17/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7177 - binary_accuracy: 0.6303 - f1: 0.6509 - loss: 0.6140 - prc_auc: 0.7171 - precision: 0.6140 - recall: 0.6933\n","Epoch 17: Validation Metrics:\n","loss: 0.6136140823364258\n","val_binary_accuracy: 0.6018182039260864\n","val_precision: 0.2008032202720642\n","val_recall: 0.7142857313156128\n","val_auc: 0.7006845474243164\n","val_prc_auc: 0.37672916054725647\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7179 - binary_accuracy: 0.6308 - f1: 0.6512 - loss: 0.6140 - prc_auc: 0.7172 - precision: 0.6145 - recall: 0.6933 - val_auc: 0.7007 - val_binary_accuracy: 0.6018 - val_f1: 0.3135 - val_loss: 0.6387 - val_prc_auc: 0.3767 - val_precision: 0.2008 - val_recall: 0.7143\n","Epoch 18/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7209 - binary_accuracy: 0.6304 - f1: 0.6507 - loss: 0.6115 - prc_auc: 0.7197 - precision: 0.6143 - recall: 0.6924\n","Epoch 18: Validation Metrics:\n","loss: 0.6112098097801208\n","val_binary_accuracy: 0.6036363840103149\n","val_precision: 0.2016129046678543\n","val_recall: 0.7142857313156128\n","val_auc: 0.7040029764175415\n","val_prc_auc: 0.38275012373924255\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7210 - binary_accuracy: 0.6310 - f1: 0.6511 - loss: 0.6115 - prc_auc: 0.7198 - precision: 0.6149 - recall: 0.6926 - val_auc: 0.7040 - val_binary_accuracy: 0.6036 - val_f1: 0.3145 - val_loss: 0.6371 - val_prc_auc: 0.3828 - val_precision: 0.2016 - val_recall: 0.7143\n","Epoch 19/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7243 - binary_accuracy: 0.6364 - f1: 0.6553 - loss: 0.6090 - prc_auc: 0.7228 - precision: 0.6204 - recall: 0.6953\n","Epoch 19: Validation Metrics:\n","loss: 0.6088255643844604\n","val_binary_accuracy: 0.6036363840103149\n","val_precision: 0.2016129046678543\n","val_recall: 0.7142857313156128\n","val_auc: 0.7063392996788025\n","val_prc_auc: 0.38375404477119446\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7245 - binary_accuracy: 0.6369 - f1: 0.6557 - loss: 0.6090 - prc_auc: 0.7229 - precision: 0.6209 - recall: 0.6953 - val_auc: 0.7063 - val_binary_accuracy: 0.6036 - val_f1: 0.3145 - val_loss: 0.6362 - val_prc_auc: 0.3838 - val_precision: 0.2016 - val_recall: 0.7143\n","Epoch 20/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7274 - binary_accuracy: 0.6384 - f1: 0.6565 - loss: 0.6066 - prc_auc: 0.7250 - precision: 0.6227 - recall: 0.6950\n","Epoch 20: Validation Metrics:\n","loss: 0.6064967513084412\n","val_binary_accuracy: 0.6054545640945435\n","val_precision: 0.2024291455745697\n","val_recall: 0.7142857313156128\n","val_auc: 0.7092857360839844\n","val_prc_auc: 0.38780277967453003\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7276 - binary_accuracy: 0.6389 - f1: 0.6568 - loss: 0.6066 - prc_auc: 0.7251 - precision: 0.6233 - recall: 0.6951 - val_auc: 0.7093 - val_binary_accuracy: 0.6055 - val_f1: 0.3155 - val_loss: 0.6348 - val_prc_auc: 0.3878 - val_precision: 0.2024 - val_recall: 0.7143\n","Starting training for label: 9\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - auc: 0.7263 - binary_accuracy: 0.6821 - f1: 0.6561 - loss: 0.6693 - prc_auc: 0.7333 - precision: 0.7244 - recall: 0.6137\n","Epoch 1: Validation Metrics:\n","loss: 0.6506240963935852\n","val_binary_accuracy: 0.8799999952316284\n","val_precision: 0.4769230782985687\n","val_recall: 0.4920634925365448\n","val_auc: 0.7854210138320923\n","val_prc_auc: 0.41693589091300964\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 518ms/step - auc: 0.7270 - binary_accuracy: 0.6829 - f1: 0.6563 - loss: 0.6688 - prc_auc: 0.7346 - precision: 0.7265 - recall: 0.6123 - val_auc: 0.7854 - val_binary_accuracy: 0.8800 - val_f1: 0.4844 - val_loss: 0.5731 - val_prc_auc: 0.4169 - val_precision: 0.4769 - val_recall: 0.4921\n","Epoch 2/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8098 - binary_accuracy: 0.7365 - f1: 0.6597 - loss: 0.5995 - prc_auc: 0.8278 - precision: 0.9098 - recall: 0.5190\n","Epoch 2: Validation Metrics:\n","loss: 0.5905303359031677\n","val_binary_accuracy: 0.8799999952316284\n","val_precision: 0.4776119291782379\n","val_recall: 0.5079365372657776\n","val_auc: 0.7917929291725159\n","val_prc_auc: 0.4283589720726013\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8092 - binary_accuracy: 0.7361 - f1: 0.6598 - loss: 0.5990 - prc_auc: 0.8275 - precision: 0.9081 - recall: 0.5196 - val_auc: 0.7918 - val_binary_accuracy: 0.8800 - val_f1: 0.4923 - val_loss: 0.5218 - val_prc_auc: 0.4284 - val_precision: 0.4776 - val_recall: 0.5079\n","Epoch 3/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8194 - binary_accuracy: 0.7452 - f1: 0.6791 - loss: 0.5566 - prc_auc: 0.8359 - precision: 0.8951 - recall: 0.5481\n","Epoch 3: Validation Metrics:\n","loss: 0.5540987849235535\n","val_binary_accuracy: 0.8781818151473999\n","val_precision: 0.4714285731315613\n","val_recall: 0.523809552192688\n","val_auc: 0.7971219420433044\n","val_prc_auc: 0.42561280727386475\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8190 - binary_accuracy: 0.7447 - f1: 0.6789 - loss: 0.5565 - prc_auc: 0.8356 - precision: 0.8939 - recall: 0.5484 - val_auc: 0.7971 - val_binary_accuracy: 0.8782 - val_f1: 0.4962 - val_loss: 0.5063 - val_prc_auc: 0.4256 - val_precision: 0.4714 - val_recall: 0.5238\n","Epoch 4/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8244 - binary_accuracy: 0.7533 - f1: 0.6946 - loss: 0.5298 - prc_auc: 0.8416 - precision: 0.8914 - recall: 0.5702\n","Epoch 4: Validation Metrics:\n","loss: 0.5325653553009033\n","val_binary_accuracy: 0.8727272748947144\n","val_precision: 0.45205479860305786\n","val_recall: 0.523809552192688\n","val_auc: 0.799631655216217\n","val_prc_auc: 0.428402304649353\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8239 - binary_accuracy: 0.7528 - f1: 0.6944 - loss: 0.5300 - prc_auc: 0.8413 - precision: 0.8903 - recall: 0.5703 - val_auc: 0.7996 - val_binary_accuracy: 0.8727 - val_f1: 0.4853 - val_loss: 0.4986 - val_prc_auc: 0.4284 - val_precision: 0.4521 - val_recall: 0.5238\n","Epoch 5/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8297 - binary_accuracy: 0.7612 - f1: 0.7079 - loss: 0.5144 - prc_auc: 0.8468 - precision: 0.8924 - recall: 0.5879\n","Epoch 5: Validation Metrics:\n","loss: 0.5204839706420898\n","val_binary_accuracy: 0.8727272748947144\n","val_precision: 0.4533333480358124\n","val_recall: 0.5396825671195984\n","val_auc: 0.8018806576728821\n","val_prc_auc: 0.43291401863098145\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8292 - binary_accuracy: 0.7605 - f1: 0.7074 - loss: 0.5147 - prc_auc: 0.8465 - precision: 0.8912 - recall: 0.5877 - val_auc: 0.8019 - val_binary_accuracy: 0.8727 - val_f1: 0.4928 - val_loss: 0.4942 - val_prc_auc: 0.4329 - val_precision: 0.4533 - val_recall: 0.5397\n","Epoch 6/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8326 - binary_accuracy: 0.7619 - f1: 0.7107 - loss: 0.5050 - prc_auc: 0.8492 - precision: 0.8871 - recall: 0.5939\n","Epoch 6: Validation Metrics:\n","loss: 0.5130347609519958\n","val_binary_accuracy: 0.8709090948104858\n","val_precision: 0.44871795177459717\n","val_recall: 0.5555555820465088\n","val_auc: 0.8052214980125427\n","val_prc_auc: 0.43936222791671753\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8321 - binary_accuracy: 0.7613 - f1: 0.7103 - loss: 0.5054 - prc_auc: 0.8489 - precision: 0.8862 - recall: 0.5936 - val_auc: 0.8052 - val_binary_accuracy: 0.8709 - val_f1: 0.4965 - val_loss: 0.4907 - val_prc_auc: 0.4394 - val_precision: 0.4487 - val_recall: 0.5556\n","Epoch 7/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8353 - binary_accuracy: 0.7609 - f1: 0.7113 - loss: 0.4988 - prc_auc: 0.8523 - precision: 0.8791 - recall: 0.5984\n","Epoch 7: Validation Metrics:\n","loss: 0.5078431367874146\n","val_binary_accuracy: 0.8690909147262573\n","val_precision: 0.4430379867553711\n","val_recall: 0.5555555820465088\n","val_auc: 0.8057593107223511\n","val_prc_auc: 0.44674962759017944\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8348 - binary_accuracy: 0.7603 - f1: 0.7110 - loss: 0.4992 - prc_auc: 0.8520 - precision: 0.8782 - recall: 0.5983 - val_auc: 0.8058 - val_binary_accuracy: 0.8691 - val_f1: 0.4930 - val_loss: 0.4884 - val_prc_auc: 0.4467 - val_precision: 0.4430 - val_recall: 0.5556\n","Epoch 8/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8386 - binary_accuracy: 0.7597 - f1: 0.7116 - loss: 0.4942 - prc_auc: 0.8549 - precision: 0.8717 - recall: 0.6024\n","Epoch 8: Validation Metrics:\n","loss: 0.5037986040115356\n","val_binary_accuracy: 0.8709090948104858\n","val_precision: 0.44999998807907104\n","val_recall: 0.5714285969734192\n","val_auc: 0.8086763620376587\n","val_prc_auc: 0.4490393102169037\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8381 - binary_accuracy: 0.7592 - f1: 0.7114 - loss: 0.4947 - prc_auc: 0.8547 - precision: 0.8710 - recall: 0.6024 - val_auc: 0.8087 - val_binary_accuracy: 0.8709 - val_f1: 0.5035 - val_loss: 0.4864 - val_prc_auc: 0.4490 - val_precision: 0.4500 - val_recall: 0.5714\n","Epoch 9/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8407 - binary_accuracy: 0.7618 - f1: 0.7141 - loss: 0.4905 - prc_auc: 0.8568 - precision: 0.8750 - recall: 0.6044\n","Epoch 9: Validation Metrics:\n","loss: 0.5003839731216431\n","val_binary_accuracy: 0.8709090948104858\n","val_precision: 0.4523809552192688\n","val_recall: 0.60317462682724\n","val_auc: 0.8103875517845154\n","val_prc_auc: 0.4577600955963135\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8402 - binary_accuracy: 0.7614 - f1: 0.7139 - loss: 0.4910 - prc_auc: 0.8565 - precision: 0.8742 - recall: 0.6044 - val_auc: 0.8104 - val_binary_accuracy: 0.8709 - val_f1: 0.5170 - val_loss: 0.4849 - val_prc_auc: 0.4578 - val_precision: 0.4524 - val_recall: 0.6032\n","Epoch 10/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8439 - binary_accuracy: 0.7624 - f1: 0.7170 - loss: 0.4873 - prc_auc: 0.8591 - precision: 0.8687 - recall: 0.6111\n","Epoch 10: Validation Metrics:\n","loss: 0.49735966324806213\n","val_binary_accuracy: 0.8672727346420288\n","val_precision: 0.44186046719551086\n","val_recall: 0.60317462682724\n","val_auc: 0.8110557794570923\n","val_prc_auc: 0.4505056142807007\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8433 - binary_accuracy: 0.7620 - f1: 0.7168 - loss: 0.4878 - prc_auc: 0.8589 - precision: 0.8682 - recall: 0.6110 - val_auc: 0.8111 - val_binary_accuracy: 0.8673 - val_f1: 0.5101 - val_loss: 0.4834 - val_prc_auc: 0.4505 - val_precision: 0.4419 - val_recall: 0.6032\n","Epoch 11/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8464 - binary_accuracy: 0.7638 - f1: 0.7190 - loss: 0.4844 - prc_auc: 0.8609 - precision: 0.8696 - recall: 0.6135\n","Epoch 11: Validation Metrics:\n","loss: 0.49456408619880676\n","val_binary_accuracy: 0.8618181943893433\n","val_precision: 0.42696627974510193\n","val_recall: 0.60317462682724\n","val_auc: 0.8118053078651428\n","val_prc_auc: 0.45964986085891724\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8459 - binary_accuracy: 0.7635 - f1: 0.7189 - loss: 0.4850 - prc_auc: 0.8606 - precision: 0.8692 - recall: 0.6136 - val_auc: 0.8118 - val_binary_accuracy: 0.8618 - val_f1: 0.5000 - val_loss: 0.4821 - val_prc_auc: 0.4596 - val_precision: 0.4270 - val_recall: 0.6032\n","Epoch 12/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8480 - binary_accuracy: 0.7662 - f1: 0.7232 - loss: 0.4817 - prc_auc: 0.8622 - precision: 0.8682 - recall: 0.6205\n","Epoch 12: Validation Metrics:\n","loss: 0.4919297993183136\n","val_binary_accuracy: 0.8618181943893433\n","val_precision: 0.42696627974510193\n","val_recall: 0.60317462682724\n","val_auc: 0.8130927681922913\n","val_prc_auc: 0.4608350396156311\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8475 - binary_accuracy: 0.7658 - f1: 0.7232 - loss: 0.4823 - prc_auc: 0.8619 - precision: 0.8677 - recall: 0.6207 - val_auc: 0.8131 - val_binary_accuracy: 0.8618 - val_f1: 0.5000 - val_loss: 0.4811 - val_prc_auc: 0.4608 - val_precision: 0.4270 - val_recall: 0.6032\n","Epoch 13/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8508 - binary_accuracy: 0.7662 - f1: 0.7265 - loss: 0.4792 - prc_auc: 0.8645 - precision: 0.8576 - recall: 0.6308\n","Epoch 13: Validation Metrics:\n","loss: 0.4894416928291321\n","val_binary_accuracy: 0.8600000143051147\n","val_precision: 0.42222222685813904\n","val_recall: 0.60317462682724\n","val_auc: 0.8140869140625\n","val_prc_auc: 0.46445000171661377\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8502 - binary_accuracy: 0.7660 - f1: 0.7265 - loss: 0.4797 - prc_auc: 0.8643 - precision: 0.8573 - recall: 0.6310 - val_auc: 0.8141 - val_binary_accuracy: 0.8600 - val_f1: 0.4967 - val_loss: 0.4799 - val_prc_auc: 0.4645 - val_precision: 0.4222 - val_recall: 0.6032\n","Epoch 14/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8525 - binary_accuracy: 0.7691 - f1: 0.7309 - loss: 0.4768 - prc_auc: 0.8657 - precision: 0.8583 - recall: 0.6370\n","Epoch 14: Validation Metrics:\n","loss: 0.4870653748512268\n","val_binary_accuracy: 0.8618181943893433\n","val_precision: 0.4285714328289032\n","val_recall: 0.6190476417541504\n","val_auc: 0.8143802285194397\n","val_prc_auc: 0.46691441535949707\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.8520 - binary_accuracy: 0.7689 - f1: 0.7309 - loss: 0.4773 - prc_auc: 0.8654 - precision: 0.8580 - recall: 0.6371 - val_auc: 0.8144 - val_binary_accuracy: 0.8618 - val_f1: 0.5065 - val_loss: 0.4789 - val_prc_auc: 0.4669 - val_precision: 0.4286 - val_recall: 0.6190\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 265ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 199ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 193ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 195ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 193ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 193ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 194ms/step\n","[[0 1 1 ... 0 0 0]\n"," [1 1 0 ... 0 1 0]\n"," [0 0 1 ... 0 0 0]\n"," ...\n"," [0 1 1 ... 1 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [1 0 1 ... 1 1 0]]\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - auc: 0.5953 - binary_accuracy: 0.5612 - f1: 0.5684 - loss: 0.6820 - prc_auc: 0.5987 - precision: 0.5593 - recall: 0.6148\n","Epoch 1: Validation Metrics:\n","loss: 0.6708510518074036\n","val_binary_accuracy: 0.6294326186180115\n","val_precision: 0.47330960631370544\n","val_recall: 0.6855670213699341\n","val_auc: 0.6904569864273071\n","val_prc_auc: 0.5086734294891357\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 251ms/step - auc: 0.5957 - binary_accuracy: 0.5615 - f1: 0.5691 - loss: 0.6819 - prc_auc: 0.5990 - precision: 0.5595 - recall: 0.6157 - val_auc: 0.6905 - val_binary_accuracy: 0.6294 - val_f1: 0.5600 - val_loss: 0.6475 - val_prc_auc: 0.5087 - val_precision: 0.4733 - val_recall: 0.6856\n","Epoch 2/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6710 - binary_accuracy: 0.6250 - f1: 0.6636 - loss: 0.6521 - prc_auc: 0.6680 - precision: 0.6200 - recall: 0.7144\n","Epoch 2: Validation Metrics:\n","loss: 0.6438671946525574\n","val_binary_accuracy: 0.6365247964859009\n","val_precision: 0.4797047972679138\n","val_recall: 0.6701030731201172\n","val_auc: 0.7018041014671326\n","val_prc_auc: 0.5129122734069824\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - auc: 0.6712 - binary_accuracy: 0.6250 - f1: 0.6635 - loss: 0.6520 - prc_auc: 0.6680 - precision: 0.6200 - recall: 0.7143 - val_auc: 0.7018 - val_binary_accuracy: 0.6365 - val_f1: 0.5591 - val_loss: 0.6308 - val_prc_auc: 0.5129 - val_precision: 0.4797 - val_recall: 0.6701\n","Epoch 3/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6878 - binary_accuracy: 0.6277 - f1: 0.6529 - loss: 0.6394 - prc_auc: 0.6809 - precision: 0.6323 - recall: 0.6754\n","Epoch 3: Validation Metrics:\n","loss: 0.6288660168647766\n","val_binary_accuracy: 0.6560283899307251\n","val_precision: 0.5\n","val_recall: 0.6597937941551208\n","val_auc: 0.7100237011909485\n","val_prc_auc: 0.517017126083374\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - auc: 0.6880 - binary_accuracy: 0.6278 - f1: 0.6529 - loss: 0.6393 - prc_auc: 0.6809 - precision: 0.6324 - recall: 0.6754 - val_auc: 0.7100 - val_binary_accuracy: 0.6560 - val_f1: 0.5689 - val_loss: 0.6226 - val_prc_auc: 0.5170 - val_precision: 0.5000 - val_recall: 0.6598\n","Epoch 4/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7004 - binary_accuracy: 0.6417 - f1: 0.6592 - loss: 0.6302 - prc_auc: 0.6881 - precision: 0.6503 - recall: 0.6688\n","Epoch 4: Validation Metrics:\n","loss: 0.6179825067520142\n","val_binary_accuracy: 0.6666666865348816\n","val_precision: 0.511904776096344\n","val_recall: 0.6649484634399414\n","val_auc: 0.7157773971557617\n","val_prc_auc: 0.5213282108306885\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7006 - binary_accuracy: 0.6418 - f1: 0.6592 - loss: 0.6301 - prc_auc: 0.6881 - precision: 0.6504 - recall: 0.6687 - val_auc: 0.7158 - val_binary_accuracy: 0.6667 - val_f1: 0.5785 - val_loss: 0.6180 - val_prc_auc: 0.5213 - val_precision: 0.5119 - val_recall: 0.6649\n","Epoch 5/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7077 - binary_accuracy: 0.6497 - f1: 0.6667 - loss: 0.6240 - prc_auc: 0.6934 - precision: 0.6573 - recall: 0.6768\n","Epoch 5: Validation Metrics:\n","loss: 0.6103121638298035\n","val_binary_accuracy: 0.6631205677986145\n","val_precision: 0.5080645084381104\n","val_recall: 0.6494845151901245\n","val_auc: 0.7200194597244263\n","val_prc_auc: 0.5242103934288025\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7079 - binary_accuracy: 0.6498 - f1: 0.6667 - loss: 0.6239 - prc_auc: 0.6934 - precision: 0.6574 - recall: 0.6768 - val_auc: 0.7200 - val_binary_accuracy: 0.6631 - val_f1: 0.5701 - val_loss: 0.6150 - val_prc_auc: 0.5242 - val_precision: 0.5081 - val_recall: 0.6495\n","Epoch 6/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7133 - binary_accuracy: 0.6472 - f1: 0.6638 - loss: 0.6196 - prc_auc: 0.6973 - precision: 0.6558 - recall: 0.6726\n","Epoch 6: Validation Metrics:\n","loss: 0.6046096086502075\n","val_binary_accuracy: 0.6631205677986145\n","val_precision: 0.5080645084381104\n","val_recall: 0.6494845151901245\n","val_auc: 0.7219072580337524\n","val_prc_auc: 0.5264722108840942\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - auc: 0.7135 - binary_accuracy: 0.6474 - f1: 0.6639 - loss: 0.6194 - prc_auc: 0.6973 - precision: 0.6559 - recall: 0.6727 - val_auc: 0.7219 - val_binary_accuracy: 0.6631 - val_f1: 0.5701 - val_loss: 0.6131 - val_prc_auc: 0.5265 - val_precision: 0.5081 - val_recall: 0.6495\n","Epoch 7/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7180 - binary_accuracy: 0.6494 - f1: 0.6656 - loss: 0.6159 - prc_auc: 0.7016 - precision: 0.6577 - recall: 0.6744\n","Epoch 7: Validation Metrics:\n","loss: 0.5999542474746704\n","val_binary_accuracy: 0.6631205677986145\n","val_precision: 0.5081300735473633\n","val_recall: 0.6443299055099487\n","val_auc: 0.7232654690742493\n","val_prc_auc: 0.5282545685768127\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - auc: 0.7182 - binary_accuracy: 0.6496 - f1: 0.6657 - loss: 0.6158 - prc_auc: 0.7016 - precision: 0.6578 - recall: 0.6745 - val_auc: 0.7233 - val_binary_accuracy: 0.6631 - val_f1: 0.5682 - val_loss: 0.6114 - val_prc_auc: 0.5283 - val_precision: 0.5081 - val_recall: 0.6443\n","Epoch 8/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7221 - binary_accuracy: 0.6495 - f1: 0.6672 - loss: 0.6126 - prc_auc: 0.7054 - precision: 0.6570 - recall: 0.6784\n","Epoch 8: Validation Metrics:\n","loss: 0.5959283113479614\n","val_binary_accuracy: 0.664893627166748\n","val_precision: 0.5102880597114563\n","val_recall: 0.6391752362251282\n","val_auc: 0.7242686152458191\n","val_prc_auc: 0.5292474031448364\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7223 - binary_accuracy: 0.6497 - f1: 0.6673 - loss: 0.6125 - prc_auc: 0.7055 - precision: 0.6571 - recall: 0.6786 - val_auc: 0.7243 - val_binary_accuracy: 0.6649 - val_f1: 0.5675 - val_loss: 0.6099 - val_prc_auc: 0.5292 - val_precision: 0.5103 - val_recall: 0.6392\n","Epoch 9/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7262 - binary_accuracy: 0.6568 - f1: 0.6731 - loss: 0.6096 - prc_auc: 0.7091 - precision: 0.6645 - recall: 0.6827\n","Epoch 9: Validation Metrics:\n","loss: 0.5923513770103455\n","val_binary_accuracy: 0.664893627166748\n","val_precision: 0.5102880597114563\n","val_recall: 0.6391752362251282\n","val_auc: 0.7241641283035278\n","val_prc_auc: 0.5317175388336182\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - auc: 0.7264 - binary_accuracy: 0.6570 - f1: 0.6733 - loss: 0.6094 - prc_auc: 0.7092 - precision: 0.6646 - recall: 0.6829 - val_auc: 0.7242 - val_binary_accuracy: 0.6649 - val_f1: 0.5675 - val_loss: 0.6086 - val_prc_auc: 0.5317 - val_precision: 0.5103 - val_recall: 0.6392\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - auc: 0.7276 - binary_accuracy: 0.6612 - f1: 0.6895 - loss: 0.6553 - prc_auc: 0.7117 - precision: 0.6464 - recall: 0.7488\n","Epoch 1: Validation Metrics:\n","loss: 0.6336135268211365\n","val_binary_accuracy: 0.686170220375061\n","val_precision: 0.5090090036392212\n","val_recall: 0.6243094205856323\n","val_auc: 0.7239876985549927\n","val_prc_auc: 0.5672600269317627\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 229ms/step - auc: 0.7277 - binary_accuracy: 0.6613 - f1: 0.6894 - loss: 0.6551 - prc_auc: 0.7117 - precision: 0.6467 - recall: 0.7481 - val_auc: 0.7240 - val_binary_accuracy: 0.6862 - val_f1: 0.5608 - val_loss: 0.6120 - val_prc_auc: 0.5673 - val_precision: 0.5090 - val_recall: 0.6243\n","Epoch 2/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7722 - binary_accuracy: 0.7137 - f1: 0.7009 - loss: 0.5846 - prc_auc: 0.7602 - precision: 0.7424 - recall: 0.6651\n","Epoch 2: Validation Metrics:\n","loss: 0.5873454809188843\n","val_binary_accuracy: 0.673758864402771\n","val_precision: 0.49367088079452515\n","val_recall: 0.6464088559150696\n","val_auc: 0.7314600348472595\n","val_prc_auc: 0.5592570304870605\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7721 - binary_accuracy: 0.7136 - f1: 0.7008 - loss: 0.5847 - prc_auc: 0.7600 - precision: 0.7421 - recall: 0.6650 - val_auc: 0.7315 - val_binary_accuracy: 0.6738 - val_f1: 0.5598 - val_loss: 0.6030 - val_prc_auc: 0.5593 - val_precision: 0.4937 - val_recall: 0.6464\n","Epoch 3/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7778 - binary_accuracy: 0.7142 - f1: 0.7089 - loss: 0.5711 - prc_auc: 0.7711 - precision: 0.7299 - recall: 0.6898\n","Epoch 3: Validation Metrics:\n","loss: 0.5776893496513367\n","val_binary_accuracy: 0.664893627166748\n","val_precision: 0.4834710657596588\n","val_recall: 0.6464088559150696\n","val_auc: 0.7371651530265808\n","val_prc_auc: 0.5589724779129028\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7777 - binary_accuracy: 0.7141 - f1: 0.7087 - loss: 0.5711 - prc_auc: 0.7710 - precision: 0.7297 - recall: 0.6897 - val_auc: 0.7372 - val_binary_accuracy: 0.6649 - val_f1: 0.5532 - val_loss: 0.5990 - val_prc_auc: 0.5590 - val_precision: 0.4835 - val_recall: 0.6464\n","Epoch 4/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7806 - binary_accuracy: 0.7200 - f1: 0.7187 - loss: 0.5664 - prc_auc: 0.7734 - precision: 0.7294 - recall: 0.7089\n","Epoch 4: Validation Metrics:\n","loss: 0.5730878710746765\n","val_binary_accuracy: 0.6631205677986145\n","val_precision: 0.48148149251937866\n","val_recall: 0.6464088559150696\n","val_auc: 0.7412980198860168\n","val_prc_auc: 0.5656644105911255\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7805 - binary_accuracy: 0.7199 - f1: 0.7185 - loss: 0.5665 - prc_auc: 0.7733 - precision: 0.7292 - recall: 0.7088 - val_auc: 0.7413 - val_binary_accuracy: 0.6631 - val_f1: 0.5519 - val_loss: 0.5963 - val_prc_auc: 0.5657 - val_precision: 0.4815 - val_recall: 0.6464\n","Epoch 5/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7836 - binary_accuracy: 0.7191 - f1: 0.7189 - loss: 0.5632 - prc_auc: 0.7778 - precision: 0.7267 - recall: 0.7118\n","Epoch 5: Validation Metrics:\n","loss: 0.569634735584259\n","val_binary_accuracy: 0.661347508430481\n","val_precision: 0.4796747863292694\n","val_recall: 0.6519337296485901\n","val_auc: 0.7449979782104492\n","val_prc_auc: 0.5720705986022949\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7835 - binary_accuracy: 0.7190 - f1: 0.7188 - loss: 0.5633 - prc_auc: 0.7776 - precision: 0.7266 - recall: 0.7118 - val_auc: 0.7450 - val_binary_accuracy: 0.6613 - val_f1: 0.5527 - val_loss: 0.5941 - val_prc_auc: 0.5721 - val_precision: 0.4797 - val_recall: 0.6519\n","Epoch 6/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7863 - binary_accuracy: 0.7184 - f1: 0.7195 - loss: 0.5605 - prc_auc: 0.7807 - precision: 0.7238 - recall: 0.7160\n","Epoch 6: Validation Metrics:\n","loss: 0.5666665434837341\n","val_binary_accuracy: 0.661347508430481\n","val_precision: 0.4795081913471222\n","val_recall: 0.6464088559150696\n","val_auc: 0.7471619248390198\n","val_prc_auc: 0.5745021104812622\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7862 - binary_accuracy: 0.7183 - f1: 0.7194 - loss: 0.5606 - prc_auc: 0.7806 - precision: 0.7237 - recall: 0.7160 - val_auc: 0.7472 - val_binary_accuracy: 0.6613 - val_f1: 0.5506 - val_loss: 0.5924 - val_prc_auc: 0.5745 - val_precision: 0.4795 - val_recall: 0.6464\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - auc: 0.6103 - binary_accuracy: 0.5700 - f1: 0.6396 - loss: 0.6829 - prc_auc: 0.5606 - precision: 0.5386 - recall: 0.7911\n","Epoch 1: Validation Metrics:\n","loss: 0.6756716370582581\n","val_binary_accuracy: 0.5\n","val_precision: 0.33942559361457825\n","val_recall: 0.8176100850105286\n","val_auc: 0.6694308519363403\n","val_prc_auc: 0.4052054286003113\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 244ms/step - auc: 0.6104 - binary_accuracy: 0.5702 - f1: 0.6397 - loss: 0.6829 - prc_auc: 0.5610 - precision: 0.5388 - recall: 0.7908 - val_auc: 0.6694 - val_binary_accuracy: 0.5000 - val_f1: 0.4797 - val_loss: 0.6922 - val_prc_auc: 0.4052 - val_precision: 0.3394 - val_recall: 0.8176\n","Epoch 2/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6639 - binary_accuracy: 0.5996 - f1: 0.6545 - loss: 0.6587 - prc_auc: 0.6178 - precision: 0.5613 - recall: 0.7861\n","Epoch 2: Validation Metrics:\n","loss: 0.6576493978500366\n","val_binary_accuracy: 0.5177304744720459\n","val_precision: 0.34770888090133667\n","val_recall: 0.8113207817077637\n","val_auc: 0.6732665300369263\n","val_prc_auc: 0.4234076142311096\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.6639 - binary_accuracy: 0.5997 - f1: 0.6546 - loss: 0.6587 - prc_auc: 0.6184 - precision: 0.5616 - recall: 0.7858 - val_auc: 0.6733 - val_binary_accuracy: 0.5177 - val_f1: 0.4868 - val_loss: 0.6803 - val_prc_auc: 0.4234 - val_precision: 0.3477 - val_recall: 0.8113\n","Epoch 3/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6761 - binary_accuracy: 0.6111 - f1: 0.6573 - loss: 0.6492 - prc_auc: 0.6387 - precision: 0.5725 - recall: 0.7732\n","Epoch 3: Validation Metrics:\n","loss: 0.6494575142860413\n","val_binary_accuracy: 0.5301418304443359\n","val_precision: 0.3543955981731415\n","val_recall: 0.8113207817077637\n","val_auc: 0.6738178730010986\n","val_prc_auc: 0.43037569522857666\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6761 - binary_accuracy: 0.6112 - f1: 0.6575 - loss: 0.6492 - prc_auc: 0.6392 - precision: 0.5729 - recall: 0.7730 - val_auc: 0.6738 - val_binary_accuracy: 0.5301 - val_f1: 0.4933 - val_loss: 0.6751 - val_prc_auc: 0.4304 - val_precision: 0.3544 - val_recall: 0.8113\n","Epoch 4/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6856 - binary_accuracy: 0.6180 - f1: 0.6549 - loss: 0.6432 - prc_auc: 0.6574 - precision: 0.5813 - recall: 0.7514\n","Epoch 4: Validation Metrics:\n","loss: 0.64362633228302\n","val_binary_accuracy: 0.5496453642845154\n","val_precision: 0.36389684677124023\n","val_recall: 0.7987421154975891\n","val_auc: 0.6750057935714722\n","val_prc_auc: 0.43131202459335327\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6856 - binary_accuracy: 0.6182 - f1: 0.6552 - loss: 0.6432 - prc_auc: 0.6578 - precision: 0.5818 - recall: 0.7514 - val_auc: 0.6750 - val_binary_accuracy: 0.5496 - val_f1: 0.5000 - val_loss: 0.6725 - val_prc_auc: 0.4313 - val_precision: 0.3639 - val_recall: 0.7987\n","Epoch 5/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6928 - binary_accuracy: 0.6291 - f1: 0.6558 - loss: 0.6385 - prc_auc: 0.6696 - precision: 0.5949 - recall: 0.7331\n","Epoch 5: Validation Metrics:\n","loss: 0.6387364864349365\n","val_binary_accuracy: 0.5620567202568054\n","val_precision: 0.369047611951828\n","val_recall: 0.7798742055892944\n","val_auc: 0.6741361618041992\n","val_prc_auc: 0.42967846989631653\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6928 - binary_accuracy: 0.6293 - f1: 0.6561 - loss: 0.6385 - prc_auc: 0.6701 - precision: 0.5953 - recall: 0.7331 - val_auc: 0.6741 - val_binary_accuracy: 0.5621 - val_f1: 0.5010 - val_loss: 0.6707 - val_prc_auc: 0.4297 - val_precision: 0.3690 - val_recall: 0.7799\n","Epoch 6/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6980 - binary_accuracy: 0.6363 - f1: 0.6540 - loss: 0.6344 - prc_auc: 0.6771 - precision: 0.6053 - recall: 0.7132\n","Epoch 6: Validation Metrics:\n","loss: 0.6344888806343079\n","val_binary_accuracy: 0.567375898361206\n","val_precision: 0.3684210479259491\n","val_recall: 0.74842768907547\n","val_auc: 0.674679696559906\n","val_prc_auc: 0.4318298101425171\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.6980 - binary_accuracy: 0.6364 - f1: 0.6543 - loss: 0.6344 - prc_auc: 0.6776 - precision: 0.6057 - recall: 0.7132 - val_auc: 0.6747 - val_binary_accuracy: 0.5674 - val_f1: 0.4938 - val_loss: 0.6694 - val_prc_auc: 0.4318 - val_precision: 0.3684 - val_recall: 0.7484\n","Epoch 7/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7024 - binary_accuracy: 0.6403 - f1: 0.6530 - loss: 0.6310 - prc_auc: 0.6830 - precision: 0.6119 - recall: 0.7021\n","Epoch 7: Validation Metrics:\n","loss: 0.6308338642120361\n","val_binary_accuracy: 0.5726950168609619\n","val_precision: 0.36942675709724426\n","val_recall: 0.7295597195625305\n","val_auc: 0.6742759346961975\n","val_prc_auc: 0.4326472878456116\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.7024 - binary_accuracy: 0.6405 - f1: 0.6533 - loss: 0.6310 - prc_auc: 0.6834 - precision: 0.6123 - recall: 0.7022 - val_auc: 0.6743 - val_binary_accuracy: 0.5727 - val_f1: 0.4905 - val_loss: 0.6684 - val_prc_auc: 0.4326 - val_precision: 0.3694 - val_recall: 0.7296\n","Epoch 8/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7056 - binary_accuracy: 0.6448 - f1: 0.6535 - loss: 0.6279 - prc_auc: 0.6877 - precision: 0.6181 - recall: 0.6953\n","Epoch 8: Validation Metrics:\n","loss: 0.6276256442070007\n","val_binary_accuracy: 0.5833333134651184\n","val_precision: 0.37662336230278015\n","val_recall: 0.7295597195625305\n","val_auc: 0.674912691116333\n","val_prc_auc: 0.4337746500968933\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.7057 - binary_accuracy: 0.6449 - f1: 0.6538 - loss: 0.6279 - prc_auc: 0.6881 - precision: 0.6185 - recall: 0.6953 - val_auc: 0.6749 - val_binary_accuracy: 0.5833 - val_f1: 0.4968 - val_loss: 0.6683 - val_prc_auc: 0.4338 - val_precision: 0.3766 - val_recall: 0.7296\n","Epoch 9/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7086 - binary_accuracy: 0.6476 - f1: 0.6542 - loss: 0.6253 - prc_auc: 0.6914 - precision: 0.6222 - recall: 0.6918\n","Epoch 9: Validation Metrics:\n","loss: 0.6247801184654236\n","val_binary_accuracy: 0.585106372833252\n","val_precision: 0.37541529536247253\n","val_recall: 0.7106918096542358\n","val_auc: 0.6748117208480835\n","val_prc_auc: 0.4315185546875\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - auc: 0.7087 - binary_accuracy: 0.6477 - f1: 0.6544 - loss: 0.6253 - prc_auc: 0.6918 - precision: 0.6226 - recall: 0.6917 - val_auc: 0.6748 - val_binary_accuracy: 0.5851 - val_f1: 0.4913 - val_loss: 0.6683 - val_prc_auc: 0.4315 - val_precision: 0.3754 - val_recall: 0.7107\n","Epoch 10/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7119 - binary_accuracy: 0.6540 - f1: 0.6588 - loss: 0.6229 - prc_auc: 0.6951 - precision: 0.6295 - recall: 0.6932\n","Epoch 10: Validation Metrics:\n","loss: 0.6221774816513062\n","val_binary_accuracy: 0.5868794322013855\n","val_precision: 0.3766666650772095\n","val_recall: 0.7106918096542358\n","val_auc: 0.6747884750366211\n","val_prc_auc: 0.4339577555656433\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - auc: 0.7120 - binary_accuracy: 0.6541 - f1: 0.6590 - loss: 0.6228 - prc_auc: 0.6955 - precision: 0.6299 - recall: 0.6931 - val_auc: 0.6748 - val_binary_accuracy: 0.5869 - val_f1: 0.4924 - val_loss: 0.6683 - val_prc_auc: 0.4340 - val_precision: 0.3767 - val_recall: 0.7107\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - auc: 0.6065 - binary_accuracy: 0.5969 - f1: 0.4752 - loss: 0.6819 - prc_auc: 0.6123 - precision: 0.6540 - recall: 0.3747\n","Epoch 1: Validation Metrics:\n","loss: 0.6748185753822327\n","val_binary_accuracy: 0.6329787373542786\n","val_precision: 0.3494623601436615\n","val_recall: 0.430463582277298\n","val_auc: 0.6252986788749695\n","val_prc_auc: 0.43157103657722473\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 299ms/step - auc: 0.6068 - binary_accuracy: 0.5970 - f1: 0.4756 - loss: 0.6818 - prc_auc: 0.6127 - precision: 0.6542 - recall: 0.3751 - val_auc: 0.6253 - val_binary_accuracy: 0.6330 - val_f1: 0.3858 - val_loss: 0.6712 - val_prc_auc: 0.4316 - val_precision: 0.3495 - val_recall: 0.4305\n","Epoch 2/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6509 - binary_accuracy: 0.5933 - f1: 0.5322 - loss: 0.6602 - prc_auc: 0.6657 - precision: 0.6105 - recall: 0.4725\n","Epoch 2: Validation Metrics:\n","loss: 0.655695915222168\n","val_binary_accuracy: 0.6436170339584351\n","val_precision: 0.3655914068222046\n","val_recall: 0.4503311216831207\n","val_auc: 0.6346311569213867\n","val_prc_auc: 0.4431438148021698\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.6509 - binary_accuracy: 0.5934 - f1: 0.5323 - loss: 0.6601 - prc_auc: 0.6658 - precision: 0.6110 - recall: 0.4725 - val_auc: 0.6346 - val_binary_accuracy: 0.6436 - val_f1: 0.4036 - val_loss: 0.6679 - val_prc_auc: 0.4431 - val_precision: 0.3656 - val_recall: 0.4503\n","Epoch 3/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6702 - binary_accuracy: 0.5943 - f1: 0.5319 - loss: 0.6490 - prc_auc: 0.6814 - precision: 0.6129 - recall: 0.4708\n","Epoch 3: Validation Metrics:\n","loss: 0.6448644399642944\n","val_binary_accuracy: 0.6436170339584351\n","val_precision: 0.36263737082481384\n","val_recall: 0.4370861053466797\n","val_auc: 0.6468018293380737\n","val_prc_auc: 0.45181214809417725\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.6704 - binary_accuracy: 0.5945 - f1: 0.5321 - loss: 0.6489 - prc_auc: 0.6815 - precision: 0.6134 - recall: 0.4708 - val_auc: 0.6468 - val_binary_accuracy: 0.6436 - val_f1: 0.3964 - val_loss: 0.6661 - val_prc_auc: 0.4518 - val_precision: 0.3626 - val_recall: 0.4371\n","Epoch 4/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6828 - binary_accuracy: 0.6127 - f1: 0.5525 - loss: 0.6402 - prc_auc: 0.6915 - precision: 0.6374 - recall: 0.4888\n","Epoch 4: Validation Metrics:\n","loss: 0.6365271806716919\n","val_binary_accuracy: 0.6453900933265686\n","val_precision: 0.37037035822868347\n","val_recall: 0.46357616782188416\n","val_auc: 0.6524942517280579\n","val_prc_auc: 0.4584999680519104\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.6829 - binary_accuracy: 0.6128 - f1: 0.5526 - loss: 0.6402 - prc_auc: 0.6916 - precision: 0.6378 - recall: 0.4887 - val_auc: 0.6525 - val_binary_accuracy: 0.6454 - val_f1: 0.4118 - val_loss: 0.6653 - val_prc_auc: 0.4585 - val_precision: 0.3704 - val_recall: 0.4636\n","Epoch 5/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6946 - binary_accuracy: 0.6292 - f1: 0.5751 - loss: 0.6329 - prc_auc: 0.6997 - precision: 0.6557 - recall: 0.5138\n","Epoch 5: Validation Metrics:\n","loss: 0.6294772028923035\n","val_binary_accuracy: 0.6471630930900574\n","val_precision: 0.38679245114326477\n","val_recall: 0.5430463552474976\n","val_auc: 0.6580504775047302\n","val_prc_auc: 0.46475091576576233\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.6947 - binary_accuracy: 0.6293 - f1: 0.5752 - loss: 0.6328 - prc_auc: 0.6998 - precision: 0.6561 - recall: 0.5136 - val_auc: 0.6581 - val_binary_accuracy: 0.6472 - val_f1: 0.4518 - val_loss: 0.6651 - val_prc_auc: 0.4648 - val_precision: 0.3868 - val_recall: 0.5430\n","Epoch 6/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7045 - binary_accuracy: 0.6439 - f1: 0.6003 - loss: 0.6265 - prc_auc: 0.7077 - precision: 0.6666 - recall: 0.5480\n","Epoch 6: Validation Metrics:\n","loss: 0.6233237981796265\n","val_binary_accuracy: 0.6294326186180115\n","val_precision: 0.375\n","val_recall: 0.5761589407920837\n","val_auc: 0.6624521017074585\n","val_prc_auc: 0.4690375328063965\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7046 - binary_accuracy: 0.6439 - f1: 0.6002 - loss: 0.6264 - prc_auc: 0.7078 - precision: 0.6669 - recall: 0.5477 - val_auc: 0.6625 - val_binary_accuracy: 0.6294 - val_f1: 0.4543 - val_loss: 0.6648 - val_prc_auc: 0.4690 - val_precision: 0.3750 - val_recall: 0.5762\n","Epoch 7/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7125 - binary_accuracy: 0.6473 - f1: 0.6100 - loss: 0.6209 - prc_auc: 0.7138 - precision: 0.6653 - recall: 0.5652\n","Epoch 7: Validation Metrics:\n","loss: 0.6179285049438477\n","val_binary_accuracy: 0.6152482032775879\n","val_precision: 0.3636363744735718\n","val_recall: 0.5827814340591431\n","val_auc: 0.6666132807731628\n","val_prc_auc: 0.47308194637298584\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7126 - binary_accuracy: 0.6473 - f1: 0.6100 - loss: 0.6208 - prc_auc: 0.7139 - precision: 0.6656 - recall: 0.5650 - val_auc: 0.6666 - val_binary_accuracy: 0.6152 - val_f1: 0.4478 - val_loss: 0.6645 - val_prc_auc: 0.4731 - val_precision: 0.3636 - val_recall: 0.5828\n","Epoch 8/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7196 - binary_accuracy: 0.6537 - f1: 0.6220 - loss: 0.6159 - prc_auc: 0.7196 - precision: 0.6683 - recall: 0.5839\n","Epoch 8: Validation Metrics:\n","loss: 0.6131052374839783\n","val_binary_accuracy: 0.609929084777832\n","val_precision: 0.3625498116016388\n","val_recall: 0.6026490330696106\n","val_auc: 0.6709667444229126\n","val_prc_auc: 0.474782794713974\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7197 - binary_accuracy: 0.6537 - f1: 0.6220 - loss: 0.6159 - prc_auc: 0.7197 - precision: 0.6686 - recall: 0.5837 - val_auc: 0.6710 - val_binary_accuracy: 0.6099 - val_f1: 0.4527 - val_loss: 0.6637 - val_prc_auc: 0.4748 - val_precision: 0.3625 - val_recall: 0.6026\n","Epoch 9/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7265 - binary_accuracy: 0.6579 - f1: 0.6312 - loss: 0.6113 - prc_auc: 0.7251 - precision: 0.6686 - recall: 0.5998\n","Epoch 9: Validation Metrics:\n","loss: 0.608629047870636\n","val_binary_accuracy: 0.6134752035140991\n","val_precision: 0.3696497976779938\n","val_recall: 0.6291390657424927\n","val_auc: 0.672794759273529\n","val_prc_auc: 0.4762505888938904\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7266 - binary_accuracy: 0.6580 - f1: 0.6312 - loss: 0.6113 - prc_auc: 0.7252 - precision: 0.6688 - recall: 0.5997 - val_auc: 0.6728 - val_binary_accuracy: 0.6135 - val_f1: 0.4657 - val_loss: 0.6630 - val_prc_auc: 0.4763 - val_precision: 0.3696 - val_recall: 0.6291\n","Epoch 10/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7321 - binary_accuracy: 0.6662 - f1: 0.6429 - loss: 0.6072 - prc_auc: 0.7292 - precision: 0.6752 - recall: 0.6152\n","Epoch 10: Validation Metrics:\n","loss: 0.6046175360679626\n","val_binary_accuracy: 0.6063829660415649\n","val_precision: 0.3639846742153168\n","val_recall: 0.6291390657424927\n","val_auc: 0.676450788974762\n","val_prc_auc: 0.478616863489151\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7321 - binary_accuracy: 0.6663 - f1: 0.6430 - loss: 0.6071 - prc_auc: 0.7293 - precision: 0.6755 - recall: 0.6152 - val_auc: 0.6765 - val_binary_accuracy: 0.6064 - val_f1: 0.4612 - val_loss: 0.6622 - val_prc_auc: 0.4786 - val_precision: 0.3640 - val_recall: 0.6291\n","Epoch 11/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7370 - binary_accuracy: 0.6693 - f1: 0.6495 - loss: 0.6034 - prc_auc: 0.7331 - precision: 0.6750 - recall: 0.6274\n","Epoch 11: Validation Metrics:\n","loss: 0.6009038090705872\n","val_binary_accuracy: 0.609929084777832\n","val_precision: 0.3698113262653351\n","val_recall: 0.6490066051483154\n","val_auc: 0.678030252456665\n","val_prc_auc: 0.48002275824546814\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7370 - binary_accuracy: 0.6694 - f1: 0.6496 - loss: 0.6033 - prc_auc: 0.7332 - precision: 0.6753 - recall: 0.6274 - val_auc: 0.6780 - val_binary_accuracy: 0.6099 - val_f1: 0.4712 - val_loss: 0.6613 - val_prc_auc: 0.4800 - val_precision: 0.3698 - val_recall: 0.6490\n","Epoch 12/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7413 - binary_accuracy: 0.6744 - f1: 0.6567 - loss: 0.5998 - prc_auc: 0.7368 - precision: 0.6789 - recall: 0.6373\n","Epoch 12: Validation Metrics:\n","loss: 0.5974725484848022\n","val_binary_accuracy: 0.6152482032775879\n","val_precision: 0.375\n","val_recall: 0.6556291580200195\n","val_auc: 0.6804515719413757\n","val_prc_auc: 0.4812238812446594\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7413 - binary_accuracy: 0.6745 - f1: 0.6568 - loss: 0.5998 - prc_auc: 0.7369 - precision: 0.6791 - recall: 0.6373 - val_auc: 0.6805 - val_binary_accuracy: 0.6152 - val_f1: 0.4771 - val_loss: 0.6606 - val_prc_auc: 0.4812 - val_precision: 0.3750 - val_recall: 0.6556\n","Epoch 13/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7454 - binary_accuracy: 0.6777 - f1: 0.6608 - loss: 0.5966 - prc_auc: 0.7400 - precision: 0.6816 - recall: 0.6426\n","Epoch 13: Validation Metrics:\n","loss: 0.5942538976669312\n","val_binary_accuracy: 0.618794322013855\n","val_precision: 0.3787878751754761\n","val_recall: 0.6622516512870789\n","val_auc: 0.6827365159988403\n","val_prc_auc: 0.4830065965652466\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7454 - binary_accuracy: 0.6778 - f1: 0.6609 - loss: 0.5965 - prc_auc: 0.7401 - precision: 0.6819 - recall: 0.6427 - val_auc: 0.6827 - val_binary_accuracy: 0.6188 - val_f1: 0.4819 - val_loss: 0.6596 - val_prc_auc: 0.4830 - val_precision: 0.3788 - val_recall: 0.6623\n","Epoch 14/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7486 - binary_accuracy: 0.6822 - f1: 0.6654 - loss: 0.5935 - prc_auc: 0.7425 - precision: 0.6862 - recall: 0.6472\n","Epoch 14: Validation Metrics:\n","loss: 0.5912145972251892\n","val_binary_accuracy: 0.6134752035140991\n","val_precision: 0.37358489632606506\n","val_recall: 0.6556291580200195\n","val_auc: 0.6844042539596558\n","val_prc_auc: 0.48334866762161255\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7487 - binary_accuracy: 0.6822 - f1: 0.6655 - loss: 0.5934 - prc_auc: 0.7426 - precision: 0.6863 - recall: 0.6471 - val_auc: 0.6844 - val_binary_accuracy: 0.6135 - val_f1: 0.4760 - val_loss: 0.6586 - val_prc_auc: 0.4833 - val_precision: 0.3736 - val_recall: 0.6556\n","Epoch 15/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7520 - binary_accuracy: 0.6822 - f1: 0.6683 - loss: 0.5905 - prc_auc: 0.7453 - precision: 0.6828 - recall: 0.6557\n","Epoch 15: Validation Metrics:\n","loss: 0.5883355736732483\n","val_binary_accuracy: 0.6170212626457214\n","val_precision: 0.37735849618911743\n","val_recall: 0.6622516512870789\n","val_auc: 0.6862162351608276\n","val_prc_auc: 0.4845759868621826\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - auc: 0.7520 - binary_accuracy: 0.6822 - f1: 0.6684 - loss: 0.5905 - prc_auc: 0.7454 - precision: 0.6830 - recall: 0.6557 - val_auc: 0.6862 - val_binary_accuracy: 0.6170 - val_f1: 0.4808 - val_loss: 0.6579 - val_prc_auc: 0.4846 - val_precision: 0.3774 - val_recall: 0.6623\n","Epoch 16/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7551 - binary_accuracy: 0.6817 - f1: 0.6685 - loss: 0.5877 - prc_auc: 0.7477 - precision: 0.6814 - recall: 0.6571\n","Epoch 16: Validation Metrics:\n","loss: 0.5855973362922668\n","val_binary_accuracy: 0.6170212626457214\n","val_precision: 0.37735849618911743\n","val_recall: 0.6622516512870789\n","val_auc: 0.6881965398788452\n","val_prc_auc: 0.4857591986656189\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7551 - binary_accuracy: 0.6817 - f1: 0.6686 - loss: 0.5876 - prc_auc: 0.7478 - precision: 0.6816 - recall: 0.6571 - val_auc: 0.6882 - val_binary_accuracy: 0.6170 - val_f1: 0.4808 - val_loss: 0.6571 - val_prc_auc: 0.4858 - val_precision: 0.3774 - val_recall: 0.6623\n","Epoch 17/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7581 - binary_accuracy: 0.6832 - f1: 0.6705 - loss: 0.5850 - prc_auc: 0.7502 - precision: 0.6826 - recall: 0.6599\n","Epoch 17: Validation Metrics:\n","loss: 0.5830176472663879\n","val_binary_accuracy: 0.6223404407501221\n","val_precision: 0.38432836532592773\n","val_recall: 0.6821191906929016\n","val_auc: 0.6893991231918335\n","val_prc_auc: 0.48693692684173584\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.7582 - binary_accuracy: 0.6832 - f1: 0.6706 - loss: 0.5850 - prc_auc: 0.7502 - precision: 0.6827 - recall: 0.6599 - val_auc: 0.6894 - val_binary_accuracy: 0.6223 - val_f1: 0.4916 - val_loss: 0.6564 - val_prc_auc: 0.4869 - val_precision: 0.3843 - val_recall: 0.6821\n","Epoch 18/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7607 - binary_accuracy: 0.6834 - f1: 0.6711 - loss: 0.5825 - prc_auc: 0.7524 - precision: 0.6824 - recall: 0.6611\n","Epoch 18: Validation Metrics:\n","loss: 0.5805544257164001\n","val_binary_accuracy: 0.6276595592498779\n","val_precision: 0.38867923617362976\n","val_recall: 0.6821191906929016\n","val_auc: 0.6912190914154053\n","val_prc_auc: 0.4877535104751587\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7608 - binary_accuracy: 0.6834 - f1: 0.6711 - loss: 0.5825 - prc_auc: 0.7525 - precision: 0.6826 - recall: 0.6611 - val_auc: 0.6912 - val_binary_accuracy: 0.6277 - val_f1: 0.4952 - val_loss: 0.6558 - val_prc_auc: 0.4878 - val_precision: 0.3887 - val_recall: 0.6821\n","Epoch 19/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7629 - binary_accuracy: 0.6831 - f1: 0.6705 - loss: 0.5801 - prc_auc: 0.7541 - precision: 0.6823 - recall: 0.6602\n","Epoch 19: Validation Metrics:\n","loss: 0.5782067179679871\n","val_binary_accuracy: 0.6276595592498779\n","val_precision: 0.38867923617362976\n","val_recall: 0.6821191906929016\n","val_auc: 0.6928146481513977\n","val_prc_auc: 0.48957788944244385\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.7629 - binary_accuracy: 0.6831 - f1: 0.6706 - loss: 0.5801 - prc_auc: 0.7542 - precision: 0.6824 - recall: 0.6602 - val_auc: 0.6928 - val_binary_accuracy: 0.6277 - val_f1: 0.4952 - val_loss: 0.6553 - val_prc_auc: 0.4896 - val_precision: 0.3887 - val_recall: 0.6821\n","Epoch 20/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7653 - binary_accuracy: 0.6847 - f1: 0.6729 - loss: 0.5777 - prc_auc: 0.7562 - precision: 0.6832 - recall: 0.6637\n","Epoch 20: Validation Metrics:\n","loss: 0.5759158730506897\n","val_binary_accuracy: 0.6258864998817444\n","val_precision: 0.38721805810928345\n","val_recall: 0.6821191906929016\n","val_auc: 0.6941376328468323\n","val_prc_auc: 0.4904720187187195\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - auc: 0.7653 - binary_accuracy: 0.6847 - f1: 0.6729 - loss: 0.5777 - prc_auc: 0.7562 - precision: 0.6833 - recall: 0.6637 - val_auc: 0.6941 - val_binary_accuracy: 0.6259 - val_f1: 0.4940 - val_loss: 0.6547 - val_prc_auc: 0.4905 - val_precision: 0.3872 - val_recall: 0.6821\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.5698 - binary_accuracy: 0.5316 - f1: 0.5124 - loss: 0.6879 - prc_auc: 0.5675 - precision: 0.5229 - recall: 0.5109\n","Epoch 1: Validation Metrics:\n","loss: 0.6806398630142212\n","val_binary_accuracy: 0.5070921778678894\n","val_precision: 0.23853211104869843\n","val_recall: 0.7289719581604004\n","val_auc: 0.6548293828964233\n","val_prc_auc: 0.37013480067253113\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 259ms/step - auc: 0.5706 - binary_accuracy: 0.5321 - f1: 0.5135 - loss: 0.6878 - prc_auc: 0.5684 - precision: 0.5235 - recall: 0.5124 - val_auc: 0.6548 - val_binary_accuracy: 0.5071 - val_f1: 0.3594 - val_loss: 0.6770 - val_prc_auc: 0.3701 - val_precision: 0.2385 - val_recall: 0.7290\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6655 - binary_accuracy: 0.6059 - f1: 0.6357 - loss: 0.6656 - prc_auc: 0.6673 - precision: 0.5809 - recall: 0.7044\n","Epoch 2: Validation Metrics:\n","loss: 0.6612799167633057\n","val_binary_accuracy: 0.5939716100692749\n","val_precision: 0.27067670226097107\n","val_recall: 0.672897219657898\n","val_auc: 0.6580809354782104\n","val_prc_auc: 0.3694007396697998\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6656 - binary_accuracy: 0.6060 - f1: 0.6356 - loss: 0.6656 - prc_auc: 0.6674 - precision: 0.5811 - recall: 0.7040 - val_auc: 0.6581 - val_binary_accuracy: 0.5940 - val_f1: 0.3861 - val_loss: 0.6612 - val_prc_auc: 0.3694 - val_precision: 0.2707 - val_recall: 0.6729\n","Epoch 3/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6762 - binary_accuracy: 0.6231 - f1: 0.6223 - loss: 0.6539 - prc_auc: 0.6759 - precision: 0.6110 - recall: 0.6358\n","Epoch 3: Validation Metrics:\n","loss: 0.6495369076728821\n","val_binary_accuracy: 0.6258864998817444\n","val_precision: 0.2777777910232544\n","val_recall: 0.6074766516685486\n","val_auc: 0.6675699353218079\n","val_prc_auc: 0.37381237745285034\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6763 - binary_accuracy: 0.6232 - f1: 0.6225 - loss: 0.6538 - prc_auc: 0.6761 - precision: 0.6113 - recall: 0.6357 - val_auc: 0.6676 - val_binary_accuracy: 0.6259 - val_f1: 0.3812 - val_loss: 0.6495 - val_prc_auc: 0.3738 - val_precision: 0.2778 - val_recall: 0.6075\n","Epoch 4/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6901 - binary_accuracy: 0.6356 - f1: 0.6228 - loss: 0.6443 - prc_auc: 0.6880 - precision: 0.6309 - recall: 0.6158\n","Epoch 4: Validation Metrics:\n","loss: 0.639516294002533\n","val_binary_accuracy: 0.6418439745903015\n","val_precision: 0.2850678861141205\n","val_recall: 0.5887850522994995\n","val_auc: 0.6759340763092041\n","val_prc_auc: 0.375238299369812\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6903 - binary_accuracy: 0.6357 - f1: 0.6231 - loss: 0.6442 - prc_auc: 0.6883 - precision: 0.6312 - recall: 0.6160 - val_auc: 0.6759 - val_binary_accuracy: 0.6418 - val_f1: 0.3841 - val_loss: 0.6395 - val_prc_auc: 0.3752 - val_precision: 0.2851 - val_recall: 0.5888\n","Epoch 5/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7029 - binary_accuracy: 0.6478 - f1: 0.6317 - loss: 0.6358 - prc_auc: 0.6995 - precision: 0.6465 - recall: 0.6180\n","Epoch 5: Validation Metrics:\n","loss: 0.6306927800178528\n","val_binary_accuracy: 0.6471630930900574\n","val_precision: 0.2788461446762085\n","val_recall: 0.5420560836791992\n","val_auc: 0.6869567036628723\n","val_prc_auc: 0.38215479254722595\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7031 - binary_accuracy: 0.6479 - f1: 0.6319 - loss: 0.6357 - prc_auc: 0.6997 - precision: 0.6467 - recall: 0.6182 - val_auc: 0.6870 - val_binary_accuracy: 0.6472 - val_f1: 0.3683 - val_loss: 0.6320 - val_prc_auc: 0.3822 - val_precision: 0.2788 - val_recall: 0.5421\n","Epoch 6/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7152 - binary_accuracy: 0.6552 - f1: 0.6351 - loss: 0.6283 - prc_auc: 0.7090 - precision: 0.6579 - recall: 0.6141\n","Epoch 6: Validation Metrics:\n","loss: 0.6232122182846069\n","val_binary_accuracy: 0.673758864402771\n","val_precision: 0.3025641143321991\n","val_recall: 0.5514018535614014\n","val_auc: 0.6946051716804504\n","val_prc_auc: 0.387545108795166\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7153 - binary_accuracy: 0.6554 - f1: 0.6354 - loss: 0.6282 - prc_auc: 0.7092 - precision: 0.6582 - recall: 0.6144 - val_auc: 0.6946 - val_binary_accuracy: 0.6738 - val_f1: 0.3907 - val_loss: 0.6258 - val_prc_auc: 0.3875 - val_precision: 0.3026 - val_recall: 0.5514\n","Epoch 7/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7244 - binary_accuracy: 0.6670 - f1: 0.6454 - loss: 0.6220 - prc_auc: 0.7170 - precision: 0.6727 - recall: 0.6203\n","Epoch 7: Validation Metrics:\n","loss: 0.6170140504837036\n","val_binary_accuracy: 0.6808510422706604\n","val_precision: 0.30481284856796265\n","val_recall: 0.5327102541923523\n","val_auc: 0.7002290487289429\n","val_prc_auc: 0.3888785243034363\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7245 - binary_accuracy: 0.6671 - f1: 0.6457 - loss: 0.6219 - prc_auc: 0.7172 - precision: 0.6730 - recall: 0.6206 - val_auc: 0.7002 - val_binary_accuracy: 0.6809 - val_f1: 0.3878 - val_loss: 0.6208 - val_prc_auc: 0.3889 - val_precision: 0.3048 - val_recall: 0.5327\n","Epoch 8/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7319 - binary_accuracy: 0.6759 - f1: 0.6525 - loss: 0.6165 - prc_auc: 0.7228 - precision: 0.6853 - recall: 0.6230\n","Epoch 8: Validation Metrics:\n","loss: 0.6117356419563293\n","val_binary_accuracy: 0.6879432797431946\n","val_precision: 0.31351351737976074\n","val_recall: 0.5420560836791992\n","val_auc: 0.704666793346405\n","val_prc_auc: 0.3915649950504303\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7320 - binary_accuracy: 0.6759 - f1: 0.6528 - loss: 0.6165 - prc_auc: 0.7230 - precision: 0.6855 - recall: 0.6233 - val_auc: 0.7047 - val_binary_accuracy: 0.6879 - val_f1: 0.3973 - val_loss: 0.6171 - val_prc_auc: 0.3916 - val_precision: 0.3135 - val_recall: 0.5421\n","Epoch 9/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7374 - binary_accuracy: 0.6879 - f1: 0.6642 - loss: 0.6118 - prc_auc: 0.7274 - precision: 0.7007 - recall: 0.6315\n","Epoch 9: Validation Metrics:\n","loss: 0.6072500944137573\n","val_binary_accuracy: 0.6968085169792175\n","val_precision: 0.3241758346557617\n","val_recall: 0.5514018535614014\n","val_auc: 0.7075809240341187\n","val_prc_auc: 0.39274314045906067\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7375 - binary_accuracy: 0.6879 - f1: 0.6643 - loss: 0.6117 - prc_auc: 0.7276 - precision: 0.7007 - recall: 0.6317 - val_auc: 0.7076 - val_binary_accuracy: 0.6968 - val_f1: 0.4083 - val_loss: 0.6142 - val_prc_auc: 0.3927 - val_precision: 0.3242 - val_recall: 0.5514\n","Epoch 10/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7415 - binary_accuracy: 0.6906 - f1: 0.6683 - loss: 0.6077 - prc_auc: 0.7298 - precision: 0.7019 - recall: 0.6380\n","Epoch 10: Validation Metrics:\n","loss: 0.6033076047897339\n","val_binary_accuracy: 0.6968085169792175\n","val_precision: 0.3241758346557617\n","val_recall: 0.5514018535614014\n","val_auc: 0.7103826999664307\n","val_prc_auc: 0.3955456018447876\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7416 - binary_accuracy: 0.6906 - f1: 0.6685 - loss: 0.6076 - prc_auc: 0.7300 - precision: 0.7020 - recall: 0.6382 - val_auc: 0.7104 - val_binary_accuracy: 0.6968 - val_f1: 0.4083 - val_loss: 0.6122 - val_prc_auc: 0.3955 - val_precision: 0.3242 - val_recall: 0.5514\n","Epoch 11/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7456 - binary_accuracy: 0.6929 - f1: 0.6705 - loss: 0.6039 - prc_auc: 0.7334 - precision: 0.7047 - recall: 0.6396\n","Epoch 11: Validation Metrics:\n","loss: 0.599762499332428\n","val_binary_accuracy: 0.7056737542152405\n","val_precision: 0.3333333432674408\n","val_recall: 0.5514018535614014\n","val_auc: 0.7107711434364319\n","val_prc_auc: 0.39549413323402405\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7457 - binary_accuracy: 0.6929 - f1: 0.6706 - loss: 0.6038 - prc_auc: 0.7336 - precision: 0.7048 - recall: 0.6398 - val_auc: 0.7108 - val_binary_accuracy: 0.7057 - val_f1: 0.4155 - val_loss: 0.6107 - val_prc_auc: 0.3955 - val_precision: 0.3333 - val_recall: 0.5514\n","Epoch 12/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7497 - binary_accuracy: 0.6910 - f1: 0.6684 - loss: 0.6004 - prc_auc: 0.7359 - precision: 0.7026 - recall: 0.6376\n","Epoch 12: Validation Metrics:\n","loss: 0.5965206623077393\n","val_binary_accuracy: 0.7056737542152405\n","val_precision: 0.33142855763435364\n","val_recall: 0.5420560836791992\n","val_auc: 0.7122333645820618\n","val_prc_auc: 0.3960384130477905\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7497 - binary_accuracy: 0.6911 - f1: 0.6686 - loss: 0.6003 - prc_auc: 0.7361 - precision: 0.7027 - recall: 0.6378 - val_auc: 0.7122 - val_binary_accuracy: 0.7057 - val_f1: 0.4113 - val_loss: 0.6096 - val_prc_auc: 0.3960 - val_precision: 0.3314 - val_recall: 0.5421\n","Epoch 13/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7530 - binary_accuracy: 0.6925 - f1: 0.6697 - loss: 0.5972 - prc_auc: 0.7383 - precision: 0.7045 - recall: 0.6383\n","Epoch 13: Validation Metrics:\n","loss: 0.5935053825378418\n","val_binary_accuracy: 0.707446813583374\n","val_precision: 0.33522728085517883\n","val_recall: 0.5514018535614014\n","val_auc: 0.7136138081550598\n","val_prc_auc: 0.39506369829177856\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7530 - binary_accuracy: 0.6925 - f1: 0.6698 - loss: 0.5971 - prc_auc: 0.7385 - precision: 0.7046 - recall: 0.6385 - val_auc: 0.7136 - val_binary_accuracy: 0.7074 - val_f1: 0.4170 - val_loss: 0.6087 - val_prc_auc: 0.3951 - val_precision: 0.3352 - val_recall: 0.5514\n","Epoch 14/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7563 - binary_accuracy: 0.6941 - f1: 0.6728 - loss: 0.5942 - prc_auc: 0.7415 - precision: 0.7043 - recall: 0.6442\n","Epoch 14: Validation Metrics:\n","loss: 0.5906984210014343\n","val_binary_accuracy: 0.7092198729515076\n","val_precision: 0.33714285492897034\n","val_recall: 0.5514018535614014\n","val_auc: 0.7140023112297058\n","val_prc_auc: 0.3964320123195648\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7564 - binary_accuracy: 0.6941 - f1: 0.6730 - loss: 0.5941 - prc_auc: 0.7417 - precision: 0.7044 - recall: 0.6444 - val_auc: 0.7140 - val_binary_accuracy: 0.7092 - val_f1: 0.4184 - val_loss: 0.6078 - val_prc_auc: 0.3964 - val_precision: 0.3371 - val_recall: 0.5514\n","Epoch 15/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7588 - binary_accuracy: 0.6968 - f1: 0.6757 - loss: 0.5914 - prc_auc: 0.7433 - precision: 0.7076 - recall: 0.6468\n","Epoch 15: Validation Metrics:\n","loss: 0.5880670547485352\n","val_binary_accuracy: 0.707446813583374\n","val_precision: 0.33707866072654724\n","val_recall: 0.5607476830482483\n","val_auc: 0.7159963250160217\n","val_prc_auc: 0.397104948759079\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7589 - binary_accuracy: 0.6968 - f1: 0.6758 - loss: 0.5913 - prc_auc: 0.7435 - precision: 0.7077 - recall: 0.6469 - val_auc: 0.7160 - val_binary_accuracy: 0.7074 - val_f1: 0.4211 - val_loss: 0.6073 - val_prc_auc: 0.3971 - val_precision: 0.3371 - val_recall: 0.5607\n","Epoch 16/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7615 - binary_accuracy: 0.6952 - f1: 0.6743 - loss: 0.5888 - prc_auc: 0.7456 - precision: 0.7054 - recall: 0.6461\n","Epoch 16: Validation Metrics:\n","loss: 0.5855913758277893\n","val_binary_accuracy: 0.7056737542152405\n","val_precision: 0.33701658248901367\n","val_recall: 0.5700934529304504\n","val_auc: 0.7172130346298218\n","val_prc_auc: 0.39888083934783936\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7616 - binary_accuracy: 0.6952 - f1: 0.6745 - loss: 0.5887 - prc_auc: 0.7458 - precision: 0.7055 - recall: 0.6463 - val_auc: 0.7172 - val_binary_accuracy: 0.7057 - val_f1: 0.4236 - val_loss: 0.6067 - val_prc_auc: 0.3989 - val_precision: 0.3370 - val_recall: 0.5701\n","Epoch 17/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7641 - binary_accuracy: 0.6983 - f1: 0.6795 - loss: 0.5863 - prc_auc: 0.7473 - precision: 0.7063 - recall: 0.6549\n","Epoch 17: Validation Metrics:\n","loss: 0.5832416415214539\n","val_binary_accuracy: 0.7056737542152405\n","val_precision: 0.33879780769348145\n","val_recall: 0.5794392228126526\n","val_auc: 0.7177959084510803\n","val_prc_auc: 0.4004519581794739\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7642 - binary_accuracy: 0.6983 - f1: 0.6796 - loss: 0.5863 - prc_auc: 0.7475 - precision: 0.7063 - recall: 0.6550 - val_auc: 0.7178 - val_binary_accuracy: 0.7057 - val_f1: 0.4276 - val_loss: 0.6061 - val_prc_auc: 0.4005 - val_precision: 0.3388 - val_recall: 0.5794\n","Epoch 18/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7662 - binary_accuracy: 0.7006 - f1: 0.6826 - loss: 0.5840 - prc_auc: 0.7491 - precision: 0.7077 - recall: 0.6594\n","Epoch 18: Validation Metrics:\n","loss: 0.5809910893440247\n","val_binary_accuracy: 0.7056737542152405\n","val_precision: 0.33879780769348145\n","val_recall: 0.5794392228126526\n","val_auc: 0.7180310487747192\n","val_prc_auc: 0.39919939637184143\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7663 - binary_accuracy: 0.7005 - f1: 0.6827 - loss: 0.5839 - prc_auc: 0.7493 - precision: 0.7078 - recall: 0.6595 - val_auc: 0.7180 - val_binary_accuracy: 0.7057 - val_f1: 0.4276 - val_loss: 0.6058 - val_prc_auc: 0.3992 - val_precision: 0.3388 - val_recall: 0.5794\n","Epoch 19/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7684 - binary_accuracy: 0.7031 - f1: 0.6854 - loss: 0.5817 - prc_auc: 0.7511 - precision: 0.7103 - recall: 0.6623\n","Epoch 19: Validation Metrics:\n","loss: 0.5788265466690063\n","val_binary_accuracy: 0.7021276354789734\n","val_precision: 0.3351351320743561\n","val_recall: 0.5794392228126526\n","val_auc: 0.7182559967041016\n","val_prc_auc: 0.39924895763397217\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7685 - binary_accuracy: 0.7031 - f1: 0.6854 - loss: 0.5817 - prc_auc: 0.7513 - precision: 0.7103 - recall: 0.6624 - val_auc: 0.7183 - val_binary_accuracy: 0.7021 - val_f1: 0.4247 - val_loss: 0.6054 - val_prc_auc: 0.3992 - val_precision: 0.3351 - val_recall: 0.5794\n","Epoch 20/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7703 - binary_accuracy: 0.6995 - f1: 0.6819 - loss: 0.5796 - prc_auc: 0.7526 - precision: 0.7060 - recall: 0.6595\n","Epoch 20: Validation Metrics:\n","loss: 0.5767237544059753\n","val_binary_accuracy: 0.7021276354789734\n","val_precision: 0.3351351320743561\n","val_recall: 0.5794392228126526\n","val_auc: 0.7186956405639648\n","val_prc_auc: 0.39874619245529175\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.7704 - binary_accuracy: 0.6995 - f1: 0.6820 - loss: 0.5795 - prc_auc: 0.7527 - precision: 0.7061 - recall: 0.6596 - val_auc: 0.7187 - val_binary_accuracy: 0.7021 - val_f1: 0.4247 - val_loss: 0.6048 - val_prc_auc: 0.3987 - val_precision: 0.3351 - val_recall: 0.5794\n","Starting training for label: 5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4973 - binary_accuracy: 0.5154 - f1: 0.5829 - loss: 0.6933 - prc_auc: 0.5024 - precision: 0.5131 - recall: 0.6793\n","Epoch 1: Validation Metrics:\n","loss: 0.6918811202049255\n","val_binary_accuracy: 0.48049646615982056\n","val_precision: 0.23548386991024017\n","val_recall: 0.565891444683075\n","val_auc: 0.510353684425354\n","val_prc_auc: 0.22339433431625366\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 257ms/step - auc: 0.4979 - binary_accuracy: 0.5155 - f1: 0.5833 - loss: 0.6933 - prc_auc: 0.5028 - precision: 0.5132 - recall: 0.6801 - val_auc: 0.5104 - val_binary_accuracy: 0.4805 - val_f1: 0.3326 - val_loss: 0.6895 - val_prc_auc: 0.2234 - val_precision: 0.2355 - val_recall: 0.5659\n","Epoch 2/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5957 - binary_accuracy: 0.5786 - f1: 0.6146 - loss: 0.6869 - prc_auc: 0.5762 - precision: 0.5691 - recall: 0.6715\n","Epoch 2: Validation Metrics:\n","loss: 0.6873908638954163\n","val_binary_accuracy: 0.49113476276397705\n","val_precision: 0.22945205867290497\n","val_recall: 0.5193798542022705\n","val_auc: 0.5024324655532837\n","val_prc_auc: 0.21973556280136108\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.5954 - binary_accuracy: 0.5783 - f1: 0.6146 - loss: 0.6870 - prc_auc: 0.5760 - precision: 0.5688 - recall: 0.6718 - val_auc: 0.5024 - val_binary_accuracy: 0.4911 - val_f1: 0.3183 - val_loss: 0.6877 - val_prc_auc: 0.2197 - val_precision: 0.2295 - val_recall: 0.5194\n","Epoch 3/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6051 - binary_accuracy: 0.5927 - f1: 0.6190 - loss: 0.6838 - prc_auc: 0.5885 - precision: 0.5852 - recall: 0.6598\n","Epoch 3: Validation Metrics:\n","loss: 0.6848047375679016\n","val_binary_accuracy: 0.5\n","val_precision: 0.22968198359012604\n","val_recall: 0.5038759708404541\n","val_auc: 0.5033146142959595\n","val_prc_auc: 0.22008255124092102\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6049 - binary_accuracy: 0.5923 - f1: 0.6188 - loss: 0.6839 - prc_auc: 0.5884 - precision: 0.5847 - recall: 0.6600 - val_auc: 0.5033 - val_binary_accuracy: 0.5000 - val_f1: 0.3155 - val_loss: 0.6865 - val_prc_auc: 0.2201 - val_precision: 0.2297 - val_recall: 0.5039\n","Epoch 4/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6118 - binary_accuracy: 0.5946 - f1: 0.6175 - loss: 0.6814 - prc_auc: 0.5954 - precision: 0.5880 - recall: 0.6525\n","Epoch 4: Validation Metrics:\n","loss: 0.6827226877212524\n","val_binary_accuracy: 0.5141844153404236\n","val_precision: 0.23826715350151062\n","val_recall: 0.5116279125213623\n","val_auc: 0.5052481293678284\n","val_prc_auc: 0.2216758280992508\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6115 - binary_accuracy: 0.5942 - f1: 0.6174 - loss: 0.6814 - prc_auc: 0.5953 - precision: 0.5876 - recall: 0.6527 - val_auc: 0.5052 - val_binary_accuracy: 0.5142 - val_f1: 0.3251 - val_loss: 0.6857 - val_prc_auc: 0.2217 - val_precision: 0.2383 - val_recall: 0.5116\n","Epoch 5/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6192 - binary_accuracy: 0.6005 - f1: 0.6180 - loss: 0.6791 - prc_auc: 0.6032 - precision: 0.5954 - recall: 0.6444\n","Epoch 5: Validation Metrics:\n","loss: 0.6808436512947083\n","val_binary_accuracy: 0.5177304744720459\n","val_precision: 0.23420074582099915\n","val_recall: 0.4883720874786377\n","val_auc: 0.5046511888504028\n","val_prc_auc: 0.22273141145706177\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6189 - binary_accuracy: 0.6001 - f1: 0.6179 - loss: 0.6792 - prc_auc: 0.6031 - precision: 0.5950 - recall: 0.6445 - val_auc: 0.5047 - val_binary_accuracy: 0.5177 - val_f1: 0.3166 - val_loss: 0.6851 - val_prc_auc: 0.2227 - val_precision: 0.2342 - val_recall: 0.4884\n","Epoch 6/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6228 - binary_accuracy: 0.6073 - f1: 0.6230 - loss: 0.6771 - prc_auc: 0.6088 - precision: 0.6026 - recall: 0.6468\n","Epoch 6: Validation Metrics:\n","loss: 0.6790990233421326\n","val_binary_accuracy: 0.5265957713127136\n","val_precision: 0.23863635957241058\n","val_recall: 0.4883720874786377\n","val_auc: 0.5071905851364136\n","val_prc_auc: 0.22392213344573975\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - auc: 0.6226 - binary_accuracy: 0.6070 - f1: 0.6228 - loss: 0.6771 - prc_auc: 0.6088 - precision: 0.6021 - recall: 0.6469 - val_auc: 0.5072 - val_binary_accuracy: 0.5266 - val_f1: 0.3206 - val_loss: 0.6845 - val_prc_auc: 0.2239 - val_precision: 0.2386 - val_recall: 0.4884\n","Starting training for label: 6\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - auc: 0.5085 - binary_accuracy: 0.5109 - f1: 0.5789 - loss: 0.6936 - prc_auc: 0.4724 - precision: 0.5030 - recall: 0.6984  \n","Epoch 1: Validation Metrics:\n","loss: 0.6893166303634644\n","val_binary_accuracy: 0.4202127754688263\n","val_precision: 0.22365038096904755\n","val_recall: 0.7767857313156128\n","val_auc: 0.5800410509109497\n","val_prc_auc: 0.2440842092037201\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - auc: 0.5092 - binary_accuracy: 0.5114 - f1: 0.5785 - loss: 0.6935 - prc_auc: 0.4731 - precision: 0.5035 - recall: 0.6965 - val_auc: 0.5800 - val_binary_accuracy: 0.4202 - val_f1: 0.3473 - val_loss: 0.6926 - val_prc_auc: 0.2441 - val_precision: 0.2237 - val_recall: 0.7768\n","Epoch 2/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6521 - binary_accuracy: 0.5710 - f1: 0.6451 - loss: 0.6803 - prc_auc: 0.6196 - precision: 0.5420 - recall: 0.8011\n","Epoch 2: Validation Metrics:\n","loss: 0.6763954758644104\n","val_binary_accuracy: 0.47695034742355347\n","val_precision: 0.2332361489534378\n","val_recall: 0.7142857313156128\n","val_auc: 0.6105996966362\n","val_prc_auc: 0.2891138792037964\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6522 - binary_accuracy: 0.5717 - f1: 0.6450 - loss: 0.6802 - prc_auc: 0.6205 - precision: 0.5429 - recall: 0.7988 - val_auc: 0.6106 - val_binary_accuracy: 0.4770 - val_f1: 0.3516 - val_loss: 0.6867 - val_prc_auc: 0.2891 - val_precision: 0.2332 - val_recall: 0.7143\n","Epoch 3/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6838 - binary_accuracy: 0.6047 - f1: 0.6593 - loss: 0.6703 - prc_auc: 0.6735 - precision: 0.5695 - recall: 0.7858\n","Epoch 3: Validation Metrics:\n","loss: 0.6658387184143066\n","val_binary_accuracy: 0.508865237236023\n","val_precision: 0.25075528025627136\n","val_recall: 0.7410714030265808\n","val_auc: 0.6345804929733276\n","val_prc_auc: 0.3120570182800293\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6838 - binary_accuracy: 0.6050 - f1: 0.6590 - loss: 0.6701 - prc_auc: 0.6739 - precision: 0.5702 - recall: 0.7838 - val_auc: 0.6346 - val_binary_accuracy: 0.5089 - val_f1: 0.3747 - val_loss: 0.6804 - val_prc_auc: 0.3121 - val_precision: 0.2508 - val_recall: 0.7411\n","Epoch 4/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6997 - binary_accuracy: 0.6255 - f1: 0.6699 - loss: 0.6606 - prc_auc: 0.6937 - precision: 0.5882 - recall: 0.7802\n","Epoch 4: Validation Metrics:\n","loss: 0.6556273102760315\n","val_binary_accuracy: 0.5159574747085571\n","val_precision: 0.24922119081020355\n","val_recall: 0.7142857313156128\n","val_auc: 0.6518548727035522\n","val_prc_auc: 0.33216696977615356\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.6998 - binary_accuracy: 0.6257 - f1: 0.6697 - loss: 0.6605 - prc_auc: 0.6940 - precision: 0.5890 - recall: 0.7786 - val_auc: 0.6519 - val_binary_accuracy: 0.5160 - val_f1: 0.3695 - val_loss: 0.6759 - val_prc_auc: 0.3322 - val_precision: 0.2492 - val_recall: 0.7143\n","Epoch 5/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7119 - binary_accuracy: 0.6286 - f1: 0.6700 - loss: 0.6515 - prc_auc: 0.7085 - precision: 0.5921 - recall: 0.7734\n","Epoch 5: Validation Metrics:\n","loss: 0.6458889842033386\n","val_binary_accuracy: 0.5230496525764465\n","val_precision: 0.2569659352302551\n","val_recall: 0.7410714030265808\n","val_auc: 0.6639242172241211\n","val_prc_auc: 0.34781911969184875\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7119 - binary_accuracy: 0.6290 - f1: 0.6700 - loss: 0.6513 - prc_auc: 0.7087 - precision: 0.5929 - recall: 0.7721 - val_auc: 0.6639 - val_binary_accuracy: 0.5230 - val_f1: 0.3816 - val_loss: 0.6725 - val_prc_auc: 0.3478 - val_precision: 0.2570 - val_recall: 0.7411\n","Epoch 6/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7184 - binary_accuracy: 0.6429 - f1: 0.6771 - loss: 0.6428 - prc_auc: 0.7149 - precision: 0.6063 - recall: 0.7684\n","Epoch 6: Validation Metrics:\n","loss: 0.6366124153137207\n","val_binary_accuracy: 0.521276593208313\n","val_precision: 0.2561728358268738\n","val_recall: 0.7410714030265808\n","val_auc: 0.6727935075759888\n","val_prc_auc: 0.36011195182800293\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7184 - binary_accuracy: 0.6431 - f1: 0.6771 - loss: 0.6426 - prc_auc: 0.7151 - precision: 0.6070 - recall: 0.7672 - val_auc: 0.6728 - val_binary_accuracy: 0.5213 - val_f1: 0.3807 - val_loss: 0.6705 - val_prc_auc: 0.3601 - val_precision: 0.2562 - val_recall: 0.7411\n","Epoch 7/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7238 - binary_accuracy: 0.6502 - f1: 0.6820 - loss: 0.6349 - prc_auc: 0.7207 - precision: 0.6134 - recall: 0.7698\n","Epoch 7: Validation Metrics:\n","loss: 0.6281688809394836\n","val_binary_accuracy: 0.5283687710762024\n","val_precision: 0.260869562625885\n","val_recall: 0.75\n","val_auc: 0.6823641061782837\n","val_prc_auc: 0.37314286828041077\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7239 - binary_accuracy: 0.6505 - f1: 0.6820 - loss: 0.6346 - prc_auc: 0.7209 - precision: 0.6142 - recall: 0.7687 - val_auc: 0.6824 - val_binary_accuracy: 0.5284 - val_f1: 0.3871 - val_loss: 0.6690 - val_prc_auc: 0.3731 - val_precision: 0.2609 - val_recall: 0.7500\n","Epoch 8/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7295 - binary_accuracy: 0.6574 - f1: 0.6866 - loss: 0.6276 - prc_auc: 0.7255 - precision: 0.6206 - recall: 0.7702\n","Epoch 8: Validation Metrics:\n","loss: 0.6207047700881958\n","val_binary_accuracy: 0.5443262457847595\n","val_precision: 0.2698412835597992\n","val_recall: 0.7589285969734192\n","val_auc: 0.6868383288383484\n","val_prc_auc: 0.38204413652420044\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7296 - binary_accuracy: 0.6576 - f1: 0.6867 - loss: 0.6274 - prc_auc: 0.7258 - precision: 0.6213 - recall: 0.7692 - val_auc: 0.6868 - val_binary_accuracy: 0.5443 - val_f1: 0.3981 - val_loss: 0.6676 - val_prc_auc: 0.3820 - val_precision: 0.2698 - val_recall: 0.7589\n","Epoch 9/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7347 - binary_accuracy: 0.6630 - f1: 0.6900 - loss: 0.6212 - prc_auc: 0.7318 - precision: 0.6266 - recall: 0.7695\n","Epoch 9: Validation Metrics:\n","loss: 0.61412513256073\n","val_binary_accuracy: 0.5460993051528931\n","val_precision: 0.2707006335258484\n","val_recall: 0.7589285969734192\n","val_auc: 0.6922013163566589\n","val_prc_auc: 0.3896094262599945\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7347 - binary_accuracy: 0.6633 - f1: 0.6901 - loss: 0.6210 - prc_auc: 0.7320 - precision: 0.6272 - recall: 0.7687 - val_auc: 0.6922 - val_binary_accuracy: 0.5461 - val_f1: 0.3991 - val_loss: 0.6669 - val_prc_auc: 0.3896 - val_precision: 0.2707 - val_recall: 0.7589\n","Epoch 10/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7386 - binary_accuracy: 0.6653 - f1: 0.6905 - loss: 0.6156 - prc_auc: 0.7357 - precision: 0.6292 - recall: 0.7667\n","Epoch 10: Validation Metrics:\n","loss: 0.6083819270133972\n","val_binary_accuracy: 0.5496453642845154\n","val_precision: 0.27243590354919434\n","val_recall: 0.7589285969734192\n","val_auc: 0.697347104549408\n","val_prc_auc: 0.3987407088279724\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7387 - binary_accuracy: 0.6655 - f1: 0.6906 - loss: 0.6154 - prc_auc: 0.7359 - precision: 0.6299 - recall: 0.7659 - val_auc: 0.6973 - val_binary_accuracy: 0.5496 - val_f1: 0.4009 - val_loss: 0.6660 - val_prc_auc: 0.3987 - val_precision: 0.2724 - val_recall: 0.7589\n","Epoch 11/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7420 - binary_accuracy: 0.6739 - f1: 0.6971 - loss: 0.6107 - prc_auc: 0.7390 - precision: 0.6377 - recall: 0.7705\n","Epoch 11: Validation Metrics:\n","loss: 0.6033332943916321\n","val_binary_accuracy: 0.5602836608886719\n","val_precision: 0.2792207896709442\n","val_recall: 0.7678571343421936\n","val_auc: 0.7007248997688293\n","val_prc_auc: 0.40649062395095825\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7421 - binary_accuracy: 0.6741 - f1: 0.6972 - loss: 0.6105 - prc_auc: 0.7393 - precision: 0.6384 - recall: 0.7696 - val_auc: 0.7007 - val_binary_accuracy: 0.5603 - val_f1: 0.4095 - val_loss: 0.6646 - val_prc_auc: 0.4065 - val_precision: 0.2792 - val_recall: 0.7679\n","Epoch 12/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7456 - binary_accuracy: 0.6844 - f1: 0.7045 - loss: 0.6064 - prc_auc: 0.7427 - precision: 0.6484 - recall: 0.7727\n","Epoch 12: Validation Metrics:\n","loss: 0.5988064408302307\n","val_binary_accuracy: 0.567375898361206\n","val_precision: 0.28431373834609985\n","val_recall: 0.7767857313156128\n","val_auc: 0.7058312296867371\n","val_prc_auc: 0.4120017886161804\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7457 - binary_accuracy: 0.6844 - f1: 0.7045 - loss: 0.6061 - prc_auc: 0.7430 - precision: 0.6490 - recall: 0.7719 - val_auc: 0.7058 - val_binary_accuracy: 0.5674 - val_f1: 0.4163 - val_loss: 0.6632 - val_prc_auc: 0.4120 - val_precision: 0.2843 - val_recall: 0.7768\n","Epoch 13/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7484 - binary_accuracy: 0.6872 - f1: 0.7043 - loss: 0.6024 - prc_auc: 0.7457 - precision: 0.6537 - recall: 0.7647\n","Epoch 13: Validation Metrics:\n","loss: 0.5947278141975403\n","val_binary_accuracy: 0.5726950168609619\n","val_precision: 0.2857142984867096\n","val_recall: 0.7678571343421936\n","val_auc: 0.7079645991325378\n","val_prc_auc: 0.417294442653656\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7486 - binary_accuracy: 0.6874 - f1: 0.7045 - loss: 0.6022 - prc_auc: 0.7460 - precision: 0.6543 - recall: 0.7641 - val_auc: 0.7080 - val_binary_accuracy: 0.5727 - val_f1: 0.4165 - val_loss: 0.6619 - val_prc_auc: 0.4173 - val_precision: 0.2857 - val_recall: 0.7679\n","Epoch 14/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7512 - binary_accuracy: 0.6927 - f1: 0.7080 - loss: 0.5989 - prc_auc: 0.7489 - precision: 0.6598 - recall: 0.7648\n","Epoch 14: Validation Metrics:\n","loss: 0.591034471988678\n","val_binary_accuracy: 0.5815602540969849\n","val_precision: 0.29054054617881775\n","val_recall: 0.7678571343421936\n","val_auc: 0.7118658423423767\n","val_prc_auc: 0.4236471652984619\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7514 - binary_accuracy: 0.6929 - f1: 0.7081 - loss: 0.5987 - prc_auc: 0.7492 - precision: 0.6604 - recall: 0.7642 - val_auc: 0.7119 - val_binary_accuracy: 0.5816 - val_f1: 0.4216 - val_loss: 0.6606 - val_prc_auc: 0.4236 - val_precision: 0.2905 - val_recall: 0.7679\n","Epoch 15/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7539 - binary_accuracy: 0.6966 - f1: 0.7094 - loss: 0.5957 - prc_auc: 0.7518 - precision: 0.6656 - recall: 0.7604\n","Epoch 15: Validation Metrics:\n","loss: 0.5876489877700806\n","val_binary_accuracy: 0.5833333134651184\n","val_precision: 0.2915254235267639\n","val_recall: 0.7678571343421936\n","val_auc: 0.7148091793060303\n","val_prc_auc: 0.4292107820510864\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7540 - binary_accuracy: 0.6967 - f1: 0.7095 - loss: 0.5955 - prc_auc: 0.7521 - precision: 0.6662 - recall: 0.7598 - val_auc: 0.7148 - val_binary_accuracy: 0.5833 - val_f1: 0.4226 - val_loss: 0.6592 - val_prc_auc: 0.4292 - val_precision: 0.2915 - val_recall: 0.7679\n","Epoch 16/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7563 - binary_accuracy: 0.6989 - f1: 0.7112 - loss: 0.5928 - prc_auc: 0.7541 - precision: 0.6681 - recall: 0.7612\n","Epoch 16: Validation Metrics:\n","loss: 0.5845078825950623\n","val_binary_accuracy: 0.585106372833252\n","val_precision: 0.2925170063972473\n","val_recall: 0.7678571343421936\n","val_auc: 0.7177524566650391\n","val_prc_auc: 0.43580546975135803\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7565 - binary_accuracy: 0.6990 - f1: 0.7113 - loss: 0.5925 - prc_auc: 0.7544 - precision: 0.6687 - recall: 0.7606 - val_auc: 0.7178 - val_binary_accuracy: 0.5851 - val_f1: 0.4236 - val_loss: 0.6577 - val_prc_auc: 0.4358 - val_precision: 0.2925 - val_recall: 0.7679\n","Epoch 17/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7592 - binary_accuracy: 0.6986 - f1: 0.7102 - loss: 0.5900 - prc_auc: 0.7567 - precision: 0.6686 - recall: 0.7583\n","Epoch 17: Validation Metrics:\n","loss: 0.5815630555152893\n","val_binary_accuracy: 0.588652491569519\n","val_precision: 0.2945205569267273\n","val_recall: 0.7678571343421936\n","val_auc: 0.7207944989204407\n","val_prc_auc: 0.43970102071762085\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7594 - binary_accuracy: 0.6987 - f1: 0.7104 - loss: 0.5897 - prc_auc: 0.7570 - precision: 0.6693 - recall: 0.7578 - val_auc: 0.7208 - val_binary_accuracy: 0.5887 - val_f1: 0.4257 - val_loss: 0.6563 - val_prc_auc: 0.4397 - val_precision: 0.2945 - val_recall: 0.7679\n","Epoch 18/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7610 - binary_accuracy: 0.6977 - f1: 0.7081 - loss: 0.5874 - prc_auc: 0.7582 - precision: 0.6690 - recall: 0.7529\n","Epoch 18: Validation Metrics:\n","loss: 0.578822672367096\n","val_binary_accuracy: 0.5957446694374084\n","val_precision: 0.30000001192092896\n","val_recall: 0.7767857313156128\n","val_auc: 0.7226611971855164\n","val_prc_auc: 0.44462424516677856\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7612 - binary_accuracy: 0.6979 - f1: 0.7083 - loss: 0.5872 - prc_auc: 0.7585 - precision: 0.6697 - recall: 0.7525 - val_auc: 0.7227 - val_binary_accuracy: 0.5957 - val_f1: 0.4328 - val_loss: 0.6547 - val_prc_auc: 0.4446 - val_precision: 0.3000 - val_recall: 0.7768\n","Epoch 19/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7634 - binary_accuracy: 0.6975 - f1: 0.7068 - loss: 0.5851 - prc_auc: 0.7613 - precision: 0.6701 - recall: 0.7486\n","Epoch 19: Validation Metrics:\n","loss: 0.576259434223175\n","val_binary_accuracy: 0.597517728805542\n","val_precision: 0.30103805661201477\n","val_recall: 0.7767857313156128\n","val_auc: 0.7251007556915283\n","val_prc_auc: 0.4482668340206146\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7636 - binary_accuracy: 0.6977 - f1: 0.7070 - loss: 0.5848 - prc_auc: 0.7616 - precision: 0.6707 - recall: 0.7483 - val_auc: 0.7251 - val_binary_accuracy: 0.5975 - val_f1: 0.4339 - val_loss: 0.6535 - val_prc_auc: 0.4483 - val_precision: 0.3010 - val_recall: 0.7768\n","Epoch 20/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7651 - binary_accuracy: 0.6980 - f1: 0.7067 - loss: 0.5828 - prc_auc: 0.7627 - precision: 0.6717 - recall: 0.7463\n","Epoch 20: Validation Metrics:\n","loss: 0.573823869228363\n","val_binary_accuracy: 0.5992907881736755\n","val_precision: 0.3020833432674408\n","val_recall: 0.7767857313156128\n","val_auc: 0.7274218201637268\n","val_prc_auc: 0.45319080352783203\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - auc: 0.7653 - binary_accuracy: 0.6983 - f1: 0.7070 - loss: 0.5826 - prc_auc: 0.7631 - precision: 0.6724 - recall: 0.7461 - val_auc: 0.7274 - val_binary_accuracy: 0.5993 - val_f1: 0.4350 - val_loss: 0.6520 - val_prc_auc: 0.4532 - val_precision: 0.3021 - val_recall: 0.7768\n","Starting training for label: 7\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - auc: 0.4983 - binary_accuracy: 0.4973 - f1: 0.3941 - loss: 0.6930 - prc_auc: 0.4867 - precision: 0.4732 - recall: 0.3456\n","Epoch 1: Validation Metrics:\n","loss: 0.6903941631317139\n","val_binary_accuracy: 0.4485815465450287\n","val_precision: 0.1545189470052719\n","val_recall: 0.7162162065505981\n","val_auc: 0.6246552467346191\n","val_prc_auc: 0.19312258064746857\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 500ms/step - auc: 0.4997 - binary_accuracy: 0.4982 - f1: 0.3973 - loss: 0.6930 - prc_auc: 0.4882 - precision: 0.4747 - recall: 0.3498 - val_auc: 0.6247 - val_binary_accuracy: 0.4486 - val_f1: 0.2542 - val_loss: 0.6935 - val_prc_auc: 0.1931 - val_precision: 0.1545 - val_recall: 0.7162\n","Epoch 2/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6287 - binary_accuracy: 0.5927 - f1: 0.6304 - loss: 0.6829 - prc_auc: 0.6234 - precision: 0.5659 - recall: 0.7137\n","Epoch 2: Validation Metrics:\n","loss: 0.6819201111793518\n","val_binary_accuracy: 0.478723406791687\n","val_precision: 0.15838509798049927\n","val_recall: 0.6891891956329346\n","val_auc: 0.6149889230728149\n","val_prc_auc: 0.1918574720621109\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6286 - binary_accuracy: 0.5922 - f1: 0.6301 - loss: 0.6829 - prc_auc: 0.6235 - precision: 0.5659 - recall: 0.7129 - val_auc: 0.6150 - val_binary_accuracy: 0.4787 - val_f1: 0.2576 - val_loss: 0.6794 - val_prc_auc: 0.1919 - val_precision: 0.1584 - val_recall: 0.6892\n","Epoch 3/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6433 - binary_accuracy: 0.6030 - f1: 0.6313 - loss: 0.6768 - prc_auc: 0.6382 - precision: 0.5775 - recall: 0.6979\n","Epoch 3: Validation Metrics:\n","loss: 0.6764956712722778\n","val_binary_accuracy: 0.5070921778678894\n","val_precision: 0.16447368264198303\n","val_recall: 0.6756756901741028\n","val_auc: 0.6151130795478821\n","val_prc_auc: 0.19207224249839783\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - auc: 0.6431 - binary_accuracy: 0.6026 - f1: 0.6312 - loss: 0.6768 - prc_auc: 0.6383 - precision: 0.5776 - recall: 0.6974 - val_auc: 0.6151 - val_binary_accuracy: 0.5071 - val_f1: 0.2646 - val_loss: 0.6727 - val_prc_auc: 0.1921 - val_precision: 0.1645 - val_recall: 0.6757\n","Epoch 4/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6531 - binary_accuracy: 0.6129 - f1: 0.6345 - loss: 0.6720 - prc_auc: 0.6465 - precision: 0.5887 - recall: 0.6895\n","Epoch 4: Validation Metrics:\n","loss: 0.6719784736633301\n","val_binary_accuracy: 0.5230496525764465\n","val_precision: 0.16949152946472168\n","val_recall: 0.6756756901741028\n","val_auc: 0.6166850328445435\n","val_prc_auc: 0.192943274974823\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6529 - binary_accuracy: 0.6126 - f1: 0.6346 - loss: 0.6720 - prc_auc: 0.6466 - precision: 0.5889 - recall: 0.6894 - val_auc: 0.6167 - val_binary_accuracy: 0.5230 - val_f1: 0.2710 - val_loss: 0.6677 - val_prc_auc: 0.1929 - val_precision: 0.1695 - val_recall: 0.6757\n","Epoch 5/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6607 - binary_accuracy: 0.6248 - f1: 0.6366 - loss: 0.6677 - prc_auc: 0.6531 - precision: 0.6040 - recall: 0.6744\n","Epoch 5: Validation Metrics:\n","loss: 0.6679039597511292\n","val_binary_accuracy: 0.5354610085487366\n","val_precision: 0.17132867872714996\n","val_recall: 0.662162184715271\n","val_auc: 0.621001124382019\n","val_prc_auc: 0.19511307775974274\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6605 - binary_accuracy: 0.6242 - f1: 0.6364 - loss: 0.6677 - prc_auc: 0.6532 - precision: 0.6040 - recall: 0.6740 - val_auc: 0.6210 - val_binary_accuracy: 0.5355 - val_f1: 0.2722 - val_loss: 0.6646 - val_prc_auc: 0.1951 - val_precision: 0.1713 - val_recall: 0.6622\n","Epoch 6/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6698 - binary_accuracy: 0.6326 - f1: 0.6411 - loss: 0.6638 - prc_auc: 0.6610 - precision: 0.6129 - recall: 0.6734\n","Epoch 6: Validation Metrics:\n","loss: 0.6641154289245605\n","val_binary_accuracy: 0.5531914830207825\n","val_precision: 0.1775362342596054\n","val_recall: 0.662162184715271\n","val_auc: 0.6257860064506531\n","val_prc_auc: 0.19892549514770508\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6696 - binary_accuracy: 0.6321 - f1: 0.6410 - loss: 0.6638 - prc_auc: 0.6610 - precision: 0.6129 - recall: 0.6730 - val_auc: 0.6258 - val_binary_accuracy: 0.5532 - val_f1: 0.2800 - val_loss: 0.6621 - val_prc_auc: 0.1989 - val_precision: 0.1775 - val_recall: 0.6622\n","Epoch 7/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6754 - binary_accuracy: 0.6356 - f1: 0.6415 - loss: 0.6601 - prc_auc: 0.6656 - precision: 0.6173 - recall: 0.6691\n","Epoch 7: Validation Metrics:\n","loss: 0.6604762673377991\n","val_binary_accuracy: 0.5620567202568054\n","val_precision: 0.17843866348266602\n","val_recall: 0.6486486196517944\n","val_auc: 0.6296746134757996\n","val_prc_auc: 0.20359809696674347\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6753 - binary_accuracy: 0.6351 - f1: 0.6413 - loss: 0.6601 - prc_auc: 0.6657 - precision: 0.6173 - recall: 0.6686 - val_auc: 0.6297 - val_binary_accuracy: 0.5621 - val_f1: 0.2799 - val_loss: 0.6603 - val_prc_auc: 0.2036 - val_precision: 0.1784 - val_recall: 0.6486\n","Epoch 8/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6827 - binary_accuracy: 0.6455 - f1: 0.6496 - loss: 0.6565 - prc_auc: 0.6715 - precision: 0.6278 - recall: 0.6746\n","Epoch 8: Validation Metrics:\n","loss: 0.6569320559501648\n","val_binary_accuracy: 0.5797872543334961\n","val_precision: 0.1853281855583191\n","val_recall: 0.6486486196517944\n","val_auc: 0.6345973610877991\n","val_prc_auc: 0.2112778127193451\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6826 - binary_accuracy: 0.6451 - f1: 0.6495 - loss: 0.6565 - prc_auc: 0.6716 - precision: 0.6281 - recall: 0.6742 - val_auc: 0.6346 - val_binary_accuracy: 0.5798 - val_f1: 0.2883 - val_loss: 0.6590 - val_prc_auc: 0.2113 - val_precision: 0.1853 - val_recall: 0.6486\n","Epoch 9/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6879 - binary_accuracy: 0.6505 - f1: 0.6506 - loss: 0.6531 - prc_auc: 0.6768 - precision: 0.6359 - recall: 0.6674\n","Epoch 9: Validation Metrics:\n","loss: 0.6534687280654907\n","val_binary_accuracy: 0.5939716100692749\n","val_precision: 0.19123506546020508\n","val_recall: 0.6486486196517944\n","val_auc: 0.6348869204521179\n","val_prc_auc: 0.21103030443191528\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6878 - binary_accuracy: 0.6505 - f1: 0.6508 - loss: 0.6531 - prc_auc: 0.6769 - precision: 0.6363 - recall: 0.6673 - val_auc: 0.6349 - val_binary_accuracy: 0.5940 - val_f1: 0.2954 - val_loss: 0.6576 - val_prc_auc: 0.2110 - val_precision: 0.1912 - val_recall: 0.6486\n","Epoch 10/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6918 - binary_accuracy: 0.6539 - f1: 0.6549 - loss: 0.6498 - prc_auc: 0.6796 - precision: 0.6388 - recall: 0.6736\n","Epoch 10: Validation Metrics:\n","loss: 0.6501268744468689\n","val_binary_accuracy: 0.5957446694374084\n","val_precision: 0.19200000166893005\n","val_recall: 0.6486486196517944\n","val_auc: 0.6390236616134644\n","val_prc_auc: 0.21698203682899475\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6918 - binary_accuracy: 0.6539 - f1: 0.6552 - loss: 0.6498 - prc_auc: 0.6797 - precision: 0.6394 - recall: 0.6735 - val_auc: 0.6390 - val_binary_accuracy: 0.5957 - val_f1: 0.2963 - val_loss: 0.6564 - val_prc_auc: 0.2170 - val_precision: 0.1920 - val_recall: 0.6486\n","Epoch 11/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6969 - binary_accuracy: 0.6551 - f1: 0.6525 - loss: 0.6467 - prc_auc: 0.6832 - precision: 0.6424 - recall: 0.6641\n","Epoch 11: Validation Metrics:\n","loss: 0.6468840837478638\n","val_binary_accuracy: 0.5957446694374084\n","val_precision: 0.1869918704032898\n","val_recall: 0.6216216087341309\n","val_auc: 0.6412851810455322\n","val_prc_auc: 0.21977078914642334\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6969 - binary_accuracy: 0.6553 - f1: 0.6531 - loss: 0.6467 - prc_auc: 0.6833 - precision: 0.6431 - recall: 0.6646 - val_auc: 0.6413 - val_binary_accuracy: 0.5957 - val_f1: 0.2875 - val_loss: 0.6555 - val_prc_auc: 0.2198 - val_precision: 0.1870 - val_recall: 0.6216\n","Epoch 12/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7009 - binary_accuracy: 0.6542 - f1: 0.6512 - loss: 0.6436 - prc_auc: 0.6866 - precision: 0.6419 - recall: 0.6621\n","Epoch 12: Validation Metrics:\n","loss: 0.6436969041824341\n","val_binary_accuracy: 0.597517728805542\n","val_precision: 0.18775510787963867\n","val_recall: 0.6216216087341309\n","val_auc: 0.6442774534225464\n","val_prc_auc: 0.22383975982666016\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7009 - binary_accuracy: 0.6547 - f1: 0.6520 - loss: 0.6436 - prc_auc: 0.6867 - precision: 0.6428 - recall: 0.6627 - val_auc: 0.6443 - val_binary_accuracy: 0.5975 - val_f1: 0.2884 - val_loss: 0.6542 - val_prc_auc: 0.2238 - val_precision: 0.1878 - val_recall: 0.6216\n","Epoch 13/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7045 - binary_accuracy: 0.6515 - f1: 0.6467 - loss: 0.6407 - prc_auc: 0.6901 - precision: 0.6404 - recall: 0.6541\n","Epoch 13: Validation Metrics:\n","loss: 0.6406261324882507\n","val_binary_accuracy: 0.6010638475418091\n","val_precision: 0.18930041790008545\n","val_recall: 0.6216216087341309\n","val_auc: 0.6471180319786072\n","val_prc_auc: 0.22508081793785095\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7046 - binary_accuracy: 0.6520 - f1: 0.6475 - loss: 0.6407 - prc_auc: 0.6903 - precision: 0.6415 - recall: 0.6547 - val_auc: 0.6471 - val_binary_accuracy: 0.6011 - val_f1: 0.2902 - val_loss: 0.6531 - val_prc_auc: 0.2251 - val_precision: 0.1893 - val_recall: 0.6216\n","Epoch 14/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7077 - binary_accuracy: 0.6576 - f1: 0.6463 - loss: 0.6378 - prc_auc: 0.6924 - precision: 0.6521 - recall: 0.6414\n","Epoch 14: Validation Metrics:\n","loss: 0.6376467347145081\n","val_binary_accuracy: 0.6081560254096985\n","val_precision: 0.19246861338615417\n","val_recall: 0.6216216087341309\n","val_auc: 0.64776611328125\n","val_prc_auc: 0.22315603494644165\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7078 - binary_accuracy: 0.6580 - f1: 0.6471 - loss: 0.6378 - prc_auc: 0.6926 - precision: 0.6528 - recall: 0.6422 - val_auc: 0.6478 - val_binary_accuracy: 0.6082 - val_f1: 0.2939 - val_loss: 0.6521 - val_prc_auc: 0.2232 - val_precision: 0.1925 - val_recall: 0.6216\n","Epoch 15/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7110 - binary_accuracy: 0.6554 - f1: 0.6424 - loss: 0.6350 - prc_auc: 0.6950 - precision: 0.6512 - recall: 0.6346\n","Epoch 15: Validation Metrics:\n","loss: 0.6347436904907227\n","val_binary_accuracy: 0.6063829660415649\n","val_precision: 0.18644067645072937\n","val_recall: 0.5945945978164673\n","val_auc: 0.6500000357627869\n","val_prc_auc: 0.2243497520685196\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7111 - binary_accuracy: 0.6559 - f1: 0.6433 - loss: 0.6350 - prc_auc: 0.6952 - precision: 0.6520 - recall: 0.6355 - val_auc: 0.6500 - val_binary_accuracy: 0.6064 - val_f1: 0.2839 - val_loss: 0.6516 - val_prc_auc: 0.2243 - val_precision: 0.1864 - val_recall: 0.5946\n","Starting training for label: 8\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - auc: 0.5379 - binary_accuracy: 0.5484 - f1: 0.3106 - loss: 0.6907 - prc_auc: 0.5409 - precision: 0.5755 - recall: 0.2427\n","Epoch 1: Validation Metrics:\n","loss: 0.6843990087509155\n","val_binary_accuracy: 0.5514184236526489\n","val_precision: 0.18983051180839539\n","val_recall: 0.800000011920929\n","val_auc: 0.7220358848571777\n","val_prc_auc: 0.36107534170150757\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 485ms/step - auc: 0.5394 - binary_accuracy: 0.5493 - f1: 0.3162 - loss: 0.6905 - prc_auc: 0.5426 - precision: 0.5763 - recall: 0.2486 - val_auc: 0.7220 - val_binary_accuracy: 0.5514 - val_f1: 0.3068 - val_loss: 0.6882 - val_prc_auc: 0.3611 - val_precision: 0.1898 - val_recall: 0.8000\n","Epoch 2/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6821 - binary_accuracy: 0.6194 - f1: 0.6629 - loss: 0.6675 - prc_auc: 0.6707 - precision: 0.5925 - recall: 0.7536\n","Epoch 2: Validation Metrics:\n","loss: 0.6649728417396545\n","val_binary_accuracy: 0.5833333134651184\n","val_precision: 0.20000000298023224\n","val_recall: 0.7857142686843872\n","val_auc: 0.7349046468734741\n","val_prc_auc: 0.38542136549949646\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6820 - binary_accuracy: 0.6194 - f1: 0.6628 - loss: 0.6675 - prc_auc: 0.6708 - precision: 0.5926 - recall: 0.7531 - val_auc: 0.7349 - val_binary_accuracy: 0.5833 - val_f1: 0.3188 - val_loss: 0.6683 - val_prc_auc: 0.3854 - val_precision: 0.2000 - val_recall: 0.7857\n","Epoch 3/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6883 - binary_accuracy: 0.6274 - f1: 0.6618 - loss: 0.6552 - prc_auc: 0.6806 - precision: 0.6032 - recall: 0.7344\n","Epoch 3: Validation Metrics:\n","loss: 0.653421938419342\n","val_binary_accuracy: 0.6063829660415649\n","val_precision: 0.20769231021404266\n","val_recall: 0.7714285850524902\n","val_auc: 0.7426403164863586\n","val_prc_auc: 0.4022158086299896\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.6883 - binary_accuracy: 0.6275 - f1: 0.6618 - loss: 0.6552 - prc_auc: 0.6808 - precision: 0.6034 - recall: 0.7340 - val_auc: 0.7426 - val_binary_accuracy: 0.6064 - val_f1: 0.3273 - val_loss: 0.6487 - val_prc_auc: 0.4022 - val_precision: 0.2077 - val_recall: 0.7714\n","Epoch 4/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6940 - binary_accuracy: 0.6260 - f1: 0.6559 - loss: 0.6464 - prc_auc: 0.6868 - precision: 0.6049 - recall: 0.7178\n","Epoch 4: Validation Metrics:\n","loss: 0.6449910402297974\n","val_binary_accuracy: 0.6081560254096985\n","val_precision: 0.20158103108406067\n","val_recall: 0.7285714149475098\n","val_auc: 0.7479901313781738\n","val_prc_auc: 0.4111015796661377\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.6940 - binary_accuracy: 0.6262 - f1: 0.6559 - loss: 0.6463 - prc_auc: 0.6870 - precision: 0.6052 - recall: 0.7174 - val_auc: 0.7480 - val_binary_accuracy: 0.6082 - val_f1: 0.3158 - val_loss: 0.6346 - val_prc_auc: 0.4111 - val_precision: 0.2016 - val_recall: 0.7286\n","Epoch 5/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7008 - binary_accuracy: 0.6367 - f1: 0.6624 - loss: 0.6396 - prc_auc: 0.6926 - precision: 0.6161 - recall: 0.7178\n","Epoch 5: Validation Metrics:\n","loss: 0.6383702754974365\n","val_binary_accuracy: 0.6205673813819885\n","val_precision: 0.2073170691728592\n","val_recall: 0.7285714149475098\n","val_auc: 0.7527761459350586\n","val_prc_auc: 0.41398125886917114\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7008 - binary_accuracy: 0.6369 - f1: 0.6625 - loss: 0.6396 - prc_auc: 0.6927 - precision: 0.6165 - recall: 0.7174 - val_auc: 0.7528 - val_binary_accuracy: 0.6206 - val_f1: 0.3228 - val_loss: 0.6242 - val_prc_auc: 0.4140 - val_precision: 0.2073 - val_recall: 0.7286\n","Epoch 6/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7060 - binary_accuracy: 0.6507 - f1: 0.6685 - loss: 0.6341 - prc_auc: 0.6971 - precision: 0.6330 - recall: 0.7093\n","Epoch 6: Validation Metrics:\n","loss: 0.632874608039856\n","val_binary_accuracy: 0.6241135001182556\n","val_precision: 0.20901639759540558\n","val_recall: 0.7285714149475098\n","val_auc: 0.7568970322608948\n","val_prc_auc: 0.41575950384140015\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7060 - binary_accuracy: 0.6508 - f1: 0.6684 - loss: 0.6341 - prc_auc: 0.6972 - precision: 0.6332 - recall: 0.7089 - val_auc: 0.7569 - val_binary_accuracy: 0.6241 - val_f1: 0.3248 - val_loss: 0.6173 - val_prc_auc: 0.4158 - val_precision: 0.2090 - val_recall: 0.7286\n","Epoch 7/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7118 - binary_accuracy: 0.6565 - f1: 0.6672 - loss: 0.6295 - prc_auc: 0.7015 - precision: 0.6442 - recall: 0.6930\n","Epoch 7: Validation Metrics:\n","loss: 0.628072202205658\n","val_binary_accuracy: 0.631205677986145\n","val_precision: 0.21250000596046448\n","val_recall: 0.7285714149475098\n","val_auc: 0.7597165703773499\n","val_prc_auc: 0.419890433549881\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.7118 - binary_accuracy: 0.6566 - f1: 0.6673 - loss: 0.6295 - prc_auc: 0.7016 - precision: 0.6444 - recall: 0.6928 - val_auc: 0.7597 - val_binary_accuracy: 0.6312 - val_f1: 0.3290 - val_loss: 0.6123 - val_prc_auc: 0.4199 - val_precision: 0.2125 - val_recall: 0.7286\n","Epoch 8/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7155 - binary_accuracy: 0.6590 - f1: 0.6681 - loss: 0.6255 - prc_auc: 0.7043 - precision: 0.6481 - recall: 0.6905\n","Epoch 8: Validation Metrics:\n","loss: 0.6237328052520752\n","val_binary_accuracy: 0.6489361524581909\n","val_precision: 0.22173912823200226\n","val_recall: 0.7285714149475098\n","val_auc: 0.762767493724823\n","val_prc_auc: 0.42394524812698364\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7156 - binary_accuracy: 0.6590 - f1: 0.6681 - loss: 0.6255 - prc_auc: 0.7044 - precision: 0.6483 - recall: 0.6902 - val_auc: 0.7628 - val_binary_accuracy: 0.6489 - val_f1: 0.3400 - val_loss: 0.6085 - val_prc_auc: 0.4239 - val_precision: 0.2217 - val_recall: 0.7286\n","Epoch 9/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7206 - binary_accuracy: 0.6612 - f1: 0.6693 - loss: 0.6220 - prc_auc: 0.7091 - precision: 0.6511 - recall: 0.6898\n","Epoch 9: Validation Metrics:\n","loss: 0.6196809411048889\n","val_binary_accuracy: 0.6542553305625916\n","val_precision: 0.22466960549354553\n","val_recall: 0.7285714149475098\n","val_auc: 0.7653123140335083\n","val_prc_auc: 0.4305606782436371\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7206 - binary_accuracy: 0.6614 - f1: 0.6693 - loss: 0.6219 - prc_auc: 0.7092 - precision: 0.6514 - recall: 0.6895 - val_auc: 0.7653 - val_binary_accuracy: 0.6543 - val_f1: 0.3434 - val_loss: 0.6051 - val_prc_auc: 0.4306 - val_precision: 0.2247 - val_recall: 0.7286\n","Epoch 10/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7243 - binary_accuracy: 0.6624 - f1: 0.6690 - loss: 0.6186 - prc_auc: 0.7118 - precision: 0.6534 - recall: 0.6866\n","Epoch 10: Validation Metrics:\n","loss: 0.6158344149589539\n","val_binary_accuracy: 0.6578013896942139\n","val_precision: 0.2266666740179062\n","val_recall: 0.7285714149475098\n","val_auc: 0.7674233317375183\n","val_prc_auc: 0.43819543719291687\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7244 - binary_accuracy: 0.6625 - f1: 0.6690 - loss: 0.6185 - prc_auc: 0.7119 - precision: 0.6537 - recall: 0.6863 - val_auc: 0.7674 - val_binary_accuracy: 0.6578 - val_f1: 0.3458 - val_loss: 0.6027 - val_prc_auc: 0.4382 - val_precision: 0.2267 - val_recall: 0.7286\n","Epoch 11/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7290 - binary_accuracy: 0.6604 - f1: 0.6682 - loss: 0.6155 - prc_auc: 0.7155 - precision: 0.6511 - recall: 0.6878\n","Epoch 11: Validation Metrics:\n","loss: 0.6121945977210999\n","val_binary_accuracy: 0.6631205677986145\n","val_precision: 0.22727273404598236\n","val_recall: 0.7142857313156128\n","val_auc: 0.7688837647438049\n","val_prc_auc: 0.43908366560935974\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7290 - binary_accuracy: 0.6606 - f1: 0.6682 - loss: 0.6154 - prc_auc: 0.7157 - precision: 0.6515 - recall: 0.6875 - val_auc: 0.7689 - val_binary_accuracy: 0.6631 - val_f1: 0.3448 - val_loss: 0.6007 - val_prc_auc: 0.4391 - val_precision: 0.2273 - val_recall: 0.7143\n","Epoch 12/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7334 - binary_accuracy: 0.6603 - f1: 0.6658 - loss: 0.6125 - prc_auc: 0.7199 - precision: 0.6533 - recall: 0.6805\n","Epoch 12: Validation Metrics:\n","loss: 0.6087433099746704\n","val_binary_accuracy: 0.6755319237709045\n","val_precision: 0.23474177718162537\n","val_recall: 0.7142857313156128\n","val_auc: 0.7702428698539734\n","val_prc_auc: 0.4433574676513672\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7335 - binary_accuracy: 0.6606 - f1: 0.6660 - loss: 0.6124 - prc_auc: 0.7200 - precision: 0.6537 - recall: 0.6803 - val_auc: 0.7702 - val_binary_accuracy: 0.6755 - val_f1: 0.3534 - val_loss: 0.5988 - val_prc_auc: 0.4434 - val_precision: 0.2347 - val_recall: 0.7143\n","Epoch 13/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7374 - binary_accuracy: 0.6684 - f1: 0.6712 - loss: 0.6097 - prc_auc: 0.7230 - precision: 0.6635 - recall: 0.6807\n","Epoch 13: Validation Metrics:\n","loss: 0.6054481267929077\n","val_binary_accuracy: 0.6755319237709045\n","val_precision: 0.23222748935222626\n","val_recall: 0.699999988079071\n","val_auc: 0.7718623876571655\n","val_prc_auc: 0.44794514775276184\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7374 - binary_accuracy: 0.6686 - f1: 0.6713 - loss: 0.6096 - prc_auc: 0.7232 - precision: 0.6639 - recall: 0.6804 - val_auc: 0.7719 - val_binary_accuracy: 0.6755 - val_f1: 0.3488 - val_loss: 0.5969 - val_prc_auc: 0.4479 - val_precision: 0.2322 - val_recall: 0.7000\n","Epoch 14/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7407 - binary_accuracy: 0.6682 - f1: 0.6704 - loss: 0.6069 - prc_auc: 0.7260 - precision: 0.6638 - recall: 0.6788\n","Epoch 14: Validation Metrics:\n","loss: 0.602263331413269\n","val_binary_accuracy: 0.6790780425071716\n","val_precision: 0.23444975912570953\n","val_recall: 0.699999988079071\n","val_auc: 0.7737998366355896\n","val_prc_auc: 0.4529372453689575\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7408 - binary_accuracy: 0.6684 - f1: 0.6705 - loss: 0.6068 - prc_auc: 0.7262 - precision: 0.6643 - recall: 0.6786 - val_auc: 0.7738 - val_binary_accuracy: 0.6791 - val_f1: 0.3513 - val_loss: 0.5952 - val_prc_auc: 0.4529 - val_precision: 0.2344 - val_recall: 0.7000\n","Epoch 15/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7442 - binary_accuracy: 0.6713 - f1: 0.6719 - loss: 0.6043 - prc_auc: 0.7300 - precision: 0.6689 - recall: 0.6767\n","Epoch 15: Validation Metrics:\n","loss: 0.5991934537887573\n","val_binary_accuracy: 0.682624101638794\n","val_precision: 0.23671497404575348\n","val_recall: 0.699999988079071\n","val_auc: 0.7753036618232727\n","val_prc_auc: 0.45865917205810547\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7444 - binary_accuracy: 0.6717 - f1: 0.6721 - loss: 0.6042 - prc_auc: 0.7302 - precision: 0.6694 - recall: 0.6765 - val_auc: 0.7753 - val_binary_accuracy: 0.6826 - val_f1: 0.3538 - val_loss: 0.5941 - val_prc_auc: 0.4587 - val_precision: 0.2367 - val_recall: 0.7000\n","Epoch 16/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7476 - binary_accuracy: 0.6792 - f1: 0.6793 - loss: 0.6018 - prc_auc: 0.7324 - precision: 0.6773 - recall: 0.6831\n","Epoch 16: Validation Metrics:\n","loss: 0.59625244140625\n","val_binary_accuracy: 0.682624101638794\n","val_precision: 0.23671497404575348\n","val_recall: 0.699999988079071\n","val_auc: 0.7761422991752625\n","val_prc_auc: 0.46262654662132263\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7478 - binary_accuracy: 0.6794 - f1: 0.6794 - loss: 0.6016 - prc_auc: 0.7326 - precision: 0.6777 - recall: 0.6828 - val_auc: 0.7761 - val_binary_accuracy: 0.6826 - val_f1: 0.3538 - val_loss: 0.5926 - val_prc_auc: 0.4626 - val_precision: 0.2367 - val_recall: 0.7000\n","Epoch 17/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7503 - binary_accuracy: 0.6819 - f1: 0.6825 - loss: 0.5993 - prc_auc: 0.7356 - precision: 0.6794 - recall: 0.6874\n","Epoch 17: Validation Metrics:\n","loss: 0.5933919548988342\n","val_binary_accuracy: 0.6843971610069275\n","val_precision: 0.23786407709121704\n","val_recall: 0.699999988079071\n","val_auc: 0.7773134708404541\n","val_prc_auc: 0.466145396232605\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7504 - binary_accuracy: 0.6821 - f1: 0.6825 - loss: 0.5992 - prc_auc: 0.7358 - precision: 0.6798 - recall: 0.6871 - val_auc: 0.7773 - val_binary_accuracy: 0.6844 - val_f1: 0.3551 - val_loss: 0.5915 - val_prc_auc: 0.4661 - val_precision: 0.2379 - val_recall: 0.7000\n","Epoch 18/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7537 - binary_accuracy: 0.6850 - f1: 0.6842 - loss: 0.5969 - prc_auc: 0.7390 - precision: 0.6835 - recall: 0.6863\n","Epoch 18: Validation Metrics:\n","loss: 0.5906174778938293\n","val_binary_accuracy: 0.686170220375061\n","val_precision: 0.2415459007024765\n","val_recall: 0.7142857313156128\n","val_auc: 0.7774724960327148\n","val_prc_auc: 0.47061336040496826\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7538 - binary_accuracy: 0.6852 - f1: 0.6842 - loss: 0.5968 - prc_auc: 0.7391 - precision: 0.6839 - recall: 0.6860 - val_auc: 0.7775 - val_binary_accuracy: 0.6862 - val_f1: 0.3610 - val_loss: 0.5903 - val_prc_auc: 0.4706 - val_precision: 0.2415 - val_recall: 0.7143\n","Epoch 19/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7562 - binary_accuracy: 0.6826 - f1: 0.6816 - loss: 0.5946 - prc_auc: 0.7418 - precision: 0.6815 - recall: 0.6834\n","Epoch 19: Validation Metrics:\n","loss: 0.5878981351852417\n","val_binary_accuracy: 0.6879432797431946\n","val_precision: 0.24271844327449799\n","val_recall: 0.7142857313156128\n","val_auc: 0.7783689498901367\n","val_prc_auc: 0.473130464553833\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.7564 - binary_accuracy: 0.6828 - f1: 0.6816 - loss: 0.5944 - prc_auc: 0.7420 - precision: 0.6818 - recall: 0.6830 - val_auc: 0.7784 - val_binary_accuracy: 0.6879 - val_f1: 0.3623 - val_loss: 0.5893 - val_prc_auc: 0.4731 - val_precision: 0.2427 - val_recall: 0.7143\n","Epoch 20/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7585 - binary_accuracy: 0.6835 - f1: 0.6823 - loss: 0.5923 - prc_auc: 0.7442 - precision: 0.6827 - recall: 0.6835\n","Epoch 20: Validation Metrics:\n","loss: 0.5852335095405579\n","val_binary_accuracy: 0.6897163391113281\n","val_precision: 0.24390244483947754\n","val_recall: 0.7142857313156128\n","val_auc: 0.7778339982032776\n","val_prc_auc: 0.4776484966278076\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - auc: 0.7588 - binary_accuracy: 0.6837 - f1: 0.6823 - loss: 0.5921 - prc_auc: 0.7444 - precision: 0.6831 - recall: 0.6831 - val_auc: 0.7778 - val_binary_accuracy: 0.6897 - val_f1: 0.3636 - val_loss: 0.5886 - val_prc_auc: 0.4776 - val_precision: 0.2439 - val_recall: 0.7143\n","Starting training for label: 9\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - auc: 0.7722 - binary_accuracy: 0.7364 - f1: 0.6719 - loss: 0.6598 - prc_auc: 0.7856 - precision: 0.8551 - recall: 0.5539\n","Epoch 1: Validation Metrics:\n","loss: 0.6351283192634583\n","val_binary_accuracy: 0.859929084777832\n","val_precision: 0.4166666567325592\n","val_recall: 0.6349206566810608\n","val_auc: 0.8342046737670898\n","val_prc_auc: 0.4594764709472656\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 509ms/step - auc: 0.7726 - binary_accuracy: 0.7369 - f1: 0.6729 - loss: 0.6591 - prc_auc: 0.7862 - precision: 0.8557 - recall: 0.5550 - val_auc: 0.8342 - val_binary_accuracy: 0.8599 - val_f1: 0.5031 - val_loss: 0.5681 - val_prc_auc: 0.4595 - val_precision: 0.4167 - val_recall: 0.6349\n","Epoch 2/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8349 - binary_accuracy: 0.7939 - f1: 0.7622 - loss: 0.5549 - prc_auc: 0.8485 - precision: 0.8795 - recall: 0.6737\n","Epoch 2: Validation Metrics:\n","loss: 0.5502988696098328\n","val_binary_accuracy: 0.8581560254096985\n","val_precision: 0.4141414165496826\n","val_recall: 0.6507936716079712\n","val_auc: 0.835155189037323\n","val_prc_auc: 0.4432196021080017\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.8338 - binary_accuracy: 0.7929 - f1: 0.7612 - loss: 0.5546 - prc_auc: 0.8475 - precision: 0.8791 - recall: 0.6722 - val_auc: 0.8352 - val_binary_accuracy: 0.8582 - val_f1: 0.5062 - val_loss: 0.5083 - val_prc_auc: 0.4432 - val_precision: 0.4141 - val_recall: 0.6508\n","Epoch 3/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8412 - binary_accuracy: 0.7941 - f1: 0.7639 - loss: 0.4978 - prc_auc: 0.8502 - precision: 0.8746 - recall: 0.6792\n","Epoch 3: Validation Metrics:\n","loss: 0.5086250901222229\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.4019607901573181\n","val_recall: 0.6507936716079712\n","val_auc: 0.8375629186630249\n","val_prc_auc: 0.45867204666137695\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8401 - binary_accuracy: 0.7933 - f1: 0.7630 - loss: 0.4983 - prc_auc: 0.8492 - precision: 0.8744 - recall: 0.6779 - val_auc: 0.8376 - val_binary_accuracy: 0.8528 - val_f1: 0.4970 - val_loss: 0.4902 - val_prc_auc: 0.4587 - val_precision: 0.4020 - val_recall: 0.6508\n","Epoch 4/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8462 - binary_accuracy: 0.7940 - f1: 0.7638 - loss: 0.4734 - prc_auc: 0.8554 - precision: 0.8745 - recall: 0.6788\n","Epoch 4: Validation Metrics:\n","loss: 0.4928373694419861\n","val_binary_accuracy: 0.8492907881736755\n","val_precision: 0.3962264060974121\n","val_recall: 0.6666666865348816\n","val_auc: 0.8408421277999878\n","val_prc_auc: 0.4626010060310364\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8451 - binary_accuracy: 0.7933 - f1: 0.7632 - loss: 0.4744 - prc_auc: 0.8544 - precision: 0.8744 - recall: 0.6779 - val_auc: 0.8408 - val_binary_accuracy: 0.8493 - val_f1: 0.4970 - val_loss: 0.4875 - val_prc_auc: 0.4626 - val_precision: 0.3962 - val_recall: 0.6667\n","Epoch 5/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8512 - binary_accuracy: 0.7927 - f1: 0.7662 - loss: 0.4641 - prc_auc: 0.8589 - precision: 0.8628 - recall: 0.6913\n","Epoch 5: Validation Metrics:\n","loss: 0.4867851734161377\n","val_binary_accuracy: 0.8492907881736755\n","val_precision: 0.39814814925193787\n","val_recall: 0.682539701461792\n","val_auc: 0.8452935218811035\n","val_prc_auc: 0.4823647141456604\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.8500 - binary_accuracy: 0.7923 - f1: 0.7657 - loss: 0.4652 - prc_auc: 0.8579 - precision: 0.8631 - recall: 0.6901 - val_auc: 0.8453 - val_binary_accuracy: 0.8493 - val_f1: 0.5029 - val_loss: 0.4863 - val_prc_auc: 0.4824 - val_precision: 0.3981 - val_recall: 0.6825\n","Epoch 6/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8539 - binary_accuracy: 0.7961 - f1: 0.7691 - loss: 0.4594 - prc_auc: 0.8623 - precision: 0.8692 - recall: 0.6913\n","Epoch 6: Validation Metrics:\n","loss: 0.4832395017147064\n","val_binary_accuracy: 0.847517728805542\n","val_precision: 0.39449542760849\n","val_recall: 0.682539701461792\n","val_auc: 0.8479865789413452\n","val_prc_auc: 0.49367108941078186\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8528 - binary_accuracy: 0.7955 - f1: 0.7684 - loss: 0.4606 - prc_auc: 0.8611 - precision: 0.8693 - recall: 0.6901 - val_auc: 0.8480 - val_binary_accuracy: 0.8475 - val_f1: 0.5000 - val_loss: 0.4850 - val_prc_auc: 0.4937 - val_precision: 0.3945 - val_recall: 0.6825\n","Epoch 7/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8565 - binary_accuracy: 0.7985 - f1: 0.7725 - loss: 0.4562 - prc_auc: 0.8669 - precision: 0.8699 - recall: 0.6962\n","Epoch 7: Validation Metrics:\n","loss: 0.48040637373924255\n","val_binary_accuracy: 0.847517728805542\n","val_precision: 0.39449542760849\n","val_recall: 0.682539701461792\n","val_auc: 0.8506479263305664\n","val_prc_auc: 0.5042098164558411\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - auc: 0.8554 - binary_accuracy: 0.7979 - f1: 0.7718 - loss: 0.4574 - prc_auc: 0.8658 - precision: 0.8700 - recall: 0.6950 - val_auc: 0.8506 - val_binary_accuracy: 0.8475 - val_f1: 0.5000 - val_loss: 0.4830 - val_prc_auc: 0.5042 - val_precision: 0.3945 - val_recall: 0.6825\n","Starting training for label: 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - auc: 0.7954 - binary_accuracy: 0.7412 - f1: 0.7503 - loss: 0.6603 - prc_auc: 0.8061 - precision: 0.7472 - recall: 0.7581\n","Epoch 1: Validation Metrics:\n","loss: 0.6379833817481995\n","val_binary_accuracy: 0.8581560254096985\n","val_precision: 0.40425533056259155\n","val_recall: 0.6129032373428345\n","val_auc: 0.7764264941215515\n","val_prc_auc: 0.38059288263320923\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - auc: 0.7955 - binary_accuracy: 0.7416 - f1: 0.7500 - loss: 0.6597 - prc_auc: 0.8061 - precision: 0.7481 - recall: 0.7566 - val_auc: 0.7764 - val_binary_accuracy: 0.8582 - val_f1: 0.4872 - val_loss: 0.5814 - val_prc_auc: 0.3806 - val_precision: 0.4043 - val_recall: 0.6129\n","Epoch 2/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8243 - binary_accuracy: 0.7771 - f1: 0.7469 - loss: 0.5707 - prc_auc: 0.8388 - precision: 0.8965 - recall: 0.6403\n","Epoch 2: Validation Metrics:\n","loss: 0.5594993829727173\n","val_binary_accuracy: 0.8581560254096985\n","val_precision: 0.40425533056259155\n","val_recall: 0.6129032373428345\n","val_auc: 0.7688761353492737\n","val_prc_auc: 0.3836609423160553\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - auc: 0.8238 - binary_accuracy: 0.7768 - f1: 0.7464 - loss: 0.5700 - prc_auc: 0.8377 - precision: 0.8948 - recall: 0.6403 - val_auc: 0.7689 - val_binary_accuracy: 0.8582 - val_f1: 0.4872 - val_loss: 0.5181 - val_prc_auc: 0.3837 - val_precision: 0.4043 - val_recall: 0.6129\n","Epoch 3/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8226 - binary_accuracy: 0.7753 - f1: 0.7461 - loss: 0.5207 - prc_auc: 0.8369 - precision: 0.8896 - recall: 0.6427\n","Epoch 3: Validation Metrics:\n","loss: 0.5189072489738464\n","val_binary_accuracy: 0.8563829660415649\n","val_precision: 0.4020618498325348\n","val_recall: 0.6290322542190552\n","val_auc: 0.769229531288147\n","val_prc_auc: 0.3973541259765625\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - auc: 0.8224 - binary_accuracy: 0.7751 - f1: 0.7457 - loss: 0.5206 - prc_auc: 0.8359 - precision: 0.8880 - recall: 0.6429 - val_auc: 0.7692 - val_binary_accuracy: 0.8564 - val_f1: 0.4906 - val_loss: 0.4972 - val_prc_auc: 0.3974 - val_precision: 0.4021 - val_recall: 0.6290\n","Epoch 4/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8234 - binary_accuracy: 0.7830 - f1: 0.7574 - loss: 0.4974 - prc_auc: 0.8373 - precision: 0.8879 - recall: 0.6605\n","Epoch 4: Validation Metrics:\n","loss: 0.5020213723182678\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.39393940567970276\n","val_recall: 0.6290322542190552\n","val_auc: 0.769229531288147\n","val_prc_auc: 0.3981133997440338\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.8233 - binary_accuracy: 0.7824 - f1: 0.7566 - loss: 0.4976 - prc_auc: 0.8365 - precision: 0.8861 - recall: 0.6603 - val_auc: 0.7692 - val_binary_accuracy: 0.8528 - val_f1: 0.4845 - val_loss: 0.4963 - val_prc_auc: 0.3981 - val_precision: 0.3939 - val_recall: 0.6290\n","Epoch 5/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8258 - binary_accuracy: 0.7829 - f1: 0.7577 - loss: 0.4878 - prc_auc: 0.8387 - precision: 0.8867 - recall: 0.6616\n","Epoch 5: Validation Metrics:\n","loss: 0.49546852707862854\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.39393940567970276\n","val_recall: 0.6290322542190552\n","val_auc: 0.771591067314148\n","val_prc_auc: 0.40228304266929626\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - auc: 0.8256 - binary_accuracy: 0.7824 - f1: 0.7569 - loss: 0.4882 - prc_auc: 0.8378 - precision: 0.8849 - recall: 0.6614 - val_auc: 0.7716 - val_binary_accuracy: 0.8528 - val_f1: 0.4845 - val_loss: 0.4981 - val_prc_auc: 0.4023 - val_precision: 0.3939 - val_recall: 0.6290\n","Epoch 6/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8280 - binary_accuracy: 0.7838 - f1: 0.7584 - loss: 0.4834 - prc_auc: 0.8411 - precision: 0.8887 - recall: 0.6616\n","Epoch 6: Validation Metrics:\n","loss: 0.4921591281890869\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.39393940567970276\n","val_recall: 0.6290322542190552\n","val_auc: 0.7724746465682983\n","val_prc_auc: 0.39577198028564453\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.8279 - binary_accuracy: 0.7833 - f1: 0.7577 - loss: 0.4839 - prc_auc: 0.8404 - precision: 0.8870 - recall: 0.6614 - val_auc: 0.7725 - val_binary_accuracy: 0.8528 - val_f1: 0.4845 - val_loss: 0.4990 - val_prc_auc: 0.3958 - val_precision: 0.3939 - val_recall: 0.6290\n","Epoch 7/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8310 - binary_accuracy: 0.7863 - f1: 0.7618 - loss: 0.4807 - prc_auc: 0.8484 - precision: 0.8894 - recall: 0.6664\n","Epoch 7: Validation Metrics:\n","loss: 0.4897422194480896\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.39393940567970276\n","val_recall: 0.6290322542190552\n","val_auc: 0.7754626274108887\n","val_prc_auc: 0.39481619000434875\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - auc: 0.8309 - binary_accuracy: 0.7857 - f1: 0.7609 - loss: 0.4812 - prc_auc: 0.8474 - precision: 0.8877 - recall: 0.6660 - val_auc: 0.7755 - val_binary_accuracy: 0.8528 - val_f1: 0.4845 - val_loss: 0.4989 - val_prc_auc: 0.3948 - val_precision: 0.3939 - val_recall: 0.6290\n","Epoch 8/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8339 - binary_accuracy: 0.7870 - f1: 0.7624 - loss: 0.4786 - prc_auc: 0.8469 - precision: 0.8911 - recall: 0.6664\n","Epoch 8: Validation Metrics:\n","loss: 0.4876244068145752\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.39393940567970276\n","val_recall: 0.6290322542190552\n","val_auc: 0.7777117490768433\n","val_prc_auc: 0.40759071707725525\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.8338 - binary_accuracy: 0.7864 - f1: 0.7616 - loss: 0.4791 - prc_auc: 0.8460 - precision: 0.8894 - recall: 0.6660 - val_auc: 0.7777 - val_binary_accuracy: 0.8528 - val_f1: 0.4845 - val_loss: 0.4984 - val_prc_auc: 0.4076 - val_precision: 0.3939 - val_recall: 0.6290\n","Starting training for label: 11\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - auc: 0.8381 - binary_accuracy: 0.7473 - f1: 0.7826 - loss: 0.6537 - prc_auc: 0.8186 - precision: 0.7090 - recall: 0.8827\n","Epoch 1: Validation Metrics:\n","loss: 0.620025098323822\n","val_binary_accuracy: 0.8847517967224121\n","val_precision: 0.3958333432674408\n","val_recall: 0.8444444537162781\n","val_auc: 0.8963391184806824\n","val_prc_auc: 0.5289849042892456\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 689ms/step - auc: 0.8397 - binary_accuracy: 0.7498 - f1: 0.7841 - loss: 0.6526 - prc_auc: 0.8207 - precision: 0.7121 - recall: 0.8819 - val_auc: 0.8963 - val_binary_accuracy: 0.8848 - val_f1: 0.5390 - val_loss: 0.5708 - val_prc_auc: 0.5290 - val_precision: 0.3958 - val_recall: 0.8444\n","Epoch 2/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8808 - binary_accuracy: 0.8541 - f1: 0.8499 - loss: 0.5354 - prc_auc: 0.8791 - precision: 0.8797 - recall: 0.8225\n","Epoch 2: Validation Metrics:\n","loss: 0.502446711063385\n","val_binary_accuracy: 0.8882978558540344\n","val_precision: 0.4021739065647125\n","val_recall: 0.8222222328186035\n","val_auc: 0.9076001048088074\n","val_prc_auc: 0.6316945552825928\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - auc: 0.8823 - binary_accuracy: 0.8552 - f1: 0.8510 - loss: 0.5332 - prc_auc: 0.8805 - precision: 0.8812 - recall: 0.8232 - val_auc: 0.9076 - val_binary_accuracy: 0.8883 - val_f1: 0.5401 - val_loss: 0.4660 - val_prc_auc: 0.6317 - val_precision: 0.4022 - val_recall: 0.8222\n","Epoch 3/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8876 - binary_accuracy: 0.8526 - f1: 0.8482 - loss: 0.4560 - prc_auc: 0.8912 - precision: 0.8794 - recall: 0.8195\n","Epoch 3: Validation Metrics:\n","loss: 0.4239537715911865\n","val_binary_accuracy: 0.8918439745903015\n","val_precision: 0.41111111640930176\n","val_recall: 0.8222222328186035\n","val_auc: 0.9145365357398987\n","val_prc_auc: 0.6671392917633057\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - auc: 0.8890 - binary_accuracy: 0.8538 - f1: 0.8493 - loss: 0.4540 - prc_auc: 0.8923 - precision: 0.8808 - recall: 0.8203 - val_auc: 0.9145 - val_binary_accuracy: 0.8918 - val_f1: 0.5481 - val_loss: 0.3952 - val_prc_auc: 0.6671 - val_precision: 0.4111 - val_recall: 0.8222\n","Epoch 4/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8909 - binary_accuracy: 0.8530 - f1: 0.8486 - loss: 0.4142 - prc_auc: 0.8981 - precision: 0.8802 - recall: 0.8195\n","Epoch 4: Validation Metrics:\n","loss: 0.38164734840393066\n","val_binary_accuracy: 0.8918439745903015\n","val_precision: 0.41111111640930176\n","val_recall: 0.8222222328186035\n","val_auc: 0.9191179871559143\n","val_prc_auc: 0.6917450428009033\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.8923 - binary_accuracy: 0.8542 - f1: 0.8497 - loss: 0.4121 - prc_auc: 0.8993 - precision: 0.8818 - recall: 0.8203 - val_auc: 0.9191 - val_binary_accuracy: 0.8918 - val_f1: 0.5481 - val_loss: 0.3599 - val_prc_auc: 0.6917 - val_precision: 0.4111 - val_recall: 0.8222\n","Epoch 5/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8929 - binary_accuracy: 0.8526 - f1: 0.8482 - loss: 0.3982 - prc_auc: 0.8991 - precision: 0.8794 - recall: 0.8195\n","Epoch 5: Validation Metrics:\n","loss: 0.3632781207561493\n","val_binary_accuracy: 0.8936170339584351\n","val_precision: 0.4157303273677826\n","val_recall: 0.8222222328186035\n","val_auc: 0.92322838306427\n","val_prc_auc: 0.7276493906974792\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.8944 - binary_accuracy: 0.8538 - f1: 0.8493 - loss: 0.3960 - prc_auc: 0.9003 - precision: 0.8808 - recall: 0.8203 - val_auc: 0.9232 - val_binary_accuracy: 0.8936 - val_f1: 0.5522 - val_loss: 0.3454 - val_prc_auc: 0.7276 - val_precision: 0.4157 - val_recall: 0.8222\n","Epoch 6/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8968 - binary_accuracy: 0.8534 - f1: 0.8491 - loss: 0.3924 - prc_auc: 0.9047 - precision: 0.8795 - recall: 0.8211\n","Epoch 6: Validation Metrics:\n","loss: 0.3549867868423462\n","val_binary_accuracy: 0.8936170339584351\n","val_precision: 0.4157303273677826\n","val_recall: 0.8222222328186035\n","val_auc: 0.9270176887512207\n","val_prc_auc: 0.7384756207466125\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - auc: 0.8982 - binary_accuracy: 0.8545 - f1: 0.8502 - loss: 0.3900 - prc_auc: 0.9059 - precision: 0.8810 - recall: 0.8218 - val_auc: 0.9270 - val_binary_accuracy: 0.8936 - val_f1: 0.5522 - val_loss: 0.3381 - val_prc_auc: 0.7385 - val_precision: 0.4157 - val_recall: 0.8222\n","Epoch 7/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8997 - binary_accuracy: 0.8534 - f1: 0.8491 - loss: 0.3886 - prc_auc: 0.9064 - precision: 0.8795 - recall: 0.8211\n","Epoch 7: Validation Metrics:\n","loss: 0.34967583417892456\n","val_binary_accuracy: 0.8936170339584351\n","val_precision: 0.4157303273677826\n","val_recall: 0.8222222328186035\n","val_auc: 0.9294796586036682\n","val_prc_auc: 0.756234884262085\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9010 - binary_accuracy: 0.8546 - f1: 0.8503 - loss: 0.3860 - prc_auc: 0.9074 - precision: 0.8810 - recall: 0.8220 - val_auc: 0.9295 - val_binary_accuracy: 0.8936 - val_f1: 0.5522 - val_loss: 0.3328 - val_prc_auc: 0.7562 - val_precision: 0.4157 - val_recall: 0.8222\n","Epoch 8/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9029 - binary_accuracy: 0.8561 - f1: 0.8515 - loss: 0.3845 - prc_auc: 0.9052 - precision: 0.8845 - recall: 0.8211\n","Epoch 8: Validation Metrics:\n","loss: 0.34514540433883667\n","val_binary_accuracy: 0.8971630930900574\n","val_precision: 0.42696627974510193\n","val_recall: 0.8444444537162781\n","val_auc: 0.930871307849884\n","val_prc_auc: 0.7691689729690552\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9041 - binary_accuracy: 0.8572 - f1: 0.8526 - loss: 0.3820 - prc_auc: 0.9064 - precision: 0.8858 - recall: 0.8220 - val_auc: 0.9309 - val_binary_accuracy: 0.8972 - val_f1: 0.5672 - val_loss: 0.3282 - val_prc_auc: 0.7692 - val_precision: 0.4270 - val_recall: 0.8444\n","Epoch 9/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9064 - binary_accuracy: 0.8561 - f1: 0.8515 - loss: 0.3803 - prc_auc: 0.9068 - precision: 0.8845 - recall: 0.8211\n","Epoch 9: Validation Metrics:\n","loss: 0.34094709157943726\n","val_binary_accuracy: 0.8953900933265686\n","val_precision: 0.42222222685813904\n","val_recall: 0.8444444537162781\n","val_auc: 0.9324126839637756\n","val_prc_auc: 0.7792454361915588\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9076 - binary_accuracy: 0.8572 - f1: 0.8526 - loss: 0.3778 - prc_auc: 0.9080 - precision: 0.8858 - recall: 0.8220 - val_auc: 0.9324 - val_binary_accuracy: 0.8954 - val_f1: 0.5630 - val_loss: 0.3239 - val_prc_auc: 0.7792 - val_precision: 0.4222 - val_recall: 0.8444\n","Epoch 10/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9080 - binary_accuracy: 0.8553 - f1: 0.8506 - loss: 0.3762 - prc_auc: 0.9025 - precision: 0.8844 - recall: 0.8196\n","Epoch 10: Validation Metrics:\n","loss: 0.3370245695114136\n","val_binary_accuracy: 0.8953900933265686\n","val_precision: 0.42222222685813904\n","val_recall: 0.8444444537162781\n","val_auc: 0.9334189891815186\n","val_prc_auc: 0.7763696908950806\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - auc: 0.9092 - binary_accuracy: 0.8564 - f1: 0.8516 - loss: 0.3737 - prc_auc: 0.9036 - precision: 0.8857 - recall: 0.8205 - val_auc: 0.9334 - val_binary_accuracy: 0.8954 - val_f1: 0.5630 - val_loss: 0.3198 - val_prc_auc: 0.7764 - val_precision: 0.4222 - val_recall: 0.8444\n","Epoch 11/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9107 - binary_accuracy: 0.8596 - f1: 0.8541 - loss: 0.3722 - prc_auc: 0.9169 - precision: 0.8924 - recall: 0.8196\n","Epoch 11: Validation Metrics:\n","loss: 0.33332377672195435\n","val_binary_accuracy: 0.8953900933265686\n","val_precision: 0.42222222685813904\n","val_recall: 0.8444444537162781\n","val_auc: 0.935024619102478\n","val_prc_auc: 0.7731479406356812\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9119 - binary_accuracy: 0.8605 - f1: 0.8550 - loss: 0.3697 - prc_auc: 0.9179 - precision: 0.8934 - recall: 0.8205 - val_auc: 0.9350 - val_binary_accuracy: 0.8954 - val_f1: 0.5630 - val_loss: 0.3161 - val_prc_auc: 0.7731 - val_precision: 0.4222 - val_recall: 0.8444\n","Epoch 12/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9120 - binary_accuracy: 0.8610 - f1: 0.8559 - loss: 0.3683 - prc_auc: 0.9121 - precision: 0.8928 - recall: 0.8226\n","Epoch 12: Validation Metrics:\n","loss: 0.3298240900039673\n","val_binary_accuracy: 0.8953900933265686\n","val_precision: 0.42222222685813904\n","val_recall: 0.8444444537162781\n","val_auc: 0.9351744651794434\n","val_prc_auc: 0.7676421999931335\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - auc: 0.9132 - binary_accuracy: 0.8619 - f1: 0.8567 - loss: 0.3658 - prc_auc: 0.9132 - precision: 0.8937 - recall: 0.8234 - val_auc: 0.9352 - val_binary_accuracy: 0.8954 - val_f1: 0.5630 - val_loss: 0.3126 - val_prc_auc: 0.7676 - val_precision: 0.4222 - val_recall: 0.8444\n","Epoch 13/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9140 - binary_accuracy: 0.8610 - f1: 0.8559 - loss: 0.3646 - prc_auc: 0.9172 - precision: 0.8928 - recall: 0.8226\n","Epoch 13: Validation Metrics:\n","loss: 0.3265317380428314\n","val_binary_accuracy: 0.8953900933265686\n","val_precision: 0.42222222685813904\n","val_recall: 0.8444444537162781\n","val_auc: 0.9366945028305054\n","val_prc_auc: 0.7762064337730408\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - auc: 0.9152 - binary_accuracy: 0.8619 - f1: 0.8567 - loss: 0.3622 - prc_auc: 0.9181 - precision: 0.8937 - recall: 0.8234 - val_auc: 0.9367 - val_binary_accuracy: 0.8954 - val_f1: 0.5630 - val_loss: 0.3096 - val_prc_auc: 0.7762 - val_precision: 0.4222 - val_recall: 0.8444\n","Starting training for label: 12\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - auc: 0.8071 - binary_accuracy: 0.6326 - f1: 0.7225 - loss: 0.6618 - prc_auc: 0.8263 - precision: 0.5995 - recall: 0.9189\n","Epoch 1: Validation Metrics:\n","loss: 0.6394951343536377\n","val_binary_accuracy: 0.8226950168609619\n","val_precision: 0.29133859276771545\n","val_recall: 0.7872340679168701\n","val_auc: 0.8901394605636597\n","val_prc_auc: 0.5267401933670044\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 788ms/step - auc: 0.8081 - binary_accuracy: 0.6356 - f1: 0.7236 - loss: 0.6610 - prc_auc: 0.8269 - precision: 0.6020 - recall: 0.9169 - val_auc: 0.8901 - val_binary_accuracy: 0.8227 - val_f1: 0.4253 - val_loss: 0.6177 - val_prc_auc: 0.5267 - val_precision: 0.2913 - val_recall: 0.7872\n","Epoch 2/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8353 - binary_accuracy: 0.7729 - f1: 0.7715 - loss: 0.5857 - prc_auc: 0.8484 - precision: 0.8015 - recall: 0.7441\n","Epoch 2: Validation Metrics:\n","loss: 0.564993679523468\n","val_binary_accuracy: 0.8315602540969849\n","val_precision: 0.30327868461608887\n","val_recall: 0.7872340679168701\n","val_auc: 0.887567400932312\n","val_prc_auc: 0.517013430595398\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - auc: 0.8366 - binary_accuracy: 0.7736 - f1: 0.7717 - loss: 0.5843 - prc_auc: 0.8490 - precision: 0.8020 - recall: 0.7439 - val_auc: 0.8876 - val_binary_accuracy: 0.8316 - val_f1: 0.4379 - val_loss: 0.5382 - val_prc_auc: 0.5170 - val_precision: 0.3033 - val_recall: 0.7872\n","Epoch 3/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8400 - binary_accuracy: 0.7664 - f1: 0.7610 - loss: 0.5374 - prc_auc: 0.8539 - precision: 0.8051 - recall: 0.7220\n","Epoch 3: Validation Metrics:\n","loss: 0.5172613263130188\n","val_binary_accuracy: 0.835106372833252\n","val_precision: 0.3083333373069763\n","val_recall: 0.7872340679168701\n","val_auc: 0.8884933590888977\n","val_prc_auc: 0.5183982849121094\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - auc: 0.8412 - binary_accuracy: 0.7674 - f1: 0.7616 - loss: 0.5360 - prc_auc: 0.8545 - precision: 0.8058 - recall: 0.7224 - val_auc: 0.8885 - val_binary_accuracy: 0.8351 - val_f1: 0.4431 - val_loss: 0.4935 - val_prc_auc: 0.5184 - val_precision: 0.3083 - val_recall: 0.7872\n","Epoch 4/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8445 - binary_accuracy: 0.7639 - f1: 0.7581 - loss: 0.5105 - prc_auc: 0.8591 - precision: 0.8033 - recall: 0.7181\n","Epoch 4: Validation Metrics:\n","loss: 0.4903777539730072\n","val_binary_accuracy: 0.835106372833252\n","val_precision: 0.3083333373069763\n","val_recall: 0.7872340679168701\n","val_auc: 0.8932055234909058\n","val_prc_auc: 0.5497498512268066\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - auc: 0.8456 - binary_accuracy: 0.7649 - f1: 0.7587 - loss: 0.5091 - prc_auc: 0.8597 - precision: 0.8038 - recall: 0.7188 - val_auc: 0.8932 - val_binary_accuracy: 0.8351 - val_f1: 0.4431 - val_loss: 0.4716 - val_prc_auc: 0.5497 - val_precision: 0.3083 - val_recall: 0.7872\n","Epoch 5/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8493 - binary_accuracy: 0.7635 - f1: 0.7571 - loss: 0.4978 - prc_auc: 0.8637 - precision: 0.8046 - recall: 0.7154\n","Epoch 5: Validation Metrics:\n","loss: 0.4766663908958435\n","val_binary_accuracy: 0.8297872543334961\n","val_precision: 0.3008130192756653\n","val_recall: 0.7872340679168701\n","val_auc: 0.8953660726547241\n","val_prc_auc: 0.5653408765792847\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - auc: 0.8503 - binary_accuracy: 0.7646 - f1: 0.7578 - loss: 0.4964 - prc_auc: 0.8643 - precision: 0.8052 - recall: 0.7162 - val_auc: 0.8954 - val_binary_accuracy: 0.8298 - val_f1: 0.4353 - val_loss: 0.4597 - val_prc_auc: 0.5653 - val_precision: 0.3008 - val_recall: 0.7872\n","Epoch 6/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8534 - binary_accuracy: 0.7690 - f1: 0.7636 - loss: 0.4908 - prc_auc: 0.8671 - precision: 0.8080 - recall: 0.7245\n","Epoch 6: Validation Metrics:\n","loss: 0.4685569703578949\n","val_binary_accuracy: 0.8297872543334961\n","val_precision: 0.3008130192756653\n","val_recall: 0.7872340679168701\n","val_auc: 0.8999958634376526\n","val_prc_auc: 0.6170716285705566\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - auc: 0.8543 - binary_accuracy: 0.7703 - f1: 0.7646 - loss: 0.4893 - prc_auc: 0.8676 - precision: 0.8086 - recall: 0.7258 - val_auc: 0.9000 - val_binary_accuracy: 0.8298 - val_f1: 0.4353 - val_loss: 0.4513 - val_prc_auc: 0.6171 - val_precision: 0.3008 - val_recall: 0.7872\n","Epoch 7/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8572 - binary_accuracy: 0.7695 - f1: 0.7641 - loss: 0.4853 - prc_auc: 0.8731 - precision: 0.8085 - recall: 0.7249\n","Epoch 7: Validation Metrics:\n","loss: 0.46239784359931946\n","val_binary_accuracy: 0.8315602540969849\n","val_precision: 0.30327868461608887\n","val_recall: 0.7872340679168701\n","val_auc: 0.901847779750824\n","val_prc_auc: 0.626004695892334\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - auc: 0.8581 - binary_accuracy: 0.7709 - f1: 0.7653 - loss: 0.4837 - prc_auc: 0.8734 - precision: 0.8092 - recall: 0.7264 - val_auc: 0.9018 - val_binary_accuracy: 0.8316 - val_f1: 0.4379 - val_loss: 0.4445 - val_prc_auc: 0.6260 - val_precision: 0.3033 - val_recall: 0.7872\n","Epoch 8/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8594 - binary_accuracy: 0.7696 - f1: 0.7641 - loss: 0.4804 - prc_auc: 0.8745 - precision: 0.8090 - recall: 0.7245\n","Epoch 8: Validation Metrics:\n","loss: 0.45720943808555603\n","val_binary_accuracy: 0.835106372833252\n","val_precision: 0.3083333373069763\n","val_recall: 0.7872340679168701\n","val_auc: 0.9040907025337219\n","val_prc_auc: 0.6324298977851868\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - auc: 0.8603 - binary_accuracy: 0.7711 - f1: 0.7653 - loss: 0.4788 - prc_auc: 0.8748 - precision: 0.8098 - recall: 0.7260 - val_auc: 0.9041 - val_binary_accuracy: 0.8351 - val_f1: 0.4431 - val_loss: 0.4387 - val_prc_auc: 0.6324 - val_precision: 0.3083 - val_recall: 0.7872\n","Starting training for label: 13\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - auc: 0.8421 - binary_accuracy: 0.6790 - f1: 0.7431 - loss: 0.6636 - prc_auc: 0.8203 - precision: 0.6219 - recall: 0.9402\n","Epoch 1: Validation Metrics:\n","loss: 0.6363704204559326\n","val_binary_accuracy: 0.9202127456665039\n","val_precision: 0.5180723071098328\n","val_recall: 0.8958333134651184\n","val_auc: 0.9287386536598206\n","val_prc_auc: 0.5807467699050903\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 778ms/step - auc: 0.8438 - binary_accuracy: 0.6831 - f1: 0.7456 - loss: 0.6626 - prc_auc: 0.8227 - precision: 0.6262 - recall: 0.9386 - val_auc: 0.9287 - val_binary_accuracy: 0.9202 - val_f1: 0.6565 - val_loss: 0.6072 - val_prc_auc: 0.5807 - val_precision: 0.5181 - val_recall: 0.8958\n","Epoch 2/20\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9355 - binary_accuracy: 0.8813 - f1: 0.8704 - loss: 0.5539 - prc_auc: 0.9146 - precision: 0.9202 - recall: 0.8265\n","Epoch 2: Validation Metrics:\n","loss: 0.5343481302261353\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.5243902206420898\n","val_recall: 0.8958333134651184\n","val_auc: 0.9382469654083252\n","val_prc_auc: 0.6084759831428528\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - auc: 0.9347 - binary_accuracy: 0.8811 - f1: 0.8704 - loss: 0.5532 - prc_auc: 0.9144 - precision: 0.9197 - recall: 0.8269 - val_auc: 0.9382 - val_binary_accuracy: 0.9220 - val_f1: 0.6615 - val_loss: 0.5107 - val_prc_auc: 0.6085 - val_precision: 0.5244 - val_recall: 0.8958\n","Epoch 3/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9409 - binary_accuracy: 0.8744 - f1: 0.8612 - loss: 0.4676 - prc_auc: 0.9177 - precision: 0.9196 - recall: 0.8113\n","Epoch 3: Validation Metrics:\n","loss: 0.4537213444709778\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.5243902206420898\n","val_recall: 0.8958333134651184\n","val_auc: 0.9426276087760925\n","val_prc_auc: 0.6127458810806274\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9394 - binary_accuracy: 0.8743 - f1: 0.8616 - loss: 0.4666 - prc_auc: 0.9172 - precision: 0.9186 - recall: 0.8126 - val_auc: 0.9426 - val_binary_accuracy: 0.9220 - val_f1: 0.6615 - val_loss: 0.4279 - val_prc_auc: 0.6127 - val_precision: 0.5244 - val_recall: 0.8958\n","Epoch 4/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9435 - binary_accuracy: 0.8744 - f1: 0.8612 - loss: 0.4019 - prc_auc: 0.9192 - precision: 0.9196 - recall: 0.8113\n","Epoch 4: Validation Metrics:\n","loss: 0.3960988223552704\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.5243902206420898\n","val_recall: 0.8958333134651184\n","val_auc: 0.9448684453964233\n","val_prc_auc: 0.6072906851768494\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - auc: 0.9421 - binary_accuracy: 0.8743 - f1: 0.8616 - loss: 0.4015 - prc_auc: 0.9187 - precision: 0.9186 - recall: 0.8126 - val_auc: 0.9449 - val_binary_accuracy: 0.9220 - val_f1: 0.6615 - val_loss: 0.3736 - val_prc_auc: 0.6073 - val_precision: 0.5244 - val_recall: 0.8958\n","Epoch 5/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9465 - binary_accuracy: 0.8744 - f1: 0.8612 - loss: 0.3602 - prc_auc: 0.9225 - precision: 0.9196 - recall: 0.8113\n","Epoch 5: Validation Metrics:\n","loss: 0.3620575964450836\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.5243902206420898\n","val_recall: 0.8958333134651184\n","val_auc: 0.9453931450843811\n","val_prc_auc: 0.587322473526001\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - auc: 0.9452 - binary_accuracy: 0.8743 - f1: 0.8616 - loss: 0.3603 - prc_auc: 0.9219 - precision: 0.9186 - recall: 0.8126 - val_auc: 0.9454 - val_binary_accuracy: 0.9220 - val_f1: 0.6615 - val_loss: 0.3470 - val_prc_auc: 0.5873 - val_precision: 0.5244 - val_recall: 0.8958\n","Epoch 6/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9490 - binary_accuracy: 0.8764 - f1: 0.8636 - loss: 0.3364 - prc_auc: 0.9233 - precision: 0.9200 - recall: 0.8152\n","Epoch 6: Validation Metrics:\n","loss: 0.34413474798202515\n","val_binary_accuracy: 0.9202127456665039\n","val_precision: 0.5180723071098328\n","val_recall: 0.8958333134651184\n","val_auc: 0.9465842247009277\n","val_prc_auc: 0.5712528228759766\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - auc: 0.9478 - binary_accuracy: 0.8762 - f1: 0.8640 - loss: 0.3370 - prc_auc: 0.9228 - precision: 0.9190 - recall: 0.8166 - val_auc: 0.9466 - val_binary_accuracy: 0.9202 - val_f1: 0.6565 - val_loss: 0.3366 - val_prc_auc: 0.5713 - val_precision: 0.5181 - val_recall: 0.8958\n","Epoch 7/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9517 - binary_accuracy: 0.8783 - f1: 0.8661 - loss: 0.3224 - prc_auc: 0.9266 - precision: 0.9204 - recall: 0.8194\n","Epoch 7: Validation Metrics:\n","loss: 0.33424660563468933\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.523809552192688\n","val_recall: 0.9166666865348816\n","val_auc: 0.9470688104629517\n","val_prc_auc: 0.5602073669433594\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9505 - binary_accuracy: 0.8782 - f1: 0.8665 - loss: 0.3233 - prc_auc: 0.9259 - precision: 0.9194 - recall: 0.8208 - val_auc: 0.9471 - val_binary_accuracy: 0.9220 - val_f1: 0.6667 - val_loss: 0.3317 - val_prc_auc: 0.5602 - val_precision: 0.5238 - val_recall: 0.9167\n","Epoch 8/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9534 - binary_accuracy: 0.8841 - f1: 0.8736 - loss: 0.3132 - prc_auc: 0.9286 - precision: 0.9206 - recall: 0.8322\n","Epoch 8: Validation Metrics:\n","loss: 0.3279467225074768\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.523809552192688\n","val_recall: 0.9166666865348816\n","val_auc: 0.9469072818756104\n","val_prc_auc: 0.5524898171424866\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9523 - binary_accuracy: 0.8838 - f1: 0.8737 - loss: 0.3143 - prc_auc: 0.9280 - precision: 0.9195 - recall: 0.8332 - val_auc: 0.9469 - val_binary_accuracy: 0.9220 - val_f1: 0.6667 - val_loss: 0.3288 - val_prc_auc: 0.5525 - val_precision: 0.5238 - val_recall: 0.9167\n","Epoch 9/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9538 - binary_accuracy: 0.8860 - f1: 0.8760 - loss: 0.3064 - prc_auc: 0.9231 - precision: 0.9210 - recall: 0.8362\n","Epoch 9: Validation Metrics:\n","loss: 0.3232468068599701\n","val_binary_accuracy: 0.9219858050346375\n","val_precision: 0.523809552192688\n","val_recall: 0.9166666865348816\n","val_auc: 0.9486030340194702\n","val_prc_auc: 0.5967835187911987\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9527 - binary_accuracy: 0.8856 - f1: 0.8760 - loss: 0.3077 - prc_auc: 0.9223 - precision: 0.9199 - recall: 0.8371 - val_auc: 0.9486 - val_binary_accuracy: 0.9220 - val_f1: 0.6667 - val_loss: 0.3265 - val_prc_auc: 0.5968 - val_precision: 0.5238 - val_recall: 0.9167\n","Epoch 10/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9556 - binary_accuracy: 0.8873 - f1: 0.8775 - loss: 0.3009 - prc_auc: 0.9317 - precision: 0.9212 - recall: 0.8387\n","Epoch 10: Validation Metrics:\n","loss: 0.31935548782348633\n","val_binary_accuracy: 0.9202127456665039\n","val_precision: 0.5176470875740051\n","val_recall: 0.9166666865348816\n","val_auc: 0.9484819173812866\n","val_prc_auc: 0.573845624923706\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - auc: 0.9545 - binary_accuracy: 0.8869 - f1: 0.8775 - loss: 0.3022 - prc_auc: 0.9308 - precision: 0.9201 - recall: 0.8396 - val_auc: 0.9485 - val_binary_accuracy: 0.9202 - val_f1: 0.6617 - val_loss: 0.3241 - val_prc_auc: 0.5738 - val_precision: 0.5176 - val_recall: 0.9167\n","Epoch 11/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9568 - binary_accuracy: 0.8877 - f1: 0.8780 - loss: 0.2962 - prc_auc: 0.9346 - precision: 0.9213 - recall: 0.8397\n","Epoch 11: Validation Metrics:\n","loss: 0.31599316000938416\n","val_binary_accuracy: 0.9202127456665039\n","val_precision: 0.5176470875740051\n","val_recall: 0.9166666865348816\n","val_auc: 0.9464429616928101\n","val_prc_auc: 0.5876381993293762\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9557 - binary_accuracy: 0.8874 - f1: 0.8781 - loss: 0.2977 - prc_auc: 0.9337 - precision: 0.9202 - recall: 0.8407 - val_auc: 0.9464 - val_binary_accuracy: 0.9202 - val_f1: 0.6617 - val_loss: 0.3219 - val_prc_auc: 0.5876 - val_precision: 0.5176 - val_recall: 0.9167\n","Epoch 12/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9574 - binary_accuracy: 0.8885 - f1: 0.8797 - loss: 0.2921 - prc_auc: 0.9356 - precision: 0.9159 - recall: 0.8473\n","Epoch 12: Validation Metrics:\n","loss: 0.31295907497406006\n","val_binary_accuracy: 0.9184397459030151\n","val_precision: 0.5116279125213623\n","val_recall: 0.9166666865348816\n","val_auc: 0.946220874786377\n","val_prc_auc: 0.5806110501289368\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - auc: 0.9563 - binary_accuracy: 0.8882 - f1: 0.8798 - loss: 0.2936 - prc_auc: 0.9347 - precision: 0.9151 - recall: 0.8481 - val_auc: 0.9462 - val_binary_accuracy: 0.9184 - val_f1: 0.6567 - val_loss: 0.3198 - val_prc_auc: 0.5806 - val_precision: 0.5116 - val_recall: 0.9167\n","Starting training for label: 14\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - auc: 0.5934 - binary_accuracy: 0.5327 - f1: 0.4909 - loss: 0.6847 - prc_auc: 0.5607 - precision: 0.5200 - recall: 0.4761\n","Epoch 1: Validation Metrics:\n","loss: 0.6635516285896301\n","val_binary_accuracy: 0.8705673813819885\n","val_precision: 0.3366336524486542\n","val_recall: 0.8500000238418579\n","val_auc: 0.9042223691940308\n","val_prc_auc: 0.4446812868118286\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 736ms/step - auc: 0.6008 - binary_accuracy: 0.5385 - f1: 0.4973 - loss: 0.6839 - prc_auc: 0.5689 - precision: 0.5277 - recall: 0.4810 - val_auc: 0.9042 - val_binary_accuracy: 0.8706 - val_f1: 0.4823 - val_loss: 0.6166 - val_prc_auc: 0.4447 - val_precision: 0.3366 - val_recall: 0.8500\n","Epoch 2/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8671 - binary_accuracy: 0.7931 - f1: 0.7603 - loss: 0.6034 - prc_auc: 0.8505 - precision: 0.8024 - recall: 0.7229\n","Epoch 2: Validation Metrics:\n","loss: 0.587700605392456\n","val_binary_accuracy: 0.8617021441459656\n","val_precision: 0.3207547068595886\n","val_recall: 0.8500000238418579\n","val_auc: 0.9016698002815247\n","val_prc_auc: 0.4337063431739807\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - auc: 0.8672 - binary_accuracy: 0.7929 - f1: 0.7608 - loss: 0.6028 - prc_auc: 0.8511 - precision: 0.8034 - recall: 0.7230 - val_auc: 0.9017 - val_binary_accuracy: 0.8617 - val_f1: 0.4658 - val_loss: 0.5491 - val_prc_auc: 0.4337 - val_precision: 0.3208 - val_recall: 0.8500\n","Epoch 3/20\n","\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8681 - binary_accuracy: 0.7871 - f1: 0.7555 - loss: 0.5448 - prc_auc: 0.8475 - precision: 0.7857 - recall: 0.7281\n","Epoch 3: Validation Metrics:\n","loss: 0.5311992168426514\n","val_binary_accuracy: 0.8617021441459656\n","val_precision: 0.3207547068595886\n","val_recall: 0.8500000238418579\n","val_auc: 0.9020276665687561\n","val_prc_auc: 0.44748175144195557\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - auc: 0.8687 - binary_accuracy: 0.7869 - f1: 0.7567 - loss: 0.5438 - prc_auc: 0.8495 - precision: 0.7883 - recall: 0.7282 - val_auc: 0.9020 - val_binary_accuracy: 0.8617 - val_f1: 0.4658 - val_loss: 0.4970 - val_prc_auc: 0.4475 - val_precision: 0.3208 - val_recall: 0.8500\n","Epoch 4/20\n","\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8704 - binary_accuracy: 0.7887 - f1: 0.7576 - loss: 0.5016 - prc_auc: 0.8491 - precision: 0.7864 - recall: 0.7314\n","Epoch 4: Validation Metrics:\n","loss: 0.4900406301021576\n","val_binary_accuracy: 0.8617021441459656\n","val_precision: 0.32407405972480774\n","val_recall: 0.875\n","val_auc: 0.9022662043571472\n","val_prc_auc: 0.43739235401153564\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - auc: 0.8712 - binary_accuracy: 0.7889 - f1: 0.7593 - loss: 0.5007 - prc_auc: 0.8514 - precision: 0.7891 - recall: 0.7322 - val_auc: 0.9023 - val_binary_accuracy: 0.8617 - val_f1: 0.4730 - val_loss: 0.4634 - val_prc_auc: 0.4374 - val_precision: 0.3241 - val_recall: 0.8750\n","Epoch 5/20\n","\u001b[1m24/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8732 - binary_accuracy: 0.7915 - f1: 0.7617 - loss: 0.4731 - prc_auc: 0.8516 - precision: 0.7860 - recall: 0.7393\n","Epoch 5: Validation Metrics:\n","loss: 0.46233272552490234\n","val_binary_accuracy: 0.859929084777832\n","val_precision: 0.3211009204387665\n","val_recall: 0.875\n","val_auc: 0.9044370651245117\n","val_prc_auc: 0.4512847065925598\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - auc: 0.8741 - binary_accuracy: 0.7918 - f1: 0.7637 - loss: 0.4723 - prc_auc: 0.8540 - precision: 0.7888 - recall: 0.7404 - val_auc: 0.9044 - val_binary_accuracy: 0.8599 - val_f1: 0.4698 - val_loss: 0.4439 - val_prc_auc: 0.4513 - val_precision: 0.3211 - val_recall: 0.8750\n","Epoch 6/20\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8779 - binary_accuracy: 0.8028 - f1: 0.7767 - loss: 0.4547 - prc_auc: 0.8564 - precision: 0.7944 - recall: 0.7601\n","Epoch 6: Validation Metrics:\n","loss: 0.44410574436187744\n","val_binary_accuracy: 0.8581560254096985\n","val_precision: 0.3181818127632141\n","val_recall: 0.875\n","val_auc: 0.9054388403892517\n","val_prc_auc: 0.4627194106578827\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - auc: 0.8783 - binary_accuracy: 0.8030 - f1: 0.7777 - loss: 0.4543 - prc_auc: 0.8574 - precision: 0.7957 - recall: 0.7609 - val_auc: 0.9054 - val_binary_accuracy: 0.8582 - val_f1: 0.4667 - val_loss: 0.4308 - val_prc_auc: 0.4627 - val_precision: 0.3182 - val_recall: 0.8750\n","Starting training for label: 15\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - auc: 0.5256 - binary_accuracy: 0.5177 - f1: 0.3597 - loss: 0.6933 - prc_auc: 0.5598 - precision: 0.6448 - recall: 0.2989\n","Epoch 1: Validation Metrics:\n","loss: 0.6897329688072205\n","val_binary_accuracy: 0.3156028389930725\n","val_precision: 0.08809524029493332\n","val_recall: 0.925000011920929\n","val_auc: 0.6245944499969482\n","val_prc_auc: 0.09433261305093765\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 875ms/step - auc: 0.5275 - binary_accuracy: 0.5192 - f1: 0.3683 - loss: 0.6931 - prc_auc: 0.5606 - precision: 0.6406 - recall: 0.3100 - val_auc: 0.6246 - val_binary_accuracy: 0.3156 - val_f1: 0.1609 - val_loss: 0.7023 - val_prc_auc: 0.0943 - val_precision: 0.0881 - val_recall: 0.9250\n","Epoch 2/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6709 - binary_accuracy: 0.6169 - f1: 0.7060 - loss: 0.6806 - prc_auc: 0.6689 - precision: 0.5867 - recall: 0.8865\n","Epoch 2: Validation Metrics:\n","loss: 0.679205060005188\n","val_binary_accuracy: 0.3439716398715973\n","val_precision: 0.08542713522911072\n","val_recall: 0.8500000238418579\n","val_auc: 0.6319179534912109\n","val_prc_auc: 0.1017289012670517\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - auc: 0.6707 - binary_accuracy: 0.6161 - f1: 0.7051 - loss: 0.6805 - prc_auc: 0.6682 - precision: 0.5858 - recall: 0.8857 - val_auc: 0.6319 - val_binary_accuracy: 0.3440 - val_f1: 0.1553 - val_loss: 0.7048 - val_prc_auc: 0.1017 - val_precision: 0.0854 - val_recall: 0.8500\n","Epoch 3/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6735 - binary_accuracy: 0.6287 - f1: 0.7131 - loss: 0.6742 - prc_auc: 0.6746 - precision: 0.5953 - recall: 0.8891\n","Epoch 3: Validation Metrics:\n","loss: 0.6722108125686646\n","val_binary_accuracy: 0.38652482628822327\n","val_precision: 0.08648648858070374\n","val_recall: 0.800000011920929\n","val_auc: 0.6362118124961853\n","val_prc_auc: 0.10064273327589035\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.6739 - binary_accuracy: 0.6283 - f1: 0.7123 - loss: 0.6741 - prc_auc: 0.6740 - precision: 0.5946 - recall: 0.8882 - val_auc: 0.6362 - val_binary_accuracy: 0.3865 - val_f1: 0.1561 - val_loss: 0.6987 - val_prc_auc: 0.1006 - val_precision: 0.0865 - val_recall: 0.8000\n","Epoch 4/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6793 - binary_accuracy: 0.6334 - f1: 0.7090 - loss: 0.6694 - prc_auc: 0.6849 - precision: 0.6026 - recall: 0.8614\n","Epoch 4: Validation Metrics:\n","loss: 0.6665730476379395\n","val_binary_accuracy: 0.4131205677986145\n","val_precision: 0.09014084190130234\n","val_recall: 0.800000011920929\n","val_auc: 0.6398617029190063\n","val_prc_auc: 0.10745194554328918\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - auc: 0.6797 - binary_accuracy: 0.6331 - f1: 0.7082 - loss: 0.6692 - prc_auc: 0.6842 - precision: 0.6020 - recall: 0.8602 - val_auc: 0.6399 - val_binary_accuracy: 0.4131 - val_f1: 0.1620 - val_loss: 0.6930 - val_prc_auc: 0.1075 - val_precision: 0.0901 - val_recall: 0.8000\n","Epoch 5/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6828 - binary_accuracy: 0.6414 - f1: 0.7103 - loss: 0.6653 - prc_auc: 0.6887 - precision: 0.6110 - recall: 0.8487\n","Epoch 5: Validation Metrics:\n","loss: 0.6618112921714783\n","val_binary_accuracy: 0.4379432499408722\n","val_precision: 0.09384164214134216\n","val_recall: 0.800000011920929\n","val_auc: 0.6448712348937988\n","val_prc_auc: 0.11015789210796356\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.6834 - binary_accuracy: 0.6410 - f1: 0.7094 - loss: 0.6652 - prc_auc: 0.6879 - precision: 0.6104 - recall: 0.8473 - val_auc: 0.6449 - val_binary_accuracy: 0.4379 - val_f1: 0.1680 - val_loss: 0.6887 - val_prc_auc: 0.1102 - val_precision: 0.0938 - val_recall: 0.8000\n","Epoch 6/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6857 - binary_accuracy: 0.6486 - f1: 0.7108 - loss: 0.6618 - prc_auc: 0.6943 - precision: 0.6200 - recall: 0.8335\n","Epoch 6: Validation Metrics:\n","loss: 0.6576610207557678\n","val_binary_accuracy: 0.4521276652812958\n","val_precision: 0.09609609842300415\n","val_recall: 0.800000011920929\n","val_auc: 0.6469942331314087\n","val_prc_auc: 0.11131225526332855\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.6864 - binary_accuracy: 0.6482 - f1: 0.7099 - loss: 0.6616 - prc_auc: 0.6937 - precision: 0.6194 - recall: 0.8321 - val_auc: 0.6470 - val_binary_accuracy: 0.4521 - val_f1: 0.1716 - val_loss: 0.6849 - val_prc_auc: 0.1113 - val_precision: 0.0961 - val_recall: 0.8000\n","Epoch 7/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6898 - binary_accuracy: 0.6467 - f1: 0.7054 - loss: 0.6586 - prc_auc: 0.6990 - precision: 0.6216 - recall: 0.8164\n","Epoch 7: Validation Metrics:\n","loss: 0.6538896560668945\n","val_binary_accuracy: 0.4716311991214752\n","val_precision: 0.09687499701976776\n","val_recall: 0.7749999761581421\n","val_auc: 0.648878812789917\n","val_prc_auc: 0.10940469801425934\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - auc: 0.6906 - binary_accuracy: 0.6466 - f1: 0.7047 - loss: 0.6584 - prc_auc: 0.6984 - precision: 0.6212 - recall: 0.8152 - val_auc: 0.6489 - val_binary_accuracy: 0.4716 - val_f1: 0.1722 - val_loss: 0.6819 - val_prc_auc: 0.1094 - val_precision: 0.0969 - val_recall: 0.7750\n","Epoch 8/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6919 - binary_accuracy: 0.6494 - f1: 0.7035 - loss: 0.6557 - prc_auc: 0.7004 - precision: 0.6268 - recall: 0.8023\n","Epoch 8: Validation Metrics:\n","loss: 0.650425374507904\n","val_binary_accuracy: 0.48049646615982056\n","val_precision: 0.09841269999742508\n","val_recall: 0.7749999761581421\n","val_auc: 0.651121199131012\n","val_prc_auc: 0.11372315883636475\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.6927 - binary_accuracy: 0.6493 - f1: 0.7028 - loss: 0.6554 - prc_auc: 0.6999 - precision: 0.6263 - recall: 0.8013 - val_auc: 0.6511 - val_binary_accuracy: 0.4805 - val_f1: 0.1746 - val_loss: 0.6797 - val_prc_auc: 0.1137 - val_precision: 0.0984 - val_recall: 0.7750\n","Epoch 9/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6957 - binary_accuracy: 0.6540 - f1: 0.7062 - loss: 0.6528 - prc_auc: 0.7046 - precision: 0.6312 - recall: 0.8023\n","Epoch 9: Validation Metrics:\n","loss: 0.6471458673477173\n","val_binary_accuracy: 0.49113476276397705\n","val_precision: 0.1003236249089241\n","val_recall: 0.7749999761581421\n","val_auc: 0.6503578424453735\n","val_prc_auc: 0.11554110050201416\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - auc: 0.6966 - binary_accuracy: 0.6539 - f1: 0.7056 - loss: 0.6526 - prc_auc: 0.7041 - precision: 0.6307 - recall: 0.8013 - val_auc: 0.6504 - val_binary_accuracy: 0.4911 - val_f1: 0.1777 - val_loss: 0.6775 - val_prc_auc: 0.1155 - val_precision: 0.1003 - val_recall: 0.7750\n","Epoch 10/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7002 - binary_accuracy: 0.6509 - f1: 0.6985 - loss: 0.6500 - prc_auc: 0.7091 - precision: 0.6337 - recall: 0.7785\n","Epoch 10: Validation Metrics:\n","loss: 0.6439646482467651\n","val_binary_accuracy: 0.51241135597229\n","val_precision: 0.10169491171836853\n","val_recall: 0.75\n","val_auc: 0.6501192450523376\n","val_prc_auc: 0.11604579538106918\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7012 - binary_accuracy: 0.6511 - f1: 0.6982 - loss: 0.6498 - prc_auc: 0.7086 - precision: 0.6334 - recall: 0.7782 - val_auc: 0.6501 - val_binary_accuracy: 0.5124 - val_f1: 0.1791 - val_loss: 0.6758 - val_prc_auc: 0.1160 - val_precision: 0.1017 - val_recall: 0.7500\n","Epoch 11/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7026 - binary_accuracy: 0.6577 - f1: 0.7038 - loss: 0.6473 - prc_auc: 0.7094 - precision: 0.6399 - recall: 0.7822\n","Epoch 11: Validation Metrics:\n","loss: 0.640902042388916\n","val_binary_accuracy: 0.5265957713127136\n","val_precision: 0.10452961921691895\n","val_recall: 0.75\n","val_auc: 0.6526240110397339\n","val_prc_auc: 0.11622165888547897\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7036 - binary_accuracy: 0.6580 - f1: 0.7035 - loss: 0.6470 - prc_auc: 0.7088 - precision: 0.6397 - recall: 0.7820 - val_auc: 0.6526 - val_binary_accuracy: 0.5266 - val_f1: 0.1835 - val_loss: 0.6742 - val_prc_auc: 0.1162 - val_precision: 0.1045 - val_recall: 0.7500\n","Epoch 12/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7062 - binary_accuracy: 0.6627 - f1: 0.7069 - loss: 0.6447 - prc_auc: 0.7141 - precision: 0.6451 - recall: 0.7822\n","Epoch 12: Validation Metrics:\n","loss: 0.6379266977310181\n","val_binary_accuracy: 0.533687949180603\n","val_precision: 0.10600706934928894\n","val_recall: 0.75\n","val_auc: 0.6553912162780762\n","val_prc_auc: 0.11775253713130951\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - auc: 0.7073 - binary_accuracy: 0.6631 - f1: 0.7067 - loss: 0.6444 - prc_auc: 0.7136 - precision: 0.6450 - recall: 0.7820 - val_auc: 0.6554 - val_binary_accuracy: 0.5337 - val_f1: 0.1858 - val_loss: 0.6726 - val_prc_auc: 0.1178 - val_precision: 0.1060 - val_recall: 0.7500\n","Epoch 13/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7101 - binary_accuracy: 0.6586 - f1: 0.7008 - loss: 0.6420 - prc_auc: 0.7193 - precision: 0.6445 - recall: 0.7684\n","Epoch 13: Validation Metrics:\n","loss: 0.634976863861084\n","val_binary_accuracy: 0.5372340679168701\n","val_precision: 0.10676156729459763\n","val_recall: 0.75\n","val_auc: 0.6552003026008606\n","val_prc_auc: 0.11679056286811829\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - auc: 0.7112 - binary_accuracy: 0.6594 - f1: 0.7010 - loss: 0.6417 - prc_auc: 0.7188 - precision: 0.6446 - recall: 0.7687 - val_auc: 0.6552 - val_binary_accuracy: 0.5372 - val_f1: 0.1869 - val_loss: 0.6713 - val_prc_auc: 0.1168 - val_precision: 0.1068 - val_recall: 0.7500\n","Epoch 14/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7127 - binary_accuracy: 0.6673 - f1: 0.7080 - loss: 0.6394 - prc_auc: 0.7211 - precision: 0.6519 - recall: 0.7751\n","Epoch 14: Validation Metrics:\n","loss: 0.6320732235908508\n","val_binary_accuracy: 0.542553186416626\n","val_precision: 0.10507246106863022\n","val_recall: 0.7250000238418579\n","val_auc: 0.6564885377883911\n","val_prc_auc: 0.1166735514998436\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7137 - binary_accuracy: 0.6681 - f1: 0.7081 - loss: 0.6390 - prc_auc: 0.7207 - precision: 0.6521 - recall: 0.7751 - val_auc: 0.6565 - val_binary_accuracy: 0.5426 - val_f1: 0.1835 - val_loss: 0.6704 - val_prc_auc: 0.1167 - val_precision: 0.1051 - val_recall: 0.7250\n","Epoch 15/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7163 - binary_accuracy: 0.6663 - f1: 0.7063 - loss: 0.6367 - prc_auc: 0.7247 - precision: 0.6519 - recall: 0.7712\n","Epoch 15: Validation Metrics:\n","loss: 0.6292011141777039\n","val_binary_accuracy: 0.5478723645210266\n","val_precision: 0.10622710734605789\n","val_recall: 0.7250000238418579\n","val_auc: 0.6570848822593689\n","val_prc_auc: 0.11681927740573883\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7173 - binary_accuracy: 0.6672 - f1: 0.7065 - loss: 0.6364 - prc_auc: 0.7243 - precision: 0.6522 - recall: 0.7712 - val_auc: 0.6571 - val_binary_accuracy: 0.5479 - val_f1: 0.1853 - val_loss: 0.6697 - val_prc_auc: 0.1168 - val_precision: 0.1062 - val_recall: 0.7250\n","Epoch 16/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7189 - binary_accuracy: 0.6729 - f1: 0.7116 - loss: 0.6341 - prc_auc: 0.7283 - precision: 0.6579 - recall: 0.7754\n","Epoch 16: Validation Metrics:\n","loss: 0.6263759732246399\n","val_binary_accuracy: 0.5585106611251831\n","val_precision: 0.1086142286658287\n","val_recall: 0.7250000238418579\n","val_auc: 0.6574666500091553\n","val_prc_auc: 0.11566268652677536\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - auc: 0.7200 - binary_accuracy: 0.6740 - f1: 0.7120 - loss: 0.6338 - prc_auc: 0.7279 - precision: 0.6584 - recall: 0.7756 - val_auc: 0.6575 - val_binary_accuracy: 0.5585 - val_f1: 0.1889 - val_loss: 0.6693 - val_prc_auc: 0.1157 - val_precision: 0.1086 - val_recall: 0.7250\n","Epoch 17/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7208 - binary_accuracy: 0.6796 - f1: 0.7150 - loss: 0.6315 - prc_auc: 0.7298 - precision: 0.6654 - recall: 0.7730\n","Epoch 17: Validation Metrics:\n","loss: 0.6235840320587158\n","val_binary_accuracy: 0.563829779624939\n","val_precision: 0.10687022656202316\n","val_recall: 0.699999988079071\n","val_auc: 0.6587309241294861\n","val_prc_auc: 0.11685998737812042\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7219 - binary_accuracy: 0.6804 - f1: 0.7153 - loss: 0.6312 - prc_auc: 0.7294 - precision: 0.6657 - recall: 0.7732 - val_auc: 0.6587 - val_binary_accuracy: 0.5638 - val_f1: 0.1854 - val_loss: 0.6686 - val_prc_auc: 0.1169 - val_precision: 0.1069 - val_recall: 0.7000\n","Epoch 18/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7241 - binary_accuracy: 0.6767 - f1: 0.7100 - loss: 0.6290 - prc_auc: 0.7328 - precision: 0.6660 - recall: 0.7604\n","Epoch 18: Validation Metrics:\n","loss: 0.620796263217926\n","val_binary_accuracy: 0.5620567202568054\n","val_precision: 0.10646387934684753\n","val_recall: 0.699999988079071\n","val_auc: 0.658492386341095\n","val_prc_auc: 0.11627697199583054\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7251 - binary_accuracy: 0.6778 - f1: 0.7104 - loss: 0.6286 - prc_auc: 0.7324 - precision: 0.6664 - recall: 0.7609 - val_auc: 0.6585 - val_binary_accuracy: 0.5621 - val_f1: 0.1848 - val_loss: 0.6681 - val_prc_auc: 0.1163 - val_precision: 0.1065 - val_recall: 0.7000\n","Epoch 19/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7258 - binary_accuracy: 0.6803 - f1: 0.7124 - loss: 0.6264 - prc_auc: 0.7354 - precision: 0.6696 - recall: 0.7614\n","Epoch 19: Validation Metrics:\n","loss: 0.6180046200752258\n","val_binary_accuracy: 0.5691489577293396\n","val_precision: 0.10810811072587967\n","val_recall: 0.699999988079071\n","val_auc: 0.6601860523223877\n","val_prc_auc: 0.11604718863964081\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7269 - binary_accuracy: 0.6812 - f1: 0.7127 - loss: 0.6260 - prc_auc: 0.7350 - precision: 0.6698 - recall: 0.7618 - val_auc: 0.6602 - val_binary_accuracy: 0.5691 - val_f1: 0.1873 - val_loss: 0.6677 - val_prc_auc: 0.1160 - val_precision: 0.1081 - val_recall: 0.7000\n","Epoch 20/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7279 - binary_accuracy: 0.6778 - f1: 0.7090 - loss: 0.6238 - prc_auc: 0.7375 - precision: 0.6692 - recall: 0.7541\n","Epoch 20: Validation Metrics:\n","loss: 0.6152126789093018\n","val_binary_accuracy: 0.5656028389930725\n","val_precision: 0.1072796955704689\n","val_recall: 0.699999988079071\n","val_auc: 0.6605916023254395\n","val_prc_auc: 0.11731494218111038\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - auc: 0.7290 - binary_accuracy: 0.6789 - f1: 0.7095 - loss: 0.6234 - prc_auc: 0.7372 - precision: 0.6696 - recall: 0.7546 - val_auc: 0.6606 - val_binary_accuracy: 0.5656 - val_f1: 0.1860 - val_loss: 0.6674 - val_prc_auc: 0.1173 - val_precision: 0.1073 - val_recall: 0.7000\n","Starting training for label: 16\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - auc: 0.6241 - binary_accuracy: 0.5977 - f1: 0.4539 - loss: 0.6863 - prc_auc: 0.6173 - precision: 0.6818 - recall: 0.3438\n","Epoch 1: Validation Metrics:\n","loss: 0.6815418601036072\n","val_binary_accuracy: 0.686170220375061\n","val_precision: 0.16402116417884827\n","val_recall: 0.6200000047683716\n","val_auc: 0.694299578666687\n","val_prc_auc: 0.1722712516784668\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 848ms/step - auc: 0.6261 - binary_accuracy: 0.5996 - f1: 0.4585 - loss: 0.6861 - prc_auc: 0.6184 - precision: 0.6837 - recall: 0.3486 - val_auc: 0.6943 - val_binary_accuracy: 0.6862 - val_f1: 0.2594 - val_loss: 0.6736 - val_prc_auc: 0.1723 - val_precision: 0.1640 - val_recall: 0.6200\n","Epoch 2/20\n","\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7420 - binary_accuracy: 0.6984 - f1: 0.6630 - loss: 0.6628 - prc_auc: 0.7305 - precision: 0.7678 - recall: 0.5837\n","Epoch 2: Validation Metrics:\n","loss: 0.659223735332489\n","val_binary_accuracy: 0.695035457611084\n","val_precision: 0.16483516991138458\n","val_recall: 0.6000000238418579\n","val_auc: 0.7102334499359131\n","val_prc_auc: 0.2615463137626648\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - auc: 0.7413 - binary_accuracy: 0.6986 - f1: 0.6628 - loss: 0.6625 - prc_auc: 0.7305 - precision: 0.7673 - recall: 0.5837 - val_auc: 0.7102 - val_binary_accuracy: 0.6950 - val_f1: 0.2586 - val_loss: 0.6526 - val_prc_auc: 0.2615 - val_precision: 0.1648 - val_recall: 0.6000\n","Epoch 3/20\n","\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7609 - binary_accuracy: 0.6760 - f1: 0.6324 - loss: 0.6458 - prc_auc: 0.7575 - precision: 0.7448 - recall: 0.5499\n","Epoch 3: Validation Metrics:\n","loss: 0.6422831416130066\n","val_binary_accuracy: 0.6843971610069275\n","val_precision: 0.15591397881507874\n","val_recall: 0.5799999833106995\n","val_auc: 0.716926097869873\n","val_prc_auc: 0.3183425962924957\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - auc: 0.7600 - binary_accuracy: 0.6772 - f1: 0.6338 - loss: 0.6455 - prc_auc: 0.7580 - precision: 0.7449 - recall: 0.5518 - val_auc: 0.7169 - val_binary_accuracy: 0.6844 - val_f1: 0.2458 - val_loss: 0.6388 - val_prc_auc: 0.3183 - val_precision: 0.1559 - val_recall: 0.5800\n","Epoch 4/20\n","\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7716 - binary_accuracy: 0.6809 - f1: 0.6420 - loss: 0.6310 - prc_auc: 0.7732 - precision: 0.7461 - recall: 0.5637\n","Epoch 4: Validation Metrics:\n","loss: 0.627456784248352\n","val_binary_accuracy: 0.6879432797431946\n","val_precision: 0.16129031777381897\n","val_recall: 0.6000000238418579\n","val_auc: 0.7218483090400696\n","val_prc_auc: 0.3453734517097473\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - auc: 0.7707 - binary_accuracy: 0.6814 - f1: 0.6426 - loss: 0.6307 - prc_auc: 0.7740 - precision: 0.7455 - recall: 0.5650 - val_auc: 0.7218 - val_binary_accuracy: 0.6879 - val_f1: 0.2542 - val_loss: 0.6295 - val_prc_auc: 0.3454 - val_precision: 0.1613 - val_recall: 0.6000\n","Epoch 5/20\n","\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7786 - binary_accuracy: 0.6906 - f1: 0.6583 - loss: 0.6175 - prc_auc: 0.7864 - precision: 0.7505 - recall: 0.5866\n","Epoch 5: Validation Metrics:\n","loss: 0.6140071749687195\n","val_binary_accuracy: 0.6843971610069275\n","val_precision: 0.1631578952074051\n","val_recall: 0.6200000047683716\n","val_auc: 0.7268871665000916\n","val_prc_auc: 0.35212889313697815\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - auc: 0.7777 - binary_accuracy: 0.6907 - f1: 0.6582 - loss: 0.6172 - prc_auc: 0.7870 - precision: 0.7497 - recall: 0.5869 - val_auc: 0.7269 - val_binary_accuracy: 0.6844 - val_f1: 0.2583 - val_loss: 0.6215 - val_prc_auc: 0.3521 - val_precision: 0.1632 - val_recall: 0.6200\n","Epoch 6/20\n","\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7832 - binary_accuracy: 0.6877 - f1: 0.6566 - loss: 0.6051 - prc_auc: 0.7910 - precision: 0.7446 - recall: 0.5876\n","Epoch 6: Validation Metrics:\n","loss: 0.6017785668373108\n","val_binary_accuracy: 0.682624101638794\n","val_precision: 0.16230367124080658\n","val_recall: 0.6200000047683716\n","val_auc: 0.7302917838096619\n","val_prc_auc: 0.3709002137184143\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - auc: 0.7822 - binary_accuracy: 0.6878 - f1: 0.6564 - loss: 0.6048 - prc_auc: 0.7915 - precision: 0.7437 - recall: 0.5878 - val_auc: 0.7303 - val_binary_accuracy: 0.6826 - val_f1: 0.2573 - val_loss: 0.6141 - val_prc_auc: 0.3709 - val_precision: 0.1623 - val_recall: 0.6200\n","Starting training for label: 17\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - auc: 0.6654 - binary_accuracy: 0.5208 - f1: 0.6029 - loss: 0.6877 - prc_auc: 0.6309 - precision: 0.4876 - recall: 0.8225\n","Epoch 1: Validation Metrics:\n","loss: 0.6803796887397766\n","val_binary_accuracy: 0.8120567202568054\n","val_precision: 0.0776699036359787\n","val_recall: 0.42105263471603394\n","val_auc: 0.6409463882446289\n","val_prc_auc: 0.05500461161136627\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - auc: 0.6649 - binary_accuracy: 0.5250 - f1: 0.6034 - loss: 0.6872 - prc_auc: 0.6348 - precision: 0.4935 - recall: 0.8106 - val_auc: 0.6409 - val_binary_accuracy: 0.8121 - val_f1: 0.1311 - val_loss: 0.6705 - val_prc_auc: 0.0550 - val_precision: 0.0777 - val_recall: 0.4211\n","Epoch 2/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7822 - binary_accuracy: 0.7325 - f1: 0.6665 - loss: 0.6531 - prc_auc: 0.7420 - precision: 0.7532 - recall: 0.5986\n","Epoch 2: Validation Metrics:\n","loss: 0.6536906957626343\n","val_binary_accuracy: 0.8209219574928284\n","val_precision: 0.09000000357627869\n","val_recall: 0.4736842215061188\n","val_auc: 0.6402221322059631\n","val_prc_auc: 0.054885752499103546\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - auc: 0.7784 - binary_accuracy: 0.7289 - f1: 0.6639 - loss: 0.6532 - prc_auc: 0.7416 - precision: 0.7531 - recall: 0.5946 - val_auc: 0.6402 - val_binary_accuracy: 0.8209 - val_f1: 0.1513 - val_loss: 0.6448 - val_prc_auc: 0.0549 - val_precision: 0.0900 - val_recall: 0.4737\n","Epoch 3/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7989 - binary_accuracy: 0.7334 - f1: 0.6662 - loss: 0.6278 - prc_auc: 0.7528 - precision: 0.7567 - recall: 0.5960\n","Epoch 3: Validation Metrics:\n","loss: 0.633457362651825\n","val_binary_accuracy: 0.8244680762290955\n","val_precision: 0.09183673560619354\n","val_recall: 0.4736842215061188\n","val_auc: 0.6411877870559692\n","val_prc_auc: 0.05499330908060074\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 172ms/step - auc: 0.7952 - binary_accuracy: 0.7299 - f1: 0.6638 - loss: 0.6282 - prc_auc: 0.7522 - precision: 0.7567 - recall: 0.5922 - val_auc: 0.6412 - val_binary_accuracy: 0.8245 - val_f1: 0.1538 - val_loss: 0.6263 - val_prc_auc: 0.0550 - val_precision: 0.0918 - val_recall: 0.4737\n","Epoch 4/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8101 - binary_accuracy: 0.7360 - f1: 0.6683 - loss: 0.6070 - prc_auc: 0.7645 - precision: 0.7622 - recall: 0.5960\n","Epoch 4: Validation Metrics:\n","loss: 0.6172054409980774\n","val_binary_accuracy: 0.8244680762290955\n","val_precision: 0.09183673560619354\n","val_recall: 0.4736842215061188\n","val_auc: 0.6462578177452087\n","val_prc_auc: 0.05571626126766205\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - auc: 0.8065 - binary_accuracy: 0.7325 - f1: 0.6659 - loss: 0.6077 - prc_auc: 0.7636 - precision: 0.7622 - recall: 0.5922 - val_auc: 0.6463 - val_binary_accuracy: 0.8245 - val_f1: 0.1538 - val_loss: 0.6131 - val_prc_auc: 0.0557 - val_precision: 0.0918 - val_recall: 0.4737\n","Epoch 5/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8134 - binary_accuracy: 0.7387 - f1: 0.6705 - loss: 0.5901 - prc_auc: 0.7634 - precision: 0.7678 - recall: 0.5960\n","Epoch 5: Validation Metrics:\n","loss: 0.6043835878372192\n","val_binary_accuracy: 0.8244680762290955\n","val_precision: 0.09183673560619354\n","val_recall: 0.4736842215061188\n","val_auc: 0.6460164189338684\n","val_prc_auc: 0.0556541346013546\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - auc: 0.8100 - binary_accuracy: 0.7352 - f1: 0.6680 - loss: 0.5911 - prc_auc: 0.7627 - precision: 0.7677 - recall: 0.5922 - val_auc: 0.6460 - val_binary_accuracy: 0.8245 - val_f1: 0.1538 - val_loss: 0.6040 - val_prc_auc: 0.0557 - val_precision: 0.0918 - val_recall: 0.4737\n","Epoch 6/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - auc: 0.8182 - binary_accuracy: 0.7389 - f1: 0.6708 - loss: 0.5766 - prc_auc: 0.7662 - precision: 0.7679 - recall: 0.5963\n","Epoch 6: Validation Metrics:\n","loss: 0.5945022702217102\n","val_binary_accuracy: 0.8209219574928284\n","val_precision: 0.09000000357627869\n","val_recall: 0.4736842215061188\n","val_auc: 0.6506518125534058\n","val_prc_auc: 0.05665966868400574\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - auc: 0.8148 - binary_accuracy: 0.7355 - f1: 0.6686 - loss: 0.5779 - prc_auc: 0.7658 - precision: 0.7680 - recall: 0.5929 - val_auc: 0.6507 - val_binary_accuracy: 0.8209 - val_f1: 0.1513 - val_loss: 0.5982 - val_prc_auc: 0.0567 - val_precision: 0.0900 - val_recall: 0.4737\n","Epoch 7/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8202 - binary_accuracy: 0.7386 - f1: 0.6713 - loss: 0.5661 - prc_auc: 0.7694 - precision: 0.7661 - recall: 0.5981\n","Epoch 7: Validation Metrics:\n","loss: 0.5869902968406677\n","val_binary_accuracy: 0.8209219574928284\n","val_precision: 0.09000000357627869\n","val_recall: 0.4736842215061188\n","val_auc: 0.651134729385376\n","val_prc_auc: 0.05725838243961334\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - auc: 0.8170 - binary_accuracy: 0.7353 - f1: 0.6692 - loss: 0.5675 - prc_auc: 0.7687 - precision: 0.7660 - recall: 0.5949 - val_auc: 0.6511 - val_binary_accuracy: 0.8209 - val_f1: 0.1513 - val_loss: 0.5947 - val_prc_auc: 0.0573 - val_precision: 0.0900 - val_recall: 0.4737\n","Epoch 8/20\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8236 - binary_accuracy: 0.7429 - f1: 0.6801 - loss: 0.5577 - prc_auc: 0.7774 - precision: 0.7664 - recall: 0.6121\n","Epoch 8: Validation Metrics:\n","loss: 0.5812162160873413\n","val_binary_accuracy: 0.8209219574928284\n","val_precision: 0.09000000357627869\n","val_recall: 0.4736842215061188\n","val_auc: 0.6530178189277649\n","val_prc_auc: 0.057574935257434845\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - auc: 0.8204 - binary_accuracy: 0.7394 - f1: 0.6778 - loss: 0.5594 - prc_auc: 0.7765 - precision: 0.7662 - recall: 0.6086 - val_auc: 0.6530 - val_binary_accuracy: 0.8209 - val_f1: 0.1513 - val_loss: 0.5925 - val_prc_auc: 0.0576 - val_precision: 0.0900 - val_recall: 0.4737\n","Starting training for label: 18\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - auc: 0.7308 - binary_accuracy: 0.6842 - f1: 0.7168 - loss: 0.6813 - prc_auc: 0.7394 - precision: 0.6628 - recall: 0.7841\n","Epoch 1: Validation Metrics:\n","loss: 0.673929750919342\n","val_binary_accuracy: 0.8031914830207825\n","val_precision: 0.10169491171836853\n","val_recall: 0.7058823704719543\n","val_auc: 0.8309495449066162\n","val_prc_auc: 0.21100343763828278\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - auc: 0.7379 - binary_accuracy: 0.6892 - f1: 0.7201 - loss: 0.6808 - prc_auc: 0.7469 - precision: 0.6676 - recall: 0.7853 - val_auc: 0.8309 - val_binary_accuracy: 0.8032 - val_f1: 0.1778 - val_loss: 0.6567 - val_prc_auc: 0.2110 - val_precision: 0.1017 - val_recall: 0.7059\n","Epoch 2/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9097 - binary_accuracy: 0.8584 - f1: 0.8586 - loss: 0.6445 - prc_auc: 0.9329 - precision: 0.8642 - recall: 0.8531\n","Epoch 2: Validation Metrics:\n","loss: 0.6376343369483948\n","val_binary_accuracy: 0.8723404407501221\n","val_precision: 0.1428571492433548\n","val_recall: 0.6470588445663452\n","val_auc: 0.860630214214325\n","val_prc_auc: 0.2569626569747925\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - auc: 0.9111 - binary_accuracy: 0.8591 - f1: 0.8591 - loss: 0.6435 - prc_auc: 0.9331 - precision: 0.8650 - recall: 0.8534 - val_auc: 0.8606 - val_binary_accuracy: 0.8723 - val_f1: 0.2340 - val_loss: 0.6197 - val_prc_auc: 0.2570 - val_precision: 0.1429 - val_recall: 0.6471\n","Epoch 3/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9190 - binary_accuracy: 0.8681 - f1: 0.8633 - loss: 0.6116 - prc_auc: 0.9411 - precision: 0.8978 - recall: 0.8314\n","Epoch 3: Validation Metrics:\n","loss: 0.6047933101654053\n","val_binary_accuracy: 0.890070915222168\n","val_precision: 0.16417910158634186\n","val_recall: 0.6470588445663452\n","val_auc: 0.864716649055481\n","val_prc_auc: 0.2634267807006836\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - auc: 0.9204 - binary_accuracy: 0.8687 - f1: 0.8640 - loss: 0.6106 - prc_auc: 0.9413 - precision: 0.8971 - recall: 0.8333 - val_auc: 0.8647 - val_binary_accuracy: 0.8901 - val_f1: 0.2619 - val_loss: 0.5841 - val_prc_auc: 0.2634 - val_precision: 0.1642 - val_recall: 0.6471\n","Epoch 4/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9200 - binary_accuracy: 0.8797 - f1: 0.8749 - loss: 0.5803 - prc_auc: 0.9427 - precision: 0.9102 - recall: 0.8425\n","Epoch 4: Validation Metrics:\n","loss: 0.5733118057250977\n","val_binary_accuracy: 0.911347508430481\n","val_precision: 0.20000000298023224\n","val_recall: 0.6470588445663452\n","val_auc: 0.8680503368377686\n","val_prc_auc: 0.2681332230567932\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - auc: 0.9215 - binary_accuracy: 0.8802 - f1: 0.8755 - loss: 0.5792 - prc_auc: 0.9430 - precision: 0.9102 - recall: 0.8435 - val_auc: 0.8681 - val_binary_accuracy: 0.9113 - val_f1: 0.3056 - val_loss: 0.5499 - val_prc_auc: 0.2681 - val_precision: 0.2000 - val_recall: 0.6471\n","Epoch 5/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9221 - binary_accuracy: 0.8911 - f1: 0.8851 - loss: 0.5495 - prc_auc: 0.9439 - precision: 0.9339 - recall: 0.8414\n","Epoch 5: Validation Metrics:\n","loss: 0.5424033403396606\n","val_binary_accuracy: 0.911347508430481\n","val_precision: 0.20000000298023224\n","val_recall: 0.6470588445663452\n","val_auc: 0.8686954975128174\n","val_prc_auc: 0.2698719799518585\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - auc: 0.9235 - binary_accuracy: 0.8903 - f1: 0.8844 - loss: 0.5484 - prc_auc: 0.9442 - precision: 0.9319 - recall: 0.8418 - val_auc: 0.8687 - val_binary_accuracy: 0.9113 - val_f1: 0.3056 - val_loss: 0.5168 - val_prc_auc: 0.2699 - val_precision: 0.2000 - val_recall: 0.6471\n","Epoch 6/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9250 - binary_accuracy: 0.8911 - f1: 0.8851 - loss: 0.5191 - prc_auc: 0.9455 - precision: 0.9339 - recall: 0.8414\n","Epoch 6: Validation Metrics:\n","loss: 0.5118433237075806\n","val_binary_accuracy: 0.9131205677986145\n","val_precision: 0.20370370149612427\n","val_recall: 0.6470588445663452\n","val_auc: 0.8720830678939819\n","val_prc_auc: 0.27785226702690125\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 177ms/step - auc: 0.9261 - binary_accuracy: 0.8903 - f1: 0.8844 - loss: 0.5180 - prc_auc: 0.9457 - precision: 0.9319 - recall: 0.8418 - val_auc: 0.8721 - val_binary_accuracy: 0.9131 - val_f1: 0.3099 - val_loss: 0.4846 - val_prc_auc: 0.2779 - val_precision: 0.2037 - val_recall: 0.6471\n","Epoch 7/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9257 - binary_accuracy: 0.8911 - f1: 0.8851 - loss: 0.4893 - prc_auc: 0.9459 - precision: 0.9339 - recall: 0.8414\n","Epoch 7: Validation Metrics:\n","loss: 0.48205816745758057\n","val_binary_accuracy: 0.9202127456665039\n","val_precision: 0.2199999988079071\n","val_recall: 0.6470588445663452\n","val_auc: 0.8711152076721191\n","val_prc_auc: 0.28463980555534363\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9269 - binary_accuracy: 0.8903 - f1: 0.8844 - loss: 0.4881 - prc_auc: 0.9462 - precision: 0.9319 - recall: 0.8418 - val_auc: 0.8711 - val_binary_accuracy: 0.9202 - val_f1: 0.3284 - val_loss: 0.4538 - val_prc_auc: 0.2846 - val_precision: 0.2200 - val_recall: 0.6471\n","Epoch 8/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9265 - binary_accuracy: 0.8859 - f1: 0.8792 - loss: 0.4606 - prc_auc: 0.9471 - precision: 0.9343 - recall: 0.8304\n","Epoch 8: Validation Metrics:\n","loss: 0.45370882749557495\n","val_binary_accuracy: 0.923758864402771\n","val_precision: 0.2291666716337204\n","val_recall: 0.6470588445663452\n","val_auc: 0.8712764382362366\n","val_prc_auc: 0.2865177392959595\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9276 - binary_accuracy: 0.8859 - f1: 0.8793 - loss: 0.4595 - prc_auc: 0.9473 - precision: 0.9330 - recall: 0.8315 - val_auc: 0.8713 - val_binary_accuracy: 0.9238 - val_f1: 0.3385 - val_loss: 0.4249 - val_prc_auc: 0.2865 - val_precision: 0.2292 - val_recall: 0.6471\n","Epoch 9/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9274 - binary_accuracy: 0.8857 - f1: 0.8777 - loss: 0.4338 - prc_auc: 0.9479 - precision: 0.9343 - recall: 0.8280\n","Epoch 9: Validation Metrics:\n","loss: 0.427420973777771\n","val_binary_accuracy: 0.9255319237709045\n","val_precision: 0.23404255509376526\n","val_recall: 0.6470588445663452\n","val_auc: 0.8713839650154114\n","val_prc_auc: 0.2915430963039398\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9285 - binary_accuracy: 0.8866 - f1: 0.8789 - loss: 0.4328 - prc_auc: 0.9481 - precision: 0.9340 - recall: 0.8304 - val_auc: 0.8714 - val_binary_accuracy: 0.9255 - val_f1: 0.3437 - val_loss: 0.3984 - val_prc_auc: 0.2915 - val_precision: 0.2340 - val_recall: 0.6471\n","Epoch 10/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9291 - binary_accuracy: 0.8857 - f1: 0.8777 - loss: 0.4093 - prc_auc: 0.9491 - precision: 0.9343 - recall: 0.8280\n","Epoch 10: Validation Metrics:\n","loss: 0.40363451838493347\n","val_binary_accuracy: 0.9255319237709045\n","val_precision: 0.23404255509376526\n","val_recall: 0.6470588445663452\n","val_auc: 0.8727282881736755\n","val_prc_auc: 0.3089126646518707\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - auc: 0.9302 - binary_accuracy: 0.8866 - f1: 0.8789 - loss: 0.4084 - prc_auc: 0.9493 - precision: 0.9340 - recall: 0.8304 - val_auc: 0.8727 - val_binary_accuracy: 0.9255 - val_f1: 0.3437 - val_loss: 0.3747 - val_prc_auc: 0.3089 - val_precision: 0.2340 - val_recall: 0.6471\n","Epoch 11/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9316 - binary_accuracy: 0.8857 - f1: 0.8777 - loss: 0.3874 - prc_auc: 0.9509 - precision: 0.9343 - recall: 0.8280\n","Epoch 11: Validation Metrics:\n","loss: 0.3826587498188019\n","val_binary_accuracy: 0.9308510422706604\n","val_precision: 0.25\n","val_recall: 0.6470588445663452\n","val_auc: 0.8723518252372742\n","val_prc_auc: 0.31593403220176697\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9324 - binary_accuracy: 0.8866 - f1: 0.8789 - loss: 0.3867 - prc_auc: 0.9511 - precision: 0.9340 - recall: 0.8304 - val_auc: 0.8724 - val_binary_accuracy: 0.9309 - val_f1: 0.3607 - val_loss: 0.3544 - val_prc_auc: 0.3159 - val_precision: 0.2500 - val_recall: 0.6471\n","Epoch 12/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9338 - binary_accuracy: 0.8943 - f1: 0.8856 - loss: 0.3683 - prc_auc: 0.9527 - precision: 0.9536 - recall: 0.8280\n","Epoch 12: Validation Metrics:\n","loss: 0.3645983338356018\n","val_binary_accuracy: 0.932624101638794\n","val_precision: 0.25581395626068115\n","val_recall: 0.6470588445663452\n","val_auc: 0.8720830082893372\n","val_prc_auc: 0.32566654682159424\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - auc: 0.9344 - binary_accuracy: 0.8942 - f1: 0.8860 - loss: 0.3677 - prc_auc: 0.9527 - precision: 0.9512 - recall: 0.8304 - val_auc: 0.8721 - val_binary_accuracy: 0.9326 - val_f1: 0.3667 - val_loss: 0.3375 - val_prc_auc: 0.3257 - val_precision: 0.2558 - val_recall: 0.6471\n","Epoch 13/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9345 - binary_accuracy: 0.8943 - f1: 0.8856 - loss: 0.3517 - prc_auc: 0.9536 - precision: 0.9536 - recall: 0.8280\n","Epoch 13: Validation Metrics:\n","loss: 0.3492125868797302\n","val_binary_accuracy: 0.936170220375061\n","val_precision: 0.26829269528388977\n","val_recall: 0.6470588445663452\n","val_auc: 0.8682653903961182\n","val_prc_auc: 0.32695823907852173\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9351 - binary_accuracy: 0.8942 - f1: 0.8860 - loss: 0.3514 - prc_auc: 0.9536 - precision: 0.9512 - recall: 0.8304 - val_auc: 0.8683 - val_binary_accuracy: 0.9362 - val_f1: 0.3793 - val_loss: 0.3233 - val_prc_auc: 0.3270 - val_precision: 0.2683 - val_recall: 0.6471\n","Epoch 14/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9363 - binary_accuracy: 0.8943 - f1: 0.8856 - loss: 0.3376 - prc_auc: 0.9553 - precision: 0.9536 - recall: 0.8280\n","Epoch 14: Validation Metrics:\n","loss: 0.33623433113098145\n","val_binary_accuracy: 0.936170220375061\n","val_precision: 0.26829269528388977\n","val_recall: 0.6470588445663452\n","val_auc: 0.8676201701164246\n","val_prc_auc: 0.3350270986557007\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - auc: 0.9367 - binary_accuracy: 0.8942 - f1: 0.8860 - loss: 0.3374 - prc_auc: 0.9551 - precision: 0.9512 - recall: 0.8304 - val_auc: 0.8676 - val_binary_accuracy: 0.9362 - val_f1: 0.3793 - val_loss: 0.3113 - val_prc_auc: 0.3350 - val_precision: 0.2683 - val_recall: 0.6471\n","Epoch 15/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9372 - binary_accuracy: 0.8895 - f1: 0.8801 - loss: 0.3256 - prc_auc: 0.9561 - precision: 0.9532 - recall: 0.8186\n","Epoch 15: Validation Metrics:\n","loss: 0.32534259557724\n","val_binary_accuracy: 0.9379432797431946\n","val_precision: 0.2750000059604645\n","val_recall: 0.6470588445663452\n","val_auc: 0.8657382726669312\n","val_prc_auc: 0.34203290939331055\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9375 - binary_accuracy: 0.8897 - f1: 0.8808 - loss: 0.3255 - prc_auc: 0.9559 - precision: 0.9516 - recall: 0.8207 - val_auc: 0.8657 - val_binary_accuracy: 0.9379 - val_f1: 0.3860 - val_loss: 0.3016 - val_prc_auc: 0.3420 - val_precision: 0.2750 - val_recall: 0.6471\n","Epoch 16/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9376 - binary_accuracy: 0.8903 - f1: 0.8811 - loss: 0.3154 - prc_auc: 0.9565 - precision: 0.9533 - recall: 0.8203\n","Epoch 16: Validation Metrics:\n","loss: 0.3162417411804199\n","val_binary_accuracy: 0.9379432797431946\n","val_precision: 0.2750000059604645\n","val_recall: 0.6470588445663452\n","val_auc: 0.865845799446106\n","val_prc_auc: 0.37267228960990906\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9379 - binary_accuracy: 0.8909 - f1: 0.8821 - loss: 0.3155 - prc_auc: 0.9564 - precision: 0.9517 - recall: 0.8231 - val_auc: 0.8658 - val_binary_accuracy: 0.9379 - val_f1: 0.3860 - val_loss: 0.2938 - val_prc_auc: 0.3727 - val_precision: 0.2750 - val_recall: 0.6471\n","Epoch 17/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.9371 - binary_accuracy: 0.8946 - f1: 0.8860 - loss: 0.3067 - prc_auc: 0.9565 - precision: 0.9536 - recall: 0.8286\n","Epoch 17: Validation Metrics:\n","loss: 0.3086332082748413\n","val_binary_accuracy: 0.9379432797431946\n","val_precision: 0.2750000059604645\n","val_recall: 0.6470588445663452\n","val_auc: 0.8645015954971313\n","val_prc_auc: 0.3529023230075836\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - auc: 0.9375 - binary_accuracy: 0.8949 - f1: 0.8868 - loss: 0.3070 - prc_auc: 0.9565 - precision: 0.9521 - recall: 0.8309 - val_auc: 0.8645 - val_binary_accuracy: 0.9379 - val_f1: 0.3860 - val_loss: 0.2876 - val_prc_auc: 0.3529 - val_precision: 0.2750 - val_recall: 0.6471\n","Epoch 18/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9376 - binary_accuracy: 0.8946 - f1: 0.8860 - loss: 0.2994 - prc_auc: 0.9568 - precision: 0.9536 - recall: 0.8286\n","Epoch 18: Validation Metrics:\n","loss: 0.3021905720233917\n","val_binary_accuracy: 0.9379432797431946\n","val_precision: 0.2750000059604645\n","val_recall: 0.6470588445663452\n","val_auc: 0.8681579232215881\n","val_prc_auc: 0.3585483133792877\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9380 - binary_accuracy: 0.8949 - f1: 0.8868 - loss: 0.2998 - prc_auc: 0.9568 - precision: 0.9521 - recall: 0.8309 - val_auc: 0.8682 - val_binary_accuracy: 0.9379 - val_f1: 0.3860 - val_loss: 0.2824 - val_prc_auc: 0.3585 - val_precision: 0.2750 - val_recall: 0.6471\n","Epoch 19/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9385 - binary_accuracy: 0.8992 - f1: 0.8911 - loss: 0.2930 - prc_auc: 0.9579 - precision: 0.9540 - recall: 0.8375\n","Epoch 19: Validation Metrics:\n","loss: 0.2966882884502411\n","val_binary_accuracy: 0.936170220375061\n","val_precision: 0.26829269528388977\n","val_recall: 0.6470588445663452\n","val_auc: 0.86627596616745\n","val_prc_auc: 0.38853225111961365\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9389 - binary_accuracy: 0.8997 - f1: 0.8921 - loss: 0.2936 - prc_auc: 0.9577 - precision: 0.9526 - recall: 0.8401 - val_auc: 0.8663 - val_binary_accuracy: 0.9362 - val_f1: 0.3793 - val_loss: 0.2781 - val_prc_auc: 0.3885 - val_precision: 0.2683 - val_recall: 0.6471\n","Epoch 20/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9390 - binary_accuracy: 0.9078 - f1: 0.9020 - loss: 0.2875 - prc_auc: 0.9584 - precision: 0.9553 - recall: 0.8550\n","Epoch 20: Validation Metrics:\n","loss: 0.2919471859931946\n","val_binary_accuracy: 0.9379432797431946\n","val_precision: 0.2857142984867096\n","val_recall: 0.7058823704719543\n","val_auc: 0.8629422187805176\n","val_prc_auc: 0.36362260580062866\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - auc: 0.9394 - binary_accuracy: 0.9074 - f1: 0.9018 - loss: 0.2882 - prc_auc: 0.9583 - precision: 0.9537 - recall: 0.8558 - val_auc: 0.8629 - val_binary_accuracy: 0.9379 - val_f1: 0.4068 - val_loss: 0.2746 - val_prc_auc: 0.3636 - val_precision: 0.2857 - val_recall: 0.7059\n","Starting training for label: 19\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_base_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - auc: 0.5801 - binary_accuracy: 0.5120 - f1: 0.0503 - loss: 0.6902 - prc_auc: 0.5460 - precision: 0.3253 - recall: 0.0277\n","Epoch 1: Validation Metrics:\n","loss: 0.6897388100624084\n","val_binary_accuracy: 0.8528369069099426\n","val_precision: 0.06666667014360428\n","val_recall: 0.2777777910232544\n","val_auc: 0.5574378967285156\n","val_prc_auc: 0.04512345418334007\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2s/step - auc: 0.5806 - binary_accuracy: 0.5133 - f1: 0.0597 - loss: 0.6902 - prc_auc: 0.5498 - precision: 0.3577 - recall: 0.0331 - val_auc: 0.5574 - val_binary_accuracy: 0.8528 - val_f1: 0.1075 - val_loss: 0.6329 - val_prc_auc: 0.0451 - val_precision: 0.0667 - val_recall: 0.2778\n","Epoch 2/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6829 - binary_accuracy: 0.5942 - f1: 0.4150 - loss: 0.6791 - prc_auc: 0.6245 - precision: 0.7158 - recall: 0.2941\n","Epoch 2: Validation Metrics:\n","loss: 0.679104745388031\n","val_binary_accuracy: 0.8191489577293396\n","val_precision: 0.05319149047136307\n","val_recall: 0.2777777910232544\n","val_auc: 0.6059218645095825\n","val_prc_auc: 0.05167356878519058\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - auc: 0.6801 - binary_accuracy: 0.5923 - f1: 0.4164 - loss: 0.6791 - prc_auc: 0.6296 - precision: 0.7106 - recall: 0.2962 - val_auc: 0.6059 - val_binary_accuracy: 0.8191 - val_f1: 0.0893 - val_loss: 0.6384 - val_prc_auc: 0.0517 - val_precision: 0.0532 - val_recall: 0.2778\n","Epoch 3/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7202 - binary_accuracy: 0.5976 - f1: 0.4410 - loss: 0.6710 - prc_auc: 0.6578 - precision: 0.6927 - recall: 0.3248\n","Epoch 3: Validation Metrics:\n","loss: 0.6710089445114136\n","val_binary_accuracy: 0.8102836608886719\n","val_precision: 0.06796116381883621\n","val_recall: 0.3888888955116272\n","val_auc: 0.6221509575843811\n","val_prc_auc: 0.05401263013482094\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - auc: 0.7170 - binary_accuracy: 0.5972 - f1: 0.4440 - loss: 0.6710 - prc_auc: 0.6619 - precision: 0.6925 - recall: 0.3280 - val_auc: 0.6222 - val_binary_accuracy: 0.8103 - val_f1: 0.1157 - val_loss: 0.6419 - val_prc_auc: 0.0540 - val_precision: 0.0680 - val_recall: 0.3889\n","Epoch 4/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7349 - binary_accuracy: 0.6223 - f1: 0.5045 - loss: 0.6642 - prc_auc: 0.6745 - precision: 0.7128 - recall: 0.3915\n","Epoch 4: Validation Metrics:\n","loss: 0.6642479300498962\n","val_binary_accuracy: 0.7996453642845154\n","val_precision: 0.06422018259763718\n","val_recall: 0.3888888955116272\n","val_auc: 0.6495726108551025\n","val_prc_auc: 0.058185458183288574\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - auc: 0.7323 - binary_accuracy: 0.6224 - f1: 0.5073 - loss: 0.6642 - prc_auc: 0.6781 - precision: 0.7128 - recall: 0.3947 - val_auc: 0.6496 - val_binary_accuracy: 0.7996 - val_f1: 0.1102 - val_loss: 0.6429 - val_prc_auc: 0.0582 - val_precision: 0.0642 - val_recall: 0.3889\n","Epoch 5/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7373 - binary_accuracy: 0.6366 - f1: 0.5383 - loss: 0.6583 - prc_auc: 0.6756 - precision: 0.7178 - recall: 0.4323\n","Epoch 5: Validation Metrics:\n","loss: 0.6583247184753418\n","val_binary_accuracy: 0.792553186416626\n","val_precision: 0.06194690242409706\n","val_recall: 0.3888888955116272\n","val_auc: 0.6555758714675903\n","val_prc_auc: 0.06415126472711563\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - auc: 0.7356 - binary_accuracy: 0.6368 - f1: 0.5413 - loss: 0.6583 - prc_auc: 0.6795 - precision: 0.7179 - recall: 0.4359 - val_auc: 0.6556 - val_binary_accuracy: 0.7926 - val_f1: 0.1069 - val_loss: 0.6420 - val_prc_auc: 0.0642 - val_precision: 0.0619 - val_recall: 0.3889\n","Epoch 6/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7435 - binary_accuracy: 0.6515 - f1: 0.5667 - loss: 0.6529 - prc_auc: 0.6902 - precision: 0.7317 - recall: 0.4631\n","Epoch 6: Validation Metrics:\n","loss: 0.652980387210846\n","val_binary_accuracy: 0.7854610085487366\n","val_precision: 0.05982905998826027\n","val_recall: 0.3888888955116272\n","val_auc: 0.663156270980835\n","val_prc_auc: 0.06875459849834442\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - auc: 0.7418 - binary_accuracy: 0.6503 - f1: 0.5668 - loss: 0.6529 - prc_auc: 0.6932 - precision: 0.7304 - recall: 0.4636 - val_auc: 0.6632 - val_binary_accuracy: 0.7855 - val_f1: 0.1037 - val_loss: 0.6398 - val_prc_auc: 0.0688 - val_precision: 0.0598 - val_recall: 0.3889\n","Epoch 7/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7450 - binary_accuracy: 0.6645 - f1: 0.5923 - loss: 0.6479 - prc_auc: 0.6883 - precision: 0.7386 - recall: 0.4952\n","Epoch 7: Validation Metrics:\n","loss: 0.6480032801628113\n","val_binary_accuracy: 0.7801418304443359\n","val_precision: 0.05833333358168602\n","val_recall: 0.3888888955116272\n","val_auc: 0.6713472008705139\n","val_prc_auc: 0.07337546348571777\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - auc: 0.7439 - binary_accuracy: 0.6627 - f1: 0.5913 - loss: 0.6480 - prc_auc: 0.6915 - precision: 0.7367 - recall: 0.4944 - val_auc: 0.6713 - val_binary_accuracy: 0.7801 - val_f1: 0.1014 - val_loss: 0.6368 - val_prc_auc: 0.0734 - val_precision: 0.0583 - val_recall: 0.3889\n","Epoch 8/20\n","\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7468 - binary_accuracy: 0.6820 - f1: 0.6216 - loss: 0.6432 - prc_auc: 0.6931 - precision: 0.7513 - recall: 0.5308\n","Epoch 8: Validation Metrics:\n","loss: 0.6432561874389648\n","val_binary_accuracy: 0.7783687710762024\n","val_precision: 0.057851240038871765\n","val_recall: 0.3888888955116272\n","val_auc: 0.6748066544532776\n","val_prc_auc: 0.07083310931921005\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - auc: 0.7461 - binary_accuracy: 0.6798 - f1: 0.6199 - loss: 0.6432 - prc_auc: 0.6963 - precision: 0.7493 - recall: 0.5292 - val_auc: 0.6748 - val_binary_accuracy: 0.7784 - val_f1: 0.1007 - val_loss: 0.6338 - val_prc_auc: 0.0708 - val_precision: 0.0579 - val_recall: 0.3889\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 240ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 193ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 191ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 191ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 190ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 278ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step\n","\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 189ms/step\n","[[0 0 1 ... 0 0 0]\n"," [1 0 1 ... 0 0 0]\n"," [0 1 1 ... 0 0 0]\n"," ...\n"," [1 1 1 ... 0 0 0]\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]]\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - auc: 0.5666 - binary_accuracy: 0.5358 - f1: 0.4152 - loss: 0.6886 - prc_auc: 0.5793 - precision: 0.5775 - recall: 0.3564\n","Epoch 1: Validation Metrics:\n","loss: 0.680171012878418\n","val_binary_accuracy: 0.6026548743247986\n","val_precision: 0.2924901247024536\n","val_recall: 0.6192468404769897\n","val_auc: 0.6517734527587891\n","val_prc_auc: 0.3696635961532593\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 399ms/step - auc: 0.5675 - binary_accuracy: 0.5366 - f1: 0.4176 - loss: 0.6885 - prc_auc: 0.5800 - precision: 0.5777 - recall: 0.3594 - val_auc: 0.6518 - val_binary_accuracy: 0.6027 - val_f1: 0.3973 - val_loss: 0.6525 - val_prc_auc: 0.3697 - val_precision: 0.2925 - val_recall: 0.6192\n","Epoch 2/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7040 - binary_accuracy: 0.6450 - f1: 0.6569 - loss: 0.6557 - prc_auc: 0.7209 - precision: 0.6530 - recall: 0.6614\n","Epoch 2: Validation Metrics:\n","loss: 0.6543908715248108\n","val_binary_accuracy: 0.6070796251296997\n","val_precision: 0.29622265696525574\n","val_recall: 0.6234309673309326\n","val_auc: 0.6667817234992981\n","val_prc_auc: 0.38398420810699463\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7037 - binary_accuracy: 0.6448 - f1: 0.6567 - loss: 0.6557 - prc_auc: 0.7203 - precision: 0.6525 - recall: 0.6613 - val_auc: 0.6668 - val_binary_accuracy: 0.6071 - val_f1: 0.4016 - val_loss: 0.6375 - val_prc_auc: 0.3840 - val_precision: 0.2962 - val_recall: 0.6234\n","Epoch 3/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7228 - binary_accuracy: 0.6518 - f1: 0.6580 - loss: 0.6362 - prc_auc: 0.7404 - precision: 0.6653 - recall: 0.6516\n","Epoch 3: Validation Metrics:\n","loss: 0.6379191279411316\n","val_binary_accuracy: 0.6141592860221863\n","val_precision: 0.3010101020336151\n","val_recall: 0.6234309673309326\n","val_auc: 0.6766690611839294\n","val_prc_auc: 0.3918684124946594\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7225 - binary_accuracy: 0.6516 - f1: 0.6579 - loss: 0.6362 - prc_auc: 0.7399 - precision: 0.6649 - recall: 0.6517 - val_auc: 0.6767 - val_binary_accuracy: 0.6142 - val_f1: 0.4060 - val_loss: 0.6317 - val_prc_auc: 0.3919 - val_precision: 0.3010 - val_recall: 0.6234\n","Epoch 4/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7358 - binary_accuracy: 0.6683 - f1: 0.6754 - loss: 0.6215 - prc_auc: 0.7528 - precision: 0.6801 - recall: 0.6713\n","Epoch 4: Validation Metrics:\n","loss: 0.6256554126739502\n","val_binary_accuracy: 0.6185840964317322\n","val_precision: 0.30408161878585815\n","val_recall: 0.6234309673309326\n","val_auc: 0.6832293272018433\n","val_prc_auc: 0.39232683181762695\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7355 - binary_accuracy: 0.6680 - f1: 0.6751 - loss: 0.6216 - prc_auc: 0.7522 - precision: 0.6796 - recall: 0.6712 - val_auc: 0.6832 - val_binary_accuracy: 0.6186 - val_f1: 0.4088 - val_loss: 0.6287 - val_prc_auc: 0.3923 - val_precision: 0.3041 - val_recall: 0.6234\n","Epoch 5/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7480 - binary_accuracy: 0.6764 - f1: 0.6803 - loss: 0.6103 - prc_auc: 0.7646 - precision: 0.6915 - recall: 0.6699\n","Epoch 5: Validation Metrics:\n","loss: 0.6162624359130859\n","val_binary_accuracy: 0.6309734582901001\n","val_precision: 0.3153527081012726\n","val_recall: 0.6359832882881165\n","val_auc: 0.6898788213729858\n","val_prc_auc: 0.39517834782600403\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7477 - binary_accuracy: 0.6761 - f1: 0.6800 - loss: 0.6104 - prc_auc: 0.7640 - precision: 0.6910 - recall: 0.6698 - val_auc: 0.6899 - val_binary_accuracy: 0.6310 - val_f1: 0.4216 - val_loss: 0.6263 - val_prc_auc: 0.3952 - val_precision: 0.3154 - val_recall: 0.6360\n","Epoch 6/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7567 - binary_accuracy: 0.6833 - f1: 0.6860 - loss: 0.6011 - prc_auc: 0.7725 - precision: 0.6999 - recall: 0.6730\n","Epoch 6: Validation Metrics:\n","loss: 0.6087087392807007\n","val_binary_accuracy: 0.6424778699874878\n","val_precision: 0.3233404755592346\n","val_recall: 0.6317991614341736\n","val_auc: 0.6945230960845947\n","val_prc_auc: 0.3956894874572754\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7564 - binary_accuracy: 0.6830 - f1: 0.6858 - loss: 0.6013 - prc_auc: 0.7719 - precision: 0.6994 - recall: 0.6730 - val_auc: 0.6945 - val_binary_accuracy: 0.6425 - val_f1: 0.4278 - val_loss: 0.6245 - val_prc_auc: 0.3957 - val_precision: 0.3233 - val_recall: 0.6318\n","Epoch 7/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7640 - binary_accuracy: 0.6903 - f1: 0.6910 - loss: 0.5934 - prc_auc: 0.7791 - precision: 0.7098 - recall: 0.6736\n","Epoch 7: Validation Metrics:\n","loss: 0.6023136377334595\n","val_binary_accuracy: 0.6548672318458557\n","val_precision: 0.3333333432674408\n","val_recall: 0.6317991614341736\n","val_auc: 0.6986438035964966\n","val_prc_auc: 0.3941539227962494\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7637 - binary_accuracy: 0.6901 - f1: 0.6907 - loss: 0.5935 - prc_auc: 0.7786 - precision: 0.7092 - recall: 0.6736 - val_auc: 0.6986 - val_binary_accuracy: 0.6549 - val_f1: 0.4364 - val_loss: 0.6228 - val_prc_auc: 0.3942 - val_precision: 0.3333 - val_recall: 0.6318\n","Epoch 8/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7701 - binary_accuracy: 0.6923 - f1: 0.6914 - loss: 0.5866 - prc_auc: 0.7845 - precision: 0.7142 - recall: 0.6706\n","Epoch 8: Validation Metrics:\n","loss: 0.5966970920562744\n","val_binary_accuracy: 0.664601743221283\n","val_precision: 0.34018266201019287\n","val_recall: 0.6234309673309326\n","val_auc: 0.7023043036460876\n","val_prc_auc: 0.3951137065887451\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7697 - binary_accuracy: 0.6920 - f1: 0.6911 - loss: 0.5867 - prc_auc: 0.7839 - precision: 0.7136 - recall: 0.6706 - val_auc: 0.7023 - val_binary_accuracy: 0.6646 - val_f1: 0.4402 - val_loss: 0.6211 - val_prc_auc: 0.3951 - val_precision: 0.3402 - val_recall: 0.6234\n","Epoch 9/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7765 - binary_accuracy: 0.6962 - f1: 0.6953 - loss: 0.5804 - prc_auc: 0.7895 - precision: 0.7179 - recall: 0.6745\n","Epoch 9: Validation Metrics:\n","loss: 0.591636061668396\n","val_binary_accuracy: 0.6778761148452759\n","val_precision: 0.3529411852359772\n","val_recall: 0.6276150345802307\n","val_auc: 0.706213653087616\n","val_prc_auc: 0.3969253599643707\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7762 - binary_accuracy: 0.6959 - f1: 0.6950 - loss: 0.5806 - prc_auc: 0.7890 - precision: 0.7173 - recall: 0.6746 - val_auc: 0.7062 - val_binary_accuracy: 0.6779 - val_f1: 0.4518 - val_loss: 0.6197 - val_prc_auc: 0.3969 - val_precision: 0.3529 - val_recall: 0.6276\n","Epoch 10/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7812 - binary_accuracy: 0.6975 - f1: 0.6977 - loss: 0.5749 - prc_auc: 0.7932 - precision: 0.7172 - recall: 0.6797\n","Epoch 10: Validation Metrics:\n","loss: 0.5870041847229004\n","val_binary_accuracy: 0.6796460151672363\n","val_precision: 0.3546099364757538\n","val_recall: 0.6276150345802307\n","val_auc: 0.7095947861671448\n","val_prc_auc: 0.3965901732444763\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7808 - binary_accuracy: 0.6972 - f1: 0.6975 - loss: 0.5750 - prc_auc: 0.7927 - precision: 0.7167 - recall: 0.6798 - val_auc: 0.7096 - val_binary_accuracy: 0.6796 - val_f1: 0.4532 - val_loss: 0.6184 - val_prc_auc: 0.3966 - val_precision: 0.3546 - val_recall: 0.6276\n","Epoch 11/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7859 - binary_accuracy: 0.7032 - f1: 0.7015 - loss: 0.5698 - prc_auc: 0.7969 - precision: 0.7265 - recall: 0.6787\n","Epoch 11: Validation Metrics:\n","loss: 0.5827584266662598\n","val_binary_accuracy: 0.6743362545967102\n","val_precision: 0.34894612431526184\n","val_recall: 0.6234309673309326\n","val_auc: 0.7117854356765747\n","val_prc_auc: 0.4008234143257141\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7855 - binary_accuracy: 0.7029 - f1: 0.7012 - loss: 0.5700 - prc_auc: 0.7964 - precision: 0.7259 - recall: 0.6788 - val_auc: 0.7118 - val_binary_accuracy: 0.6743 - val_f1: 0.4474 - val_loss: 0.6172 - val_prc_auc: 0.4008 - val_precision: 0.3489 - val_recall: 0.6234\n","Epoch 12/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7901 - binary_accuracy: 0.7106 - f1: 0.7087 - loss: 0.5652 - prc_auc: 0.7999 - precision: 0.7343 - recall: 0.6854\n","Epoch 12: Validation Metrics:\n","loss: 0.5788065195083618\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.35476189851760864\n","val_recall: 0.6234309673309326\n","val_auc: 0.7140348553657532\n","val_prc_auc: 0.39861130714416504\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7897 - binary_accuracy: 0.7103 - f1: 0.7085 - loss: 0.5654 - prc_auc: 0.7994 - precision: 0.7337 - recall: 0.6854 - val_auc: 0.7140 - val_binary_accuracy: 0.6805 - val_f1: 0.4522 - val_loss: 0.6160 - val_prc_auc: 0.3986 - val_precision: 0.3548 - val_recall: 0.6234\n","Epoch 13/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7940 - binary_accuracy: 0.7177 - f1: 0.7161 - loss: 0.5608 - prc_auc: 0.8039 - precision: 0.7410 - recall: 0.6931\n","Epoch 13: Validation Metrics:\n","loss: 0.5750697255134583\n","val_binary_accuracy: 0.682300865650177\n","val_precision: 0.35576921701431274\n","val_recall: 0.6192468404769897\n","val_auc: 0.7165143489837646\n","val_prc_auc: 0.40032532811164856\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7936 - binary_accuracy: 0.7174 - f1: 0.7158 - loss: 0.5610 - prc_auc: 0.8033 - precision: 0.7404 - recall: 0.6930 - val_auc: 0.7165 - val_binary_accuracy: 0.6823 - val_f1: 0.4519 - val_loss: 0.6149 - val_prc_auc: 0.4003 - val_precision: 0.3558 - val_recall: 0.6192\n","Epoch 14/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7980 - binary_accuracy: 0.7169 - f1: 0.7143 - loss: 0.5567 - prc_auc: 0.8068 - precision: 0.7421 - recall: 0.6888\n","Epoch 14: Validation Metrics:\n","loss: 0.5715152025222778\n","val_binary_accuracy: 0.6814159154891968\n","val_precision: 0.35629454255104065\n","val_recall: 0.6276150345802307\n","val_auc: 0.7183035016059875\n","val_prc_auc: 0.40042373538017273\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7977 - binary_accuracy: 0.7166 - f1: 0.7140 - loss: 0.5570 - prc_auc: 0.8063 - precision: 0.7415 - recall: 0.6888 - val_auc: 0.7183 - val_binary_accuracy: 0.6814 - val_f1: 0.4545 - val_loss: 0.6137 - val_prc_auc: 0.4004 - val_precision: 0.3563 - val_recall: 0.6276\n","Epoch 15/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8018 - binary_accuracy: 0.7233 - f1: 0.7212 - loss: 0.5529 - prc_auc: 0.8102 - precision: 0.7479 - recall: 0.6966\n","Epoch 15: Validation Metrics:\n","loss: 0.5681330561637878\n","val_binary_accuracy: 0.6796460151672363\n","val_precision: 0.35322195291519165\n","val_recall: 0.6192468404769897\n","val_auc: 0.7203860878944397\n","val_prc_auc: 0.4009785056114197\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.8014 - binary_accuracy: 0.7230 - f1: 0.7209 - loss: 0.5531 - prc_auc: 0.8096 - precision: 0.7473 - recall: 0.6966 - val_auc: 0.7204 - val_binary_accuracy: 0.6796 - val_f1: 0.4498 - val_loss: 0.6125 - val_prc_auc: 0.4010 - val_precision: 0.3532 - val_recall: 0.6192\n","Epoch 16/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8052 - binary_accuracy: 0.7253 - f1: 0.7239 - loss: 0.5492 - prc_auc: 0.8136 - precision: 0.7486 - recall: 0.7011\n","Epoch 16: Validation Metrics:\n","loss: 0.564867377281189\n","val_binary_accuracy: 0.6831858158111572\n","val_precision: 0.3573141396045685\n","val_recall: 0.6234309673309326\n","val_auc: 0.7223936319351196\n","val_prc_auc: 0.4027996063232422\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.8049 - binary_accuracy: 0.7250 - f1: 0.7236 - loss: 0.5494 - prc_auc: 0.8131 - precision: 0.7480 - recall: 0.7010 - val_auc: 0.7224 - val_binary_accuracy: 0.6832 - val_f1: 0.4543 - val_loss: 0.6114 - val_prc_auc: 0.4028 - val_precision: 0.3573 - val_recall: 0.6234\n","Epoch 17/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8086 - binary_accuracy: 0.7272 - f1: 0.7258 - loss: 0.5456 - prc_auc: 0.8164 - precision: 0.7505 - recall: 0.7030\n","Epoch 17: Validation Metrics:\n","loss: 0.5616920590400696\n","val_binary_accuracy: 0.6814159154891968\n","val_precision: 0.35560858249664307\n","val_recall: 0.6234309673309326\n","val_auc: 0.724175751209259\n","val_prc_auc: 0.4043807089328766\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.8082 - binary_accuracy: 0.7269 - f1: 0.7255 - loss: 0.5459 - prc_auc: 0.8159 - precision: 0.7498 - recall: 0.7030 - val_auc: 0.7242 - val_binary_accuracy: 0.6814 - val_f1: 0.4529 - val_loss: 0.6104 - val_prc_auc: 0.4044 - val_precision: 0.3556 - val_recall: 0.6234\n","Epoch 18/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8116 - binary_accuracy: 0.7298 - f1: 0.7293 - loss: 0.5422 - prc_auc: 0.8195 - precision: 0.7513 - recall: 0.7087\n","Epoch 18: Validation Metrics:\n","loss: 0.5585945248603821\n","val_binary_accuracy: 0.6840708255767822\n","val_precision: 0.35885167121887207\n","val_recall: 0.6276150345802307\n","val_auc: 0.7257159948348999\n","val_prc_auc: 0.4052979350090027\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.8112 - binary_accuracy: 0.7295 - f1: 0.7289 - loss: 0.5425 - prc_auc: 0.8190 - precision: 0.7507 - recall: 0.7087 - val_auc: 0.7257 - val_binary_accuracy: 0.6841 - val_f1: 0.4566 - val_loss: 0.6093 - val_prc_auc: 0.4053 - val_precision: 0.3589 - val_recall: 0.6276\n","Epoch 19/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8145 - binary_accuracy: 0.7326 - f1: 0.7325 - loss: 0.5389 - prc_auc: 0.8224 - precision: 0.7537 - recall: 0.7127\n","Epoch 19: Validation Metrics:\n","loss: 0.5555899143218994\n","val_binary_accuracy: 0.6858407258987427\n","val_precision: 0.3612440228462219\n","val_recall: 0.6317991614341736\n","val_auc: 0.7270872592926025\n","val_prc_auc: 0.4067855477333069\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.8141 - binary_accuracy: 0.7323 - f1: 0.7322 - loss: 0.5392 - prc_auc: 0.8218 - precision: 0.7530 - recall: 0.7127 - val_auc: 0.7271 - val_binary_accuracy: 0.6858 - val_f1: 0.4597 - val_loss: 0.6082 - val_prc_auc: 0.4068 - val_precision: 0.3612 - val_recall: 0.6318\n","Epoch 20/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8172 - binary_accuracy: 0.7339 - f1: 0.7342 - loss: 0.5357 - prc_auc: 0.8251 - precision: 0.7541 - recall: 0.7157\n","Epoch 20: Validation Metrics:\n","loss: 0.5526405572891235\n","val_binary_accuracy: 0.6840708255767822\n","val_precision: 0.35952380299568176\n","val_recall: 0.6317991614341736\n","val_auc: 0.7283364534378052\n","val_prc_auc: 0.4085566997528076\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.8168 - binary_accuracy: 0.7336 - f1: 0.7339 - loss: 0.5360 - prc_auc: 0.8246 - precision: 0.7534 - recall: 0.7156 - val_auc: 0.7283 - val_binary_accuracy: 0.6841 - val_f1: 0.4583 - val_loss: 0.6073 - val_prc_auc: 0.4086 - val_precision: 0.3595 - val_recall: 0.6318\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852ms/step - auc: 0.6401 - binary_accuracy: 0.6018 - f1: 0.6922 - loss: 0.6766 - prc_auc: 0.6230 - precision: 0.5737 - recall: 0.8740\n","Epoch 1: Validation Metrics:\n","loss: 0.6671770811080933\n","val_binary_accuracy: 0.6123893857002258\n","val_precision: 0.3772242069244385\n","val_recall: 0.7066666483879089\n","val_auc: 0.7225542068481445\n","val_prc_auc: 0.5150548815727234\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - auc: 0.6404 - binary_accuracy: 0.6021 - f1: 0.6921 - loss: 0.6764 - prc_auc: 0.6234 - precision: 0.5738 - recall: 0.8733 - val_auc: 0.7226 - val_binary_accuracy: 0.6124 - val_f1: 0.4919 - val_loss: 0.6386 - val_prc_auc: 0.5151 - val_precision: 0.3772 - val_recall: 0.7067\n","Epoch 2/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7083 - binary_accuracy: 0.6662 - f1: 0.6887 - loss: 0.6408 - prc_auc: 0.7148 - precision: 0.6590 - recall: 0.7214\n","Epoch 2: Validation Metrics:\n","loss: 0.6393268704414368\n","val_binary_accuracy: 0.6362831592559814\n","val_precision: 0.39306357502937317\n","val_recall: 0.6800000071525574\n","val_auc: 0.7242429852485657\n","val_prc_auc: 0.5179190039634705\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7081 - binary_accuracy: 0.6660 - f1: 0.6883 - loss: 0.6408 - prc_auc: 0.7143 - precision: 0.6586 - recall: 0.7210 - val_auc: 0.7242 - val_binary_accuracy: 0.6363 - val_f1: 0.4982 - val_loss: 0.6135 - val_prc_auc: 0.5179 - val_precision: 0.3931 - val_recall: 0.6800\n","Epoch 3/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7136 - binary_accuracy: 0.6668 - f1: 0.6815 - loss: 0.6274 - prc_auc: 0.7223 - precision: 0.6682 - recall: 0.6953\n","Epoch 3: Validation Metrics:\n","loss: 0.6288080215454102\n","val_binary_accuracy: 0.6451327204704285\n","val_precision: 0.3992016017436981\n","val_recall: 0.6666666865348816\n","val_auc: 0.7246084213256836\n","val_prc_auc: 0.5153757929801941\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7135 - binary_accuracy: 0.6668 - f1: 0.6812 - loss: 0.6275 - prc_auc: 0.7218 - precision: 0.6679 - recall: 0.6952 - val_auc: 0.7246 - val_binary_accuracy: 0.6451 - val_f1: 0.4994 - val_loss: 0.6056 - val_prc_auc: 0.5154 - val_precision: 0.3992 - val_recall: 0.6667\n","Epoch 4/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7186 - binary_accuracy: 0.6664 - f1: 0.6795 - loss: 0.6209 - prc_auc: 0.7280 - precision: 0.6697 - recall: 0.6898\n","Epoch 4: Validation Metrics:\n","loss: 0.6232107877731323\n","val_binary_accuracy: 0.6513274312019348\n","val_precision: 0.40408164262771606\n","val_recall: 0.6600000262260437\n","val_auc: 0.7255942821502686\n","val_prc_auc: 0.5169801115989685\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7184 - binary_accuracy: 0.6664 - f1: 0.6793 - loss: 0.6210 - prc_auc: 0.7276 - precision: 0.6694 - recall: 0.6896 - val_auc: 0.7256 - val_binary_accuracy: 0.6513 - val_f1: 0.5013 - val_loss: 0.6028 - val_prc_auc: 0.5170 - val_precision: 0.4041 - val_recall: 0.6600\n","Epoch 5/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7231 - binary_accuracy: 0.6710 - f1: 0.6818 - loss: 0.6165 - prc_auc: 0.7330 - precision: 0.6760 - recall: 0.6879\n","Epoch 5: Validation Metrics:\n","loss: 0.6191098690032959\n","val_binary_accuracy: 0.6513274312019348\n","val_precision: 0.403292179107666\n","val_recall: 0.653333306312561\n","val_auc: 0.7263253331184387\n","val_prc_auc: 0.5217665433883667\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7230 - binary_accuracy: 0.6710 - f1: 0.6816 - loss: 0.6166 - prc_auc: 0.7326 - precision: 0.6757 - recall: 0.6878 - val_auc: 0.7263 - val_binary_accuracy: 0.6513 - val_f1: 0.4987 - val_loss: 0.6011 - val_prc_auc: 0.5218 - val_precision: 0.4033 - val_recall: 0.6533\n","Epoch 6/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7281 - binary_accuracy: 0.6709 - f1: 0.6807 - loss: 0.6129 - prc_auc: 0.7383 - precision: 0.6769 - recall: 0.6847\n","Epoch 6: Validation Metrics:\n","loss: 0.6156350374221802\n","val_binary_accuracy: 0.6601769924163818\n","val_precision: 0.4121339023113251\n","val_recall: 0.6566666960716248\n","val_auc: 0.7267751097679138\n","val_prc_auc: 0.5198871493339539\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7280 - binary_accuracy: 0.6709 - f1: 0.6805 - loss: 0.6129 - prc_auc: 0.7379 - precision: 0.6767 - recall: 0.6846 - val_auc: 0.7268 - val_binary_accuracy: 0.6602 - val_f1: 0.5064 - val_loss: 0.6002 - val_prc_auc: 0.5199 - val_precision: 0.4121 - val_recall: 0.6567\n","Epoch 7/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7327 - binary_accuracy: 0.6712 - f1: 0.6803 - loss: 0.6096 - prc_auc: 0.7429 - precision: 0.6777 - recall: 0.6832\n","Epoch 7: Validation Metrics:\n","loss: 0.6124811172485352\n","val_binary_accuracy: 0.6610619425773621\n","val_precision: 0.41299790143966675\n","val_recall: 0.6566666960716248\n","val_auc: 0.7280582189559937\n","val_prc_auc: 0.5227316617965698\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7326 - binary_accuracy: 0.6711 - f1: 0.6801 - loss: 0.6096 - prc_auc: 0.7424 - precision: 0.6774 - recall: 0.6831 - val_auc: 0.7281 - val_binary_accuracy: 0.6611 - val_f1: 0.5071 - val_loss: 0.5993 - val_prc_auc: 0.5227 - val_precision: 0.4130 - val_recall: 0.6567\n","Epoch 8/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7365 - binary_accuracy: 0.6740 - f1: 0.6825 - loss: 0.6065 - prc_auc: 0.7466 - precision: 0.6809 - recall: 0.6846\n","Epoch 8: Validation Metrics:\n","loss: 0.6095111966133118\n","val_binary_accuracy: 0.664601743221283\n","val_precision: 0.415778249502182\n","val_recall: 0.6499999761581421\n","val_auc: 0.7288253307342529\n","val_prc_auc: 0.5260258913040161\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7364 - binary_accuracy: 0.6739 - f1: 0.6823 - loss: 0.6065 - prc_auc: 0.7461 - precision: 0.6806 - recall: 0.6843 - val_auc: 0.7288 - val_binary_accuracy: 0.6646 - val_f1: 0.5072 - val_loss: 0.5983 - val_prc_auc: 0.5260 - val_precision: 0.4158 - val_recall: 0.6500\n","Epoch 9/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7405 - binary_accuracy: 0.6774 - f1: 0.6841 - loss: 0.6036 - prc_auc: 0.7502 - precision: 0.6863 - recall: 0.6823\n","Epoch 9: Validation Metrics:\n","loss: 0.606719970703125\n","val_binary_accuracy: 0.6637167930603027\n","val_precision: 0.4145299196243286\n","val_recall: 0.6466666460037231\n","val_auc: 0.7294859886169434\n","val_prc_auc: 0.5263932943344116\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7403 - binary_accuracy: 0.6773 - f1: 0.6838 - loss: 0.6036 - prc_auc: 0.7498 - precision: 0.6860 - recall: 0.6821 - val_auc: 0.7295 - val_binary_accuracy: 0.6637 - val_f1: 0.5052 - val_loss: 0.5974 - val_prc_auc: 0.5264 - val_precision: 0.4145 - val_recall: 0.6467\n","Epoch 10/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7437 - binary_accuracy: 0.6770 - f1: 0.6820 - loss: 0.6007 - prc_auc: 0.7531 - precision: 0.6880 - recall: 0.6766\n","Epoch 10: Validation Metrics:\n","loss: 0.6040390729904175\n","val_binary_accuracy: 0.6707964539527893\n","val_precision: 0.4220779240131378\n","val_recall: 0.6499999761581421\n","val_auc: 0.7307891249656677\n","val_prc_auc: 0.5268567800521851\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7435 - binary_accuracy: 0.6770 - f1: 0.6818 - loss: 0.6008 - prc_auc: 0.7527 - precision: 0.6877 - recall: 0.6764 - val_auc: 0.7308 - val_binary_accuracy: 0.6708 - val_f1: 0.5118 - val_loss: 0.5965 - val_prc_auc: 0.5269 - val_precision: 0.4221 - val_recall: 0.6500\n","Epoch 11/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7468 - binary_accuracy: 0.6780 - f1: 0.6825 - loss: 0.5980 - prc_auc: 0.7555 - precision: 0.6895 - recall: 0.6762\n","Epoch 11: Validation Metrics:\n","loss: 0.601463794708252\n","val_binary_accuracy: 0.6725663542747498\n","val_precision: 0.4235807955265045\n","val_recall: 0.6466666460037231\n","val_auc: 0.7315643429756165\n","val_prc_auc: 0.5279186367988586\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7466 - binary_accuracy: 0.6779 - f1: 0.6823 - loss: 0.5981 - prc_auc: 0.7551 - precision: 0.6892 - recall: 0.6760 - val_auc: 0.7316 - val_binary_accuracy: 0.6726 - val_f1: 0.5119 - val_loss: 0.5957 - val_prc_auc: 0.5279 - val_precision: 0.4236 - val_recall: 0.6467\n","Epoch 12/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7499 - binary_accuracy: 0.6821 - f1: 0.6842 - loss: 0.5953 - prc_auc: 0.7583 - precision: 0.6969 - recall: 0.6722\n","Epoch 12: Validation Metrics:\n","loss: 0.5989692211151123\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.4235033392906189\n","val_recall: 0.6366666555404663\n","val_auc: 0.7323494553565979\n","val_prc_auc: 0.5286909341812134\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7497 - binary_accuracy: 0.6820 - f1: 0.6839 - loss: 0.5954 - prc_auc: 0.7579 - precision: 0.6965 - recall: 0.6720 - val_auc: 0.7323 - val_binary_accuracy: 0.6735 - val_f1: 0.5087 - val_loss: 0.5949 - val_prc_auc: 0.5287 - val_precision: 0.4235 - val_recall: 0.6367\n","Epoch 13/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7530 - binary_accuracy: 0.6842 - f1: 0.6845 - loss: 0.5927 - prc_auc: 0.7612 - precision: 0.7014 - recall: 0.6685\n","Epoch 13: Validation Metrics:\n","loss: 0.5965396165847778\n","val_binary_accuracy: 0.6761062145233154\n","val_precision: 0.4263392984867096\n","val_recall: 0.6366666555404663\n","val_auc: 0.7325582504272461\n","val_prc_auc: 0.5283583998680115\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7528 - binary_accuracy: 0.6841 - f1: 0.6842 - loss: 0.5928 - prc_auc: 0.7608 - precision: 0.7010 - recall: 0.6683 - val_auc: 0.7326 - val_binary_accuracy: 0.6761 - val_f1: 0.5107 - val_loss: 0.5941 - val_prc_auc: 0.5284 - val_precision: 0.4263 - val_recall: 0.6367\n","Epoch 14/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7566 - binary_accuracy: 0.6871 - f1: 0.6863 - loss: 0.5902 - prc_auc: 0.7646 - precision: 0.7057 - recall: 0.6681\n","Epoch 14: Validation Metrics:\n","loss: 0.5941526889801025\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.43115124106407166\n","val_recall: 0.6366666555404663\n","val_auc: 0.7326405644416809\n","val_prc_auc: 0.5299647450447083\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7565 - binary_accuracy: 0.6869 - f1: 0.6860 - loss: 0.5903 - prc_auc: 0.7642 - precision: 0.7052 - recall: 0.6680 - val_auc: 0.7326 - val_binary_accuracy: 0.6805 - val_f1: 0.5141 - val_loss: 0.5935 - val_prc_auc: 0.5300 - val_precision: 0.4312 - val_recall: 0.6367\n","Epoch 15/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7593 - binary_accuracy: 0.6907 - f1: 0.6907 - loss: 0.5876 - prc_auc: 0.7670 - precision: 0.7082 - recall: 0.6744\n","Epoch 15: Validation Metrics:\n","loss: 0.5917840600013733\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.43083900213241577\n","val_recall: 0.6333333253860474\n","val_auc: 0.7327771186828613\n","val_prc_auc: 0.5314488410949707\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7592 - binary_accuracy: 0.6905 - f1: 0.6904 - loss: 0.5877 - prc_auc: 0.7666 - precision: 0.7077 - recall: 0.6742 - val_auc: 0.7328 - val_binary_accuracy: 0.6805 - val_f1: 0.5128 - val_loss: 0.5928 - val_prc_auc: 0.5314 - val_precision: 0.4308 - val_recall: 0.6333\n","Epoch 16/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7626 - binary_accuracy: 0.6963 - f1: 0.6944 - loss: 0.5851 - prc_auc: 0.7700 - precision: 0.7166 - recall: 0.6737\n","Epoch 16: Validation Metrics:\n","loss: 0.5894600749015808\n","val_binary_accuracy: 0.682300865650177\n","val_precision: 0.43310657143592834\n","val_recall: 0.6366666555404663\n","val_auc: 0.7328614592552185\n","val_prc_auc: 0.5294904112815857\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - auc: 0.7624 - binary_accuracy: 0.6960 - f1: 0.6940 - loss: 0.5852 - prc_auc: 0.7696 - precision: 0.7160 - recall: 0.6735 - val_auc: 0.7329 - val_binary_accuracy: 0.6823 - val_f1: 0.5155 - val_loss: 0.5923 - val_prc_auc: 0.5295 - val_precision: 0.4331 - val_recall: 0.6367\n","Epoch 17/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7655 - binary_accuracy: 0.6978 - f1: 0.6955 - loss: 0.5826 - prc_auc: 0.7728 - precision: 0.7187 - recall: 0.6740\n","Epoch 17: Validation Metrics:\n","loss: 0.5871333479881287\n","val_binary_accuracy: 0.6849557757377625\n","val_precision: 0.43607306480407715\n","val_recall: 0.6366666555404663\n","val_auc: 0.7327890992164612\n","val_prc_auc: 0.5306012034416199\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7653 - binary_accuracy: 0.6975 - f1: 0.6952 - loss: 0.5827 - prc_auc: 0.7723 - precision: 0.7181 - recall: 0.6739 - val_auc: 0.7328 - val_binary_accuracy: 0.6850 - val_f1: 0.5176 - val_loss: 0.5917 - val_prc_auc: 0.5306 - val_precision: 0.4361 - val_recall: 0.6367\n","Epoch 18/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7686 - binary_accuracy: 0.7026 - f1: 0.6990 - loss: 0.5801 - prc_auc: 0.7755 - precision: 0.7259 - recall: 0.6743\n","Epoch 18: Validation Metrics:\n","loss: 0.5848401188850403\n","val_binary_accuracy: 0.6814159154891968\n","val_precision: 0.43119266629219055\n","val_recall: 0.6266666650772095\n","val_auc: 0.7325944304466248\n","val_prc_auc: 0.5302450656890869\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7684 - binary_accuracy: 0.7023 - f1: 0.6986 - loss: 0.5803 - prc_auc: 0.7751 - precision: 0.7252 - recall: 0.6741 - val_auc: 0.7326 - val_binary_accuracy: 0.6814 - val_f1: 0.5109 - val_loss: 0.5910 - val_prc_auc: 0.5302 - val_precision: 0.4312 - val_recall: 0.6267\n","Epoch 19/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7714 - binary_accuracy: 0.7045 - f1: 0.7016 - loss: 0.5777 - prc_auc: 0.7780 - precision: 0.7268 - recall: 0.6783\n","Epoch 19: Validation Metrics:\n","loss: 0.5825599431991577\n","val_binary_accuracy: 0.6796460151672363\n","val_precision: 0.4288990795612335\n","val_recall: 0.6233333349227905\n","val_auc: 0.7325661778450012\n","val_prc_auc: 0.5293591022491455\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7713 - binary_accuracy: 0.7042 - f1: 0.7012 - loss: 0.5778 - prc_auc: 0.7775 - precision: 0.7262 - recall: 0.6781 - val_auc: 0.7326 - val_binary_accuracy: 0.6796 - val_f1: 0.5082 - val_loss: 0.5905 - val_prc_auc: 0.5294 - val_precision: 0.4289 - val_recall: 0.6233\n","Epoch 20/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7744 - binary_accuracy: 0.7050 - f1: 0.7020 - loss: 0.5753 - prc_auc: 0.7802 - precision: 0.7274 - recall: 0.6785\n","Epoch 20: Validation Metrics:\n","loss: 0.5802920460700989\n","val_binary_accuracy: 0.6831858158111572\n","val_precision: 0.43317973613739014\n","val_recall: 0.6266666650772095\n","val_auc: 0.731666624546051\n","val_prc_auc: 0.5291244387626648\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7742 - binary_accuracy: 0.7048 - f1: 0.7017 - loss: 0.5754 - prc_auc: 0.7798 - precision: 0.7269 - recall: 0.6784 - val_auc: 0.7317 - val_binary_accuracy: 0.6832 - val_f1: 0.5123 - val_loss: 0.5902 - val_prc_auc: 0.5291 - val_precision: 0.4332 - val_recall: 0.6267\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6597 - binary_accuracy: 0.5953 - f1: 0.5921 - loss: 0.6700 - prc_auc: 0.6629 - precision: 0.6062 - recall: 0.5982\n","Epoch 1: Validation Metrics:\n","loss: 0.6572219133377075\n","val_binary_accuracy: 0.6610619425773621\n","val_precision: 0.5534442067146301\n","val_recall: 0.5443925261497498\n","val_auc: 0.7110958099365234\n","val_prc_auc: 0.620629072189331\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 185ms/step - auc: 0.6599 - binary_accuracy: 0.5955 - f1: 0.5920 - loss: 0.6698 - prc_auc: 0.6629 - precision: 0.6065 - recall: 0.5977 - val_auc: 0.7111 - val_binary_accuracy: 0.6611 - val_f1: 0.5489 - val_loss: 0.6258 - val_prc_auc: 0.6206 - val_precision: 0.5534 - val_recall: 0.5444\n","Epoch 2/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7019 - binary_accuracy: 0.6417 - f1: 0.6018 - loss: 0.6313 - prc_auc: 0.6955 - precision: 0.6747 - recall: 0.5440\n","Epoch 2: Validation Metrics:\n","loss: 0.6326874494552612\n","val_binary_accuracy: 0.6628318428993225\n","val_precision: 0.5540229678153992\n","val_recall: 0.5630841255187988\n","val_auc: 0.7142876386642456\n","val_prc_auc: 0.6267735958099365\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7018 - binary_accuracy: 0.6416 - f1: 0.6018 - loss: 0.6313 - prc_auc: 0.6954 - precision: 0.6745 - recall: 0.5441 - val_auc: 0.7143 - val_binary_accuracy: 0.6628 - val_f1: 0.5585 - val_loss: 0.6162 - val_prc_auc: 0.6268 - val_precision: 0.5540 - val_recall: 0.5631\n","Epoch 3/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7097 - binary_accuracy: 0.6518 - f1: 0.6151 - loss: 0.6240 - prc_auc: 0.7021 - precision: 0.6846 - recall: 0.5594\n","Epoch 3: Validation Metrics:\n","loss: 0.6268675327301025\n","val_binary_accuracy: 0.6707964539527893\n","val_precision: 0.5648148059844971\n","val_recall: 0.5700934529304504\n","val_auc: 0.7165542244911194\n","val_prc_auc: 0.6285860538482666\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7097 - binary_accuracy: 0.6516 - f1: 0.6151 - loss: 0.6241 - prc_auc: 0.7021 - precision: 0.6844 - recall: 0.5594 - val_auc: 0.7166 - val_binary_accuracy: 0.6708 - val_f1: 0.5674 - val_loss: 0.6125 - val_prc_auc: 0.6286 - val_precision: 0.5648 - val_recall: 0.5701\n","Epoch 4/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7155 - binary_accuracy: 0.6548 - f1: 0.6198 - loss: 0.6199 - prc_auc: 0.7074 - precision: 0.6873 - recall: 0.5651\n","Epoch 4: Validation Metrics:\n","loss: 0.6230210065841675\n","val_binary_accuracy: 0.6690265536308289\n","val_precision: 0.5622119903564453\n","val_recall: 0.5700934529304504\n","val_auc: 0.718878984451294\n","val_prc_auc: 0.6307716369628906\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7155 - binary_accuracy: 0.6548 - f1: 0.6198 - loss: 0.6199 - prc_auc: 0.7074 - precision: 0.6871 - recall: 0.5652 - val_auc: 0.7189 - val_binary_accuracy: 0.6690 - val_f1: 0.5661 - val_loss: 0.6100 - val_prc_auc: 0.6308 - val_precision: 0.5622 - val_recall: 0.5701\n","Epoch 5/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7205 - binary_accuracy: 0.6579 - f1: 0.6227 - loss: 0.6166 - prc_auc: 0.7124 - precision: 0.6916 - recall: 0.5671\n","Epoch 5: Validation Metrics:\n","loss: 0.619803786277771\n","val_binary_accuracy: 0.6743362545967102\n","val_precision: 0.5694444179534912\n","val_recall: 0.5747663378715515\n","val_auc: 0.7209241986274719\n","val_prc_auc: 0.6344084143638611\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7204 - binary_accuracy: 0.6578 - f1: 0.6227 - loss: 0.6166 - prc_auc: 0.7124 - precision: 0.6914 - recall: 0.5672 - val_auc: 0.7209 - val_binary_accuracy: 0.6743 - val_f1: 0.5721 - val_loss: 0.6081 - val_prc_auc: 0.6344 - val_precision: 0.5694 - val_recall: 0.5748\n","Epoch 6/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7252 - binary_accuracy: 0.6633 - f1: 0.6296 - loss: 0.6135 - prc_auc: 0.7169 - precision: 0.6970 - recall: 0.5749\n","Epoch 6: Validation Metrics:\n","loss: 0.616866409778595\n","val_binary_accuracy: 0.6743362545967102\n","val_precision: 0.5694444179534912\n","val_recall: 0.5747663378715515\n","val_auc: 0.7223353981971741\n","val_prc_auc: 0.6347084045410156\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7251 - binary_accuracy: 0.6632 - f1: 0.6296 - loss: 0.6135 - prc_auc: 0.7169 - precision: 0.6968 - recall: 0.5750 - val_auc: 0.7223 - val_binary_accuracy: 0.6743 - val_f1: 0.5721 - val_loss: 0.6065 - val_prc_auc: 0.6347 - val_precision: 0.5694 - val_recall: 0.5748\n","Epoch 7/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7295 - binary_accuracy: 0.6663 - f1: 0.6330 - loss: 0.6106 - prc_auc: 0.7210 - precision: 0.7004 - recall: 0.5783\n","Epoch 7: Validation Metrics:\n","loss: 0.6140811443328857\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.5678160786628723\n","val_recall: 0.577102780342102\n","val_auc: 0.7235052585601807\n","val_prc_auc: 0.6353521943092346\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7294 - binary_accuracy: 0.6662 - f1: 0.6331 - loss: 0.6107 - prc_auc: 0.7210 - precision: 0.7002 - recall: 0.5784 - val_auc: 0.7235 - val_binary_accuracy: 0.6735 - val_f1: 0.5724 - val_loss: 0.6050 - val_prc_auc: 0.6354 - val_precision: 0.5678 - val_recall: 0.5771\n","Epoch 8/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7330 - binary_accuracy: 0.6696 - f1: 0.6390 - loss: 0.6079 - prc_auc: 0.7253 - precision: 0.7018 - recall: 0.5872\n","Epoch 8: Validation Metrics:\n","loss: 0.6113874316215515\n","val_binary_accuracy: 0.6716814041137695\n","val_precision: 0.5652173757553101\n","val_recall: 0.577102780342102\n","val_auc: 0.724565327167511\n","val_prc_auc: 0.6347761154174805\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7329 - binary_accuracy: 0.6695 - f1: 0.6390 - loss: 0.6080 - prc_auc: 0.7253 - precision: 0.7016 - recall: 0.5874 - val_auc: 0.7246 - val_binary_accuracy: 0.6717 - val_f1: 0.5711 - val_loss: 0.6039 - val_prc_auc: 0.6348 - val_precision: 0.5652 - val_recall: 0.5771\n","Epoch 9/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7369 - binary_accuracy: 0.6728 - f1: 0.6423 - loss: 0.6052 - prc_auc: 0.7304 - precision: 0.7059 - recall: 0.5899\n","Epoch 9: Validation Metrics:\n","loss: 0.6087414622306824\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.568129301071167\n","val_recall: 0.5747663378715515\n","val_auc: 0.7252726554870605\n","val_prc_auc: 0.6349292993545532\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7369 - binary_accuracy: 0.6728 - f1: 0.6423 - loss: 0.6053 - prc_auc: 0.7304 - precision: 0.7057 - recall: 0.5900 - val_auc: 0.7253 - val_binary_accuracy: 0.6735 - val_f1: 0.5714 - val_loss: 0.6028 - val_prc_auc: 0.6349 - val_precision: 0.5681 - val_recall: 0.5748\n","Epoch 10/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7405 - binary_accuracy: 0.6782 - f1: 0.6494 - loss: 0.6026 - prc_auc: 0.7343 - precision: 0.7110 - recall: 0.5982\n","Epoch 10: Validation Metrics:\n","loss: 0.6061241626739502\n","val_binary_accuracy: 0.6725663542747498\n","val_precision: 0.5668202638626099\n","val_recall: 0.5747663378715515\n","val_auc: 0.7257185578346252\n","val_prc_auc: 0.6354764103889465\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7404 - binary_accuracy: 0.6781 - f1: 0.6493 - loss: 0.6026 - prc_auc: 0.7343 - precision: 0.7108 - recall: 0.5984 - val_auc: 0.7257 - val_binary_accuracy: 0.6726 - val_f1: 0.5708 - val_loss: 0.6018 - val_prc_auc: 0.6355 - val_precision: 0.5668 - val_recall: 0.5748\n","Epoch 11/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7438 - binary_accuracy: 0.6842 - f1: 0.6578 - loss: 0.5999 - prc_auc: 0.7382 - precision: 0.7157 - recall: 0.6095\n","Epoch 11: Validation Metrics:\n","loss: 0.6035261154174805\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.5684455037117004\n","val_recall: 0.572429895401001\n","val_auc: 0.7266006469726562\n","val_prc_auc: 0.6350688338279724\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7438 - binary_accuracy: 0.6841 - f1: 0.6578 - loss: 0.6000 - prc_auc: 0.7382 - precision: 0.7155 - recall: 0.6096 - val_auc: 0.7266 - val_binary_accuracy: 0.6735 - val_f1: 0.5704 - val_loss: 0.6010 - val_prc_auc: 0.6351 - val_precision: 0.5684 - val_recall: 0.5724\n","Epoch 12/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7472 - binary_accuracy: 0.6883 - f1: 0.6636 - loss: 0.5973 - prc_auc: 0.7423 - precision: 0.7187 - recall: 0.6172\n","Epoch 12: Validation Metrics:\n","loss: 0.6009497046470642\n","val_binary_accuracy: 0.6699115037918091\n","val_precision: 0.563805103302002\n","val_recall: 0.5677570104598999\n","val_auc: 0.7272679209709167\n","val_prc_auc: 0.6353709101676941\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7471 - binary_accuracy: 0.6882 - f1: 0.6636 - loss: 0.5973 - prc_auc: 0.7423 - precision: 0.7185 - recall: 0.6174 - val_auc: 0.7273 - val_binary_accuracy: 0.6699 - val_f1: 0.5658 - val_loss: 0.6004 - val_prc_auc: 0.6354 - val_precision: 0.5638 - val_recall: 0.5678\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - auc: 0.7114 - binary_accuracy: 0.6685 - f1: 0.6547 - loss: 0.6489 - prc_auc: 0.6622 - precision: 0.6618 - recall: 0.6609\n","Epoch 1: Validation Metrics:\n","loss: 0.6223645210266113\n","val_binary_accuracy: 0.6761062145233154\n","val_precision: 0.5412371158599854\n","val_recall: 0.760869562625885\n","val_auc: 0.7467377781867981\n","val_prc_auc: 0.5942250490188599\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 232ms/step - auc: 0.7116 - binary_accuracy: 0.6687 - f1: 0.6552 - loss: 0.6486 - prc_auc: 0.6624 - precision: 0.6619 - recall: 0.6616 - val_auc: 0.7467 - val_binary_accuracy: 0.6761 - val_f1: 0.6325 - val_loss: 0.6112 - val_prc_auc: 0.5942 - val_precision: 0.5412 - val_recall: 0.7609\n","Epoch 2/20\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7633 - binary_accuracy: 0.7011 - f1: 0.7216 - loss: 0.5817 - prc_auc: 0.7181 - precision: 0.6691 - recall: 0.7831\n","Epoch 2: Validation Metrics:\n","loss: 0.5792912840843201\n","val_binary_accuracy: 0.6796460151672363\n","val_precision: 0.54347825050354\n","val_recall: 0.7850241661071777\n","val_auc: 0.755566418170929\n","val_prc_auc: 0.6218984127044678\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7632 - binary_accuracy: 0.7011 - f1: 0.7216 - loss: 0.5817 - prc_auc: 0.7181 - precision: 0.6691 - recall: 0.7831 - val_auc: 0.7556 - val_binary_accuracy: 0.6796 - val_f1: 0.6423 - val_loss: 0.5934 - val_prc_auc: 0.6219 - val_precision: 0.5435 - val_recall: 0.7850\n","Epoch 3/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7724 - binary_accuracy: 0.7064 - f1: 0.7302 - loss: 0.5674 - prc_auc: 0.7328 - precision: 0.6693 - recall: 0.8034\n","Epoch 3: Validation Metrics:\n","loss: 0.5676509737968445\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.5369458198547363\n","val_recall: 0.7898550629615784\n","val_auc: 0.7600160241127014\n","val_prc_auc: 0.6297354102134705\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7724 - binary_accuracy: 0.7064 - f1: 0.7302 - loss: 0.5674 - prc_auc: 0.7328 - precision: 0.6693 - recall: 0.8034 - val_auc: 0.7600 - val_binary_accuracy: 0.6735 - val_f1: 0.6393 - val_loss: 0.5884 - val_prc_auc: 0.6297 - val_precision: 0.5369 - val_recall: 0.7899\n","Epoch 4/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7790 - binary_accuracy: 0.7087 - f1: 0.7355 - loss: 0.5603 - prc_auc: 0.7458 - precision: 0.6675 - recall: 0.8192\n","Epoch 4: Validation Metrics:\n","loss: 0.5614386200904846\n","val_binary_accuracy: 0.6769911646842957\n","val_precision: 0.5399673581123352\n","val_recall: 0.7995169162750244\n","val_auc: 0.7631450295448303\n","val_prc_auc: 0.6368470788002014\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7790 - binary_accuracy: 0.7087 - f1: 0.7355 - loss: 0.5604 - prc_auc: 0.7457 - precision: 0.6675 - recall: 0.8191 - val_auc: 0.7631 - val_binary_accuracy: 0.6770 - val_f1: 0.6446 - val_loss: 0.5863 - val_prc_auc: 0.6368 - val_precision: 0.5400 - val_recall: 0.7995\n","Epoch 5/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7835 - binary_accuracy: 0.7139 - f1: 0.7422 - loss: 0.5556 - prc_auc: 0.7506 - precision: 0.6693 - recall: 0.8331\n","Epoch 5: Validation Metrics:\n","loss: 0.5571231842041016\n","val_binary_accuracy: 0.6787610650062561\n","val_precision: 0.541329026222229\n","val_recall: 0.8067632913589478\n","val_auc: 0.7648638486862183\n","val_prc_auc: 0.6414021253585815\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7835 - binary_accuracy: 0.7139 - f1: 0.7422 - loss: 0.5557 - prc_auc: 0.7506 - precision: 0.6694 - recall: 0.8330 - val_auc: 0.7649 - val_binary_accuracy: 0.6788 - val_f1: 0.6479 - val_loss: 0.5853 - val_prc_auc: 0.6414 - val_precision: 0.5413 - val_recall: 0.8068\n","Epoch 6/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7875 - binary_accuracy: 0.7163 - f1: 0.7458 - loss: 0.5518 - prc_auc: 0.7561 - precision: 0.6696 - recall: 0.8417\n","Epoch 6: Validation Metrics:\n","loss: 0.5535549521446228\n","val_binary_accuracy: 0.6752212643623352\n","val_precision: 0.5378422141075134\n","val_recall: 0.8067632913589478\n","val_auc: 0.7661255598068237\n","val_prc_auc: 0.6422972679138184\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7875 - binary_accuracy: 0.7163 - f1: 0.7458 - loss: 0.5519 - prc_auc: 0.7561 - precision: 0.6697 - recall: 0.8415 - val_auc: 0.7661 - val_binary_accuracy: 0.6752 - val_f1: 0.6454 - val_loss: 0.5845 - val_prc_auc: 0.6423 - val_precision: 0.5378 - val_recall: 0.8068\n","Epoch 7/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7911 - binary_accuracy: 0.7168 - f1: 0.7459 - loss: 0.5484 - prc_auc: 0.7591 - precision: 0.6705 - recall: 0.8406\n","Epoch 7: Validation Metrics:\n","loss: 0.55028235912323\n","val_binary_accuracy: 0.6761062145233154\n","val_precision: 0.5384615659713745\n","val_recall: 0.8115941882133484\n","val_auc: 0.7678089141845703\n","val_prc_auc: 0.6476842164993286\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7910 - binary_accuracy: 0.7168 - f1: 0.7459 - loss: 0.5484 - prc_auc: 0.7590 - precision: 0.6706 - recall: 0.8405 - val_auc: 0.7678 - val_binary_accuracy: 0.6761 - val_f1: 0.6474 - val_loss: 0.5840 - val_prc_auc: 0.6477 - val_precision: 0.5385 - val_recall: 0.8116\n","Epoch 8/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7942 - binary_accuracy: 0.7208 - f1: 0.7493 - loss: 0.5451 - prc_auc: 0.7633 - precision: 0.6741 - recall: 0.8435\n","Epoch 8: Validation Metrics:\n","loss: 0.5471909046173096\n","val_binary_accuracy: 0.6725663542747498\n","val_precision: 0.5350318551063538\n","val_recall: 0.8115941882133484\n","val_auc: 0.7693169116973877\n","val_prc_auc: 0.6493539810180664\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7941 - binary_accuracy: 0.7208 - f1: 0.7493 - loss: 0.5451 - prc_auc: 0.7633 - precision: 0.6742 - recall: 0.8434 - val_auc: 0.7693 - val_binary_accuracy: 0.6726 - val_f1: 0.6449 - val_loss: 0.5835 - val_prc_auc: 0.6494 - val_precision: 0.5350 - val_recall: 0.8116\n","Epoch 9/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7978 - binary_accuracy: 0.7236 - f1: 0.7513 - loss: 0.5419 - prc_auc: 0.7670 - precision: 0.6770 - recall: 0.8441\n","Epoch 9: Validation Metrics:\n","loss: 0.5441957116127014\n","val_binary_accuracy: 0.6716814041137695\n","val_precision: 0.5341812372207642\n","val_recall: 0.8115941882133484\n","val_auc: 0.7703813314437866\n","val_prc_auc: 0.6500385999679565\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7978 - binary_accuracy: 0.7236 - f1: 0.7513 - loss: 0.5420 - prc_auc: 0.7670 - precision: 0.6771 - recall: 0.8440 - val_auc: 0.7704 - val_binary_accuracy: 0.6717 - val_f1: 0.6443 - val_loss: 0.5829 - val_prc_auc: 0.6500 - val_precision: 0.5342 - val_recall: 0.8116\n","Epoch 10/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8006 - binary_accuracy: 0.7268 - f1: 0.7537 - loss: 0.5388 - prc_auc: 0.7702 - precision: 0.6804 - recall: 0.8447\n","Epoch 10: Validation Metrics:\n","loss: 0.5412439107894897\n","val_binary_accuracy: 0.6752212643623352\n","val_precision: 0.5375999808311462\n","val_recall: 0.8115941882133484\n","val_auc: 0.7719482183456421\n","val_prc_auc: 0.6526666879653931\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.8005 - binary_accuracy: 0.7268 - f1: 0.7537 - loss: 0.5389 - prc_auc: 0.7701 - precision: 0.6805 - recall: 0.8446 - val_auc: 0.7719 - val_binary_accuracy: 0.6752 - val_f1: 0.6468 - val_loss: 0.5821 - val_prc_auc: 0.6527 - val_precision: 0.5376 - val_recall: 0.8116\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_5_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - auc: 0.6895 - binary_accuracy: 0.6429 - f1: 0.5957 - loss: 0.6560 - prc_auc: 0.6719 - precision: 0.6716 - recall: 0.5357\n","Epoch 1: Validation Metrics:\n","loss: 0.6286122798919678\n","val_binary_accuracy: 0.6884955763816833\n","val_precision: 0.5835240483283997\n","val_recall: 0.6000000238418579\n","val_auc: 0.7162302732467651\n","val_prc_auc: 0.5831030607223511\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 240ms/step - auc: 0.6898 - binary_accuracy: 0.6433 - f1: 0.5963 - loss: 0.6558 - prc_auc: 0.6723 - precision: 0.6720 - recall: 0.5363 - val_auc: 0.7162 - val_binary_accuracy: 0.6885 - val_f1: 0.5916 - val_loss: 0.6240 - val_prc_auc: 0.5831 - val_precision: 0.5835 - val_recall: 0.6000\n","Epoch 2/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7619 - binary_accuracy: 0.7051 - f1: 0.6890 - loss: 0.5905 - prc_auc: 0.7314 - precision: 0.7173 - recall: 0.6634\n","Epoch 2: Validation Metrics:\n","loss: 0.5826085805892944\n","val_binary_accuracy: 0.6955752372741699\n","val_precision: 0.5886214375495911\n","val_recall: 0.6329411864280701\n","val_auc: 0.7383179068565369\n","val_prc_auc: 0.5968421101570129\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7620 - binary_accuracy: 0.7052 - f1: 0.6891 - loss: 0.5903 - prc_auc: 0.7319 - precision: 0.7175 - recall: 0.6634 - val_auc: 0.7383 - val_binary_accuracy: 0.6956 - val_f1: 0.6100 - val_loss: 0.6116 - val_prc_auc: 0.5968 - val_precision: 0.5886 - val_recall: 0.6329\n","Epoch 3/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7773 - binary_accuracy: 0.7175 - f1: 0.7074 - loss: 0.5750 - prc_auc: 0.7423 - precision: 0.7226 - recall: 0.6934\n","Epoch 3: Validation Metrics:\n","loss: 0.5703783631324768\n","val_binary_accuracy: 0.6982300877571106\n","val_precision: 0.5897436141967773\n","val_recall: 0.6494117379188538\n","val_auc: 0.7442219257354736\n","val_prc_auc: 0.6050475835800171\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7774 - binary_accuracy: 0.7174 - f1: 0.7074 - loss: 0.5749 - prc_auc: 0.7427 - precision: 0.7227 - recall: 0.6933 - val_auc: 0.7442 - val_binary_accuracy: 0.6982 - val_f1: 0.6181 - val_loss: 0.6048 - val_prc_auc: 0.6050 - val_precision: 0.5897 - val_recall: 0.6494\n","Epoch 4/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7842 - binary_accuracy: 0.7178 - f1: 0.7116 - loss: 0.5668 - prc_auc: 0.7525 - precision: 0.7168 - recall: 0.7069\n","Epoch 4: Validation Metrics:\n","loss: 0.5637010335922241\n","val_binary_accuracy: 0.6973451375961304\n","val_precision: 0.5873684287071228\n","val_recall: 0.6564705967903137\n","val_auc: 0.7460041642189026\n","val_prc_auc: 0.6063756346702576\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7843 - binary_accuracy: 0.7177 - f1: 0.7116 - loss: 0.5667 - prc_auc: 0.7528 - precision: 0.7169 - recall: 0.7067 - val_auc: 0.7460 - val_binary_accuracy: 0.6973 - val_f1: 0.6200 - val_loss: 0.6018 - val_prc_auc: 0.6064 - val_precision: 0.5874 - val_recall: 0.6565\n","Epoch 5/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7874 - binary_accuracy: 0.7211 - f1: 0.7170 - loss: 0.5615 - prc_auc: 0.7565 - precision: 0.7172 - recall: 0.7171\n","Epoch 5: Validation Metrics:\n","loss: 0.5590862035751343\n","val_binary_accuracy: 0.6946902871131897\n","val_precision: 0.5826446413993835\n","val_recall: 0.6635293960571289\n","val_auc: 0.7472140192985535\n","val_prc_auc: 0.6089378595352173\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7874 - binary_accuracy: 0.7211 - f1: 0.7170 - loss: 0.5615 - prc_auc: 0.7568 - precision: 0.7173 - recall: 0.7170 - val_auc: 0.7472 - val_binary_accuracy: 0.6947 - val_f1: 0.6205 - val_loss: 0.5999 - val_prc_auc: 0.6089 - val_precision: 0.5826 - val_recall: 0.6635\n","Epoch 6/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7906 - binary_accuracy: 0.7214 - f1: 0.7191 - loss: 0.5574 - prc_auc: 0.7611 - precision: 0.7145 - recall: 0.7243\n","Epoch 6: Validation Metrics:\n","loss: 0.5552805662155151\n","val_binary_accuracy: 0.6964601874351501\n","val_precision: 0.5843621492385864\n","val_recall: 0.6682353019714355\n","val_auc: 0.748106837272644\n","val_prc_auc: 0.6126435399055481\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7906 - binary_accuracy: 0.7213 - f1: 0.7191 - loss: 0.5574 - prc_auc: 0.7614 - precision: 0.7147 - recall: 0.7241 - val_auc: 0.7481 - val_binary_accuracy: 0.6965 - val_f1: 0.6235 - val_loss: 0.5985 - val_prc_auc: 0.6126 - val_precision: 0.5844 - val_recall: 0.6682\n","Epoch 7/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7934 - binary_accuracy: 0.7211 - f1: 0.7193 - loss: 0.5539 - prc_auc: 0.7652 - precision: 0.7136 - recall: 0.7255\n","Epoch 7: Validation Metrics:\n","loss: 0.5518974661827087\n","val_binary_accuracy: 0.6991150379180908\n","val_precision: 0.5869120359420776\n","val_recall: 0.6752941012382507\n","val_auc: 0.7489011883735657\n","val_prc_auc: 0.6140797138214111\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7934 - binary_accuracy: 0.7211 - f1: 0.7193 - loss: 0.5539 - prc_auc: 0.7656 - precision: 0.7138 - recall: 0.7254 - val_auc: 0.7489 - val_binary_accuracy: 0.6991 - val_f1: 0.6280 - val_loss: 0.5975 - val_prc_auc: 0.6141 - val_precision: 0.5869 - val_recall: 0.6753\n","Epoch 8/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7958 - binary_accuracy: 0.7248 - f1: 0.7244 - loss: 0.5507 - prc_auc: 0.7691 - precision: 0.7152 - recall: 0.7345\n","Epoch 8: Validation Metrics:\n","loss: 0.548723042011261\n","val_binary_accuracy: 0.6973451375961304\n","val_precision: 0.5845214128494263\n","val_recall: 0.6752941012382507\n","val_auc: 0.7498757243156433\n","val_prc_auc: 0.6163549423217773\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7958 - binary_accuracy: 0.7248 - f1: 0.7244 - loss: 0.5507 - prc_auc: 0.7695 - precision: 0.7153 - recall: 0.7343 - val_auc: 0.7499 - val_binary_accuracy: 0.6973 - val_f1: 0.6266 - val_loss: 0.5966 - val_prc_auc: 0.6164 - val_precision: 0.5845 - val_recall: 0.6753\n","Epoch 9/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7983 - binary_accuracy: 0.7262 - f1: 0.7263 - loss: 0.5477 - prc_auc: 0.7731 - precision: 0.7157 - recall: 0.7378\n","Epoch 9: Validation Metrics:\n","loss: 0.5456603169441223\n","val_binary_accuracy: 0.6955752372741699\n","val_precision: 0.5821501016616821\n","val_recall: 0.6752941012382507\n","val_auc: 0.7502912282943726\n","val_prc_auc: 0.6179960370063782\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7984 - binary_accuracy: 0.7261 - f1: 0.7263 - loss: 0.5476 - prc_auc: 0.7735 - precision: 0.7158 - recall: 0.7377 - val_auc: 0.7503 - val_binary_accuracy: 0.6956 - val_f1: 0.6253 - val_loss: 0.5958 - val_prc_auc: 0.6180 - val_precision: 0.5822 - val_recall: 0.6753\n","Epoch 10/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8010 - binary_accuracy: 0.7269 - f1: 0.7269 - loss: 0.5446 - prc_auc: 0.7766 - precision: 0.7167 - recall: 0.7379\n","Epoch 10: Validation Metrics:\n","loss: 0.5426656007766724\n","val_binary_accuracy: 0.6955752372741699\n","val_precision: 0.581818163394928\n","val_recall: 0.677647054195404\n","val_auc: 0.750953733921051\n","val_prc_auc: 0.619818925857544\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8010 - binary_accuracy: 0.7268 - f1: 0.7269 - loss: 0.5446 - prc_auc: 0.7770 - precision: 0.7168 - recall: 0.7378 - val_auc: 0.7510 - val_binary_accuracy: 0.6956 - val_f1: 0.6261 - val_loss: 0.5951 - val_prc_auc: 0.6198 - val_precision: 0.5818 - val_recall: 0.6776\n","Epoch 11/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8032 - binary_accuracy: 0.7285 - f1: 0.7297 - loss: 0.5417 - prc_auc: 0.7798 - precision: 0.7163 - recall: 0.7441\n","Epoch 11: Validation Metrics:\n","loss: 0.5397239327430725\n","val_binary_accuracy: 0.6929203271865845\n","val_precision: 0.5783132314682007\n","val_recall: 0.677647054195404\n","val_auc: 0.7516412138938904\n","val_prc_auc: 0.6219176650047302\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8033 - binary_accuracy: 0.7285 - f1: 0.7297 - loss: 0.5417 - prc_auc: 0.7802 - precision: 0.7164 - recall: 0.7440 - val_auc: 0.7516 - val_binary_accuracy: 0.6929 - val_f1: 0.6241 - val_loss: 0.5944 - val_prc_auc: 0.6219 - val_precision: 0.5783 - val_recall: 0.6776\n","Epoch 12/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8058 - binary_accuracy: 0.7314 - f1: 0.7332 - loss: 0.5388 - prc_auc: 0.7836 - precision: 0.7181 - recall: 0.7496\n","Epoch 12: Validation Metrics:\n","loss: 0.5367587804794312\n","val_binary_accuracy: 0.6938053369522095\n","val_precision: 0.5788423418998718\n","val_recall: 0.6823529601097107\n","val_auc: 0.7524522542953491\n","val_prc_auc: 0.6245408058166504\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8058 - binary_accuracy: 0.7313 - f1: 0.7332 - loss: 0.5387 - prc_auc: 0.7839 - precision: 0.7181 - recall: 0.7494 - val_auc: 0.7525 - val_binary_accuracy: 0.6938 - val_f1: 0.6263 - val_loss: 0.5938 - val_prc_auc: 0.6245 - val_precision: 0.5788 - val_recall: 0.6824\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 423ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 427ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 423ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 427ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 424ms/step\n","[[1 1 0 1 0]\n"," [0 1 0 0 1]\n"," [0 1 0 1 0]\n"," ...\n"," [1 0 1 0 0]\n"," [0 1 0 0 1]\n"," [0 0 0 1 1]]\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - auc: 0.5881 - binary_accuracy: 0.5719 - f1: 0.3827 - loss: 0.6867 - prc_auc: 0.6273 - precision: 0.6269 - recall: 0.2916\n","Epoch 1: Validation Metrics:\n","loss: 0.6795690059661865\n","val_binary_accuracy: 0.7808641791343689\n","val_precision: 0.4439024329185486\n","val_recall: 0.3486590087413788\n","val_auc: 0.7047365307807922\n","val_prc_auc: 0.44886091351509094\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 391ms/step - auc: 0.5889 - binary_accuracy: 0.5724 - f1: 0.3848 - loss: 0.6866 - prc_auc: 0.6278 - precision: 0.6275 - recall: 0.2937 - val_auc: 0.7047 - val_binary_accuracy: 0.7809 - val_f1: 0.3906 - val_loss: 0.6356 - val_prc_auc: 0.4489 - val_precision: 0.4439 - val_recall: 0.3487\n","Epoch 2/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6835 - binary_accuracy: 0.6075 - f1: 0.4834 - loss: 0.6613 - prc_auc: 0.7052 - precision: 0.7206 - recall: 0.3690\n","Epoch 2: Validation Metrics:\n","loss: 0.6542866230010986\n","val_binary_accuracy: 0.7739197611808777\n","val_precision: 0.4292035400867462\n","val_recall: 0.37164750695228577\n","val_auc: 0.7122179269790649\n","val_prc_auc: 0.4525384306907654\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.6837 - binary_accuracy: 0.6080 - f1: 0.4852 - loss: 0.6611 - prc_auc: 0.7052 - precision: 0.7198 - recall: 0.3713 - val_auc: 0.7122 - val_binary_accuracy: 0.7739 - val_f1: 0.3984 - val_loss: 0.6022 - val_prc_auc: 0.4525 - val_precision: 0.4292 - val_recall: 0.3716\n","Epoch 3/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6898 - binary_accuracy: 0.6210 - f1: 0.5195 - loss: 0.6443 - prc_auc: 0.7148 - precision: 0.7230 - recall: 0.4117\n","Epoch 3: Validation Metrics:\n","loss: 0.6370053291320801\n","val_binary_accuracy: 0.7692901492118835\n","val_precision: 0.42016807198524475\n","val_recall: 0.38314175605773926\n","val_auc: 0.7172062397003174\n","val_prc_auc: 0.4557510018348694\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.6901 - binary_accuracy: 0.6213 - f1: 0.5210 - loss: 0.6441 - prc_auc: 0.7149 - precision: 0.7221 - recall: 0.4137 - val_auc: 0.7172 - val_binary_accuracy: 0.7693 - val_f1: 0.4008 - val_loss: 0.5800 - val_prc_auc: 0.4558 - val_precision: 0.4202 - val_recall: 0.3831\n","Epoch 4/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6949 - binary_accuracy: 0.6304 - f1: 0.5465 - loss: 0.6340 - prc_auc: 0.7213 - precision: 0.7196 - recall: 0.4475\n","Epoch 4: Validation Metrics:\n","loss: 0.6262586116790771\n","val_binary_accuracy: 0.7692901492118835\n","val_precision: 0.42213115096092224\n","val_recall: 0.39463600516319275\n","val_auc: 0.7214207649230957\n","val_prc_auc: 0.4564702808856964\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.6952 - binary_accuracy: 0.6307 - f1: 0.5477 - loss: 0.6338 - prc_auc: 0.7214 - precision: 0.7187 - recall: 0.4493 - val_auc: 0.7214 - val_binary_accuracy: 0.7693 - val_f1: 0.4079 - val_loss: 0.5675 - val_prc_auc: 0.4565 - val_precision: 0.4221 - val_recall: 0.3946\n","Epoch 5/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7008 - binary_accuracy: 0.6382 - f1: 0.5679 - loss: 0.6271 - prc_auc: 0.7276 - precision: 0.7179 - recall: 0.4761\n","Epoch 5: Validation Metrics:\n","loss: 0.6188944578170776\n","val_binary_accuracy: 0.7762345671653748\n","val_precision: 0.44081631302833557\n","val_recall: 0.4137931168079376\n","val_auc: 0.7255353331565857\n","val_prc_auc: 0.4604913592338562\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7013 - binary_accuracy: 0.6384 - f1: 0.5688 - loss: 0.6269 - prc_auc: 0.7277 - precision: 0.7171 - recall: 0.4777 - val_auc: 0.7255 - val_binary_accuracy: 0.7762 - val_f1: 0.4269 - val_loss: 0.5599 - val_prc_auc: 0.4605 - val_precision: 0.4408 - val_recall: 0.4138\n","Epoch 6/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7062 - binary_accuracy: 0.6451 - f1: 0.5790 - loss: 0.6219 - prc_auc: 0.7322 - precision: 0.7266 - recall: 0.4892\n","Epoch 6: Validation Metrics:\n","loss: 0.6133077144622803\n","val_binary_accuracy: 0.7777777910232544\n","val_precision: 0.44489794969558716\n","val_recall: 0.4176245331764221\n","val_auc: 0.7300941348075867\n","val_prc_auc: 0.4617938697338104\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7067 - binary_accuracy: 0.6453 - f1: 0.5799 - loss: 0.6217 - prc_auc: 0.7324 - precision: 0.7257 - recall: 0.4907 - val_auc: 0.7301 - val_binary_accuracy: 0.7778 - val_f1: 0.4308 - val_loss: 0.5541 - val_prc_auc: 0.4618 - val_precision: 0.4449 - val_recall: 0.4176\n","Epoch 7/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7115 - binary_accuracy: 0.6477 - f1: 0.5873 - loss: 0.6177 - prc_auc: 0.7367 - precision: 0.7224 - recall: 0.5034\n","Epoch 7: Validation Metrics:\n","loss: 0.6086946725845337\n","val_binary_accuracy: 0.7770061492919922\n","val_precision: 0.44354838132858276\n","val_recall: 0.4214559495449066\n","val_auc: 0.7332537770271301\n","val_prc_auc: 0.4647213816642761\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7120 - binary_accuracy: 0.6479 - f1: 0.5882 - loss: 0.6174 - prc_auc: 0.7369 - precision: 0.7215 - recall: 0.5049 - val_auc: 0.7333 - val_binary_accuracy: 0.7770 - val_f1: 0.4322 - val_loss: 0.5499 - val_prc_auc: 0.4647 - val_precision: 0.4435 - val_recall: 0.4215\n","Epoch 8/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7161 - binary_accuracy: 0.6529 - f1: 0.5978 - loss: 0.6141 - prc_auc: 0.7413 - precision: 0.7245 - recall: 0.5171\n","Epoch 8: Validation Metrics:\n","loss: 0.6047799587249756\n","val_binary_accuracy: 0.7808641791343689\n","val_precision: 0.45418328046798706\n","val_recall: 0.4367816150188446\n","val_auc: 0.7362985014915466\n","val_prc_auc: 0.46779513359069824\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7165 - binary_accuracy: 0.6531 - f1: 0.5986 - loss: 0.6139 - prc_auc: 0.7414 - precision: 0.7237 - recall: 0.5185 - val_auc: 0.7363 - val_binary_accuracy: 0.7809 - val_f1: 0.4453 - val_loss: 0.5467 - val_prc_auc: 0.4678 - val_precision: 0.4542 - val_recall: 0.4368\n","Epoch 9/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7192 - binary_accuracy: 0.6568 - f1: 0.6080 - loss: 0.6111 - prc_auc: 0.7443 - precision: 0.7210 - recall: 0.5320\n","Epoch 9: Validation Metrics:\n","loss: 0.6014106869697571\n","val_binary_accuracy: 0.779321014881134\n","val_precision: 0.45136186480522156\n","val_recall: 0.4444444477558136\n","val_auc: 0.7385640740394592\n","val_prc_auc: 0.4710414707660675\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7197 - binary_accuracy: 0.6570 - f1: 0.6088 - loss: 0.6108 - prc_auc: 0.7445 - precision: 0.7203 - recall: 0.5334 - val_auc: 0.7386 - val_binary_accuracy: 0.7793 - val_f1: 0.4479 - val_loss: 0.5439 - val_prc_auc: 0.4710 - val_precision: 0.4514 - val_recall: 0.4444\n","Epoch 10/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7227 - binary_accuracy: 0.6628 - f1: 0.6165 - loss: 0.6083 - prc_auc: 0.7478 - precision: 0.7262 - recall: 0.5421\n","Epoch 10: Validation Metrics:\n","loss: 0.5983865261077881\n","val_binary_accuracy: 0.7824074029922485\n","val_precision: 0.4591439664363861\n","val_recall: 0.4521072804927826\n","val_auc: 0.7411664128303528\n","val_prc_auc: 0.4731021523475647\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7232 - binary_accuracy: 0.6631 - f1: 0.6172 - loss: 0.6080 - prc_auc: 0.7480 - precision: 0.7256 - recall: 0.5435 - val_auc: 0.7412 - val_binary_accuracy: 0.7824 - val_f1: 0.4556 - val_loss: 0.5416 - val_prc_auc: 0.4731 - val_precision: 0.4591 - val_recall: 0.4521\n","Epoch 11/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7262 - binary_accuracy: 0.6644 - f1: 0.6216 - loss: 0.6058 - prc_auc: 0.7509 - precision: 0.7234 - recall: 0.5519\n","Epoch 11: Validation Metrics:\n","loss: 0.5956164002418518\n","val_binary_accuracy: 0.7839506268501282\n","val_precision: 0.4630350172519684\n","val_recall: 0.4559386968612671\n","val_auc: 0.7429119348526001\n","val_prc_auc: 0.4749357998371124\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7267 - binary_accuracy: 0.6647 - f1: 0.6224 - loss: 0.6055 - prc_auc: 0.7510 - precision: 0.7229 - recall: 0.5533 - val_auc: 0.7429 - val_binary_accuracy: 0.7840 - val_f1: 0.4595 - val_loss: 0.5390 - val_prc_auc: 0.4749 - val_precision: 0.4630 - val_recall: 0.4559\n","Epoch 12/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7288 - binary_accuracy: 0.6719 - f1: 0.6330 - loss: 0.6035 - prc_auc: 0.7531 - precision: 0.7284 - recall: 0.5666\n","Epoch 12: Validation Metrics:\n","loss: 0.5930130481719971\n","val_binary_accuracy: 0.7762345671653748\n","val_precision: 0.44486692547798157\n","val_recall: 0.4482758641242981\n","val_auc: 0.7450312376022339\n","val_prc_auc: 0.47534072399139404\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7293 - binary_accuracy: 0.6721 - f1: 0.6337 - loss: 0.6032 - prc_auc: 0.7532 - precision: 0.7278 - recall: 0.5679 - val_auc: 0.7450 - val_binary_accuracy: 0.7762 - val_f1: 0.4466 - val_loss: 0.5369 - val_prc_auc: 0.4753 - val_precision: 0.4449 - val_recall: 0.4483\n","Epoch 13/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7313 - binary_accuracy: 0.6714 - f1: 0.6333 - loss: 0.6013 - prc_auc: 0.7554 - precision: 0.7280 - recall: 0.5685\n","Epoch 13: Validation Metrics:\n","loss: 0.5905580520629883\n","val_binary_accuracy: 0.7777777910232544\n","val_precision: 0.44905659556388855\n","val_recall: 0.4559386968612671\n","val_auc: 0.7467451095581055\n","val_prc_auc: 0.48012077808380127\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7318 - binary_accuracy: 0.6716 - f1: 0.6340 - loss: 0.6010 - prc_auc: 0.7556 - precision: 0.7274 - recall: 0.5697 - val_auc: 0.7467 - val_binary_accuracy: 0.7778 - val_f1: 0.4525 - val_loss: 0.5349 - val_prc_auc: 0.4801 - val_precision: 0.4491 - val_recall: 0.4559\n","Epoch 14/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7338 - binary_accuracy: 0.6736 - f1: 0.6370 - loss: 0.5993 - prc_auc: 0.7577 - precision: 0.7294 - recall: 0.5731\n","Epoch 14: Validation Metrics:\n","loss: 0.5882849097251892\n","val_binary_accuracy: 0.779321014881134\n","val_precision: 0.4528301954269409\n","val_recall: 0.4597701132297516\n","val_auc: 0.7479649782180786\n","val_prc_auc: 0.4815616309642792\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7344 - binary_accuracy: 0.6738 - f1: 0.6375 - loss: 0.5990 - prc_auc: 0.7579 - precision: 0.7287 - recall: 0.5743 - val_auc: 0.7480 - val_binary_accuracy: 0.7793 - val_f1: 0.4563 - val_loss: 0.5330 - val_prc_auc: 0.4816 - val_precision: 0.4528 - val_recall: 0.4598\n","Epoch 15/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7361 - binary_accuracy: 0.6792 - f1: 0.6441 - loss: 0.5974 - prc_auc: 0.7592 - precision: 0.7344 - recall: 0.5814\n","Epoch 15: Validation Metrics:\n","loss: 0.5861477255821228\n","val_binary_accuracy: 0.7800925970077515\n","val_precision: 0.4548872113227844\n","val_recall: 0.4636015295982361\n","val_auc: 0.7489163279533386\n","val_prc_auc: 0.4836254119873047\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7366 - binary_accuracy: 0.6794 - f1: 0.6447 - loss: 0.5971 - prc_auc: 0.7594 - precision: 0.7337 - recall: 0.5826 - val_auc: 0.7489 - val_binary_accuracy: 0.7801 - val_f1: 0.4592 - val_loss: 0.5314 - val_prc_auc: 0.4836 - val_precision: 0.4549 - val_recall: 0.4636\n","Epoch 16/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7381 - binary_accuracy: 0.6820 - f1: 0.6478 - loss: 0.5956 - prc_auc: 0.7609 - precision: 0.7368 - recall: 0.5859\n","Epoch 16: Validation Metrics:\n","loss: 0.5841024518013\n","val_binary_accuracy: 0.7800925970077515\n","val_precision: 0.4552238881587982\n","val_recall: 0.4674329459667206\n","val_auc: 0.7503026723861694\n","val_prc_auc: 0.48532140254974365\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7387 - binary_accuracy: 0.6822 - f1: 0.6483 - loss: 0.5953 - prc_auc: 0.7611 - precision: 0.7361 - recall: 0.5871 - val_auc: 0.7503 - val_binary_accuracy: 0.7801 - val_f1: 0.4612 - val_loss: 0.5301 - val_prc_auc: 0.4853 - val_precision: 0.4552 - val_recall: 0.4674\n","Epoch 17/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7398 - binary_accuracy: 0.6838 - f1: 0.6521 - loss: 0.5939 - prc_auc: 0.7627 - precision: 0.7358 - recall: 0.5929\n","Epoch 17: Validation Metrics:\n","loss: 0.582155168056488\n","val_binary_accuracy: 0.7770061492919922\n","val_precision: 0.4485294222831726\n","val_recall: 0.4674329459667206\n","val_auc: 0.7511928677558899\n","val_prc_auc: 0.4856691360473633\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7403 - binary_accuracy: 0.6839 - f1: 0.6526 - loss: 0.5936 - prc_auc: 0.7629 - precision: 0.7352 - recall: 0.5940 - val_auc: 0.7512 - val_binary_accuracy: 0.7770 - val_f1: 0.4578 - val_loss: 0.5288 - val_prc_auc: 0.4857 - val_precision: 0.4485 - val_recall: 0.4674\n","Epoch 18/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7416 - binary_accuracy: 0.6839 - f1: 0.6534 - loss: 0.5923 - prc_auc: 0.7640 - precision: 0.7336 - recall: 0.5964\n","Epoch 18: Validation Metrics:\n","loss: 0.5803022384643555\n","val_binary_accuracy: 0.7754629850387573\n","val_precision: 0.44485294818878174\n","val_recall: 0.4636015295982361\n","val_auc: 0.7519184350967407\n","val_prc_auc: 0.4871917963027954\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7422 - binary_accuracy: 0.6840 - f1: 0.6539 - loss: 0.5919 - prc_auc: 0.7642 - precision: 0.7329 - recall: 0.5975 - val_auc: 0.7519 - val_binary_accuracy: 0.7755 - val_f1: 0.4540 - val_loss: 0.5274 - val_prc_auc: 0.4872 - val_precision: 0.4449 - val_recall: 0.4636\n","Epoch 19/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7433 - binary_accuracy: 0.6838 - f1: 0.6541 - loss: 0.5908 - prc_auc: 0.7654 - precision: 0.7329 - recall: 0.5984\n","Epoch 19: Validation Metrics:\n","loss: 0.5784931182861328\n","val_binary_accuracy: 0.7739197611808777\n","val_precision: 0.4416058361530304\n","val_recall: 0.4636015295982361\n","val_auc: 0.7526736855506897\n","val_prc_auc: 0.4873534142971039\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7439 - binary_accuracy: 0.6840 - f1: 0.6546 - loss: 0.5904 - prc_auc: 0.7656 - precision: 0.7324 - recall: 0.5995 - val_auc: 0.7527 - val_binary_accuracy: 0.7739 - val_f1: 0.4523 - val_loss: 0.5262 - val_prc_auc: 0.4874 - val_precision: 0.4416 - val_recall: 0.4636\n","Epoch 20/20\n","\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7448 - binary_accuracy: 0.6873 - f1: 0.6590 - loss: 0.5893 - prc_auc: 0.7668 - precision: 0.7353 - recall: 0.6049\n","Epoch 20: Validation Metrics:\n","loss: 0.5767543911933899\n","val_binary_accuracy: 0.770061731338501\n","val_precision: 0.4341636896133423\n","val_recall: 0.4674329459667206\n","val_auc: 0.7533826231956482\n","val_prc_auc: 0.4898452162742615\n","\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - auc: 0.7454 - binary_accuracy: 0.6874 - f1: 0.6595 - loss: 0.5889 - prc_auc: 0.7670 - precision: 0.7346 - recall: 0.6059 - val_auc: 0.7534 - val_binary_accuracy: 0.7701 - val_f1: 0.4502 - val_loss: 0.5249 - val_prc_auc: 0.4898 - val_precision: 0.4342 - val_recall: 0.4674\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - auc: 0.5438 - binary_accuracy: 0.5419 - f1: 0.6712 - loss: 0.6885 - prc_auc: 0.5547 - precision: 0.5349 - recall: 0.9075\n","Epoch 1: Validation Metrics:\n","loss: 0.6837303042411804\n","val_binary_accuracy: 0.6998456716537476\n","val_precision: 0.6125461459159851\n","val_recall: 0.36888888478279114\n","val_auc: 0.6926451325416565\n","val_prc_auc: 0.5432710647583008\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 233ms/step - auc: 0.5442 - binary_accuracy: 0.5422 - f1: 0.6708 - loss: 0.6885 - prc_auc: 0.5547 - precision: 0.5351 - recall: 0.9058 - val_auc: 0.6926 - val_binary_accuracy: 0.6998 - val_f1: 0.4605 - val_loss: 0.6605 - val_prc_auc: 0.5433 - val_precision: 0.6125 - val_recall: 0.3689\n","Epoch 2/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6677 - binary_accuracy: 0.6061 - f1: 0.6486 - loss: 0.6675 - prc_auc: 0.6727 - precision: 0.6116 - recall: 0.7130\n","Epoch 2: Validation Metrics:\n","loss: 0.6651375889778137\n","val_binary_accuracy: 0.6751543283462524\n","val_precision: 0.5344418287277222\n","val_recall: 0.5\n","val_auc: 0.6986367106437683\n","val_prc_auc: 0.5470013618469238\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.6677 - binary_accuracy: 0.6062 - f1: 0.6483 - loss: 0.6674 - prc_auc: 0.6724 - precision: 0.6114 - recall: 0.7123 - val_auc: 0.6986 - val_binary_accuracy: 0.6752 - val_f1: 0.5166 - val_loss: 0.6436 - val_prc_auc: 0.5470 - val_precision: 0.5344 - val_recall: 0.5000\n","Epoch 3/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6896 - binary_accuracy: 0.6244 - f1: 0.6606 - loss: 0.6504 - prc_auc: 0.6970 - precision: 0.6227 - recall: 0.7119\n","Epoch 3: Validation Metrics:\n","loss: 0.6504766941070557\n","val_binary_accuracy: 0.658178985118866\n","val_precision: 0.5072765350341797\n","val_recall: 0.5422222018241882\n","val_auc: 0.7004833817481995\n","val_prc_auc: 0.5497258305549622\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - auc: 0.6895 - binary_accuracy: 0.6245 - f1: 0.6603 - loss: 0.6504 - prc_auc: 0.6967 - precision: 0.6227 - recall: 0.7112 - val_auc: 0.7005 - val_binary_accuracy: 0.6582 - val_f1: 0.5242 - val_loss: 0.6312 - val_prc_auc: 0.5497 - val_precision: 0.5073 - val_recall: 0.5422\n","Epoch 4/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6983 - binary_accuracy: 0.6337 - f1: 0.6654 - loss: 0.6380 - prc_auc: 0.7077 - precision: 0.6322 - recall: 0.7076\n","Epoch 4: Validation Metrics:\n","loss: 0.6402606964111328\n","val_binary_accuracy: 0.6535493731498718\n","val_precision: 0.5009980201721191\n","val_recall: 0.5577777624130249\n","val_auc: 0.7012319564819336\n","val_prc_auc: 0.5506894588470459\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.6982 - binary_accuracy: 0.6337 - f1: 0.6651 - loss: 0.6380 - prc_auc: 0.7074 - precision: 0.6321 - recall: 0.7069 - val_auc: 0.7012 - val_binary_accuracy: 0.6535 - val_f1: 0.5279 - val_loss: 0.6241 - val_prc_auc: 0.5507 - val_precision: 0.5010 - val_recall: 0.5578\n","Epoch 5/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7031 - binary_accuracy: 0.6343 - f1: 0.6625 - loss: 0.6303 - prc_auc: 0.7143 - precision: 0.6352 - recall: 0.6966\n","Epoch 5: Validation Metrics:\n","loss: 0.6338561177253723\n","val_binary_accuracy: 0.6512345671653748\n","val_precision: 0.498046875\n","val_recall: 0.5666666626930237\n","val_auc: 0.7017743587493896\n","val_prc_auc: 0.5513689517974854\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7030 - binary_accuracy: 0.6344 - f1: 0.6622 - loss: 0.6303 - prc_auc: 0.7139 - precision: 0.6352 - recall: 0.6961 - val_auc: 0.7018 - val_binary_accuracy: 0.6512 - val_f1: 0.5301 - val_loss: 0.6199 - val_prc_auc: 0.5514 - val_precision: 0.4980 - val_recall: 0.5667\n","Epoch 6/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7062 - binary_accuracy: 0.6345 - f1: 0.6596 - loss: 0.6253 - prc_auc: 0.7189 - precision: 0.6377 - recall: 0.6869\n","Epoch 6: Validation Metrics:\n","loss: 0.6297094821929932\n","val_binary_accuracy: 0.6496913433074951\n","val_precision: 0.4961538314819336\n","val_recall: 0.5733333230018616\n","val_auc: 0.7026937007904053\n","val_prc_auc: 0.5528340339660645\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7061 - binary_accuracy: 0.6346 - f1: 0.6594 - loss: 0.6254 - prc_auc: 0.7185 - precision: 0.6376 - recall: 0.6864 - val_auc: 0.7027 - val_binary_accuracy: 0.6497 - val_f1: 0.5320 - val_loss: 0.6175 - val_prc_auc: 0.5528 - val_precision: 0.4962 - val_recall: 0.5733\n","Epoch 7/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7086 - binary_accuracy: 0.6358 - f1: 0.6597 - loss: 0.6223 - prc_auc: 0.7218 - precision: 0.6397 - recall: 0.6845\n","Epoch 7: Validation Metrics:\n","loss: 0.627008855342865\n","val_binary_accuracy: 0.6512345671653748\n","val_precision: 0.4980769157409668\n","val_recall: 0.5755555629730225\n","val_auc: 0.7029590010643005\n","val_prc_auc: 0.5530526638031006\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7085 - binary_accuracy: 0.6359 - f1: 0.6595 - loss: 0.6224 - prc_auc: 0.7214 - precision: 0.6396 - recall: 0.6841 - val_auc: 0.7030 - val_binary_accuracy: 0.6512 - val_f1: 0.5340 - val_loss: 0.6161 - val_prc_auc: 0.5531 - val_precision: 0.4981 - val_recall: 0.5756\n","Epoch 8/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7106 - binary_accuracy: 0.6362 - f1: 0.6585 - loss: 0.6202 - prc_auc: 0.7245 - precision: 0.6411 - recall: 0.6804\n","Epoch 8: Validation Metrics:\n","loss: 0.6249722242355347\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.5\n","val_recall: 0.5777778029441833\n","val_auc: 0.7034003138542175\n","val_prc_auc: 0.5540590882301331\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7105 - binary_accuracy: 0.6363 - f1: 0.6583 - loss: 0.6203 - prc_auc: 0.7241 - precision: 0.6410 - recall: 0.6800 - val_auc: 0.7034 - val_binary_accuracy: 0.6528 - val_f1: 0.5361 - val_loss: 0.6153 - val_prc_auc: 0.5541 - val_precision: 0.5000 - val_recall: 0.5778\n","Epoch 9/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7122 - binary_accuracy: 0.6383 - f1: 0.6609 - loss: 0.6186 - prc_auc: 0.7267 - precision: 0.6429 - recall: 0.6825\n","Epoch 9: Validation Metrics:\n","loss: 0.6233243942260742\n","val_binary_accuracy: 0.6550925970077515\n","val_precision: 0.5029013752937317\n","val_recall: 0.5777778029441833\n","val_auc: 0.7035513520240784\n","val_prc_auc: 0.554534912109375\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7121 - binary_accuracy: 0.6384 - f1: 0.6607 - loss: 0.6187 - prc_auc: 0.7263 - precision: 0.6428 - recall: 0.6821 - val_auc: 0.7036 - val_binary_accuracy: 0.6551 - val_f1: 0.5377 - val_loss: 0.6148 - val_prc_auc: 0.5545 - val_precision: 0.5029 - val_recall: 0.5778\n","Epoch 10/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7139 - binary_accuracy: 0.6412 - f1: 0.6633 - loss: 0.6173 - prc_auc: 0.7287 - precision: 0.6458 - recall: 0.6843\n","Epoch 10: Validation Metrics:\n","loss: 0.6218764781951904\n","val_binary_accuracy: 0.6574074029922485\n","val_precision: 0.505836546421051\n","val_recall: 0.5777778029441833\n","val_auc: 0.7037627696990967\n","val_prc_auc: 0.555303156375885\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7138 - binary_accuracy: 0.6412 - f1: 0.6631 - loss: 0.6174 - prc_auc: 0.7283 - precision: 0.6457 - recall: 0.6840 - val_auc: 0.7038 - val_binary_accuracy: 0.6574 - val_f1: 0.5394 - val_loss: 0.6144 - val_prc_auc: 0.5553 - val_precision: 0.5058 - val_recall: 0.5778\n","Epoch 11/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7152 - binary_accuracy: 0.6444 - f1: 0.6675 - loss: 0.6161 - prc_auc: 0.7305 - precision: 0.6479 - recall: 0.6903\n","Epoch 11: Validation Metrics:\n","loss: 0.6205682754516602\n","val_binary_accuracy: 0.6566358208656311\n","val_precision: 0.5048923492431641\n","val_recall: 0.5733333230018616\n","val_auc: 0.7043078541755676\n","val_prc_auc: 0.5562875866889954\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7151 - binary_accuracy: 0.6445 - f1: 0.6672 - loss: 0.6162 - prc_auc: 0.7301 - precision: 0.6478 - recall: 0.6898 - val_auc: 0.7043 - val_binary_accuracy: 0.6566 - val_f1: 0.5369 - val_loss: 0.6141 - val_prc_auc: 0.5563 - val_precision: 0.5049 - val_recall: 0.5733\n","Epoch 12/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7165 - binary_accuracy: 0.6477 - f1: 0.6707 - loss: 0.6150 - prc_auc: 0.7321 - precision: 0.6508 - recall: 0.6937\n","Epoch 12: Validation Metrics:\n","loss: 0.6193667054176331\n","val_binary_accuracy: 0.658178985118866\n","val_precision: 0.5068762302398682\n","val_recall: 0.5733333230018616\n","val_auc: 0.7043236494064331\n","val_prc_auc: 0.5569853782653809\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7164 - binary_accuracy: 0.6477 - f1: 0.6704 - loss: 0.6151 - prc_auc: 0.7317 - precision: 0.6506 - recall: 0.6932 - val_auc: 0.7043 - val_binary_accuracy: 0.6582 - val_f1: 0.5381 - val_loss: 0.6140 - val_prc_auc: 0.5570 - val_precision: 0.5069 - val_recall: 0.5733\n","Epoch 13/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7185 - binary_accuracy: 0.6516 - f1: 0.6739 - loss: 0.6140 - prc_auc: 0.7344 - precision: 0.6547 - recall: 0.6962\n","Epoch 13: Validation Metrics:\n","loss: 0.6182242035865784\n","val_binary_accuracy: 0.6566358208656311\n","val_precision: 0.5048923492431641\n","val_recall: 0.5733333230018616\n","val_auc: 0.7045193314552307\n","val_prc_auc: 0.5576479434967041\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7184 - binary_accuracy: 0.6516 - f1: 0.6736 - loss: 0.6141 - prc_auc: 0.7340 - precision: 0.6546 - recall: 0.6957 - val_auc: 0.7045 - val_binary_accuracy: 0.6566 - val_f1: 0.5369 - val_loss: 0.6139 - val_prc_auc: 0.5576 - val_precision: 0.5049 - val_recall: 0.5733\n","Epoch 14/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7199 - binary_accuracy: 0.6545 - f1: 0.6763 - loss: 0.6130 - prc_auc: 0.7362 - precision: 0.6576 - recall: 0.6978\n","Epoch 14: Validation Metrics:\n","loss: 0.6171317100524902\n","val_binary_accuracy: 0.6566358208656311\n","val_precision: 0.5048732757568359\n","val_recall: 0.5755555629730225\n","val_auc: 0.7045298218727112\n","val_prc_auc: 0.5576000809669495\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7198 - binary_accuracy: 0.6545 - f1: 0.6760 - loss: 0.6131 - prc_auc: 0.7358 - precision: 0.6575 - recall: 0.6973 - val_auc: 0.7045 - val_binary_accuracy: 0.6566 - val_f1: 0.5379 - val_loss: 0.6136 - val_prc_auc: 0.5576 - val_precision: 0.5049 - val_recall: 0.5756\n","Epoch 15/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7210 - binary_accuracy: 0.6557 - f1: 0.6775 - loss: 0.6121 - prc_auc: 0.7375 - precision: 0.6591 - recall: 0.6993\n","Epoch 15: Validation Metrics:\n","loss: 0.6160652041435242\n","val_binary_accuracy: 0.6597222089767456\n","val_precision: 0.5088062882423401\n","val_recall: 0.5777778029441833\n","val_auc: 0.7046861052513123\n","val_prc_auc: 0.5582218170166016\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7210 - binary_accuracy: 0.6557 - f1: 0.6772 - loss: 0.6122 - prc_auc: 0.7371 - precision: 0.6589 - recall: 0.6988 - val_auc: 0.7047 - val_binary_accuracy: 0.6597 - val_f1: 0.5411 - val_loss: 0.6134 - val_prc_auc: 0.5582 - val_precision: 0.5088 - val_recall: 0.5778\n","Epoch 16/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7221 - binary_accuracy: 0.6566 - f1: 0.6777 - loss: 0.6112 - prc_auc: 0.7380 - precision: 0.6606 - recall: 0.6978\n","Epoch 16: Validation Metrics:\n","loss: 0.6150365471839905\n","val_binary_accuracy: 0.6574074029922485\n","val_precision: 0.5058823823928833\n","val_recall: 0.5733333230018616\n","val_auc: 0.7046847939491272\n","val_prc_auc: 0.5597744584083557\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7220 - binary_accuracy: 0.6566 - f1: 0.6774 - loss: 0.6112 - prc_auc: 0.7376 - precision: 0.6605 - recall: 0.6973 - val_auc: 0.7047 - val_binary_accuracy: 0.6574 - val_f1: 0.5375 - val_loss: 0.6134 - val_prc_auc: 0.5598 - val_precision: 0.5059 - val_recall: 0.5733\n","Epoch 17/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7235 - binary_accuracy: 0.6594 - f1: 0.6792 - loss: 0.6103 - prc_auc: 0.7400 - precision: 0.6640 - recall: 0.6971\n","Epoch 17: Validation Metrics:\n","loss: 0.6140535473823547\n","val_binary_accuracy: 0.6558641791343689\n","val_precision: 0.5039215683937073\n","val_recall: 0.5711110830307007\n","val_auc: 0.7048910856246948\n","val_prc_auc: 0.5595598220825195\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7234 - binary_accuracy: 0.6594 - f1: 0.6789 - loss: 0.6104 - prc_auc: 0.7396 - precision: 0.6639 - recall: 0.6966 - val_auc: 0.7049 - val_binary_accuracy: 0.6559 - val_f1: 0.5354 - val_loss: 0.6133 - val_prc_auc: 0.5596 - val_precision: 0.5039 - val_recall: 0.5711\n","Epoch 18/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7246 - binary_accuracy: 0.6600 - f1: 0.6798 - loss: 0.6094 - prc_auc: 0.7411 - precision: 0.6644 - recall: 0.6980\n","Epoch 18: Validation Metrics:\n","loss: 0.6130982041358948\n","val_binary_accuracy: 0.6574074029922485\n","val_precision: 0.5058823823928833\n","val_recall: 0.5733333230018616\n","val_auc: 0.7052101492881775\n","val_prc_auc: 0.5598593354225159\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7245 - binary_accuracy: 0.6599 - f1: 0.6795 - loss: 0.6095 - prc_auc: 0.7407 - precision: 0.6643 - recall: 0.6975 - val_auc: 0.7052 - val_binary_accuracy: 0.6574 - val_f1: 0.5375 - val_loss: 0.6134 - val_prc_auc: 0.5599 - val_precision: 0.5059 - val_recall: 0.5733\n","Epoch 19/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7255 - binary_accuracy: 0.6625 - f1: 0.6828 - loss: 0.6086 - prc_auc: 0.7422 - precision: 0.6663 - recall: 0.7018\n","Epoch 19: Validation Metrics:\n","loss: 0.6121652126312256\n","val_binary_accuracy: 0.6550925970077515\n","val_precision: 0.5029354095458984\n","val_recall: 0.5711110830307007\n","val_auc: 0.7051365375518799\n","val_prc_auc: 0.5607516169548035\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7255 - binary_accuracy: 0.6625 - f1: 0.6824 - loss: 0.6087 - prc_auc: 0.7418 - precision: 0.6662 - recall: 0.7013 - val_auc: 0.7051 - val_binary_accuracy: 0.6551 - val_f1: 0.5349 - val_loss: 0.6134 - val_prc_auc: 0.5608 - val_precision: 0.5029 - val_recall: 0.5711\n","Epoch 20/20\n","\u001b[1m112/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7266 - binary_accuracy: 0.6661 - f1: 0.6855 - loss: 0.6078 - prc_auc: 0.7433 - precision: 0.6704 - recall: 0.7032\n","Epoch 20: Validation Metrics:\n","loss: 0.6112464070320129\n","val_binary_accuracy: 0.6512345671653748\n","val_precision: 0.498046875\n","val_recall: 0.5666666626930237\n","val_auc: 0.7049212455749512\n","val_prc_auc: 0.5598275065422058\n","\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7266 - binary_accuracy: 0.6660 - f1: 0.6852 - loss: 0.6078 - prc_auc: 0.7430 - precision: 0.6702 - recall: 0.7026 - val_auc: 0.7049 - val_binary_accuracy: 0.6512 - val_f1: 0.5301 - val_loss: 0.6133 - val_prc_auc: 0.5598 - val_precision: 0.4980 - val_recall: 0.5667\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - auc: 0.5788 - binary_accuracy: 0.5497 - f1: 0.6839 - loss: 0.6866 - prc_auc: 0.6116 - precision: 0.5414 - recall: 0.9362\n","Epoch 1: Validation Metrics:\n","loss: 0.683455228805542\n","val_binary_accuracy: 0.7986111044883728\n","val_precision: 0.4923076927661896\n","val_recall: 0.2471042424440384\n","val_auc: 0.7165215015411377\n","val_prc_auc: 0.3892957270145416\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 353ms/step - auc: 0.5791 - binary_accuracy: 0.5500 - f1: 0.6830 - loss: 0.6866 - prc_auc: 0.6115 - precision: 0.5416 - recall: 0.9328 - val_auc: 0.7165 - val_binary_accuracy: 0.7986 - val_f1: 0.3290 - val_loss: 0.6448 - val_prc_auc: 0.3893 - val_precision: 0.4923 - val_recall: 0.2471\n","Epoch 2/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6918 - binary_accuracy: 0.6127 - f1: 0.6097 - loss: 0.6709 - prc_auc: 0.7176 - precision: 0.6559 - recall: 0.6136\n","Epoch 2: Validation Metrics:\n","loss: 0.6663389205932617\n","val_binary_accuracy: 0.7662037014961243\n","val_precision: 0.41472867131233215\n","val_recall: 0.41312742233276367\n","val_auc: 0.7247033715248108\n","val_prc_auc: 0.407498300075531\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.6916 - binary_accuracy: 0.6129 - f1: 0.6099 - loss: 0.6708 - prc_auc: 0.7172 - precision: 0.6555 - recall: 0.6136 - val_auc: 0.7247 - val_binary_accuracy: 0.7662 - val_f1: 0.4139 - val_loss: 0.6321 - val_prc_auc: 0.4075 - val_precision: 0.4147 - val_recall: 0.4131\n","Epoch 3/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7233 - binary_accuracy: 0.6573 - f1: 0.6749 - loss: 0.6521 - prc_auc: 0.7472 - precision: 0.6759 - recall: 0.6876\n","Epoch 3: Validation Metrics:\n","loss: 0.6483092904090881\n","val_binary_accuracy: 0.7330247163772583\n","val_precision: 0.38082191348075867\n","val_recall: 0.5366795659065247\n","val_auc: 0.7300816178321838\n","val_prc_auc: 0.41985517740249634\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7231 - binary_accuracy: 0.6574 - f1: 0.6745 - loss: 0.6520 - prc_auc: 0.7468 - precision: 0.6757 - recall: 0.6869 - val_auc: 0.7301 - val_binary_accuracy: 0.7330 - val_f1: 0.4455 - val_loss: 0.6257 - val_prc_auc: 0.4199 - val_precision: 0.3808 - val_recall: 0.5367\n","Epoch 4/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7433 - binary_accuracy: 0.6726 - f1: 0.6945 - loss: 0.6327 - prc_auc: 0.7653 - precision: 0.6817 - recall: 0.7127\n","Epoch 4: Validation Metrics:\n","loss: 0.6299264430999756\n","val_binary_accuracy: 0.7060185074806213\n","val_precision: 0.36199095845222473\n","val_recall: 0.6177605986595154\n","val_auc: 0.7349236011505127\n","val_prc_auc: 0.42872554063796997\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7431 - binary_accuracy: 0.6725 - f1: 0.6941 - loss: 0.6326 - prc_auc: 0.7650 - precision: 0.6817 - recall: 0.7117 - val_auc: 0.7349 - val_binary_accuracy: 0.7060 - val_f1: 0.4565 - val_loss: 0.6228 - val_prc_auc: 0.4287 - val_precision: 0.3620 - val_recall: 0.6178\n","Epoch 5/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7551 - binary_accuracy: 0.6827 - f1: 0.6996 - loss: 0.6146 - prc_auc: 0.7755 - precision: 0.6953 - recall: 0.7066\n","Epoch 5: Validation Metrics:\n","loss: 0.6133266091346741\n","val_binary_accuracy: 0.6952160596847534\n","val_precision: 0.35531914234161377\n","val_recall: 0.6447876691818237\n","val_auc: 0.7389131188392639\n","val_prc_auc: 0.43406611680984497\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7549 - binary_accuracy: 0.6827 - f1: 0.6992 - loss: 0.6146 - prc_auc: 0.7752 - precision: 0.6953 - recall: 0.7058 - val_auc: 0.7389 - val_binary_accuracy: 0.6952 - val_f1: 0.4582 - val_loss: 0.6159 - val_prc_auc: 0.4341 - val_precision: 0.3553 - val_recall: 0.6448\n","Epoch 6/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7610 - binary_accuracy: 0.6952 - f1: 0.7076 - loss: 0.6004 - prc_auc: 0.7807 - precision: 0.7121 - recall: 0.7053\n","Epoch 6: Validation Metrics:\n","loss: 0.6005673408508301\n","val_binary_accuracy: 0.6952160596847534\n","val_precision: 0.3571428656578064\n","val_recall: 0.6563706398010254\n","val_auc: 0.7418228983879089\n","val_prc_auc: 0.4404008090496063\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.7609 - binary_accuracy: 0.6951 - f1: 0.7073 - loss: 0.6004 - prc_auc: 0.7804 - precision: 0.7121 - recall: 0.7045 - val_auc: 0.7418 - val_binary_accuracy: 0.6952 - val_f1: 0.4626 - val_loss: 0.6090 - val_prc_auc: 0.4404 - val_precision: 0.3571 - val_recall: 0.6564\n","Epoch 7/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7656 - binary_accuracy: 0.6974 - f1: 0.7100 - loss: 0.5900 - prc_auc: 0.7843 - precision: 0.7144 - recall: 0.7074\n","Epoch 7: Validation Metrics:\n","loss: 0.5913515090942383\n","val_binary_accuracy: 0.6967592835426331\n","val_precision: 0.3574468195438385\n","val_recall: 0.6486486196517944\n","val_auc: 0.7446133494377136\n","val_prc_auc: 0.44154882431030273\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7655 - binary_accuracy: 0.6974 - f1: 0.7096 - loss: 0.5900 - prc_auc: 0.7841 - precision: 0.7143 - recall: 0.7067 - val_auc: 0.7446 - val_binary_accuracy: 0.6968 - val_f1: 0.4609 - val_loss: 0.6034 - val_prc_auc: 0.4415 - val_precision: 0.3574 - val_recall: 0.6486\n","Epoch 8/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7689 - binary_accuracy: 0.6991 - f1: 0.7106 - loss: 0.5826 - prc_auc: 0.7868 - precision: 0.7173 - recall: 0.7056\n","Epoch 8: Validation Metrics:\n","loss: 0.5848256945610046\n","val_binary_accuracy: 0.6967592835426331\n","val_precision: 0.3580508530139923\n","val_recall: 0.6525096297264099\n","val_auc: 0.746728241443634\n","val_prc_auc: 0.4418794512748718\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.7688 - binary_accuracy: 0.6991 - f1: 0.7102 - loss: 0.5826 - prc_auc: 0.7865 - precision: 0.7172 - recall: 0.7049 - val_auc: 0.7467 - val_binary_accuracy: 0.6968 - val_f1: 0.4624 - val_loss: 0.5999 - val_prc_auc: 0.4419 - val_precision: 0.3581 - val_recall: 0.6525\n","Epoch 9/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7715 - binary_accuracy: 0.6970 - f1: 0.7081 - loss: 0.5773 - prc_auc: 0.7882 - precision: 0.7159 - recall: 0.7019\n","Epoch 9: Validation Metrics:\n","loss: 0.5801820755004883\n","val_binary_accuracy: 0.6967592835426331\n","val_precision: 0.35683760046958923\n","val_recall: 0.6447876691818237\n","val_auc: 0.7484147548675537\n","val_prc_auc: 0.44409528374671936\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7714 - binary_accuracy: 0.6970 - f1: 0.7077 - loss: 0.5773 - prc_auc: 0.7879 - precision: 0.7158 - recall: 0.7013 - val_auc: 0.7484 - val_binary_accuracy: 0.6968 - val_f1: 0.4594 - val_loss: 0.5973 - val_prc_auc: 0.4441 - val_precision: 0.3568 - val_recall: 0.6448\n","Epoch 10/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7735 - binary_accuracy: 0.6972 - f1: 0.7089 - loss: 0.5735 - prc_auc: 0.7899 - precision: 0.7152 - recall: 0.7043\n","Epoch 10: Validation Metrics:\n","loss: 0.5767576694488525\n","val_binary_accuracy: 0.6967592835426331\n","val_precision: 0.35683760046958923\n","val_recall: 0.6447876691818237\n","val_auc: 0.749844491481781\n","val_prc_auc: 0.4449983239173889\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - auc: 0.7734 - binary_accuracy: 0.6972 - f1: 0.7086 - loss: 0.5736 - prc_auc: 0.7896 - precision: 0.7151 - recall: 0.7037 - val_auc: 0.7498 - val_binary_accuracy: 0.6968 - val_f1: 0.4594 - val_loss: 0.5958 - val_prc_auc: 0.4450 - val_precision: 0.3568 - val_recall: 0.6448\n","Epoch 11/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7751 - binary_accuracy: 0.7046 - f1: 0.7152 - loss: 0.5707 - prc_auc: 0.7913 - precision: 0.7236 - recall: 0.7085\n","Epoch 11: Validation Metrics:\n","loss: 0.574155867099762\n","val_binary_accuracy: 0.6959876418113708\n","val_precision: 0.35546037554740906\n","val_recall: 0.6409266591072083\n","val_auc: 0.7514976859092712\n","val_prc_auc: 0.4451882243156433\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.7750 - binary_accuracy: 0.7045 - f1: 0.7148 - loss: 0.5708 - prc_auc: 0.7910 - precision: 0.7235 - recall: 0.7079 - val_auc: 0.7515 - val_binary_accuracy: 0.6960 - val_f1: 0.4573 - val_loss: 0.5946 - val_prc_auc: 0.4452 - val_precision: 0.3555 - val_recall: 0.6409\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - auc: 0.6307 - binary_accuracy: 0.5735 - f1: 0.3035 - loss: 0.6898 - prc_auc: 0.6287 - precision: 0.7641 - recall: 0.2005\n","Epoch 1: Validation Metrics:\n","loss: 0.6878508925437927\n","val_binary_accuracy: 0.6149691343307495\n","val_precision: 0.14964789152145386\n","val_recall: 0.8415841460227966\n","val_auc: 0.797265887260437\n","val_prc_auc: 0.28998178243637085\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 782ms/step - auc: 0.6325 - binary_accuracy: 0.5751 - f1: 0.3100 - loss: 0.6897 - prc_auc: 0.6310 - precision: 0.7631 - recall: 0.2062 - val_auc: 0.7973 - val_binary_accuracy: 0.6150 - val_f1: 0.2541 - val_loss: 0.6875 - val_prc_auc: 0.2900 - val_precision: 0.1496 - val_recall: 0.8416\n","Epoch 2/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8202 - binary_accuracy: 0.7317 - f1: 0.7515 - loss: 0.6786 - prc_auc: 0.8201 - precision: 0.6911 - recall: 0.8262\n","Epoch 2: Validation Metrics:\n","loss: 0.6770365834236145\n","val_binary_accuracy: 0.6535493731498718\n","val_precision: 0.1627907007932663\n","val_recall: 0.8316831588745117\n","val_auc: 0.8062885999679565\n","val_prc_auc: 0.29583340883255005\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - auc: 0.8191 - binary_accuracy: 0.7314 - f1: 0.7505 - loss: 0.6785 - prc_auc: 0.8199 - precision: 0.6926 - recall: 0.8217 - val_auc: 0.8063 - val_binary_accuracy: 0.6535 - val_f1: 0.2723 - val_loss: 0.6801 - val_prc_auc: 0.2958 - val_precision: 0.1628 - val_recall: 0.8317\n","Epoch 3/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8236 - binary_accuracy: 0.7376 - f1: 0.7482 - loss: 0.6689 - prc_auc: 0.8307 - precision: 0.7103 - recall: 0.7931\n","Epoch 3: Validation Metrics:\n","loss: 0.6671867966651917\n","val_binary_accuracy: 0.7021604776382446\n","val_precision: 0.17977528274059296\n","val_recall: 0.7920792102813721\n","val_auc: 0.8078089952468872\n","val_prc_auc: 0.3029595911502838\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - auc: 0.8229 - binary_accuracy: 0.7375 - f1: 0.7473 - loss: 0.6688 - prc_auc: 0.8305 - precision: 0.7120 - recall: 0.7891 - val_auc: 0.8078 - val_binary_accuracy: 0.7022 - val_f1: 0.2930 - val_loss: 0.6685 - val_prc_auc: 0.3030 - val_precision: 0.1798 - val_recall: 0.7921\n","Epoch 4/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8242 - binary_accuracy: 0.7303 - f1: 0.7332 - loss: 0.6590 - prc_auc: 0.8331 - precision: 0.7155 - recall: 0.7532\n","Epoch 4: Validation Metrics:\n","loss: 0.6569818258285522\n","val_binary_accuracy: 0.7044752836227417\n","val_precision: 0.18385650217533112\n","val_recall: 0.8118811845779419\n","val_auc: 0.8087658882141113\n","val_prc_auc: 0.31102898716926575\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - auc: 0.8238 - binary_accuracy: 0.7306 - f1: 0.7330 - loss: 0.6588 - prc_auc: 0.8331 - precision: 0.7173 - recall: 0.7509 - val_auc: 0.8088 - val_binary_accuracy: 0.7045 - val_f1: 0.2998 - val_loss: 0.6608 - val_prc_auc: 0.3110 - val_precision: 0.1839 - val_recall: 0.8119\n","Epoch 5/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8238 - binary_accuracy: 0.7358 - f1: 0.7364 - loss: 0.6481 - prc_auc: 0.8340 - precision: 0.7246 - recall: 0.7501\n","Epoch 5: Validation Metrics:\n","loss: 0.646027684211731\n","val_binary_accuracy: 0.7160493731498718\n","val_precision: 0.18881118297576904\n","val_recall: 0.801980197429657\n","val_auc: 0.81135094165802\n","val_prc_auc: 0.31151238083839417\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8236 - binary_accuracy: 0.7362 - f1: 0.7363 - loss: 0.6479 - prc_auc: 0.8342 - precision: 0.7267 - recall: 0.7478 - val_auc: 0.8114 - val_binary_accuracy: 0.7160 - val_f1: 0.3057 - val_loss: 0.6498 - val_prc_auc: 0.3115 - val_precision: 0.1888 - val_recall: 0.8020\n","Epoch 6/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8292 - binary_accuracy: 0.7368 - f1: 0.7356 - loss: 0.6367 - prc_auc: 0.8393 - precision: 0.7286 - recall: 0.7446\n","Epoch 6: Validation Metrics:\n","loss: 0.6347541809082031\n","val_binary_accuracy: 0.720678985118866\n","val_precision: 0.19148936867713928\n","val_recall: 0.801980197429657\n","val_auc: 0.8153113126754761\n","val_prc_auc: 0.3167842626571655\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8290 - binary_accuracy: 0.7375 - f1: 0.7359 - loss: 0.6366 - prc_auc: 0.8392 - precision: 0.7311 - recall: 0.7425 - val_auc: 0.8153 - val_binary_accuracy: 0.7207 - val_f1: 0.3092 - val_loss: 0.6403 - val_prc_auc: 0.3168 - val_precision: 0.1915 - val_recall: 0.8020\n","Epoch 7/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8325 - binary_accuracy: 0.7415 - f1: 0.7419 - loss: 0.6249 - prc_auc: 0.8428 - precision: 0.7306 - recall: 0.7551\n","Epoch 7: Validation Metrics:\n","loss: 0.6228349208831787\n","val_binary_accuracy: 0.7245370149612427\n","val_precision: 0.1893203854560852\n","val_recall: 0.7722772359848022\n","val_auc: 0.8174986243247986\n","val_prc_auc: 0.3182509243488312\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8324 - binary_accuracy: 0.7423 - f1: 0.7423 - loss: 0.6248 - prc_auc: 0.8428 - precision: 0.7331 - recall: 0.7531 - val_auc: 0.8175 - val_binary_accuracy: 0.7245 - val_f1: 0.3041 - val_loss: 0.6302 - val_prc_auc: 0.3183 - val_precision: 0.1893 - val_recall: 0.7723\n","Epoch 8/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8357 - binary_accuracy: 0.7494 - f1: 0.7467 - loss: 0.6125 - prc_auc: 0.8468 - precision: 0.7437 - recall: 0.7511\n","Epoch 8: Validation Metrics:\n","loss: 0.6103236675262451\n","val_binary_accuracy: 0.7283950448036194\n","val_precision: 0.19464720785617828\n","val_recall: 0.7920792102813721\n","val_auc: 0.821272611618042\n","val_prc_auc: 0.32682234048843384\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - auc: 0.8356 - binary_accuracy: 0.7501 - f1: 0.7470 - loss: 0.6123 - prc_auc: 0.8468 - precision: 0.7461 - recall: 0.7493 - val_auc: 0.8213 - val_binary_accuracy: 0.7284 - val_f1: 0.3125 - val_loss: 0.6207 - val_prc_auc: 0.3268 - val_precision: 0.1946 - val_recall: 0.7921\n","Epoch 9/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8410 - binary_accuracy: 0.7589 - f1: 0.7566 - loss: 0.6001 - prc_auc: 0.8521 - precision: 0.7525 - recall: 0.7619\n","Epoch 9: Validation Metrics:\n","loss: 0.5979084968566895\n","val_binary_accuracy: 0.7314814925193787\n","val_precision: 0.19656018912792206\n","val_recall: 0.7920792102813721\n","val_auc: 0.8255645036697388\n","val_prc_auc: 0.3319278061389923\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8410 - binary_accuracy: 0.7594 - f1: 0.7568 - loss: 0.6000 - prc_auc: 0.8522 - precision: 0.7546 - recall: 0.7602 - val_auc: 0.8256 - val_binary_accuracy: 0.7315 - val_f1: 0.3150 - val_loss: 0.6124 - val_prc_auc: 0.3319 - val_precision: 0.1966 - val_recall: 0.7921\n","Epoch 10/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8464 - binary_accuracy: 0.7620 - f1: 0.7605 - loss: 0.5877 - prc_auc: 0.8567 - precision: 0.7542 - recall: 0.7680\n","Epoch 10: Validation Metrics:\n","loss: 0.5854967832565308\n","val_binary_accuracy: 0.7337962985038757\n","val_precision: 0.19950738549232483\n","val_recall: 0.801980197429657\n","val_auc: 0.8305025100708008\n","val_prc_auc: 0.34053006768226624\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - auc: 0.8463 - binary_accuracy: 0.7626 - f1: 0.7608 - loss: 0.5876 - prc_auc: 0.8568 - precision: 0.7563 - recall: 0.7664 - val_auc: 0.8305 - val_binary_accuracy: 0.7338 - val_f1: 0.3195 - val_loss: 0.6028 - val_prc_auc: 0.3405 - val_precision: 0.1995 - val_recall: 0.8020\n","Epoch 11/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8532 - binary_accuracy: 0.7696 - f1: 0.7676 - loss: 0.5753 - prc_auc: 0.8628 - precision: 0.7625 - recall: 0.7738\n","Epoch 11: Validation Metrics:\n","loss: 0.5731593370437622\n","val_binary_accuracy: 0.7337962985038757\n","val_precision: 0.19950738549232483\n","val_recall: 0.801980197429657\n","val_auc: 0.8345001339912415\n","val_prc_auc: 0.344718337059021\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - auc: 0.8531 - binary_accuracy: 0.7701 - f1: 0.7680 - loss: 0.5752 - prc_auc: 0.8628 - precision: 0.7645 - recall: 0.7725 - val_auc: 0.8345 - val_binary_accuracy: 0.7338 - val_f1: 0.3195 - val_loss: 0.5951 - val_prc_auc: 0.3447 - val_precision: 0.1995 - val_recall: 0.8020\n","Epoch 12/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8571 - binary_accuracy: 0.7741 - f1: 0.7718 - loss: 0.5633 - prc_auc: 0.8663 - precision: 0.7677 - recall: 0.7767\n","Epoch 12: Validation Metrics:\n","loss: 0.5611301064491272\n","val_binary_accuracy: 0.7391975522041321\n","val_precision: 0.2030075192451477\n","val_recall: 0.801980197429657\n","val_auc: 0.8385642170906067\n","val_prc_auc: 0.35092559456825256\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8570 - binary_accuracy: 0.7747 - f1: 0.7722 - loss: 0.5632 - prc_auc: 0.8664 - precision: 0.7696 - recall: 0.7755 - val_auc: 0.8386 - val_binary_accuracy: 0.7392 - val_f1: 0.3240 - val_loss: 0.5866 - val_prc_auc: 0.3509 - val_precision: 0.2030 - val_recall: 0.8020\n","Epoch 13/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8626 - binary_accuracy: 0.7804 - f1: 0.7773 - loss: 0.5515 - prc_auc: 0.8709 - precision: 0.7757 - recall: 0.7795\n","Epoch 13: Validation Metrics:\n","loss: 0.5492896437644958\n","val_binary_accuracy: 0.7453703880310059\n","val_precision: 0.2101265788078308\n","val_recall: 0.8217821717262268\n","val_auc: 0.8422097563743591\n","val_prc_auc: 0.35747456550598145\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - auc: 0.8624 - binary_accuracy: 0.7810 - f1: 0.7778 - loss: 0.5514 - prc_auc: 0.8709 - precision: 0.7775 - recall: 0.7787 - val_auc: 0.8422 - val_binary_accuracy: 0.7454 - val_f1: 0.3347 - val_loss: 0.5782 - val_prc_auc: 0.3575 - val_precision: 0.2101 - val_recall: 0.8218\n","Epoch 14/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8675 - binary_accuracy: 0.7881 - f1: 0.7855 - loss: 0.5400 - prc_auc: 0.8759 - precision: 0.7824 - recall: 0.7893\n","Epoch 14: Validation Metrics:\n","loss: 0.5377896428108215\n","val_binary_accuracy: 0.7461419701576233\n","val_precision: 0.21212121844291687\n","val_recall: 0.8316831588745117\n","val_auc: 0.8463855385780334\n","val_prc_auc: 0.36447980999946594\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - auc: 0.8674 - binary_accuracy: 0.7886 - f1: 0.7858 - loss: 0.5398 - prc_auc: 0.8759 - precision: 0.7842 - recall: 0.7881 - val_auc: 0.8464 - val_binary_accuracy: 0.7461 - val_f1: 0.3380 - val_loss: 0.5711 - val_prc_auc: 0.3645 - val_precision: 0.2121 - val_recall: 0.8317\n","Epoch 15/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8711 - binary_accuracy: 0.7887 - f1: 0.7862 - loss: 0.5288 - prc_auc: 0.8789 - precision: 0.7826 - recall: 0.7905\n","Epoch 15: Validation Metrics:\n","loss: 0.5265324115753174\n","val_binary_accuracy: 0.7484567761421204\n","val_precision: 0.21374045312404633\n","val_recall: 0.8316831588745117\n","val_auc: 0.8500186800956726\n","val_prc_auc: 0.36842912435531616\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8710 - binary_accuracy: 0.7893 - f1: 0.7867 - loss: 0.5286 - prc_auc: 0.8790 - precision: 0.7845 - recall: 0.7896 - val_auc: 0.8500 - val_binary_accuracy: 0.7485 - val_f1: 0.3401 - val_loss: 0.5652 - val_prc_auc: 0.3684 - val_precision: 0.2137 - val_recall: 0.8317\n","Epoch 16/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8763 - binary_accuracy: 0.7880 - f1: 0.7861 - loss: 0.5177 - prc_auc: 0.8831 - precision: 0.7805 - recall: 0.7923\n","Epoch 16: Validation Metrics:\n","loss: 0.5155729055404663\n","val_binary_accuracy: 0.7492284178733826\n","val_precision: 0.2142857164144516\n","val_recall: 0.8316831588745117\n","val_auc: 0.8535937666893005\n","val_prc_auc: 0.3741224706172943\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8761 - binary_accuracy: 0.7887 - f1: 0.7866 - loss: 0.5175 - prc_auc: 0.8831 - precision: 0.7825 - recall: 0.7914 - val_auc: 0.8536 - val_binary_accuracy: 0.7492 - val_f1: 0.3408 - val_loss: 0.5582 - val_prc_auc: 0.3741 - val_precision: 0.2143 - val_recall: 0.8317\n","Epoch 17/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8816 - binary_accuracy: 0.7904 - f1: 0.7886 - loss: 0.5071 - prc_auc: 0.8876 - precision: 0.7824 - recall: 0.7956\n","Epoch 17: Validation Metrics:\n","loss: 0.5050337910652161\n","val_binary_accuracy: 0.7554012537002563\n","val_precision: 0.22164948284626007\n","val_recall: 0.8514851331710815\n","val_auc: 0.8574920296669006\n","val_prc_auc: 0.38006722927093506\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8814 - binary_accuracy: 0.7911 - f1: 0.7893 - loss: 0.5070 - prc_auc: 0.8876 - precision: 0.7844 - recall: 0.7948 - val_auc: 0.8575 - val_binary_accuracy: 0.7554 - val_f1: 0.3517 - val_loss: 0.5519 - val_prc_auc: 0.3801 - val_precision: 0.2216 - val_recall: 0.8515\n","Epoch 18/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8858 - binary_accuracy: 0.7945 - f1: 0.7919 - loss: 0.4970 - prc_auc: 0.8911 - precision: 0.7889 - recall: 0.7956\n","Epoch 18: Validation Metrics:\n","loss: 0.4948195517063141\n","val_binary_accuracy: 0.7569444179534912\n","val_precision: 0.2227979302406311\n","val_recall: 0.8514851331710815\n","val_auc: 0.8610630035400391\n","val_prc_auc: 0.38583093881607056\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - auc: 0.8857 - binary_accuracy: 0.7953 - f1: 0.7926 - loss: 0.4968 - prc_auc: 0.8912 - precision: 0.7910 - recall: 0.7948 - val_auc: 0.8611 - val_binary_accuracy: 0.7569 - val_f1: 0.3532 - val_loss: 0.5462 - val_prc_auc: 0.3858 - val_precision: 0.2228 - val_recall: 0.8515\n","Epoch 19/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8901 - binary_accuracy: 0.7959 - f1: 0.7932 - loss: 0.4871 - prc_auc: 0.8949 - precision: 0.7907 - recall: 0.7963\n","Epoch 19: Validation Metrics:\n","loss: 0.48497164249420166\n","val_binary_accuracy: 0.7631173133850098\n","val_precision: 0.22751322388648987\n","val_recall: 0.8514851331710815\n","val_auc: 0.8649321794509888\n","val_prc_auc: 0.3904712200164795\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8900 - binary_accuracy: 0.7968 - f1: 0.7941 - loss: 0.4869 - prc_auc: 0.8949 - precision: 0.7928 - recall: 0.7959 - val_auc: 0.8649 - val_binary_accuracy: 0.7631 - val_f1: 0.3591 - val_loss: 0.5402 - val_prc_auc: 0.3905 - val_precision: 0.2275 - val_recall: 0.8515\n","Epoch 20/20\n","\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8944 - binary_accuracy: 0.7966 - f1: 0.7940 - loss: 0.4776 - prc_auc: 0.8985 - precision: 0.7912 - recall: 0.7973\n","Epoch 20: Validation Metrics:\n","loss: 0.4754188656806946\n","val_binary_accuracy: 0.7716049551963806\n","val_precision: 0.23577235639095306\n","val_recall: 0.8613861203193665\n","val_auc: 0.8689092993736267\n","val_prc_auc: 0.3968949615955353\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - auc: 0.8942 - binary_accuracy: 0.7976 - f1: 0.7949 - loss: 0.4774 - prc_auc: 0.8985 - precision: 0.7935 - recall: 0.7970 - val_auc: 0.8689 - val_binary_accuracy: 0.7716 - val_f1: 0.3702 - val_loss: 0.5340 - val_prc_auc: 0.3969 - val_precision: 0.2358 - val_recall: 0.8614\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - auc: 0.5689 - binary_accuracy: 0.5344 - f1: 0.6684 - loss: 0.6898 - prc_auc: 0.5723 - precision: 0.5284 - recall: 0.9178\n","Epoch 1: Validation Metrics:\n","loss: 0.6865028738975525\n","val_binary_accuracy: 0.7361111044883728\n","val_precision: 0.463878333568573\n","val_recall: 0.37770897150039673\n","val_auc: 0.6897295117378235\n","val_prc_auc: 0.44076815247535706\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 296ms/step - auc: 0.5693 - binary_accuracy: 0.5347 - f1: 0.6678 - loss: 0.6898 - prc_auc: 0.5724 - precision: 0.5286 - recall: 0.9153 - val_auc: 0.6897 - val_binary_accuracy: 0.7361 - val_f1: 0.4164 - val_loss: 0.6673 - val_prc_auc: 0.4408 - val_precision: 0.4639 - val_recall: 0.3777\n","Epoch 2/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6751 - binary_accuracy: 0.6255 - f1: 0.6200 - loss: 0.6774 - prc_auc: 0.6844 - precision: 0.6546 - recall: 0.6012\n","Epoch 2: Validation Metrics:\n","loss: 0.6726232767105103\n","val_binary_accuracy: 0.6967592835426331\n","val_precision: 0.4088541567325592\n","val_recall: 0.48606809973716736\n","val_auc: 0.687279462814331\n","val_prc_auc: 0.4484254717826843\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.6751 - binary_accuracy: 0.6255 - f1: 0.6198 - loss: 0.6773 - prc_auc: 0.6843 - precision: 0.6543 - recall: 0.6009 - val_auc: 0.6873 - val_binary_accuracy: 0.6968 - val_f1: 0.4441 - val_loss: 0.6593 - val_prc_auc: 0.4484 - val_precision: 0.4089 - val_recall: 0.4861\n","Epoch 3/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6848 - binary_accuracy: 0.6336 - f1: 0.6347 - loss: 0.6656 - prc_auc: 0.6943 - precision: 0.6549 - recall: 0.6205\n","Epoch 3: Validation Metrics:\n","loss: 0.6598378419876099\n","val_binary_accuracy: 0.6720678806304932\n","val_precision: 0.3905579447746277\n","val_recall: 0.5634675025939941\n","val_auc: 0.6866669058799744\n","val_prc_auc: 0.45647889375686646\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.6850 - binary_accuracy: 0.6336 - f1: 0.6343 - loss: 0.6654 - prc_auc: 0.6942 - precision: 0.6548 - recall: 0.6197 - val_auc: 0.6867 - val_binary_accuracy: 0.6721 - val_f1: 0.4613 - val_loss: 0.6545 - val_prc_auc: 0.4565 - val_precision: 0.3906 - val_recall: 0.5635\n","Epoch 4/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6917 - binary_accuracy: 0.6342 - f1: 0.6372 - loss: 0.6543 - prc_auc: 0.7028 - precision: 0.6524 - recall: 0.6246\n","Epoch 4: Validation Metrics:\n","loss: 0.6481300592422485\n","val_binary_accuracy: 0.654321014881134\n","val_precision: 0.37672585248947144\n","val_recall: 0.5913312435150146\n","val_auc: 0.6874942183494568\n","val_prc_auc: 0.4616195559501648\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.6919 - binary_accuracy: 0.6344 - f1: 0.6368 - loss: 0.6542 - prc_auc: 0.7027 - precision: 0.6525 - recall: 0.6237 - val_auc: 0.6875 - val_binary_accuracy: 0.6543 - val_f1: 0.4602 - val_loss: 0.6485 - val_prc_auc: 0.4616 - val_precision: 0.3767 - val_recall: 0.5913\n","Epoch 5/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6962 - binary_accuracy: 0.6423 - f1: 0.6428 - loss: 0.6450 - prc_auc: 0.7081 - precision: 0.6625 - recall: 0.6256\n","Epoch 5: Validation Metrics:\n","loss: 0.6384209394454956\n","val_binary_accuracy: 0.6489197611808777\n","val_precision: 0.37593984603881836\n","val_recall: 0.6191950440406799\n","val_auc: 0.6885777115821838\n","val_prc_auc: 0.46406087279319763\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.6965 - binary_accuracy: 0.6424 - f1: 0.6425 - loss: 0.6448 - prc_auc: 0.7080 - precision: 0.6625 - recall: 0.6249 - val_auc: 0.6886 - val_binary_accuracy: 0.6489 - val_f1: 0.4678 - val_loss: 0.6434 - val_prc_auc: 0.4641 - val_precision: 0.3759 - val_recall: 0.6192\n","Epoch 6/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7010 - binary_accuracy: 0.6434 - f1: 0.6444 - loss: 0.6375 - prc_auc: 0.7139 - precision: 0.6632 - recall: 0.6278\n","Epoch 6: Validation Metrics:\n","loss: 0.6307274103164673\n","val_binary_accuracy: 0.645061731338501\n","val_precision: 0.37291279435157776\n","val_recall: 0.6222910284996033\n","val_auc: 0.689570426940918\n","val_prc_auc: 0.4665759205818176\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7012 - binary_accuracy: 0.6435 - f1: 0.6442 - loss: 0.6373 - prc_auc: 0.7138 - precision: 0.6632 - recall: 0.6274 - val_auc: 0.6896 - val_binary_accuracy: 0.6451 - val_f1: 0.4664 - val_loss: 0.6390 - val_prc_auc: 0.4666 - val_precision: 0.3729 - val_recall: 0.6223\n","Epoch 7/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7043 - binary_accuracy: 0.6448 - f1: 0.6470 - loss: 0.6318 - prc_auc: 0.7176 - precision: 0.6635 - recall: 0.6324\n","Epoch 7: Validation Metrics:\n","loss: 0.6249040961265564\n","val_binary_accuracy: 0.6458333134651184\n","val_precision: 0.3736059367656708\n","val_recall: 0.6222910284996033\n","val_auc: 0.6911773085594177\n","val_prc_auc: 0.46757182478904724\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7045 - binary_accuracy: 0.6450 - f1: 0.6469 - loss: 0.6316 - prc_auc: 0.7175 - precision: 0.6636 - recall: 0.6321 - val_auc: 0.6912 - val_binary_accuracy: 0.6458 - val_f1: 0.4669 - val_loss: 0.6358 - val_prc_auc: 0.4676 - val_precision: 0.3736 - val_recall: 0.6223\n","Epoch 8/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7080 - binary_accuracy: 0.6477 - f1: 0.6495 - loss: 0.6274 - prc_auc: 0.7210 - precision: 0.6671 - recall: 0.6339\n","Epoch 8: Validation Metrics:\n","loss: 0.6204262375831604\n","val_binary_accuracy: 0.6481481194496155\n","val_precision: 0.37616387009620667\n","val_recall: 0.6253870129585266\n","val_auc: 0.692238450050354\n","val_prc_auc: 0.4660918712615967\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.7083 - binary_accuracy: 0.6479 - f1: 0.6495 - loss: 0.6272 - prc_auc: 0.7209 - precision: 0.6671 - recall: 0.6338 - val_auc: 0.6922 - val_binary_accuracy: 0.6481 - val_f1: 0.4698 - val_loss: 0.6335 - val_prc_auc: 0.4661 - val_precision: 0.3762 - val_recall: 0.6254\n","Epoch 9/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7109 - binary_accuracy: 0.6504 - f1: 0.6520 - loss: 0.6240 - prc_auc: 0.7246 - precision: 0.6701 - recall: 0.6359\n","Epoch 9: Validation Metrics:\n","loss: 0.6170640587806702\n","val_binary_accuracy: 0.6512345671653748\n","val_precision: 0.38033396005630493\n","val_recall: 0.6346749067306519\n","val_auc: 0.6930498480796814\n","val_prc_auc: 0.46449464559555054\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7112 - binary_accuracy: 0.6506 - f1: 0.6519 - loss: 0.6238 - prc_auc: 0.7245 - precision: 0.6701 - recall: 0.6357 - val_auc: 0.6930 - val_binary_accuracy: 0.6512 - val_f1: 0.4756 - val_loss: 0.6315 - val_prc_auc: 0.4645 - val_precision: 0.3803 - val_recall: 0.6347\n","Epoch 10/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7137 - binary_accuracy: 0.6518 - f1: 0.6525 - loss: 0.6213 - prc_auc: 0.7272 - precision: 0.6726 - recall: 0.6346\n","Epoch 10: Validation Metrics:\n","loss: 0.6143858432769775\n","val_binary_accuracy: 0.654321014881134\n","val_precision: 0.38361266255378723\n","val_recall: 0.6377708911895752\n","val_auc: 0.693921685218811\n","val_prc_auc: 0.4648149013519287\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7139 - binary_accuracy: 0.6521 - f1: 0.6525 - loss: 0.6211 - prc_auc: 0.7270 - precision: 0.6726 - recall: 0.6346 - val_auc: 0.6939 - val_binary_accuracy: 0.6543 - val_f1: 0.4791 - val_loss: 0.6302 - val_prc_auc: 0.4648 - val_precision: 0.3836 - val_recall: 0.6378\n","Epoch 11/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7164 - binary_accuracy: 0.6548 - f1: 0.6555 - loss: 0.6190 - prc_auc: 0.7299 - precision: 0.6755 - recall: 0.6377\n","Epoch 11: Validation Metrics:\n","loss: 0.6121492981910706\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.3817504644393921\n","val_recall: 0.6346749067306519\n","val_auc: 0.6950575709342957\n","val_prc_auc: 0.46567150950431824\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.7167 - binary_accuracy: 0.6550 - f1: 0.6555 - loss: 0.6188 - prc_auc: 0.7297 - precision: 0.6755 - recall: 0.6376 - val_auc: 0.6951 - val_binary_accuracy: 0.6528 - val_f1: 0.4767 - val_loss: 0.6295 - val_prc_auc: 0.4657 - val_precision: 0.3818 - val_recall: 0.6347\n","Epoch 12/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7191 - binary_accuracy: 0.6577 - f1: 0.6600 - loss: 0.6169 - prc_auc: 0.7326 - precision: 0.6769 - recall: 0.6450\n","Epoch 12: Validation Metrics:\n","loss: 0.6101766228675842\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.3813084065914154\n","val_recall: 0.6315789222717285\n","val_auc: 0.6960185170173645\n","val_prc_auc: 0.4651283323764801\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7193 - binary_accuracy: 0.6579 - f1: 0.6599 - loss: 0.6167 - prc_auc: 0.7324 - precision: 0.6769 - recall: 0.6449 - val_auc: 0.6960 - val_binary_accuracy: 0.6528 - val_f1: 0.4755 - val_loss: 0.6284 - val_prc_auc: 0.4651 - val_precision: 0.3813 - val_recall: 0.6316\n","Epoch 13/20\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7217 - binary_accuracy: 0.6609 - f1: 0.6629 - loss: 0.6149 - prc_auc: 0.7345 - precision: 0.6801 - recall: 0.6476\n","Epoch 13: Validation Metrics:\n","loss: 0.6084392070770264\n","val_binary_accuracy: 0.6558641791343689\n","val_precision: 0.38504672050476074\n","val_recall: 0.6377708911895752\n","val_auc: 0.696860134601593\n","val_prc_auc: 0.46536222100257874\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7218 - binary_accuracy: 0.6610 - f1: 0.6629 - loss: 0.6148 - prc_auc: 0.7344 - precision: 0.6801 - recall: 0.6476 - val_auc: 0.6969 - val_binary_accuracy: 0.6559 - val_f1: 0.4802 - val_loss: 0.6278 - val_prc_auc: 0.4654 - val_precision: 0.3850 - val_recall: 0.6378\n","Epoch 14/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7235 - binary_accuracy: 0.6617 - f1: 0.6631 - loss: 0.6131 - prc_auc: 0.7367 - precision: 0.6818 - recall: 0.6465\n","Epoch 14: Validation Metrics:\n","loss: 0.606844425201416\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.3817504644393921\n","val_recall: 0.6346749067306519\n","val_auc: 0.69808030128479\n","val_prc_auc: 0.46635884046554565\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7237 - binary_accuracy: 0.6620 - f1: 0.6632 - loss: 0.6130 - prc_auc: 0.7365 - precision: 0.6818 - recall: 0.6466 - val_auc: 0.6981 - val_binary_accuracy: 0.6528 - val_f1: 0.4767 - val_loss: 0.6273 - val_prc_auc: 0.4664 - val_precision: 0.3818 - val_recall: 0.6347\n","Epoch 15/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7261 - binary_accuracy: 0.6650 - f1: 0.6644 - loss: 0.6114 - prc_auc: 0.7393 - precision: 0.6877 - recall: 0.6439\n","Epoch 15: Validation Metrics:\n","loss: 0.6053306460380554\n","val_binary_accuracy: 0.6535493731498718\n","val_precision: 0.38333332538604736\n","val_recall: 0.6408668756484985\n","val_auc: 0.6985704302787781\n","val_prc_auc: 0.4665791094303131\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7263 - binary_accuracy: 0.6652 - f1: 0.6644 - loss: 0.6113 - prc_auc: 0.7390 - precision: 0.6876 - recall: 0.6439 - val_auc: 0.6986 - val_binary_accuracy: 0.6535 - val_f1: 0.4797 - val_loss: 0.6267 - val_prc_auc: 0.4666 - val_precision: 0.3833 - val_recall: 0.6409\n","Epoch 16/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7280 - binary_accuracy: 0.6672 - f1: 0.6659 - loss: 0.6097 - prc_auc: 0.7414 - precision: 0.6908 - recall: 0.6440\n","Epoch 16: Validation Metrics:\n","loss: 0.6039361357688904\n","val_binary_accuracy: 0.6558641791343689\n","val_precision: 0.3858998119831085\n","val_recall: 0.6439628601074219\n","val_auc: 0.6992878913879395\n","val_prc_auc: 0.46720805764198303\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7282 - binary_accuracy: 0.6674 - f1: 0.6658 - loss: 0.6096 - prc_auc: 0.7412 - precision: 0.6907 - recall: 0.6440 - val_auc: 0.6993 - val_binary_accuracy: 0.6559 - val_f1: 0.4826 - val_loss: 0.6261 - val_prc_auc: 0.4672 - val_precision: 0.3859 - val_recall: 0.6440\n","Epoch 17/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7299 - binary_accuracy: 0.6666 - f1: 0.6659 - loss: 0.6082 - prc_auc: 0.7430 - precision: 0.6894 - recall: 0.6452\n","Epoch 17: Validation Metrics:\n","loss: 0.6026017665863037\n","val_binary_accuracy: 0.654321014881134\n","val_precision: 0.38489872217178345\n","val_recall: 0.6470588445663452\n","val_auc: 0.7000690698623657\n","val_prc_auc: 0.4673934876918793\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7301 - binary_accuracy: 0.6668 - f1: 0.6659 - loss: 0.6080 - prc_auc: 0.7428 - precision: 0.6894 - recall: 0.6453 - val_auc: 0.7001 - val_binary_accuracy: 0.6543 - val_f1: 0.4827 - val_loss: 0.6257 - val_prc_auc: 0.4674 - val_precision: 0.3849 - val_recall: 0.6471\n","Epoch 18/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7318 - binary_accuracy: 0.6646 - f1: 0.6643 - loss: 0.6066 - prc_auc: 0.7450 - precision: 0.6870 - recall: 0.6445\n","Epoch 18: Validation Metrics:\n","loss: 0.6013152003288269\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.3830570876598358\n","val_recall: 0.6439628601074219\n","val_auc: 0.7006529569625854\n","val_prc_auc: 0.46759653091430664\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - auc: 0.7320 - binary_accuracy: 0.6649 - f1: 0.6644 - loss: 0.6065 - prc_auc: 0.7447 - precision: 0.6870 - recall: 0.6446 - val_auc: 0.7007 - val_binary_accuracy: 0.6528 - val_f1: 0.4804 - val_loss: 0.6254 - val_prc_auc: 0.4676 - val_precision: 0.3831 - val_recall: 0.6440\n","Epoch 19/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7335 - binary_accuracy: 0.6667 - f1: 0.6664 - loss: 0.6051 - prc_auc: 0.7468 - precision: 0.6893 - recall: 0.6464\n","Epoch 19: Validation Metrics:\n","loss: 0.6000557541847229\n","val_binary_accuracy: 0.6535493731498718\n","val_precision: 0.38333332538604736\n","val_recall: 0.6408668756484985\n","val_auc: 0.7018349766731262\n","val_prc_auc: 0.46861451864242554\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7337 - binary_accuracy: 0.6670 - f1: 0.6665 - loss: 0.6049 - prc_auc: 0.7466 - precision: 0.6892 - recall: 0.6465 - val_auc: 0.7018 - val_binary_accuracy: 0.6535 - val_f1: 0.4797 - val_loss: 0.6250 - val_prc_auc: 0.4686 - val_precision: 0.3833 - val_recall: 0.6409\n","Epoch 20/20\n","\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7353 - binary_accuracy: 0.6689 - f1: 0.6687 - loss: 0.6036 - prc_auc: 0.7492 - precision: 0.6915 - recall: 0.6487\n","Epoch 20: Validation Metrics:\n","loss: 0.5988325476646423\n","val_binary_accuracy: 0.6527777910232544\n","val_precision: 0.3830570876598358\n","val_recall: 0.6439628601074219\n","val_auc: 0.702092707157135\n","val_prc_auc: 0.46828949451446533\n","\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - auc: 0.7355 - binary_accuracy: 0.6692 - f1: 0.6687 - loss: 0.6034 - prc_auc: 0.7490 - precision: 0.6914 - recall: 0.6488 - val_auc: 0.7021 - val_binary_accuracy: 0.6528 - val_f1: 0.4804 - val_loss: 0.6248 - val_prc_auc: 0.4683 - val_precision: 0.3831 - val_recall: 0.6440\n","Starting training for label: 5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - auc: 0.6352 - binary_accuracy: 0.6163 - f1: 0.6150 - loss: 0.6835 - prc_auc: 0.6487 - precision: 0.6341 - recall: 0.6375\n","Epoch 1: Validation Metrics:\n","loss: 0.6738262176513672\n","val_binary_accuracy: 0.8850308656692505\n","val_precision: 0.43939393758773804\n","val_recall: 0.43609023094177246\n","val_auc: 0.7746656537055969\n","val_prc_auc: 0.3825749456882477\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 603ms/step - auc: 0.6369 - binary_accuracy: 0.6175 - f1: 0.6144 - loss: 0.6832 - prc_auc: 0.6510 - precision: 0.6368 - recall: 0.6335 - val_auc: 0.7747 - val_binary_accuracy: 0.8850 - val_f1: 0.4377 - val_loss: 0.6221 - val_prc_auc: 0.3826 - val_precision: 0.4394 - val_recall: 0.4361\n","Epoch 2/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7656 - binary_accuracy: 0.6954 - f1: 0.6030 - loss: 0.6435 - prc_auc: 0.7830 - precision: 0.8362 - recall: 0.4717\n","Epoch 2: Validation Metrics:\n","loss: 0.6369243860244751\n","val_binary_accuracy: 0.8680555820465088\n","val_precision: 0.386904776096344\n","val_recall: 0.4887218177318573\n","val_auc: 0.7811048030853271\n","val_prc_auc: 0.39140579104423523\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - auc: 0.7647 - binary_accuracy: 0.6952 - f1: 0.6033 - loss: 0.6431 - prc_auc: 0.7830 - precision: 0.8362 - recall: 0.4720 - val_auc: 0.7811 - val_binary_accuracy: 0.8681 - val_f1: 0.4319 - val_loss: 0.5985 - val_prc_auc: 0.3914 - val_precision: 0.3869 - val_recall: 0.4887\n","Epoch 3/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7746 - binary_accuracy: 0.6869 - f1: 0.5972 - loss: 0.6130 - prc_auc: 0.7863 - precision: 0.8102 - recall: 0.4730\n","Epoch 3: Validation Metrics:\n","loss: 0.6077279448509216\n","val_binary_accuracy: 0.8641975522041321\n","val_precision: 0.3757225573062897\n","val_recall: 0.4887218177318573\n","val_auc: 0.781699538230896\n","val_prc_auc: 0.403614342212677\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - auc: 0.7737 - binary_accuracy: 0.6871 - f1: 0.5979 - loss: 0.6127 - prc_auc: 0.7866 - precision: 0.8110 - recall: 0.4737 - val_auc: 0.7817 - val_binary_accuracy: 0.8642 - val_f1: 0.4248 - val_loss: 0.5714 - val_prc_auc: 0.4036 - val_precision: 0.3757 - val_recall: 0.4887\n","Epoch 4/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7802 - binary_accuracy: 0.6877 - f1: 0.6009 - loss: 0.5892 - prc_auc: 0.7909 - precision: 0.8052 - recall: 0.4795\n","Epoch 4: Validation Metrics:\n","loss: 0.5860427618026733\n","val_binary_accuracy: 0.8611111044883728\n","val_precision: 0.3672316372394562\n","val_recall: 0.4887218177318573\n","val_auc: 0.7852585315704346\n","val_prc_auc: 0.40901947021484375\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - auc: 0.7794 - binary_accuracy: 0.6878 - f1: 0.6017 - loss: 0.5890 - prc_auc: 0.7913 - precision: 0.8059 - recall: 0.4802 - val_auc: 0.7853 - val_binary_accuracy: 0.8611 - val_f1: 0.4194 - val_loss: 0.5547 - val_prc_auc: 0.4090 - val_precision: 0.3672 - val_recall: 0.4887\n","Epoch 5/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7835 - binary_accuracy: 0.6895 - f1: 0.6041 - loss: 0.5743 - prc_auc: 0.7930 - precision: 0.8064 - recall: 0.4832\n","Epoch 5: Validation Metrics:\n","loss: 0.572759747505188\n","val_binary_accuracy: 0.8603395223617554\n","val_precision: 0.36666667461395264\n","val_recall: 0.49624061584472656\n","val_auc: 0.7855687737464905\n","val_prc_auc: 0.4117526710033417\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - auc: 0.7828 - binary_accuracy: 0.6896 - f1: 0.6048 - loss: 0.5743 - prc_auc: 0.7935 - precision: 0.8070 - recall: 0.4839 - val_auc: 0.7856 - val_binary_accuracy: 0.8603 - val_f1: 0.4217 - val_loss: 0.5434 - val_prc_auc: 0.4118 - val_precision: 0.3667 - val_recall: 0.4962\n","Epoch 6/20\n","\u001b[1m33/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7866 - binary_accuracy: 0.6907 - f1: 0.6067 - loss: 0.5654 - prc_auc: 0.7954 - precision: 0.8063 - recall: 0.4865\n","Epoch 6: Validation Metrics:\n","loss: 0.5646591782569885\n","val_binary_accuracy: 0.8649691343307495\n","val_precision: 0.37931033968925476\n","val_recall: 0.49624061584472656\n","val_auc: 0.7863511443138123\n","val_prc_auc: 0.4156515300273895\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - auc: 0.7860 - binary_accuracy: 0.6910 - f1: 0.6076 - loss: 0.5653 - prc_auc: 0.7959 - precision: 0.8070 - recall: 0.4874 - val_auc: 0.7864 - val_binary_accuracy: 0.8650 - val_f1: 0.4300 - val_loss: 0.5382 - val_prc_auc: 0.4157 - val_precision: 0.3793 - val_recall: 0.4962\n","Starting training for label: 6\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - auc: 0.6440 - binary_accuracy: 0.6009 - f1: 0.4850 - loss: 0.6843 - prc_auc: 0.6315 - precision: 0.6594 - recall: 0.3922\n","Epoch 1: Validation Metrics:\n","loss: 0.6762475371360779\n","val_binary_accuracy: 0.5586419701576233\n","val_precision: 0.4275861978530884\n","val_recall: 0.834080696105957\n","val_auc: 0.7276998162269592\n","val_prc_auc: 0.5856680870056152\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 233ms/step - auc: 0.6442 - binary_accuracy: 0.6011 - f1: 0.4860 - loss: 0.6843 - prc_auc: 0.6318 - precision: 0.6592 - recall: 0.3936 - val_auc: 0.7277 - val_binary_accuracy: 0.5586 - val_f1: 0.5653 - val_loss: 0.6737 - val_prc_auc: 0.5857 - val_precision: 0.4276 - val_recall: 0.8341\n","Epoch 2/20\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7074 - binary_accuracy: 0.6434 - f1: 0.6281 - loss: 0.6550 - prc_auc: 0.7023 - precision: 0.6459 - recall: 0.6179\n","Epoch 2: Validation Metrics:\n","loss: 0.6473450660705566\n","val_binary_accuracy: 0.6604938507080078\n","val_precision: 0.5047468543052673\n","val_recall: 0.7152466177940369\n","val_auc: 0.7350330352783203\n","val_prc_auc: 0.5919383764266968\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7075 - binary_accuracy: 0.6435 - f1: 0.6283 - loss: 0.6549 - prc_auc: 0.7024 - precision: 0.6461 - recall: 0.6180 - val_auc: 0.7350 - val_binary_accuracy: 0.6605 - val_f1: 0.5918 - val_loss: 0.6406 - val_prc_auc: 0.5919 - val_precision: 0.5047 - val_recall: 0.7152\n","Epoch 3/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7236 - binary_accuracy: 0.6687 - f1: 0.6404 - loss: 0.6300 - prc_auc: 0.7161 - precision: 0.6841 - recall: 0.6035\n","Epoch 3: Validation Metrics:\n","loss: 0.6243700981140137\n","val_binary_accuracy: 0.6720678806304932\n","val_precision: 0.5176470875740051\n","val_recall: 0.6905829310417175\n","val_auc: 0.7424057126045227\n","val_prc_auc: 0.5958700776100159\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7238 - binary_accuracy: 0.6688 - f1: 0.6407 - loss: 0.6299 - prc_auc: 0.7162 - precision: 0.6842 - recall: 0.6040 - val_auc: 0.7424 - val_binary_accuracy: 0.6721 - val_f1: 0.5917 - val_loss: 0.6227 - val_prc_auc: 0.5959 - val_precision: 0.5176 - val_recall: 0.6906\n","Epoch 4/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7376 - binary_accuracy: 0.6792 - f1: 0.6513 - loss: 0.6121 - prc_auc: 0.7262 - precision: 0.6967 - recall: 0.6127\n","Epoch 4: Validation Metrics:\n","loss: 0.6091873049736023\n","val_binary_accuracy: 0.6743826866149902\n","val_precision: 0.520477831363678\n","val_recall: 0.6838564872741699\n","val_auc: 0.74756920337677\n","val_prc_auc: 0.6011936664581299\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7377 - binary_accuracy: 0.6793 - f1: 0.6516 - loss: 0.6121 - prc_auc: 0.7263 - precision: 0.6969 - recall: 0.6131 - val_auc: 0.7476 - val_binary_accuracy: 0.6744 - val_f1: 0.5911 - val_loss: 0.6134 - val_prc_auc: 0.6012 - val_precision: 0.5205 - val_recall: 0.6839\n","Epoch 5/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7476 - binary_accuracy: 0.6851 - f1: 0.6576 - loss: 0.6003 - prc_auc: 0.7340 - precision: 0.7035 - recall: 0.6183\n","Epoch 5: Validation Metrics:\n","loss: 0.599658727645874\n","val_binary_accuracy: 0.6836419701576233\n","val_precision: 0.5310344696044922\n","val_recall: 0.6905829310417175\n","val_auc: 0.750830888748169\n","val_prc_auc: 0.6048811674118042\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7476 - binary_accuracy: 0.6852 - f1: 0.6579 - loss: 0.6002 - prc_auc: 0.7341 - precision: 0.7037 - recall: 0.6187 - val_auc: 0.7508 - val_binary_accuracy: 0.6836 - val_f1: 0.6004 - val_loss: 0.6091 - val_prc_auc: 0.6049 - val_precision: 0.5310 - val_recall: 0.6906\n","Epoch 6/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7549 - binary_accuracy: 0.6911 - f1: 0.6651 - loss: 0.5923 - prc_auc: 0.7398 - precision: 0.7084 - recall: 0.6280\n","Epoch 6: Validation Metrics:\n","loss: 0.5934385061264038\n","val_binary_accuracy: 0.6851851940155029\n","val_precision: 0.5326460599899292\n","val_recall: 0.695067286491394\n","val_auc: 0.7531931400299072\n","val_prc_auc: 0.6079613566398621\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7549 - binary_accuracy: 0.6912 - f1: 0.6653 - loss: 0.5923 - prc_auc: 0.7399 - precision: 0.7085 - recall: 0.6282 - val_auc: 0.7532 - val_binary_accuracy: 0.6852 - val_f1: 0.6031 - val_loss: 0.6064 - val_prc_auc: 0.6080 - val_precision: 0.5326 - val_recall: 0.6951\n","Epoch 7/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7604 - binary_accuracy: 0.6906 - f1: 0.6658 - loss: 0.5865 - prc_auc: 0.7442 - precision: 0.7064 - recall: 0.6305\n","Epoch 7: Validation Metrics:\n","loss: 0.5889056921005249\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5400696992874146\n","val_recall: 0.695067286491394\n","val_auc: 0.7543550729751587\n","val_prc_auc: 0.611273467540741\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7603 - binary_accuracy: 0.6907 - f1: 0.6661 - loss: 0.5866 - prc_auc: 0.7442 - precision: 0.7066 - recall: 0.6308 - val_auc: 0.7544 - val_binary_accuracy: 0.6914 - val_f1: 0.6078 - val_loss: 0.6044 - val_prc_auc: 0.6113 - val_precision: 0.5401 - val_recall: 0.6951\n","Epoch 8/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7644 - binary_accuracy: 0.6952 - f1: 0.6719 - loss: 0.5820 - prc_auc: 0.7480 - precision: 0.7102 - recall: 0.6382\n","Epoch 8: Validation Metrics:\n","loss: 0.5854371786117554\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5399305820465088\n","val_recall: 0.6973094344139099\n","val_auc: 0.7555117011070251\n","val_prc_auc: 0.6127395033836365\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7643 - binary_accuracy: 0.6952 - f1: 0.6721 - loss: 0.5821 - prc_auc: 0.7481 - precision: 0.7103 - recall: 0.6384 - val_auc: 0.7555 - val_binary_accuracy: 0.6914 - val_f1: 0.6086 - val_loss: 0.6032 - val_prc_auc: 0.6127 - val_precision: 0.5399 - val_recall: 0.6973\n","Epoch 9/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7675 - binary_accuracy: 0.6977 - f1: 0.6747 - loss: 0.5786 - prc_auc: 0.7512 - precision: 0.7128 - recall: 0.6410\n","Epoch 9: Validation Metrics:\n","loss: 0.5826388597488403\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5399305820465088\n","val_recall: 0.6973094344139099\n","val_auc: 0.7568293213844299\n","val_prc_auc: 0.616611897945404\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7674 - binary_accuracy: 0.6977 - f1: 0.6749 - loss: 0.5786 - prc_auc: 0.7513 - precision: 0.7129 - recall: 0.6413 - val_auc: 0.7568 - val_binary_accuracy: 0.6914 - val_f1: 0.6086 - val_loss: 0.6020 - val_prc_auc: 0.6166 - val_precision: 0.5399 - val_recall: 0.6973\n","Epoch 10/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7704 - binary_accuracy: 0.7006 - f1: 0.6785 - loss: 0.5756 - prc_auc: 0.7547 - precision: 0.7151 - recall: 0.6460\n","Epoch 10: Validation Metrics:\n","loss: 0.5802363753318787\n","val_binary_accuracy: 0.6921296119689941\n","val_precision: 0.5408695936203003\n","val_recall: 0.6973094344139099\n","val_auc: 0.7573463916778564\n","val_prc_auc: 0.6172256469726562\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7703 - binary_accuracy: 0.7006 - f1: 0.6787 - loss: 0.5757 - prc_auc: 0.7548 - precision: 0.7151 - recall: 0.6463 - val_auc: 0.7573 - val_binary_accuracy: 0.6921 - val_f1: 0.6092 - val_loss: 0.6008 - val_prc_auc: 0.6172 - val_precision: 0.5409 - val_recall: 0.6973\n","Epoch 11/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7726 - binary_accuracy: 0.7013 - f1: 0.6796 - loss: 0.5730 - prc_auc: 0.7577 - precision: 0.7158 - recall: 0.6472\n","Epoch 11: Validation Metrics:\n","loss: 0.5780980587005615\n","val_binary_accuracy: 0.6921296119689941\n","val_precision: 0.5407279133796692\n","val_recall: 0.6995515823364258\n","val_auc: 0.7581825256347656\n","val_prc_auc: 0.6199153661727905\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7725 - binary_accuracy: 0.7013 - f1: 0.6798 - loss: 0.5731 - prc_auc: 0.7577 - precision: 0.7158 - recall: 0.6476 - val_auc: 0.7582 - val_binary_accuracy: 0.6921 - val_f1: 0.6100 - val_loss: 0.6000 - val_prc_auc: 0.6199 - val_precision: 0.5407 - val_recall: 0.6996\n","Epoch 12/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7748 - binary_accuracy: 0.7016 - f1: 0.6800 - loss: 0.5707 - prc_auc: 0.7602 - precision: 0.7160 - recall: 0.6478\n","Epoch 12: Validation Metrics:\n","loss: 0.5761737823486328\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5396551489830017\n","val_recall: 0.7017937302589417\n","val_auc: 0.7590517997741699\n","val_prc_auc: 0.6227297782897949\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7747 - binary_accuracy: 0.7016 - f1: 0.6801 - loss: 0.5708 - prc_auc: 0.7602 - precision: 0.7160 - recall: 0.6481 - val_auc: 0.7591 - val_binary_accuracy: 0.6914 - val_f1: 0.6101 - val_loss: 0.5992 - val_prc_auc: 0.6227 - val_precision: 0.5397 - val_recall: 0.7018\n","Epoch 13/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7767 - binary_accuracy: 0.7032 - f1: 0.6832 - loss: 0.5687 - prc_auc: 0.7631 - precision: 0.7154 - recall: 0.6543\n","Epoch 13: Validation Metrics:\n","loss: 0.574443519115448\n","val_binary_accuracy: 0.6944444179534912\n","val_precision: 0.5426621437072754\n","val_recall: 0.713004469871521\n","val_auc: 0.7598588466644287\n","val_prc_auc: 0.6239562630653381\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7766 - binary_accuracy: 0.7032 - f1: 0.6834 - loss: 0.5688 - prc_auc: 0.7631 - precision: 0.7155 - recall: 0.6546 - val_auc: 0.7599 - val_binary_accuracy: 0.6944 - val_f1: 0.6163 - val_loss: 0.5986 - val_prc_auc: 0.6240 - val_precision: 0.5427 - val_recall: 0.7130\n","Epoch 14/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7784 - binary_accuracy: 0.7055 - f1: 0.6858 - loss: 0.5668 - prc_auc: 0.7655 - precision: 0.7178 - recall: 0.6570\n","Epoch 14: Validation Metrics:\n","loss: 0.5727930665016174\n","val_binary_accuracy: 0.6936728358268738\n","val_precision: 0.5417376756668091\n","val_recall: 0.713004469871521\n","val_auc: 0.7607438564300537\n","val_prc_auc: 0.6269952058792114\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7783 - binary_accuracy: 0.7054 - f1: 0.6859 - loss: 0.5669 - prc_auc: 0.7655 - precision: 0.7178 - recall: 0.6572 - val_auc: 0.7607 - val_binary_accuracy: 0.6937 - val_f1: 0.6157 - val_loss: 0.5979 - val_prc_auc: 0.6270 - val_precision: 0.5417 - val_recall: 0.7130\n","Epoch 15/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7800 - binary_accuracy: 0.7080 - f1: 0.6893 - loss: 0.5650 - prc_auc: 0.7676 - precision: 0.7195 - recall: 0.6620\n","Epoch 15: Validation Metrics:\n","loss: 0.5712680816650391\n","val_binary_accuracy: 0.6936728358268738\n","val_precision: 0.5415959358215332\n","val_recall: 0.7152466177940369\n","val_auc: 0.761719822883606\n","val_prc_auc: 0.6305260062217712\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7799 - binary_accuracy: 0.7079 - f1: 0.6894 - loss: 0.5652 - prc_auc: 0.7676 - precision: 0.7195 - recall: 0.6622 - val_auc: 0.7617 - val_binary_accuracy: 0.6937 - val_f1: 0.6164 - val_loss: 0.5971 - val_prc_auc: 0.6305 - val_precision: 0.5416 - val_recall: 0.7152\n","Epoch 16/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7815 - binary_accuracy: 0.7093 - f1: 0.6913 - loss: 0.5634 - prc_auc: 0.7691 - precision: 0.7200 - recall: 0.6653\n","Epoch 16: Validation Metrics:\n","loss: 0.5698065757751465\n","val_binary_accuracy: 0.6913580298423767\n","val_precision: 0.5387205481529236\n","val_recall: 0.7174887657165527\n","val_auc: 0.7620323896408081\n","val_prc_auc: 0.6318315267562866\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7814 - binary_accuracy: 0.7092 - f1: 0.6915 - loss: 0.5635 - prc_auc: 0.7691 - precision: 0.7200 - recall: 0.6656 - val_auc: 0.7620 - val_binary_accuracy: 0.6914 - val_f1: 0.6154 - val_loss: 0.5965 - val_prc_auc: 0.6318 - val_precision: 0.5387 - val_recall: 0.7175\n","Epoch 17/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7832 - binary_accuracy: 0.7083 - f1: 0.6908 - loss: 0.5618 - prc_auc: 0.7718 - precision: 0.7183 - recall: 0.6657\n","Epoch 17: Validation Metrics:\n","loss: 0.5683777928352356\n","val_binary_accuracy: 0.6929012537002563\n","val_precision: 0.5404040217399597\n","val_recall: 0.7197309136390686\n","val_auc: 0.7624900937080383\n","val_prc_auc: 0.6337496638298035\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7831 - binary_accuracy: 0.7083 - f1: 0.6909 - loss: 0.5619 - prc_auc: 0.7717 - precision: 0.7183 - recall: 0.6659 - val_auc: 0.7625 - val_binary_accuracy: 0.6929 - val_f1: 0.6173 - val_loss: 0.5959 - val_prc_auc: 0.6337 - val_precision: 0.5404 - val_recall: 0.7197\n","Epoch 18/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7844 - binary_accuracy: 0.7090 - f1: 0.6925 - loss: 0.5603 - prc_auc: 0.7737 - precision: 0.7176 - recall: 0.6696\n","Epoch 18: Validation Metrics:\n","loss: 0.5670405626296997\n","val_binary_accuracy: 0.6921296119689941\n","val_precision: 0.5393635034561157\n","val_recall: 0.7219731211662292\n","val_auc: 0.763143002986908\n","val_prc_auc: 0.6348613500595093\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7843 - binary_accuracy: 0.7090 - f1: 0.6926 - loss: 0.5604 - prc_auc: 0.7737 - precision: 0.7176 - recall: 0.6698 - val_auc: 0.7631 - val_binary_accuracy: 0.6921 - val_f1: 0.6174 - val_loss: 0.5955 - val_prc_auc: 0.6349 - val_precision: 0.5394 - val_recall: 0.7220\n","Epoch 19/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7855 - binary_accuracy: 0.7110 - f1: 0.6955 - loss: 0.5589 - prc_auc: 0.7753 - precision: 0.7183 - recall: 0.6744\n","Epoch 19: Validation Metrics:\n","loss: 0.5657496452331543\n","val_binary_accuracy: 0.6936728358268738\n","val_precision: 0.5410385131835938\n","val_recall: 0.7242152690887451\n","val_auc: 0.7636362314224243\n","val_prc_auc: 0.6375442147254944\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7854 - binary_accuracy: 0.7109 - f1: 0.6956 - loss: 0.5590 - prc_auc: 0.7753 - precision: 0.7183 - recall: 0.6747 - val_auc: 0.7636 - val_binary_accuracy: 0.6937 - val_f1: 0.6194 - val_loss: 0.5949 - val_prc_auc: 0.6375 - val_precision: 0.5410 - val_recall: 0.7242\n","Epoch 20/20\n","\u001b[1m111/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7871 - binary_accuracy: 0.7120 - f1: 0.6969 - loss: 0.5575 - prc_auc: 0.7773 - precision: 0.7187 - recall: 0.6769\n","Epoch 20: Validation Metrics:\n","loss: 0.5644792318344116\n","val_binary_accuracy: 0.6936728358268738\n","val_precision: 0.5411764979362488\n","val_recall: 0.7219731211662292\n","val_auc: 0.7642903923988342\n","val_prc_auc: 0.6385801434516907\n","\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7869 - binary_accuracy: 0.7120 - f1: 0.6971 - loss: 0.5576 - prc_auc: 0.7772 - precision: 0.7187 - recall: 0.6772 - val_auc: 0.7643 - val_binary_accuracy: 0.6937 - val_f1: 0.6186 - val_loss: 0.5943 - val_prc_auc: 0.6386 - val_precision: 0.5412 - val_recall: 0.7220\n","Starting training for label: 7\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - auc: 0.5642 - binary_accuracy: 0.5065 - f1: 0.4807 - loss: 0.6917 - prc_auc: 0.5399 - precision: 0.4938 - recall: 0.4943\n","Epoch 1: Validation Metrics:\n","loss: 0.6907055377960205\n","val_binary_accuracy: 0.852623462677002\n","val_precision: 0.061349693685770035\n","val_recall: 0.2083333283662796\n","val_auc: 0.6897369027137756\n","val_prc_auc: 0.09594860672950745\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - auc: 0.5646 - binary_accuracy: 0.5076 - f1: 0.4755 - loss: 0.6917 - prc_auc: 0.5413 - precision: 0.4969 - recall: 0.4822 - val_auc: 0.6897 - val_binary_accuracy: 0.8526 - val_f1: 0.0948 - val_loss: 0.6724 - val_prc_auc: 0.0959 - val_precision: 0.0613 - val_recall: 0.2083\n","Epoch 2/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7262 - binary_accuracy: 0.6354 - f1: 0.4890 - loss: 0.6841 - prc_auc: 0.7049 - precision: 0.7492 - recall: 0.3636\n","Epoch 2: Validation Metrics:\n","loss: 0.6836708188056946\n","val_binary_accuracy: 0.8140432238578796\n","val_precision: 0.09282700717449188\n","val_recall: 0.4583333432674408\n","val_auc: 0.7596571445465088\n","val_prc_auc: 0.1197860911488533\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - auc: 0.7271 - binary_accuracy: 0.6341 - f1: 0.4889 - loss: 0.6841 - prc_auc: 0.7066 - precision: 0.7486 - recall: 0.3636 - val_auc: 0.7597 - val_binary_accuracy: 0.8140 - val_f1: 0.1544 - val_loss: 0.6765 - val_prc_auc: 0.1198 - val_precision: 0.0928 - val_recall: 0.4583\n","Epoch 3/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7741 - binary_accuracy: 0.6978 - f1: 0.6361 - loss: 0.6792 - prc_auc: 0.7545 - precision: 0.7562 - recall: 0.5493\n","Epoch 3: Validation Metrics:\n","loss: 0.6784239411354065\n","val_binary_accuracy: 0.790123462677002\n","val_precision: 0.1164383590221405\n","val_recall: 0.7083333134651184\n","val_auc: 0.7909488081932068\n","val_prc_auc: 0.13620507717132568\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 315ms/step - auc: 0.7752 - binary_accuracy: 0.6981 - f1: 0.6379 - loss: 0.6792 - prc_auc: 0.7563 - precision: 0.7575 - recall: 0.5512 - val_auc: 0.7909 - val_binary_accuracy: 0.7901 - val_f1: 0.2000 - val_loss: 0.6801 - val_prc_auc: 0.1362 - val_precision: 0.1164 - val_recall: 0.7083\n","Epoch 4/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7929 - binary_accuracy: 0.7352 - f1: 0.7102 - loss: 0.6747 - prc_auc: 0.7721 - precision: 0.7509 - recall: 0.6743\n","Epoch 4: Validation Metrics:\n","loss: 0.6736086010932922\n","val_binary_accuracy: 0.7916666865348816\n","val_precision: 0.11724138259887695\n","val_recall: 0.7083333134651184\n","val_auc: 0.8044120073318481\n","val_prc_auc: 0.15592658519744873\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.7937 - binary_accuracy: 0.7353 - f1: 0.7110 - loss: 0.6747 - prc_auc: 0.7738 - precision: 0.7522 - recall: 0.6747 - val_auc: 0.8044 - val_binary_accuracy: 0.7917 - val_f1: 0.2012 - val_loss: 0.6772 - val_prc_auc: 0.1559 - val_precision: 0.1172 - val_recall: 0.7083\n","Epoch 5/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8121 - binary_accuracy: 0.7356 - f1: 0.7097 - loss: 0.6700 - prc_auc: 0.7929 - precision: 0.7542 - recall: 0.6709\n","Epoch 5: Validation Metrics:\n","loss: 0.6686844825744629\n","val_binary_accuracy: 0.8070987462997437\n","val_precision: 0.12867647409439087\n","val_recall: 0.7291666865348816\n","val_auc: 0.8164646625518799\n","val_prc_auc: 0.17657697200775146\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 316ms/step - auc: 0.8127 - binary_accuracy: 0.7361 - f1: 0.7108 - loss: 0.6699 - prc_auc: 0.7942 - precision: 0.7562 - recall: 0.6711 - val_auc: 0.8165 - val_binary_accuracy: 0.8071 - val_f1: 0.2187 - val_loss: 0.6705 - val_prc_auc: 0.1766 - val_precision: 0.1287 - val_recall: 0.7292\n","Epoch 6/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8146 - binary_accuracy: 0.7462 - f1: 0.7150 - loss: 0.6649 - prc_auc: 0.7998 - precision: 0.7793 - recall: 0.6611\n","Epoch 6: Validation Metrics:\n","loss: 0.6635880470275879\n","val_binary_accuracy: 0.8202160596847534\n","val_precision: 0.13725490868091583\n","val_recall: 0.7291666865348816\n","val_auc: 0.8227747678756714\n","val_prc_auc: 0.20082367956638336\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 316ms/step - auc: 0.8157 - binary_accuracy: 0.7463 - f1: 0.7157 - loss: 0.6648 - prc_auc: 0.8015 - precision: 0.7807 - recall: 0.6613 - val_auc: 0.8228 - val_binary_accuracy: 0.8202 - val_f1: 0.2310 - val_loss: 0.6631 - val_prc_auc: 0.2008 - val_precision: 0.1373 - val_recall: 0.7292\n","Epoch 7/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8269 - binary_accuracy: 0.7547 - f1: 0.7219 - loss: 0.6595 - prc_auc: 0.8097 - precision: 0.7961 - recall: 0.6611\n","Epoch 7: Validation Metrics:\n","loss: 0.6580609083175659\n","val_binary_accuracy: 0.8271604776382446\n","val_precision: 0.14227642118930817\n","val_recall: 0.7291666865348816\n","val_auc: 0.8301281929016113\n","val_prc_auc: 0.21579614281654358\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 319ms/step - auc: 0.8276 - binary_accuracy: 0.7549 - f1: 0.7227 - loss: 0.6594 - prc_auc: 0.8112 - precision: 0.7978 - recall: 0.6613 - val_auc: 0.8301 - val_binary_accuracy: 0.8272 - val_f1: 0.2381 - val_loss: 0.6561 - val_prc_auc: 0.2158 - val_precision: 0.1423 - val_recall: 0.7292\n","Epoch 8/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8271 - binary_accuracy: 0.7619 - f1: 0.7289 - loss: 0.6539 - prc_auc: 0.8146 - precision: 0.8079 - recall: 0.6646\n","Epoch 8: Validation Metrics:\n","loss: 0.652270495891571\n","val_binary_accuracy: 0.8302469253540039\n","val_precision: 0.14462809264659882\n","val_recall: 0.7291666865348816\n","val_auc: 0.8361127376556396\n","val_prc_auc: 0.2463141530752182\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 316ms/step - auc: 0.8282 - binary_accuracy: 0.7624 - f1: 0.7300 - loss: 0.6537 - prc_auc: 0.8163 - precision: 0.8097 - recall: 0.6653 - val_auc: 0.8361 - val_binary_accuracy: 0.8302 - val_f1: 0.2414 - val_loss: 0.6511 - val_prc_auc: 0.2463 - val_precision: 0.1446 - val_recall: 0.7292\n","Epoch 9/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8324 - binary_accuracy: 0.7627 - f1: 0.7316 - loss: 0.6483 - prc_auc: 0.8189 - precision: 0.8039 - recall: 0.6717\n","Epoch 9: Validation Metrics:\n","loss: 0.6464767456054688\n","val_binary_accuracy: 0.8310185074806213\n","val_precision: 0.14522822201251984\n","val_recall: 0.7291666865348816\n","val_auc: 0.8437833786010742\n","val_prc_auc: 0.2655947804450989\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8336 - binary_accuracy: 0.7634 - f1: 0.7330 - loss: 0.6482 - prc_auc: 0.8208 - precision: 0.8058 - recall: 0.6727 - val_auc: 0.8438 - val_binary_accuracy: 0.8310 - val_f1: 0.2422 - val_loss: 0.6466 - val_prc_auc: 0.2656 - val_precision: 0.1452 - val_recall: 0.7292\n","Epoch 10/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8383 - binary_accuracy: 0.7720 - f1: 0.7414 - loss: 0.6427 - prc_auc: 0.8263 - precision: 0.8173 - recall: 0.6786\n","Epoch 10: Validation Metrics:\n","loss: 0.6405489444732666\n","val_binary_accuracy: 0.8356481194496155\n","val_precision: 0.1489361673593521\n","val_recall: 0.7291666865348816\n","val_auc: 0.8495259284973145\n","val_prc_auc: 0.27741867303848267\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8393 - binary_accuracy: 0.7727 - f1: 0.7429 - loss: 0.6425 - prc_auc: 0.8280 - precision: 0.8191 - recall: 0.6799 - val_auc: 0.8495 - val_binary_accuracy: 0.8356 - val_f1: 0.2473 - val_loss: 0.6412 - val_prc_auc: 0.2774 - val_precision: 0.1489 - val_recall: 0.7292\n","Epoch 11/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8401 - binary_accuracy: 0.7747 - f1: 0.7451 - loss: 0.6368 - prc_auc: 0.8279 - precision: 0.8183 - recall: 0.6841\n","Epoch 11: Validation Metrics:\n","loss: 0.6344204545021057\n","val_binary_accuracy: 0.8371913433074951\n","val_precision: 0.15021459758281708\n","val_recall: 0.7291666865348816\n","val_auc: 0.853331983089447\n","val_prc_auc: 0.2853076457977295\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8412 - binary_accuracy: 0.7760 - f1: 0.7474 - loss: 0.6366 - prc_auc: 0.8297 - precision: 0.8204 - recall: 0.6866 - val_auc: 0.8533 - val_binary_accuracy: 0.8372 - val_f1: 0.2491 - val_loss: 0.6360 - val_prc_auc: 0.2853 - val_precision: 0.1502 - val_recall: 0.7292\n","Epoch 12/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8449 - binary_accuracy: 0.7754 - f1: 0.7452 - loss: 0.6309 - prc_auc: 0.8348 - precision: 0.8215 - recall: 0.6821\n","Epoch 12: Validation Metrics:\n","loss: 0.6283934712409973\n","val_binary_accuracy: 0.8487654328346252\n","val_precision: 0.16055046021938324\n","val_recall: 0.7291666865348816\n","val_auc: 0.856553852558136\n","val_prc_auc: 0.29451537132263184\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 316ms/step - auc: 0.8460 - binary_accuracy: 0.7767 - f1: 0.7474 - loss: 0.6307 - prc_auc: 0.8365 - precision: 0.8236 - recall: 0.6843 - val_auc: 0.8566 - val_binary_accuracy: 0.8488 - val_f1: 0.2632 - val_loss: 0.6282 - val_prc_auc: 0.2945 - val_precision: 0.1606 - val_recall: 0.7292\n","Epoch 13/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8493 - binary_accuracy: 0.7773 - f1: 0.7465 - loss: 0.6248 - prc_auc: 0.8391 - precision: 0.8269 - recall: 0.6807\n","Epoch 13: Validation Metrics:\n","loss: 0.6221723556518555\n","val_binary_accuracy: 0.8564814925193787\n","val_precision: 0.1650485396385193\n","val_recall: 0.7083333134651184\n","val_auc: 0.8572549819946289\n","val_prc_auc: 0.30103087425231934\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8504 - binary_accuracy: 0.7785 - f1: 0.7485 - loss: 0.6246 - prc_auc: 0.8408 - precision: 0.8290 - recall: 0.6826 - val_auc: 0.8573 - val_binary_accuracy: 0.8565 - val_f1: 0.2677 - val_loss: 0.6204 - val_prc_auc: 0.3010 - val_precision: 0.1650 - val_recall: 0.7083\n","Epoch 14/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8518 - binary_accuracy: 0.7871 - f1: 0.7547 - loss: 0.6185 - prc_auc: 0.8408 - precision: 0.8476 - recall: 0.6807\n","Epoch 14: Validation Metrics:\n","loss: 0.6157359480857849\n","val_binary_accuracy: 0.8611111044883728\n","val_precision: 0.17000000178813934\n","val_recall: 0.7083333134651184\n","val_auc: 0.8587156534194946\n","val_prc_auc: 0.310425341129303\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 319ms/step - auc: 0.8529 - binary_accuracy: 0.7879 - f1: 0.7564 - loss: 0.6183 - prc_auc: 0.8426 - precision: 0.8489 - recall: 0.6826 - val_auc: 0.8587 - val_binary_accuracy: 0.8611 - val_f1: 0.2742 - val_loss: 0.6130 - val_prc_auc: 0.3104 - val_precision: 0.1700 - val_recall: 0.7083\n","Epoch 15/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8538 - binary_accuracy: 0.7815 - f1: 0.7466 - loss: 0.6120 - prc_auc: 0.8441 - precision: 0.8452 - recall: 0.6689\n","Epoch 15: Validation Metrics:\n","loss: 0.6091088652610779\n","val_binary_accuracy: 0.8641975522041321\n","val_precision: 0.1734693944454193\n","val_recall: 0.7083333134651184\n","val_auc: 0.8607271313667297\n","val_prc_auc: 0.31813278794288635\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8549 - binary_accuracy: 0.7821 - f1: 0.7481 - loss: 0.6118 - prc_auc: 0.8458 - precision: 0.8465 - recall: 0.6704 - val_auc: 0.8607 - val_binary_accuracy: 0.8642 - val_f1: 0.2787 - val_loss: 0.6055 - val_prc_auc: 0.3181 - val_precision: 0.1735 - val_recall: 0.7083\n","Epoch 16/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8588 - binary_accuracy: 0.7866 - f1: 0.7529 - loss: 0.6055 - prc_auc: 0.8492 - precision: 0.8503 - recall: 0.6758\n","Epoch 16: Validation Metrics:\n","loss: 0.6023738980293274\n","val_binary_accuracy: 0.8703703880310059\n","val_precision: 0.1808510571718216\n","val_recall: 0.7083333134651184\n","val_auc: 0.8652427196502686\n","val_prc_auc: 0.3283795416355133\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8599 - binary_accuracy: 0.7874 - f1: 0.7546 - loss: 0.6053 - prc_auc: 0.8509 - precision: 0.8518 - recall: 0.6776 - val_auc: 0.8652 - val_binary_accuracy: 0.8704 - val_f1: 0.2881 - val_loss: 0.5995 - val_prc_auc: 0.3284 - val_precision: 0.1809 - val_recall: 0.7083\n","Epoch 17/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8567 - binary_accuracy: 0.7877 - f1: 0.7543 - loss: 0.5991 - prc_auc: 0.8485 - precision: 0.8515 - recall: 0.6772\n","Epoch 17: Validation Metrics:\n","loss: 0.5955814719200134\n","val_binary_accuracy: 0.8765432238578796\n","val_precision: 0.19230769574642181\n","val_recall: 0.7291666865348816\n","val_auc: 0.8673794865608215\n","val_prc_auc: 0.34304240345954895\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - auc: 0.8579 - binary_accuracy: 0.7889 - f1: 0.7564 - loss: 0.5988 - prc_auc: 0.8504 - precision: 0.8534 - recall: 0.6794 - val_auc: 0.8674 - val_binary_accuracy: 0.8765 - val_f1: 0.3043 - val_loss: 0.5932 - val_prc_auc: 0.3430 - val_precision: 0.1923 - val_recall: 0.7292\n","Epoch 18/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8617 - binary_accuracy: 0.7863 - f1: 0.7522 - loss: 0.5925 - prc_auc: 0.8536 - precision: 0.8510 - recall: 0.6742\n","Epoch 18: Validation Metrics:\n","loss: 0.5886977314949036\n","val_binary_accuracy: 0.8819444179534912\n","val_precision: 0.20000000298023224\n","val_recall: 0.7291666865348816\n","val_auc: 0.8706096410751343\n","val_prc_auc: 0.3574713468551636\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - auc: 0.8628 - binary_accuracy: 0.7876 - f1: 0.7544 - loss: 0.5922 - prc_auc: 0.8553 - precision: 0.8529 - recall: 0.6766 - val_auc: 0.8706 - val_binary_accuracy: 0.8819 - val_f1: 0.3139 - val_loss: 0.5854 - val_prc_auc: 0.3575 - val_precision: 0.2000 - val_recall: 0.7292\n","Epoch 19/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8632 - binary_accuracy: 0.7868 - f1: 0.7526 - loss: 0.5858 - prc_auc: 0.8541 - precision: 0.8520 - recall: 0.6742\n","Epoch 19: Validation Metrics:\n","loss: 0.581741452217102\n","val_binary_accuracy: 0.8850308656692505\n","val_precision: 0.20467835664749146\n","val_recall: 0.7291666865348816\n","val_auc: 0.8726546168327332\n","val_prc_auc: 0.3726561665534973\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8644 - binary_accuracy: 0.7882 - f1: 0.7550 - loss: 0.5855 - prc_auc: 0.8560 - precision: 0.8543 - recall: 0.6766 - val_auc: 0.8727 - val_binary_accuracy: 0.8850 - val_f1: 0.3196 - val_loss: 0.5778 - val_prc_auc: 0.3727 - val_precision: 0.2047 - val_recall: 0.7292\n","Epoch 20/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8656 - binary_accuracy: 0.7868 - f1: 0.7526 - loss: 0.5792 - prc_auc: 0.8575 - precision: 0.8520 - recall: 0.6742\n","Epoch 20: Validation Metrics:\n","loss: 0.5746703147888184\n","val_binary_accuracy: 0.8896604776382446\n","val_precision: 0.21212121844291687\n","val_recall: 0.7291666865348816\n","val_auc: 0.8740985989570618\n","val_prc_auc: 0.38212376832962036\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - auc: 0.8668 - binary_accuracy: 0.7882 - f1: 0.7550 - loss: 0.5788 - prc_auc: 0.8592 - precision: 0.8543 - recall: 0.6766 - val_auc: 0.8741 - val_binary_accuracy: 0.8897 - val_f1: 0.3286 - val_loss: 0.5703 - val_prc_auc: 0.3821 - val_precision: 0.2121 - val_recall: 0.7292\n","Starting training for label: 8\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - auc: 0.5698 - binary_accuracy: 0.5536 - f1: 0.4613 - loss: 0.6887 - prc_auc: 0.5735 - precision: 0.4976 - recall: 0.4467\n","Epoch 1: Validation Metrics:\n","loss: 0.6820162534713745\n","val_binary_accuracy: 0.7314814925193787\n","val_precision: 0.584761917591095\n","val_recall: 0.7025171518325806\n","val_auc: 0.7638545036315918\n","val_prc_auc: 0.5950031876564026\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 374ms/step - auc: 0.5705 - binary_accuracy: 0.5541 - f1: 0.4628 - loss: 0.6886 - prc_auc: 0.5741 - precision: 0.4985 - recall: 0.4485 - val_auc: 0.7639 - val_binary_accuracy: 0.7315 - val_f1: 0.6383 - val_loss: 0.6576 - val_prc_auc: 0.5950 - val_precision: 0.5848 - val_recall: 0.7025\n","Epoch 2/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7071 - binary_accuracy: 0.6555 - f1: 0.6726 - loss: 0.6623 - prc_auc: 0.6745 - precision: 0.6366 - recall: 0.7137\n","Epoch 2: Validation Metrics:\n","loss: 0.6547991633415222\n","val_binary_accuracy: 0.7291666865348816\n","val_precision: 0.5814393758773804\n","val_recall: 0.7025171518325806\n","val_auc: 0.7766547799110413\n","val_prc_auc: 0.5981594324111938\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7073 - binary_accuracy: 0.6556 - f1: 0.6728 - loss: 0.6622 - prc_auc: 0.6748 - precision: 0.6369 - recall: 0.7138 - val_auc: 0.7767 - val_binary_accuracy: 0.7292 - val_f1: 0.6363 - val_loss: 0.6228 - val_prc_auc: 0.5982 - val_precision: 0.5814 - val_recall: 0.7025\n","Epoch 3/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7174 - binary_accuracy: 0.6616 - f1: 0.6732 - loss: 0.6384 - prc_auc: 0.6764 - precision: 0.6472 - recall: 0.7018\n","Epoch 3: Validation Metrics:\n","loss: 0.629558801651001\n","val_binary_accuracy: 0.7237654328346252\n","val_precision: 0.5699114799499512\n","val_recall: 0.7368420958518982\n","val_auc: 0.783383846282959\n","val_prc_auc: 0.6019003391265869\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7177 - binary_accuracy: 0.6618 - f1: 0.6734 - loss: 0.6382 - prc_auc: 0.6767 - precision: 0.6475 - recall: 0.7019 - val_auc: 0.7834 - val_binary_accuracy: 0.7238 - val_f1: 0.6427 - val_loss: 0.5980 - val_prc_auc: 0.6019 - val_precision: 0.5699 - val_recall: 0.7368\n","Epoch 4/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7250 - binary_accuracy: 0.6727 - f1: 0.6854 - loss: 0.6199 - prc_auc: 0.6793 - precision: 0.6567 - recall: 0.7171\n","Epoch 4: Validation Metrics:\n","loss: 0.6104201674461365\n","val_binary_accuracy: 0.716821014881134\n","val_precision: 0.5591216087341309\n","val_recall: 0.7574370503425598\n","val_auc: 0.7865646481513977\n","val_prc_auc: 0.6042965650558472\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7253 - binary_accuracy: 0.6729 - f1: 0.6855 - loss: 0.6198 - prc_auc: 0.6796 - precision: 0.6570 - recall: 0.7171 - val_auc: 0.7866 - val_binary_accuracy: 0.7168 - val_f1: 0.6433 - val_loss: 0.5825 - val_prc_auc: 0.6043 - val_precision: 0.5591 - val_recall: 0.7574\n","Epoch 5/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7297 - binary_accuracy: 0.6738 - f1: 0.6874 - loss: 0.6083 - prc_auc: 0.6810 - precision: 0.6568 - recall: 0.7213\n","Epoch 5: Validation Metrics:\n","loss: 0.5982610583305359\n","val_binary_accuracy: 0.7175925970077515\n","val_precision: 0.5594639778137207\n","val_recall: 0.7643020749092102\n","val_auc: 0.7887837290763855\n","val_prc_auc: 0.6082144379615784\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7300 - binary_accuracy: 0.6739 - f1: 0.6875 - loss: 0.6081 - prc_auc: 0.6813 - precision: 0.6571 - recall: 0.7212 - val_auc: 0.7888 - val_binary_accuracy: 0.7176 - val_f1: 0.6460 - val_loss: 0.5734 - val_prc_auc: 0.6082 - val_precision: 0.5595 - val_recall: 0.7643\n","Epoch 6/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7335 - binary_accuracy: 0.6729 - f1: 0.6861 - loss: 0.6014 - prc_auc: 0.6836 - precision: 0.6564 - recall: 0.7188\n","Epoch 6: Validation Metrics:\n","loss: 0.5908660888671875\n","val_binary_accuracy: 0.7191358208656311\n","val_precision: 0.5609349012374878\n","val_recall: 0.768878698348999\n","val_auc: 0.7907696962356567\n","val_prc_auc: 0.6109126806259155\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7338 - binary_accuracy: 0.6731 - f1: 0.6863 - loss: 0.6012 - prc_auc: 0.6840 - precision: 0.6567 - recall: 0.7189 - val_auc: 0.7908 - val_binary_accuracy: 0.7191 - val_f1: 0.6486 - val_loss: 0.5675 - val_prc_auc: 0.6109 - val_precision: 0.5609 - val_recall: 0.7689\n","Epoch 7/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7365 - binary_accuracy: 0.6744 - f1: 0.6885 - loss: 0.5968 - prc_auc: 0.6872 - precision: 0.6570 - recall: 0.7234\n","Epoch 7: Validation Metrics:\n","loss: 0.5859950184822083\n","val_binary_accuracy: 0.7175925970077515\n","val_precision: 0.5588722825050354\n","val_recall: 0.7711670398712158\n","val_auc: 0.7928635478019714\n","val_prc_auc: 0.6158063411712646\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - auc: 0.7368 - binary_accuracy: 0.6746 - f1: 0.6886 - loss: 0.5966 - prc_auc: 0.6875 - precision: 0.6573 - recall: 0.7234 - val_auc: 0.7929 - val_binary_accuracy: 0.7176 - val_f1: 0.6481 - val_loss: 0.5637 - val_prc_auc: 0.6158 - val_precision: 0.5589 - val_recall: 0.7712\n","Epoch 8/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7394 - binary_accuracy: 0.6743 - f1: 0.6881 - loss: 0.5935 - prc_auc: 0.6904 - precision: 0.6569 - recall: 0.7227\n","Epoch 8: Validation Metrics:\n","loss: 0.5824355483055115\n","val_binary_accuracy: 0.7145061492919922\n","val_precision: 0.5548281669616699\n","val_recall: 0.7757437229156494\n","val_auc: 0.794555127620697\n","val_prc_auc: 0.6197482943534851\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7397 - binary_accuracy: 0.6745 - f1: 0.6883 - loss: 0.5933 - prc_auc: 0.6908 - precision: 0.6572 - recall: 0.7228 - val_auc: 0.7946 - val_binary_accuracy: 0.7145 - val_f1: 0.6469 - val_loss: 0.5611 - val_prc_auc: 0.6197 - val_precision: 0.5548 - val_recall: 0.7757\n","Epoch 9/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7421 - binary_accuracy: 0.6754 - f1: 0.6905 - loss: 0.5907 - prc_auc: 0.6949 - precision: 0.6567 - recall: 0.7282\n","Epoch 9: Validation Metrics:\n","loss: 0.5796447396278381\n","val_binary_accuracy: 0.7145061492919922\n","val_precision: 0.5541195273399353\n","val_recall: 0.7848970293998718\n","val_auc: 0.7957192659378052\n","val_prc_auc: 0.6230722665786743\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7424 - binary_accuracy: 0.6756 - f1: 0.6907 - loss: 0.5905 - prc_auc: 0.6953 - precision: 0.6570 - recall: 0.7283 - val_auc: 0.7957 - val_binary_accuracy: 0.7145 - val_f1: 0.6496 - val_loss: 0.5591 - val_prc_auc: 0.6231 - val_precision: 0.5541 - val_recall: 0.7849\n","Epoch 10/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7444 - binary_accuracy: 0.6754 - f1: 0.6911 - loss: 0.5884 - prc_auc: 0.6973 - precision: 0.6562 - recall: 0.7302\n","Epoch 10: Validation Metrics:\n","loss: 0.5772915482521057\n","val_binary_accuracy: 0.7129629850387573\n","val_precision: 0.5525040626525879\n","val_recall: 0.782608687877655\n","val_auc: 0.7969087362289429\n","val_prc_auc: 0.6266337037086487\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7447 - binary_accuracy: 0.6756 - f1: 0.6913 - loss: 0.5882 - prc_auc: 0.6977 - precision: 0.6564 - recall: 0.7303 - val_auc: 0.7969 - val_binary_accuracy: 0.7130 - val_f1: 0.6477 - val_loss: 0.5573 - val_prc_auc: 0.6266 - val_precision: 0.5525 - val_recall: 0.7826\n","Epoch 11/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7467 - binary_accuracy: 0.6794 - f1: 0.6958 - loss: 0.5862 - prc_auc: 0.7002 - precision: 0.6588 - recall: 0.7375\n","Epoch 11: Validation Metrics:\n","loss: 0.5752620697021484\n","val_binary_accuracy: 0.7145061492919922\n","val_precision: 0.5539452433586121\n","val_recall: 0.7871853709220886\n","val_auc: 0.7981794476509094\n","val_prc_auc: 0.6303902864456177\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7470 - binary_accuracy: 0.6796 - f1: 0.6960 - loss: 0.5860 - prc_auc: 0.7006 - precision: 0.6590 - recall: 0.7375 - val_auc: 0.7982 - val_binary_accuracy: 0.7145 - val_f1: 0.6503 - val_loss: 0.5559 - val_prc_auc: 0.6304 - val_precision: 0.5539 - val_recall: 0.7872\n","Epoch 12/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7488 - binary_accuracy: 0.6810 - f1: 0.6972 - loss: 0.5843 - prc_auc: 0.7029 - precision: 0.6603 - recall: 0.7387\n","Epoch 12: Validation Metrics:\n","loss: 0.5734260082244873\n","val_binary_accuracy: 0.7137345671653748\n","val_precision: 0.5532258152961731\n","val_recall: 0.7848970293998718\n","val_auc: 0.7989706993103027\n","val_prc_auc: 0.6316710710525513\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - auc: 0.7491 - binary_accuracy: 0.6812 - f1: 0.6974 - loss: 0.5841 - prc_auc: 0.7033 - precision: 0.6606 - recall: 0.7388 - val_auc: 0.7990 - val_binary_accuracy: 0.7137 - val_f1: 0.6490 - val_loss: 0.5547 - val_prc_auc: 0.6317 - val_precision: 0.5532 - val_recall: 0.7849\n","Epoch 13/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7507 - binary_accuracy: 0.6833 - f1: 0.6998 - loss: 0.5825 - prc_auc: 0.7061 - precision: 0.6621 - recall: 0.7422\n","Epoch 13: Validation Metrics:\n","loss: 0.5717346668243408\n","val_binary_accuracy: 0.7129629850387573\n","val_precision: 0.5521669387817383\n","val_recall: 0.7871853709220886\n","val_auc: 0.8001920580863953\n","val_prc_auc: 0.635446310043335\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - auc: 0.7510 - binary_accuracy: 0.6835 - f1: 0.6999 - loss: 0.5823 - prc_auc: 0.7064 - precision: 0.6623 - recall: 0.7423 - val_auc: 0.8002 - val_binary_accuracy: 0.7130 - val_f1: 0.6491 - val_loss: 0.5539 - val_prc_auc: 0.6354 - val_precision: 0.5522 - val_recall: 0.7872\n","Epoch 14/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7526 - binary_accuracy: 0.6857 - f1: 0.7024 - loss: 0.5807 - prc_auc: 0.7082 - precision: 0.6639 - recall: 0.7458\n","Epoch 14: Validation Metrics:\n","loss: 0.5701305270195007\n","val_binary_accuracy: 0.7106481194496155\n","val_precision: 0.5495207905769348\n","val_recall: 0.7871853709220886\n","val_auc: 0.8008407950401306\n","val_prc_auc: 0.6370424032211304\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - auc: 0.7528 - binary_accuracy: 0.6859 - f1: 0.7026 - loss: 0.5805 - prc_auc: 0.7085 - precision: 0.6642 - recall: 0.7459 - val_auc: 0.8008 - val_binary_accuracy: 0.7106 - val_f1: 0.6472 - val_loss: 0.5529 - val_prc_auc: 0.6370 - val_precision: 0.5495 - val_recall: 0.7872\n","Epoch 15/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7540 - binary_accuracy: 0.6895 - f1: 0.7063 - loss: 0.5790 - prc_auc: 0.7101 - precision: 0.6671 - recall: 0.7506\n","Epoch 15: Validation Metrics:\n","loss: 0.5686137080192566\n","val_binary_accuracy: 0.7114197611808777\n","val_precision: 0.5500794649124146\n","val_recall: 0.7917619943618774\n","val_auc: 0.8014867901802063\n","val_prc_auc: 0.6391758322715759\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7542 - binary_accuracy: 0.6897 - f1: 0.7064 - loss: 0.5789 - prc_auc: 0.7104 - precision: 0.6673 - recall: 0.7506 - val_auc: 0.8015 - val_binary_accuracy: 0.7114 - val_f1: 0.6492 - val_loss: 0.5523 - val_prc_auc: 0.6392 - val_precision: 0.5501 - val_recall: 0.7918\n","Epoch 16/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7561 - binary_accuracy: 0.6912 - f1: 0.7079 - loss: 0.5774 - prc_auc: 0.7131 - precision: 0.6686 - recall: 0.7524\n","Epoch 16: Validation Metrics:\n","loss: 0.5671562552452087\n","val_binary_accuracy: 0.7129629850387573\n","val_precision: 0.5515055656433105\n","val_recall: 0.796338677406311\n","val_auc: 0.8024630546569824\n","val_prc_auc: 0.6431843042373657\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7564 - binary_accuracy: 0.6914 - f1: 0.7080 - loss: 0.5772 - prc_auc: 0.7134 - precision: 0.6688 - recall: 0.7524 - val_auc: 0.8025 - val_binary_accuracy: 0.7130 - val_f1: 0.6517 - val_loss: 0.5519 - val_prc_auc: 0.6432 - val_precision: 0.5515 - val_recall: 0.7963\n","Epoch 17/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7581 - binary_accuracy: 0.6911 - f1: 0.7083 - loss: 0.5758 - prc_auc: 0.7156 - precision: 0.6680 - recall: 0.7541\n","Epoch 17: Validation Metrics:\n","loss: 0.5657528638839722\n","val_binary_accuracy: 0.7106481194496155\n","val_precision: 0.5488958954811096\n","val_recall: 0.796338677406311\n","val_auc: 0.8032023310661316\n","val_prc_auc: 0.6455954313278198\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7583 - binary_accuracy: 0.6913 - f1: 0.7084 - loss: 0.5757 - prc_auc: 0.7160 - precision: 0.6682 - recall: 0.7541 - val_auc: 0.8032 - val_binary_accuracy: 0.7106 - val_f1: 0.6499 - val_loss: 0.5513 - val_prc_auc: 0.6456 - val_precision: 0.5489 - val_recall: 0.7963\n","Epoch 18/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7594 - binary_accuracy: 0.6911 - f1: 0.7083 - loss: 0.5743 - prc_auc: 0.7169 - precision: 0.6679 - recall: 0.7542\n","Epoch 18: Validation Metrics:\n","loss: 0.564396858215332\n","val_binary_accuracy: 0.7106481194496155\n","val_precision: 0.5488958954811096\n","val_recall: 0.796338677406311\n","val_auc: 0.8036711812019348\n","val_prc_auc: 0.6470666527748108\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7596 - binary_accuracy: 0.6913 - f1: 0.7085 - loss: 0.5741 - prc_auc: 0.7172 - precision: 0.6681 - recall: 0.7543 - val_auc: 0.8037 - val_binary_accuracy: 0.7106 - val_f1: 0.6499 - val_loss: 0.5508 - val_prc_auc: 0.6471 - val_precision: 0.5489 - val_recall: 0.7963\n","Epoch 19/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7614 - binary_accuracy: 0.6913 - f1: 0.7087 - loss: 0.5727 - prc_auc: 0.7197 - precision: 0.6679 - recall: 0.7549\n","Epoch 19: Validation Metrics:\n","loss: 0.5630514621734619\n","val_binary_accuracy: 0.7129629850387573\n","val_precision: 0.5508607029914856\n","val_recall: 0.8054919838905334\n","val_auc: 0.8041360378265381\n","val_prc_auc: 0.6476007103919983\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7617 - binary_accuracy: 0.6915 - f1: 0.7088 - loss: 0.5725 - prc_auc: 0.7200 - precision: 0.6682 - recall: 0.7549 - val_auc: 0.8041 - val_binary_accuracy: 0.7130 - val_f1: 0.6543 - val_loss: 0.5504 - val_prc_auc: 0.6476 - val_precision: 0.5509 - val_recall: 0.8055\n","Epoch 20/20\n","\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7629 - binary_accuracy: 0.6922 - f1: 0.7092 - loss: 0.5712 - prc_auc: 0.7213 - precision: 0.6691 - recall: 0.7547\n","Epoch 20: Validation Metrics:\n","loss: 0.5617663860321045\n","val_binary_accuracy: 0.7145061492919922\n","val_precision: 0.5524256825447083\n","val_recall: 0.8077803254127502\n","val_auc: 0.8048766255378723\n","val_prc_auc: 0.6499912142753601\n","\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7631 - binary_accuracy: 0.6924 - f1: 0.7094 - loss: 0.5711 - prc_auc: 0.7216 - precision: 0.6694 - recall: 0.7548 - val_auc: 0.8049 - val_binary_accuracy: 0.7145 - val_f1: 0.6561 - val_loss: 0.5501 - val_prc_auc: 0.6500 - val_precision: 0.5524 - val_recall: 0.8078\n","Starting training for label: 9\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_10_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - auc: 0.4788 - binary_accuracy: 0.4851 - f1: 0.4450 - loss: 0.6936 - prc_auc: 0.4896 - precision: 0.4676 - recall: 0.4352\n","Epoch 1: Validation Metrics:\n","loss: 0.6928573846817017\n","val_binary_accuracy: 0.3927469253540039\n","val_precision: 0.2154989391565323\n","val_recall: 0.8087649345397949\n","val_auc: 0.5650928020477295\n","val_prc_auc: 0.226918026804924\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 351ms/step - auc: 0.4793 - binary_accuracy: 0.4853 - f1: 0.4465 - loss: 0.6936 - prc_auc: 0.4902 - precision: 0.4681 - recall: 0.4375 - val_auc: 0.5651 - val_binary_accuracy: 0.3927 - val_f1: 0.3403 - val_loss: 0.6959 - val_prc_auc: 0.2269 - val_precision: 0.2155 - val_recall: 0.8088\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5636 - binary_accuracy: 0.5358 - f1: 0.5355 - loss: 0.6910 - prc_auc: 0.5558 - precision: 0.5308 - recall: 0.5569\n","Epoch 2: Validation Metrics:\n","loss: 0.6909339427947998\n","val_binary_accuracy: 0.4158950746059418\n","val_precision: 0.2170022428035736\n","val_recall: 0.7729083895683289\n","val_auc: 0.5630530714988708\n","val_prc_auc: 0.23349791765213013\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.5633 - binary_accuracy: 0.5356 - f1: 0.5358 - loss: 0.6910 - prc_auc: 0.5557 - precision: 0.5306 - recall: 0.5575 - val_auc: 0.5631 - val_binary_accuracy: 0.4159 - val_f1: 0.3389 - val_loss: 0.6934 - val_prc_auc: 0.2335 - val_precision: 0.2170 - val_recall: 0.7729\n","Epoch 3/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5762 - binary_accuracy: 0.5543 - f1: 0.5581 - loss: 0.6897 - prc_auc: 0.5549 - precision: 0.5482 - recall: 0.5826\n","Epoch 3: Validation Metrics:\n","loss: 0.6897836923599243\n","val_binary_accuracy: 0.4266975224018097\n","val_precision: 0.2178899049758911\n","val_recall: 0.7569721341133118\n","val_auc: 0.5703749656677246\n","val_prc_auc: 0.2321527749300003\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5756 - binary_accuracy: 0.5537 - f1: 0.5585 - loss: 0.6897 - prc_auc: 0.5547 - precision: 0.5477 - recall: 0.5835 - val_auc: 0.5704 - val_binary_accuracy: 0.4267 - val_f1: 0.3384 - val_loss: 0.6917 - val_prc_auc: 0.2322 - val_precision: 0.2179 - val_recall: 0.7570\n","Epoch 4/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5842 - binary_accuracy: 0.5589 - f1: 0.5637 - loss: 0.6887 - prc_auc: 0.5702 - precision: 0.5520 - recall: 0.5879\n","Epoch 4: Validation Metrics:\n","loss: 0.6887689232826233\n","val_binary_accuracy: 0.4413580298423767\n","val_precision: 0.2194543331861496\n","val_recall: 0.737051784992218\n","val_auc: 0.565224289894104\n","val_prc_auc: 0.2266724407672882\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5836 - binary_accuracy: 0.5582 - f1: 0.5640 - loss: 0.6887 - prc_auc: 0.5698 - precision: 0.5514 - recall: 0.5887 - val_auc: 0.5652 - val_binary_accuracy: 0.4414 - val_f1: 0.3382 - val_loss: 0.6899 - val_prc_auc: 0.2267 - val_precision: 0.2195 - val_recall: 0.7371\n","Epoch 5/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5888 - binary_accuracy: 0.5630 - f1: 0.5696 - loss: 0.6878 - prc_auc: 0.5708 - precision: 0.5559 - recall: 0.5944\n","Epoch 5: Validation Metrics:\n","loss: 0.6878774762153625\n","val_binary_accuracy: 0.4544753134250641\n","val_precision: 0.22262774407863617\n","val_recall: 0.7290836572647095\n","val_auc: 0.5651366114616394\n","val_prc_auc: 0.2312486320734024\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.5882 - binary_accuracy: 0.5624 - f1: 0.5698 - loss: 0.6878 - prc_auc: 0.5705 - precision: 0.5554 - recall: 0.5953 - val_auc: 0.5651 - val_binary_accuracy: 0.4545 - val_f1: 0.3411 - val_loss: 0.6888 - val_prc_auc: 0.2312 - val_precision: 0.2226 - val_recall: 0.7291\n","Epoch 6/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5926 - binary_accuracy: 0.5649 - f1: 0.5727 - loss: 0.6869 - prc_auc: 0.5713 - precision: 0.5574 - recall: 0.5983\n","Epoch 6: Validation Metrics:\n","loss: 0.6870182156562805\n","val_binary_accuracy: 0.46759259700775146\n","val_precision: 0.2225031554698944\n","val_recall: 0.701195240020752\n","val_auc: 0.5682723522186279\n","val_prc_auc: 0.22978419065475464\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5921 - binary_accuracy: 0.5644 - f1: 0.5730 - loss: 0.6869 - prc_auc: 0.5712 - precision: 0.5570 - recall: 0.5992 - val_auc: 0.5683 - val_binary_accuracy: 0.4676 - val_f1: 0.3378 - val_loss: 0.6871 - val_prc_auc: 0.2298 - val_precision: 0.2225 - val_recall: 0.7012\n","Epoch 7/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5968 - binary_accuracy: 0.5672 - f1: 0.5741 - loss: 0.6861 - prc_auc: 0.5750 - precision: 0.5609 - recall: 0.5960\n","Epoch 7: Validation Metrics:\n","loss: 0.6861713528633118\n","val_binary_accuracy: 0.46759259700775146\n","val_precision: 0.2196679413318634\n","val_recall: 0.6852589845657349\n","val_auc: 0.568687915802002\n","val_prc_auc: 0.23222757875919342\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.5963 - binary_accuracy: 0.5667 - f1: 0.5745 - loss: 0.6861 - prc_auc: 0.5748 - precision: 0.5604 - recall: 0.5971 - val_auc: 0.5687 - val_binary_accuracy: 0.4676 - val_f1: 0.3327 - val_loss: 0.6859 - val_prc_auc: 0.2322 - val_precision: 0.2197 - val_recall: 0.6853\n","Epoch 8/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6019 - binary_accuracy: 0.5720 - f1: 0.5801 - loss: 0.6853 - prc_auc: 0.5820 - precision: 0.5655 - recall: 0.6029\n","Epoch 8: Validation Metrics:\n","loss: 0.6853767037391663\n","val_binary_accuracy: 0.47762346267700195\n","val_precision: 0.22047244012355804\n","val_recall: 0.6693227291107178\n","val_auc: 0.5662841796875\n","val_prc_auc: 0.22549735009670258\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.6013 - binary_accuracy: 0.5716 - f1: 0.5804 - loss: 0.6853 - prc_auc: 0.5817 - precision: 0.5651 - recall: 0.6040 - val_auc: 0.5663 - val_binary_accuracy: 0.4776 - val_f1: 0.3317 - val_loss: 0.6847 - val_prc_auc: 0.2255 - val_precision: 0.2205 - val_recall: 0.6693\n","Epoch 9/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6049 - binary_accuracy: 0.5751 - f1: 0.5831 - loss: 0.6845 - prc_auc: 0.5810 - precision: 0.5686 - recall: 0.6053\n","Epoch 9: Validation Metrics:\n","loss: 0.6845561861991882\n","val_binary_accuracy: 0.485339492559433\n","val_precision: 0.21967655420303345\n","val_recall: 0.649402379989624\n","val_auc: 0.5645399689674377\n","val_prc_auc: 0.22754661738872528\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.6044 - binary_accuracy: 0.5747 - f1: 0.5835 - loss: 0.6845 - prc_auc: 0.5809 - precision: 0.5682 - recall: 0.6065 - val_auc: 0.5645 - val_binary_accuracy: 0.4853 - val_f1: 0.3283 - val_loss: 0.6830 - val_prc_auc: 0.2275 - val_precision: 0.2197 - val_recall: 0.6494\n","Epoch 10/20\n","\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6065 - binary_accuracy: 0.5784 - f1: 0.5831 - loss: 0.6837 - prc_auc: 0.5842 - precision: 0.5739 - recall: 0.5982\n","Epoch 10: Validation Metrics:\n","loss: 0.6837608218193054\n","val_binary_accuracy: 0.4961419701576233\n","val_precision: 0.22237569093704224\n","val_recall: 0.6414342522621155\n","val_auc: 0.5658628940582275\n","val_prc_auc: 0.23088045418262482\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.6060 - binary_accuracy: 0.5780 - f1: 0.5836 - loss: 0.6837 - prc_auc: 0.5841 - precision: 0.5734 - recall: 0.5997 - val_auc: 0.5659 - val_binary_accuracy: 0.4961 - val_f1: 0.3303 - val_loss: 0.6816 - val_prc_auc: 0.2309 - val_precision: 0.2224 - val_recall: 0.6414\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 247ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step\n","[[1 0 0 ... 0 0 0]\n"," [1 0 1 ... 1 0 0]\n"," [1 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 1 1]\n"," [0 0 1 ... 0 1 1]\n"," [0 0 0 ... 0 1 1]]\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - auc: 0.5965 - binary_accuracy: 0.5135 - f1: 0.3969 - loss: 0.6894 - prc_auc: 0.6207 - precision: 0.5194 - recall: 0.3417\n","Epoch 1: Validation Metrics:\n","loss: 0.6820594668388367\n","val_binary_accuracy: 0.7280831933021545\n","val_precision: 0.11922141164541245\n","val_recall: 0.9245283007621765\n","val_auc: 0.919223964214325\n","val_prc_auc: 0.39764344692230225\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - auc: 0.6018 - binary_accuracy: 0.5193 - f1: 0.4092 - loss: 0.6889 - prc_auc: 0.6273 - precision: 0.5255 - recall: 0.3558 - val_auc: 0.9192 - val_binary_accuracy: 0.7281 - val_f1: 0.2112 - val_loss: 0.6753 - val_prc_auc: 0.3976 - val_precision: 0.1192 - val_recall: 0.9245\n","Epoch 2/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8803 - binary_accuracy: 0.7831 - f1: 0.8028 - loss: 0.6515 - prc_auc: 0.8971 - precision: 0.7694 - recall: 0.8408\n","Epoch 2: Validation Metrics:\n","loss: 0.6494317054748535\n","val_binary_accuracy: 0.7176820039749146\n","val_precision: 0.11709602177143097\n","val_recall: 0.9433962106704712\n","val_auc: 0.9365816116333008\n","val_prc_auc: 0.474610298871994\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - auc: 0.8775 - binary_accuracy: 0.7798 - f1: 0.7991 - loss: 0.6512 - prc_auc: 0.8944 - precision: 0.7635 - recall: 0.8395 - val_auc: 0.9366 - val_binary_accuracy: 0.7177 - val_f1: 0.2083 - val_loss: 0.6619 - val_prc_auc: 0.4746 - val_precision: 0.1171 - val_recall: 0.9434\n","Epoch 3/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8959 - binary_accuracy: 0.8039 - f1: 0.8196 - loss: 0.6191 - prc_auc: 0.9153 - precision: 0.7952 - recall: 0.8469\n","Epoch 3: Validation Metrics:\n","loss: 0.6204224228858948\n","val_binary_accuracy: 0.7340267300605774\n","val_precision: 0.12345679104328156\n","val_recall: 0.9433962106704712\n","val_auc: 0.9422361850738525\n","val_prc_auc: 0.4812755286693573\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.8930 - binary_accuracy: 0.8000 - f1: 0.8153 - loss: 0.6193 - prc_auc: 0.9127 - precision: 0.7885 - recall: 0.8454 - val_auc: 0.9422 - val_binary_accuracy: 0.7340 - val_f1: 0.2183 - val_loss: 0.6396 - val_prc_auc: 0.4813 - val_precision: 0.1235 - val_recall: 0.9434\n","Epoch 4/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9002 - binary_accuracy: 0.8101 - f1: 0.8249 - loss: 0.5895 - prc_auc: 0.9189 - precision: 0.8018 - recall: 0.8511\n","Epoch 4: Validation Metrics:\n","loss: 0.5930774211883545\n","val_binary_accuracy: 0.751857340335846\n","val_precision: 0.1312336027622223\n","val_recall: 0.9433962106704712\n","val_auc: 0.9449794888496399\n","val_prc_auc: 0.48824119567871094\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - auc: 0.8977 - binary_accuracy: 0.8060 - f1: 0.8206 - loss: 0.5899 - prc_auc: 0.9167 - precision: 0.7947 - recall: 0.8497 - val_auc: 0.9450 - val_binary_accuracy: 0.7519 - val_f1: 0.2304 - val_loss: 0.6119 - val_prc_auc: 0.4882 - val_precision: 0.1312 - val_recall: 0.9434\n","Epoch 5/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9021 - binary_accuracy: 0.8130 - f1: 0.8271 - loss: 0.5615 - prc_auc: 0.9207 - precision: 0.8056 - recall: 0.8511\n","Epoch 5: Validation Metrics:\n","loss: 0.5668655633926392\n","val_binary_accuracy: 0.7778603434562683\n","val_precision: 0.14450867474079132\n","val_recall: 0.9433962106704712\n","val_auc: 0.9491456151008606\n","val_prc_auc: 0.493585467338562\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.8997 - binary_accuracy: 0.8100 - f1: 0.8236 - loss: 0.5622 - prc_auc: 0.9186 - precision: 0.8002 - recall: 0.8497 - val_auc: 0.9491 - val_binary_accuracy: 0.7779 - val_f1: 0.2506 - val_loss: 0.5826 - val_prc_auc: 0.4936 - val_precision: 0.1445 - val_recall: 0.9434\n","Epoch 6/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9048 - binary_accuracy: 0.8151 - f1: 0.8268 - loss: 0.5350 - prc_auc: 0.9226 - precision: 0.8141 - recall: 0.8408\n","Epoch 6: Validation Metrics:\n","loss: 0.541912853717804\n","val_binary_accuracy: 0.797919750213623\n","val_precision: 0.15673981606960297\n","val_recall: 0.9433962106704712\n","val_auc: 0.9507873058319092\n","val_prc_auc: 0.5059522390365601\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - auc: 0.9024 - binary_accuracy: 0.8119 - f1: 0.8229 - loss: 0.5359 - prc_auc: 0.9206 - precision: 0.8088 - recall: 0.8382 - val_auc: 0.9508 - val_binary_accuracy: 0.7979 - val_f1: 0.2688 - val_loss: 0.5543 - val_prc_auc: 0.5060 - val_precision: 0.1567 - val_recall: 0.9434\n","Epoch 7/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9061 - binary_accuracy: 0.8304 - f1: 0.8380 - loss: 0.5099 - prc_auc: 0.9237 - precision: 0.8399 - recall: 0.8370\n","Epoch 7: Validation Metrics:\n","loss: 0.5182763338088989\n","val_binary_accuracy: 0.8194651007652283\n","val_precision: 0.17241379618644714\n","val_recall: 0.9433962106704712\n","val_auc: 0.9521224498748779\n","val_prc_auc: 0.5072917342185974\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9039 - binary_accuracy: 0.8267 - f1: 0.8336 - loss: 0.5110 - prc_auc: 0.9217 - precision: 0.8342 - recall: 0.8337 - val_auc: 0.9521 - val_binary_accuracy: 0.8195 - val_f1: 0.2915 - val_loss: 0.5276 - val_prc_auc: 0.5073 - val_precision: 0.1724 - val_recall: 0.9434\n","Epoch 8/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9077 - binary_accuracy: 0.8331 - f1: 0.8394 - loss: 0.4868 - prc_auc: 0.9249 - precision: 0.8476 - recall: 0.8319\n","Epoch 8: Validation Metrics:\n","loss: 0.4965907633304596\n","val_binary_accuracy: 0.8335809707641602\n","val_precision: 0.18215613067150116\n","val_recall: 0.9245283007621765\n","val_auc: 0.9535014629364014\n","val_prc_auc: 0.5168834328651428\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - auc: 0.9056 - binary_accuracy: 0.8306 - f1: 0.8359 - loss: 0.4881 - prc_auc: 0.9229 - precision: 0.8438 - recall: 0.8287 - val_auc: 0.9535 - val_binary_accuracy: 0.8336 - val_f1: 0.3043 - val_loss: 0.5019 - val_prc_auc: 0.5169 - val_precision: 0.1822 - val_recall: 0.9245\n","Epoch 9/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9088 - binary_accuracy: 0.8353 - f1: 0.8408 - loss: 0.4663 - prc_auc: 0.9256 - precision: 0.8526 - recall: 0.8297\n","Epoch 9: Validation Metrics:\n","loss: 0.4772562086582184\n","val_binary_accuracy: 0.8506686687469482\n","val_precision: 0.1991869956254959\n","val_recall: 0.9245283007621765\n","val_auc: 0.9542967081069946\n","val_prc_auc: 0.5146875977516174\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - auc: 0.9068 - binary_accuracy: 0.8331 - f1: 0.8375 - loss: 0.4678 - prc_auc: 0.9237 - precision: 0.8496 - recall: 0.8262 - val_auc: 0.9543 - val_binary_accuracy: 0.8507 - val_f1: 0.3278 - val_loss: 0.4777 - val_prc_auc: 0.5147 - val_precision: 0.1992 - val_recall: 0.9245\n","Epoch 10/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9106 - binary_accuracy: 0.8359 - f1: 0.8376 - loss: 0.4488 - prc_auc: 0.9268 - precision: 0.8727 - recall: 0.8057\n","Epoch 10: Validation Metrics:\n","loss: 0.4604072868824005\n","val_binary_accuracy: 0.8595839738845825\n","val_precision: 0.2094017118215561\n","val_recall: 0.9245283007621765\n","val_auc: 0.9551723003387451\n","val_prc_auc: 0.5168589949607849\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9086 - binary_accuracy: 0.8346 - f1: 0.8353 - loss: 0.4503 - prc_auc: 0.9249 - precision: 0.8696 - recall: 0.8041 - val_auc: 0.9552 - val_binary_accuracy: 0.8596 - val_f1: 0.3415 - val_loss: 0.4568 - val_prc_auc: 0.5169 - val_precision: 0.2094 - val_recall: 0.9245\n","Epoch 11/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9121 - binary_accuracy: 0.8411 - f1: 0.8419 - loss: 0.4337 - prc_auc: 0.9277 - precision: 0.8825 - recall: 0.8057\n","Epoch 11: Validation Metrics:\n","loss: 0.4458581209182739\n","val_binary_accuracy: 0.8670133948326111\n","val_precision: 0.21875\n","val_recall: 0.9245283007621765\n","val_auc: 0.9567336440086365\n","val_prc_auc: 0.5243366956710815\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9101 - binary_accuracy: 0.8395 - f1: 0.8393 - loss: 0.4353 - prc_auc: 0.9258 - precision: 0.8786 - recall: 0.8041 - val_auc: 0.9567 - val_binary_accuracy: 0.8670 - val_f1: 0.3538 - val_loss: 0.4387 - val_prc_auc: 0.5243 - val_precision: 0.2188 - val_recall: 0.9245\n","Epoch 12/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9133 - binary_accuracy: 0.8355 - f1: 0.8354 - loss: 0.4210 - prc_auc: 0.9289 - precision: 0.8809 - recall: 0.7950\n","Epoch 12: Validation Metrics:\n","loss: 0.43338853120803833\n","val_binary_accuracy: 0.8759286999702454\n","val_precision: 0.23113207519054413\n","val_recall: 0.9245283007621765\n","val_auc: 0.9575872421264648\n","val_prc_auc: 0.5194710493087769\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - auc: 0.9115 - binary_accuracy: 0.8337 - f1: 0.8325 - loss: 0.4227 - prc_auc: 0.9270 - precision: 0.8770 - recall: 0.7929 - val_auc: 0.9576 - val_binary_accuracy: 0.8759 - val_f1: 0.3698 - val_loss: 0.4235 - val_prc_auc: 0.5195 - val_precision: 0.2311 - val_recall: 0.9245\n","Epoch 13/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9150 - binary_accuracy: 0.8337 - f1: 0.8326 - loss: 0.4103 - prc_auc: 0.9301 - precision: 0.8841 - recall: 0.7874\n","Epoch 13: Validation Metrics:\n","loss: 0.42274633049964905\n","val_binary_accuracy: 0.8789004683494568\n","val_precision: 0.23557692766189575\n","val_recall: 0.9245283007621765\n","val_auc: 0.9585212469100952\n","val_prc_auc: 0.5248628854751587\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9132 - binary_accuracy: 0.8324 - f1: 0.8302 - loss: 0.4119 - prc_auc: 0.9282 - precision: 0.8808 - recall: 0.7857 - val_auc: 0.9585 - val_binary_accuracy: 0.8789 - val_f1: 0.3755 - val_loss: 0.4110 - val_prc_auc: 0.5249 - val_precision: 0.2356 - val_recall: 0.9245\n","Epoch 14/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9160 - binary_accuracy: 0.8337 - f1: 0.8326 - loss: 0.4013 - prc_auc: 0.9307 - precision: 0.8841 - recall: 0.7874\n","Epoch 14: Validation Metrics:\n","loss: 0.41373804211616516\n","val_binary_accuracy: 0.8818722367286682\n","val_precision: 0.2401960790157318\n","val_recall: 0.9245283007621765\n","val_auc: 0.959674060344696\n","val_prc_auc: 0.5330049991607666\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9143 - binary_accuracy: 0.8324 - f1: 0.8302 - loss: 0.4030 - prc_auc: 0.9289 - precision: 0.8808 - recall: 0.7857 - val_auc: 0.9597 - val_binary_accuracy: 0.8819 - val_f1: 0.3813 - val_loss: 0.4006 - val_prc_auc: 0.5330 - val_precision: 0.2402 - val_recall: 0.9245\n","Epoch 15/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9179 - binary_accuracy: 0.8389 - f1: 0.8373 - loss: 0.3937 - prc_auc: 0.9321 - precision: 0.8921 - recall: 0.7896\n","Epoch 15: Validation Metrics:\n","loss: 0.406083345413208\n","val_binary_accuracy: 0.8848440051078796\n","val_precision: 0.24500000476837158\n","val_recall: 0.9245283007621765\n","val_auc: 0.9599512219429016\n","val_prc_auc: 0.53055739402771\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 287ms/step - auc: 0.9162 - binary_accuracy: 0.8375 - f1: 0.8349 - loss: 0.3954 - prc_auc: 0.9302 - precision: 0.8884 - recall: 0.7883 - val_auc: 0.9600 - val_binary_accuracy: 0.8848 - val_f1: 0.3874 - val_loss: 0.3914 - val_prc_auc: 0.5306 - val_precision: 0.2450 - val_recall: 0.9245\n","Epoch 16/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9192 - binary_accuracy: 0.8367 - f1: 0.8347 - loss: 0.3874 - prc_auc: 0.9334 - precision: 0.8915 - recall: 0.7854\n","Epoch 16: Validation Metrics:\n","loss: 0.39958760142326355\n","val_binary_accuracy: 0.8848440051078796\n","val_precision: 0.24500000476837158\n","val_recall: 0.9245283007621765\n","val_auc: 0.9607976675033569\n","val_prc_auc: 0.5304595232009888\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9175 - binary_accuracy: 0.8353 - f1: 0.8323 - loss: 0.3890 - prc_auc: 0.9315 - precision: 0.8878 - recall: 0.7840 - val_auc: 0.9608 - val_binary_accuracy: 0.8848 - val_f1: 0.3874 - val_loss: 0.3836 - val_prc_auc: 0.5305 - val_precision: 0.2450 - val_recall: 0.9245\n","Epoch 17/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9202 - binary_accuracy: 0.8385 - f1: 0.8362 - loss: 0.3820 - prc_auc: 0.9340 - precision: 0.8949 - recall: 0.7854\n","Epoch 17: Validation Metrics:\n","loss: 0.39400386810302734\n","val_binary_accuracy: 0.8848440051078796\n","val_precision: 0.24500000476837158\n","val_recall: 0.9245283007621765\n","val_auc: 0.9614980220794678\n","val_prc_auc: 0.5341108441352844\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 284ms/step - auc: 0.9185 - binary_accuracy: 0.8372 - f1: 0.8339 - loss: 0.3836 - prc_auc: 0.9321 - precision: 0.8913 - recall: 0.7840 - val_auc: 0.9615 - val_binary_accuracy: 0.8848 - val_f1: 0.3874 - val_loss: 0.3770 - val_prc_auc: 0.5341 - val_precision: 0.2450 - val_recall: 0.9245\n","Epoch 18/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9212 - binary_accuracy: 0.8411 - f1: 0.8393 - loss: 0.3774 - prc_auc: 0.9347 - precision: 0.8955 - recall: 0.7905\n","Epoch 18: Validation Metrics:\n","loss: 0.3892165422439575\n","val_binary_accuracy: 0.8878157734870911\n","val_precision: 0.25\n","val_recall: 0.9245283007621765\n","val_auc: 0.962628960609436\n","val_prc_auc: 0.5469177961349487\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - auc: 0.9196 - binary_accuracy: 0.8398 - f1: 0.8370 - loss: 0.3789 - prc_auc: 0.9329 - precision: 0.8920 - recall: 0.7890 - val_auc: 0.9626 - val_binary_accuracy: 0.8878 - val_f1: 0.3936 - val_loss: 0.3716 - val_prc_auc: 0.5469 - val_precision: 0.2500 - val_recall: 0.9245\n","Epoch 19/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9220 - binary_accuracy: 0.8476 - f1: 0.8465 - loss: 0.3734 - prc_auc: 0.9353 - precision: 0.8994 - recall: 0.8000\n","Epoch 19: Validation Metrics:\n","loss: 0.3850525915622711\n","val_binary_accuracy: 0.8878157734870911\n","val_precision: 0.25\n","val_recall: 0.9245283007621765\n","val_auc: 0.9631980657577515\n","val_prc_auc: 0.5482556223869324\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9205 - binary_accuracy: 0.8466 - f1: 0.8446 - loss: 0.3749 - prc_auc: 0.9335 - precision: 0.8962 - recall: 0.7992 - val_auc: 0.9632 - val_binary_accuracy: 0.8878 - val_f1: 0.3936 - val_loss: 0.3667 - val_prc_auc: 0.5483 - val_precision: 0.2500 - val_recall: 0.9245\n","Epoch 20/20\n","\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9229 - binary_accuracy: 0.8516 - f1: 0.8499 - loss: 0.3699 - prc_auc: 0.9360 - precision: 0.9072 - recall: 0.8000\n","Epoch 20: Validation Metrics:\n","loss: 0.3814215064048767\n","val_binary_accuracy: 0.8893016576766968\n","val_precision: 0.2525773048400879\n","val_recall: 0.9245283007621765\n","val_auc: 0.9637014865875244\n","val_prc_auc: 0.5430596470832825\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 285ms/step - auc: 0.9214 - binary_accuracy: 0.8504 - f1: 0.8478 - loss: 0.3715 - prc_auc: 0.9343 - precision: 0.9036 - recall: 0.7992 - val_auc: 0.9637 - val_binary_accuracy: 0.8893 - val_f1: 0.3968 - val_loss: 0.3626 - val_prc_auc: 0.5431 - val_precision: 0.2526 - val_recall: 0.9245\n","Starting training for label: 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - auc: 0.5788 - binary_accuracy: 0.5600 - f1: 0.5954 - loss: 0.6849 - prc_auc: 0.6047 - precision: 0.5666 - recall: 0.6364\n","Epoch 1: Validation Metrics:\n","loss: 0.6785044074058533\n","val_binary_accuracy: 0.6775631308555603\n","val_precision: 0.3512747883796692\n","val_recall: 0.37689968943595886\n","val_auc: 0.6173142194747925\n","val_prc_auc: 0.3666421175003052\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 473ms/step - auc: 0.5792 - binary_accuracy: 0.5602 - f1: 0.5949 - loss: 0.6848 - prc_auc: 0.6048 - precision: 0.5668 - recall: 0.6352 - val_auc: 0.6173 - val_binary_accuracy: 0.6776 - val_f1: 0.3636 - val_loss: 0.6573 - val_prc_auc: 0.3666 - val_precision: 0.3513 - val_recall: 0.3769\n","Epoch 2/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6139 - binary_accuracy: 0.5800 - f1: 0.5099 - loss: 0.6704 - prc_auc: 0.6583 - precision: 0.6364 - recall: 0.4261\n","Epoch 2: Validation Metrics:\n","loss: 0.6650809645652771\n","val_binary_accuracy: 0.6716195940971375\n","val_precision: 0.34770888090133667\n","val_recall: 0.39209726452827454\n","val_auc: 0.6237757205963135\n","val_prc_auc: 0.36638277769088745\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6143 - binary_accuracy: 0.5804 - f1: 0.5100 - loss: 0.6703 - prc_auc: 0.6582 - precision: 0.6365 - recall: 0.4262 - val_auc: 0.6238 - val_binary_accuracy: 0.6716 - val_f1: 0.3686 - val_loss: 0.6561 - val_prc_auc: 0.3664 - val_precision: 0.3477 - val_recall: 0.3921\n","Epoch 3/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6227 - binary_accuracy: 0.5836 - f1: 0.5270 - loss: 0.6647 - prc_auc: 0.6618 - precision: 0.6326 - recall: 0.4524\n","Epoch 3: Validation Metrics:\n","loss: 0.6590015292167664\n","val_binary_accuracy: 0.6656760573387146\n","val_precision: 0.3460559844970703\n","val_recall: 0.4133738577365875\n","val_auc: 0.6283065676689148\n","val_prc_auc: 0.3712514638900757\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6231 - binary_accuracy: 0.5840 - f1: 0.5270 - loss: 0.6645 - prc_auc: 0.6618 - precision: 0.6328 - recall: 0.4524 - val_auc: 0.6283 - val_binary_accuracy: 0.6657 - val_f1: 0.3767 - val_loss: 0.6549 - val_prc_auc: 0.3713 - val_precision: 0.3461 - val_recall: 0.4134\n","Epoch 4/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6325 - binary_accuracy: 0.5878 - f1: 0.5367 - loss: 0.6600 - prc_auc: 0.6717 - precision: 0.6347 - recall: 0.4657\n","Epoch 4: Validation Metrics:\n","loss: 0.654442548751831\n","val_binary_accuracy: 0.6627042889595032\n","val_precision: 0.34491315484046936\n","val_recall: 0.4224924147129059\n","val_auc: 0.6332216262817383\n","val_prc_auc: 0.37660303711891174\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6329 - binary_accuracy: 0.5882 - f1: 0.5367 - loss: 0.6599 - prc_auc: 0.6717 - precision: 0.6349 - recall: 0.4655 - val_auc: 0.6332 - val_binary_accuracy: 0.6627 - val_f1: 0.3798 - val_loss: 0.6544 - val_prc_auc: 0.3766 - val_precision: 0.3449 - val_recall: 0.4225\n","Epoch 5/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6420 - binary_accuracy: 0.5878 - f1: 0.5415 - loss: 0.6556 - prc_auc: 0.6808 - precision: 0.6318 - recall: 0.4744\n","Epoch 5: Validation Metrics:\n","loss: 0.6504232287406921\n","val_binary_accuracy: 0.6671619415283203\n","val_precision: 0.35380834341049194\n","val_recall: 0.43768996000289917\n","val_auc: 0.6364299058914185\n","val_prc_auc: 0.37870997190475464\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6423 - binary_accuracy: 0.5882 - f1: 0.5415 - loss: 0.6555 - prc_auc: 0.6806 - precision: 0.6322 - recall: 0.4742 - val_auc: 0.6364 - val_binary_accuracy: 0.6672 - val_f1: 0.3913 - val_loss: 0.6541 - val_prc_auc: 0.3787 - val_precision: 0.3538 - val_recall: 0.4377\n","Epoch 6/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6501 - binary_accuracy: 0.5874 - f1: 0.5404 - loss: 0.6513 - prc_auc: 0.6871 - precision: 0.6322 - recall: 0.4725\n","Epoch 6: Validation Metrics:\n","loss: 0.6466339230537415\n","val_binary_accuracy: 0.6656760573387146\n","val_precision: 0.34987592697143555\n","val_recall: 0.4285714328289032\n","val_auc: 0.64042729139328\n","val_prc_auc: 0.3829156756401062\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6504 - binary_accuracy: 0.5878 - f1: 0.5403 - loss: 0.6511 - prc_auc: 0.6870 - precision: 0.6326 - recall: 0.4722 - val_auc: 0.6404 - val_binary_accuracy: 0.6657 - val_f1: 0.3852 - val_loss: 0.6551 - val_prc_auc: 0.3829 - val_precision: 0.3499 - val_recall: 0.4286\n","Epoch 7/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6590 - binary_accuracy: 0.5980 - f1: 0.5563 - loss: 0.6471 - prc_auc: 0.6945 - precision: 0.6424 - recall: 0.4917\n","Epoch 7: Validation Metrics:\n","loss: 0.6431624889373779\n","val_binary_accuracy: 0.6723625659942627\n","val_precision: 0.35641026496887207\n","val_recall: 0.4224924147129059\n","val_auc: 0.6447534561157227\n","val_prc_auc: 0.38692396879196167\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6593 - binary_accuracy: 0.5984 - f1: 0.5561 - loss: 0.6470 - prc_auc: 0.6943 - precision: 0.6428 - recall: 0.4911 - val_auc: 0.6448 - val_binary_accuracy: 0.6724 - val_f1: 0.3866 - val_loss: 0.6554 - val_prc_auc: 0.3869 - val_precision: 0.3564 - val_recall: 0.4225\n","Epoch 8/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6692 - binary_accuracy: 0.6016 - f1: 0.5668 - loss: 0.6433 - prc_auc: 0.7024 - precision: 0.6422 - recall: 0.5090\n","Epoch 8: Validation Metrics:\n","loss: 0.6399419903755188\n","val_binary_accuracy: 0.679049015045166\n","val_precision: 0.3641161024570465\n","val_recall: 0.41945287585258484\n","val_auc: 0.6471280455589294\n","val_prc_auc: 0.3889077305793762\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6694 - binary_accuracy: 0.6020 - f1: 0.5664 - loss: 0.6432 - prc_auc: 0.7022 - precision: 0.6427 - recall: 0.5081 - val_auc: 0.6471 - val_binary_accuracy: 0.6790 - val_f1: 0.3898 - val_loss: 0.6561 - val_prc_auc: 0.3889 - val_precision: 0.3641 - val_recall: 0.4195\n","Epoch 9/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6791 - binary_accuracy: 0.6226 - f1: 0.5900 - loss: 0.6398 - prc_auc: 0.7100 - precision: 0.6672 - recall: 0.5311\n","Epoch 9: Validation Metrics:\n","loss: 0.6369996666908264\n","val_binary_accuracy: 0.6775631308555603\n","val_precision: 0.3629242777824402\n","val_recall: 0.4224924147129059\n","val_auc: 0.6496175527572632\n","val_prc_auc: 0.3903351426124573\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6793 - binary_accuracy: 0.6227 - f1: 0.5894 - loss: 0.6397 - prc_auc: 0.7098 - precision: 0.6675 - recall: 0.5299 - val_auc: 0.6496 - val_binary_accuracy: 0.6776 - val_f1: 0.3904 - val_loss: 0.6569 - val_prc_auc: 0.3903 - val_precision: 0.3629 - val_recall: 0.4225\n","Epoch 10/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6889 - binary_accuracy: 0.6310 - f1: 0.6012 - loss: 0.6366 - prc_auc: 0.7173 - precision: 0.6748 - recall: 0.5447\n","Epoch 10: Validation Metrics:\n","loss: 0.6343256831169128\n","val_binary_accuracy: 0.6820207834243774\n","val_precision: 0.3720930218696594\n","val_recall: 0.43768996000289917\n","val_auc: 0.6514347791671753\n","val_prc_auc: 0.39241504669189453\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6890 - binary_accuracy: 0.6310 - f1: 0.6004 - loss: 0.6365 - prc_auc: 0.7169 - precision: 0.6750 - recall: 0.5434 - val_auc: 0.6514 - val_binary_accuracy: 0.6820 - val_f1: 0.4022 - val_loss: 0.6571 - val_prc_auc: 0.3924 - val_precision: 0.3721 - val_recall: 0.4377\n","Epoch 11/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6952 - binary_accuracy: 0.6396 - f1: 0.6102 - loss: 0.6337 - prc_auc: 0.7221 - precision: 0.6846 - recall: 0.5532\n","Epoch 11: Validation Metrics:\n","loss: 0.6318213939666748\n","val_binary_accuracy: 0.6738484501838684\n","val_precision: 0.3638613820075989\n","val_recall: 0.44680851697921753\n","val_auc: 0.6518650650978088\n","val_prc_auc: 0.3932502269744873\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.6953 - binary_accuracy: 0.6395 - f1: 0.6093 - loss: 0.6336 - prc_auc: 0.7218 - precision: 0.6848 - recall: 0.5517 - val_auc: 0.6519 - val_binary_accuracy: 0.6738 - val_f1: 0.4011 - val_loss: 0.6576 - val_prc_auc: 0.3933 - val_precision: 0.3639 - val_recall: 0.4468\n","Epoch 12/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7019 - binary_accuracy: 0.6467 - f1: 0.6214 - loss: 0.6309 - prc_auc: 0.7270 - precision: 0.6891 - recall: 0.5689\n","Epoch 12: Validation Metrics:\n","loss: 0.629511833190918\n","val_binary_accuracy: 0.6693907976150513\n","val_precision: 0.3619047701358795\n","val_recall: 0.4620060920715332\n","val_auc: 0.6526466012001038\n","val_prc_auc: 0.3949149549007416\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7019 - binary_accuracy: 0.6466 - f1: 0.6205 - loss: 0.6309 - prc_auc: 0.7266 - precision: 0.6893 - recall: 0.5673 - val_auc: 0.6526 - val_binary_accuracy: 0.6694 - val_f1: 0.4059 - val_loss: 0.6580 - val_prc_auc: 0.3949 - val_precision: 0.3619 - val_recall: 0.4620\n","Epoch 13/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7062 - binary_accuracy: 0.6511 - f1: 0.6277 - loss: 0.6284 - prc_auc: 0.7303 - precision: 0.6924 - recall: 0.5773\n","Epoch 13: Validation Metrics:\n","loss: 0.6273261904716492\n","val_binary_accuracy: 0.6619613766670227\n","val_precision: 0.3581081032752991\n","val_recall: 0.4832826852798462\n","val_auc: 0.6535477042198181\n","val_prc_auc: 0.3957226574420929\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7062 - binary_accuracy: 0.6510 - f1: 0.6268 - loss: 0.6284 - prc_auc: 0.7299 - precision: 0.6926 - recall: 0.5757 - val_auc: 0.6535 - val_binary_accuracy: 0.6620 - val_f1: 0.4114 - val_loss: 0.6581 - val_prc_auc: 0.3957 - val_precision: 0.3581 - val_recall: 0.4833\n","Epoch 14/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7101 - binary_accuracy: 0.6543 - f1: 0.6344 - loss: 0.6260 - prc_auc: 0.7333 - precision: 0.6919 - recall: 0.5890\n","Epoch 14: Validation Metrics:\n","loss: 0.6252939105033875\n","val_binary_accuracy: 0.6597325205802917\n","val_precision: 0.3576158881187439\n","val_recall: 0.49240121245384216\n","val_auc: 0.6547566652297974\n","val_prc_auc: 0.397199422121048\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - auc: 0.7100 - binary_accuracy: 0.6541 - f1: 0.6334 - loss: 0.6260 - prc_auc: 0.7329 - precision: 0.6921 - recall: 0.5874 - val_auc: 0.6548 - val_binary_accuracy: 0.6597 - val_f1: 0.4143 - val_loss: 0.6586 - val_prc_auc: 0.3972 - val_precision: 0.3576 - val_recall: 0.4924\n","Epoch 15/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7129 - binary_accuracy: 0.6569 - f1: 0.6400 - loss: 0.6238 - prc_auc: 0.7357 - precision: 0.6918 - recall: 0.5985\n","Epoch 15: Validation Metrics:\n","loss: 0.6233430504798889\n","val_binary_accuracy: 0.6567607522010803\n","val_precision: 0.3569892346858978\n","val_recall: 0.5045592784881592\n","val_auc: 0.6550570726394653\n","val_prc_auc: 0.3983863294124603\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7128 - binary_accuracy: 0.6568 - f1: 0.6392 - loss: 0.6237 - prc_auc: 0.7353 - precision: 0.6921 - recall: 0.5970 - val_auc: 0.6551 - val_binary_accuracy: 0.6568 - val_f1: 0.4181 - val_loss: 0.6592 - val_prc_auc: 0.3984 - val_precision: 0.3570 - val_recall: 0.5046\n","Epoch 16/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7154 - binary_accuracy: 0.6587 - f1: 0.6437 - loss: 0.6216 - prc_auc: 0.7381 - precision: 0.6919 - recall: 0.6049\n","Epoch 16: Validation Metrics:\n","loss: 0.6214698553085327\n","val_binary_accuracy: 0.6448736786842346\n","val_precision: 0.3457556962966919\n","val_recall: 0.5075987577438354\n","val_auc: 0.6555382013320923\n","val_prc_auc: 0.4008350074291229\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7154 - binary_accuracy: 0.6586 - f1: 0.6430 - loss: 0.6216 - prc_auc: 0.7377 - precision: 0.6922 - recall: 0.6034 - val_auc: 0.6555 - val_binary_accuracy: 0.6449 - val_f1: 0.4113 - val_loss: 0.6597 - val_prc_auc: 0.4008 - val_precision: 0.3458 - val_recall: 0.5076\n","Epoch 17/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7181 - binary_accuracy: 0.6614 - f1: 0.6480 - loss: 0.6196 - prc_auc: 0.7400 - precision: 0.6936 - recall: 0.6110\n","Epoch 17: Validation Metrics:\n","loss: 0.6196784377098083\n","val_binary_accuracy: 0.6352154612541199\n","val_precision: 0.33864542841911316\n","val_recall: 0.5167173147201538\n","val_auc: 0.656546950340271\n","val_prc_auc: 0.40122082829475403\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7181 - binary_accuracy: 0.6614 - f1: 0.6473 - loss: 0.6196 - prc_auc: 0.7396 - precision: 0.6939 - recall: 0.6095 - val_auc: 0.6565 - val_binary_accuracy: 0.6352 - val_f1: 0.4091 - val_loss: 0.6602 - val_prc_auc: 0.4012 - val_precision: 0.3386 - val_recall: 0.5167\n","Epoch 18/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7199 - binary_accuracy: 0.6633 - f1: 0.6521 - loss: 0.6176 - prc_auc: 0.7420 - precision: 0.6931 - recall: 0.6185\n","Epoch 18: Validation Metrics:\n","loss: 0.6179661750793457\n","val_binary_accuracy: 0.629271924495697\n","val_precision: 0.3346303403377533\n","val_recall: 0.5227963328361511\n","val_auc: 0.6570236086845398\n","val_prc_auc: 0.4023764133453369\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7199 - binary_accuracy: 0.6633 - f1: 0.6514 - loss: 0.6176 - prc_auc: 0.7416 - precision: 0.6934 - recall: 0.6170 - val_auc: 0.6570 - val_binary_accuracy: 0.6293 - val_f1: 0.4081 - val_loss: 0.6604 - val_prc_auc: 0.4024 - val_precision: 0.3346 - val_recall: 0.5228\n","Epoch 19/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7223 - binary_accuracy: 0.6672 - f1: 0.6572 - loss: 0.6157 - prc_auc: 0.7439 - precision: 0.6961 - recall: 0.6250\n","Epoch 19: Validation Metrics:\n","loss: 0.6163155436515808\n","val_binary_accuracy: 0.6337295770645142\n","val_precision: 0.344696968793869\n","val_recall: 0.5531914830207825\n","val_auc: 0.6573822498321533\n","val_prc_auc: 0.4035332202911377\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7223 - binary_accuracy: 0.6672 - f1: 0.6565 - loss: 0.6158 - prc_auc: 0.7435 - precision: 0.6963 - recall: 0.6236 - val_auc: 0.6574 - val_binary_accuracy: 0.6337 - val_f1: 0.4247 - val_loss: 0.6607 - val_prc_auc: 0.4035 - val_precision: 0.3447 - val_recall: 0.5532\n","Epoch 20/20\n","\u001b[1m82/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7243 - binary_accuracy: 0.6697 - f1: 0.6609 - loss: 0.6140 - prc_auc: 0.7457 - precision: 0.6971 - recall: 0.6307\n","Epoch 20: Validation Metrics:\n","loss: 0.6147085428237915\n","val_binary_accuracy: 0.6315007209777832\n","val_precision: 0.34333959221839905\n","val_recall: 0.5562310218811035\n","val_auc: 0.6575451493263245\n","val_prc_auc: 0.4045250415802002\n","\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - auc: 0.7243 - binary_accuracy: 0.6696 - f1: 0.6601 - loss: 0.6140 - prc_auc: 0.7453 - precision: 0.6972 - recall: 0.6292 - val_auc: 0.6575 - val_binary_accuracy: 0.6315 - val_f1: 0.4246 - val_loss: 0.6610 - val_prc_auc: 0.4045 - val_precision: 0.3433 - val_recall: 0.5562\n","Starting training for label: 2\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - auc: 0.6736 - binary_accuracy: 0.6315 - f1: 0.7006 - loss: 0.6640 - prc_auc: 0.7142 - precision: 0.6186 - recall: 0.8295\n","Epoch 1: Validation Metrics:\n","loss: 0.6297795176506042\n","val_binary_accuracy: 0.8514115810394287\n","val_precision: 0.4066985547542572\n","val_recall: 0.5279502868652344\n","val_auc: 0.7665566205978394\n","val_prc_auc: 0.35733723640441895\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 890ms/step - auc: 0.6760 - binary_accuracy: 0.6334 - f1: 0.7009 - loss: 0.6632 - prc_auc: 0.7162 - precision: 0.6206 - recall: 0.8269 - val_auc: 0.7666 - val_binary_accuracy: 0.8514 - val_f1: 0.4595 - val_loss: 0.5640 - val_prc_auc: 0.3573 - val_precision: 0.4067 - val_recall: 0.5280\n","Epoch 2/20\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7899 - binary_accuracy: 0.7482 - f1: 0.7179 - loss: 0.5640 - prc_auc: 0.8132 - precision: 0.8539 - recall: 0.6194\n","Epoch 2: Validation Metrics:\n","loss: 0.5455266237258911\n","val_binary_accuracy: 0.8447251319885254\n","val_precision: 0.3909091055393219\n","val_recall: 0.5341615080833435\n","val_auc: 0.7840160727500916\n","val_prc_auc: 0.3783589005470276\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - auc: 0.7904 - binary_accuracy: 0.7487 - f1: 0.7180 - loss: 0.5632 - prc_auc: 0.8137 - precision: 0.8541 - recall: 0.6196 - val_auc: 0.7840 - val_binary_accuracy: 0.8447 - val_f1: 0.4514 - val_loss: 0.5179 - val_prc_auc: 0.3784 - val_precision: 0.3909 - val_recall: 0.5342\n","Epoch 3/20\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7972 - binary_accuracy: 0.7529 - f1: 0.7250 - loss: 0.5345 - prc_auc: 0.8255 - precision: 0.8541 - recall: 0.6300\n","Epoch 3: Validation Metrics:\n","loss: 0.5219413638114929\n","val_binary_accuracy: 0.8424962759017944\n","val_precision: 0.3856502175331116\n","val_recall: 0.5341615080833435\n","val_auc: 0.7918022274971008\n","val_prc_auc: 0.40884101390838623\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - auc: 0.7979 - binary_accuracy: 0.7533 - f1: 0.7250 - loss: 0.5339 - prc_auc: 0.8260 - precision: 0.8541 - recall: 0.6300 - val_auc: 0.7918 - val_binary_accuracy: 0.8425 - val_f1: 0.4479 - val_loss: 0.5140 - val_prc_auc: 0.4088 - val_precision: 0.3857 - val_recall: 0.5342\n","Epoch 4/20\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8028 - binary_accuracy: 0.7533 - f1: 0.7263 - loss: 0.5287 - prc_auc: 0.8347 - precision: 0.8521 - recall: 0.6330\n","Epoch 4: Validation Metrics:\n","loss: 0.5165306329727173\n","val_binary_accuracy: 0.841753363609314\n","val_precision: 0.3849557638168335\n","val_recall: 0.5403726696968079\n","val_auc: 0.7981366515159607\n","val_prc_auc: 0.44064825773239136\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - auc: 0.8035 - binary_accuracy: 0.7537 - f1: 0.7263 - loss: 0.5282 - prc_auc: 0.8350 - precision: 0.8522 - recall: 0.6330 - val_auc: 0.7981 - val_binary_accuracy: 0.8418 - val_f1: 0.4496 - val_loss: 0.5122 - val_prc_auc: 0.4406 - val_precision: 0.3850 - val_recall: 0.5404\n","Epoch 5/20\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8086 - binary_accuracy: 0.7536 - f1: 0.7268 - loss: 0.5258 - prc_auc: 0.8419 - precision: 0.8523 - recall: 0.6337\n","Epoch 5: Validation Metrics:\n","loss: 0.51344895362854\n","val_binary_accuracy: 0.8424962759017944\n","val_precision: 0.3876652121543884\n","val_recall: 0.5465838313102722\n","val_auc: 0.8014860153198242\n","val_prc_auc: 0.4479066729545593\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - auc: 0.8091 - binary_accuracy: 0.7540 - f1: 0.7268 - loss: 0.5252 - prc_auc: 0.8422 - precision: 0.8524 - recall: 0.6337 - val_auc: 0.8015 - val_binary_accuracy: 0.8425 - val_f1: 0.4536 - val_loss: 0.5089 - val_prc_auc: 0.4479 - val_precision: 0.3877 - val_recall: 0.5466\n","Epoch 6/20\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8121 - binary_accuracy: 0.7536 - f1: 0.7268 - loss: 0.5230 - prc_auc: 0.8444 - precision: 0.8523 - recall: 0.6337\n","Epoch 6: Validation Metrics:\n","loss: 0.510682225227356\n","val_binary_accuracy: 0.8424962759017944\n","val_precision: 0.3876652121543884\n","val_recall: 0.5465838313102722\n","val_auc: 0.803632378578186\n","val_prc_auc: 0.45962318778038025\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - auc: 0.8126 - binary_accuracy: 0.7540 - f1: 0.7268 - loss: 0.5224 - prc_auc: 0.8446 - precision: 0.8524 - recall: 0.6337 - val_auc: 0.8036 - val_binary_accuracy: 0.8425 - val_f1: 0.4536 - val_loss: 0.5049 - val_prc_auc: 0.4596 - val_precision: 0.3877 - val_recall: 0.5466\n","Starting training for label: 3\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - auc: 0.7849 - binary_accuracy: 0.7717 - f1: 0.7284 - loss: 0.6466 - prc_auc: 0.8003 - precision: 0.8879 - recall: 0.6202\n","Epoch 1: Validation Metrics:\n","loss: 0.6228041052818298\n","val_binary_accuracy: 0.8647845387458801\n","val_precision: 0.4000000059604645\n","val_recall: 0.6000000238418579\n","val_auc: 0.7870795130729675\n","val_prc_auc: 0.3519361913204193\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - auc: 0.7846 - binary_accuracy: 0.7716 - f1: 0.7285 - loss: 0.6459 - prc_auc: 0.7999 - precision: 0.8873 - recall: 0.6206 - val_auc: 0.7871 - val_binary_accuracy: 0.8648 - val_f1: 0.4800 - val_loss: 0.5485 - val_prc_auc: 0.3519 - val_precision: 0.4000 - val_recall: 0.6000\n","Epoch 2/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8158 - binary_accuracy: 0.7785 - f1: 0.7397 - loss: 0.5503 - prc_auc: 0.8284 - precision: 0.8867 - recall: 0.6357\n","Epoch 2: Validation Metrics:\n","loss: 0.5463360548019409\n","val_binary_accuracy: 0.8595839738845825\n","val_precision: 0.388127863407135\n","val_recall: 0.6071428656578064\n","val_auc: 0.7942607402801514\n","val_prc_auc: 0.36236825585365295\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - auc: 0.8152 - binary_accuracy: 0.7783 - f1: 0.7397 - loss: 0.5501 - prc_auc: 0.8278 - precision: 0.8862 - recall: 0.6359 - val_auc: 0.7943 - val_binary_accuracy: 0.8596 - val_f1: 0.4735 - val_loss: 0.5022 - val_prc_auc: 0.3624 - val_precision: 0.3881 - val_recall: 0.6071\n","Epoch 3/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8269 - binary_accuracy: 0.7833 - f1: 0.7482 - loss: 0.5082 - prc_auc: 0.8380 - precision: 0.8841 - recall: 0.6496\n","Epoch 3: Validation Metrics:\n","loss: 0.5163964629173279\n","val_binary_accuracy: 0.8558692336082458\n","val_precision: 0.38053098320961\n","val_recall: 0.6142857074737549\n","val_auc: 0.7957177758216858\n","val_prc_auc: 0.3695981204509735\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - auc: 0.8264 - binary_accuracy: 0.7830 - f1: 0.7481 - loss: 0.5085 - prc_auc: 0.8374 - precision: 0.8835 - recall: 0.6496 - val_auc: 0.7957 - val_binary_accuracy: 0.8559 - val_f1: 0.4699 - val_loss: 0.4970 - val_prc_auc: 0.3696 - val_precision: 0.3805 - val_recall: 0.6143\n","Epoch 4/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8355 - binary_accuracy: 0.7821 - f1: 0.7483 - loss: 0.4931 - prc_auc: 0.8485 - precision: 0.8776 - recall: 0.6534\n","Epoch 4: Validation Metrics:\n","loss: 0.5071272253990173\n","val_binary_accuracy: 0.8551263213157654\n","val_precision: 0.3788546323776245\n","val_recall: 0.6142857074737549\n","val_auc: 0.7977493405342102\n","val_prc_auc: 0.3718782663345337\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - auc: 0.8350 - binary_accuracy: 0.7818 - f1: 0.7481 - loss: 0.4935 - prc_auc: 0.8479 - precision: 0.8768 - recall: 0.6534 - val_auc: 0.7977 - val_binary_accuracy: 0.8551 - val_f1: 0.4687 - val_loss: 0.4999 - val_prc_auc: 0.3719 - val_precision: 0.3789 - val_recall: 0.6143\n","Epoch 5/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8413 - binary_accuracy: 0.7821 - f1: 0.7483 - loss: 0.4875 - prc_auc: 0.8543 - precision: 0.8776 - recall: 0.6534\n","Epoch 5: Validation Metrics:\n","loss: 0.5036390423774719\n","val_binary_accuracy: 0.8543833494186401\n","val_precision: 0.37719297409057617\n","val_recall: 0.6142857074737549\n","val_auc: 0.8006928563117981\n","val_prc_auc: 0.3806239068508148\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - auc: 0.8408 - binary_accuracy: 0.7818 - f1: 0.7481 - loss: 0.4879 - prc_auc: 0.8537 - precision: 0.8768 - recall: 0.6534 - val_auc: 0.8007 - val_binary_accuracy: 0.8544 - val_f1: 0.4674 - val_loss: 0.5003 - val_prc_auc: 0.3806 - val_precision: 0.3772 - val_recall: 0.6143\n","Epoch 6/20\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8453 - binary_accuracy: 0.7817 - f1: 0.7480 - loss: 0.4844 - prc_auc: 0.8586 - precision: 0.8767 - recall: 0.6534\n","Epoch 6: Validation Metrics:\n","loss: 0.5014320015907288\n","val_binary_accuracy: 0.8543833494186401\n","val_precision: 0.37719297409057617\n","val_recall: 0.6142857074737549\n","val_auc: 0.8015428781509399\n","val_prc_auc: 0.3777272701263428\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - auc: 0.8449 - binary_accuracy: 0.7814 - f1: 0.7478 - loss: 0.4849 - prc_auc: 0.8581 - precision: 0.8760 - recall: 0.6534 - val_auc: 0.8015 - val_binary_accuracy: 0.8544 - val_f1: 0.4674 - val_loss: 0.4993 - val_prc_auc: 0.3777 - val_precision: 0.3772 - val_recall: 0.6143\n","Starting training for label: 4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - auc: 0.5744 - binary_accuracy: 0.5390 - f1: 0.6580 - loss: 0.6876 - prc_auc: 0.5848 - precision: 0.5369 - recall: 0.8514\n","Epoch 1: Validation Metrics:\n","loss: 0.68276447057724\n","val_binary_accuracy: 0.681277871131897\n","val_precision: 0.30295565724372864\n","val_recall: 0.45724907517433167\n","val_auc: 0.6431158185005188\n","val_prc_auc: 0.3089146018028259\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 808ms/step - auc: 0.5750 - binary_accuracy: 0.5395 - f1: 0.6578 - loss: 0.6875 - prc_auc: 0.5847 - precision: 0.5371 - recall: 0.8504 - val_auc: 0.6431 - val_binary_accuracy: 0.6813 - val_f1: 0.3644 - val_loss: 0.6548 - val_prc_auc: 0.3089 - val_precision: 0.3030 - val_recall: 0.4572\n","Epoch 2/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6437 - binary_accuracy: 0.6125 - f1: 0.6182 - loss: 0.6713 - prc_auc: 0.6392 - precision: 0.6405 - recall: 0.6067\n","Epoch 2: Validation Metrics:\n","loss: 0.667556643486023\n","val_binary_accuracy: 0.6545319557189941\n","val_precision: 0.2966805100440979\n","val_recall: 0.5315985083580017\n","val_auc: 0.651879608631134\n","val_prc_auc: 0.3286173343658447\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6437 - binary_accuracy: 0.6125 - f1: 0.6184 - loss: 0.6712 - prc_auc: 0.6383 - precision: 0.6395 - recall: 0.6076 - val_auc: 0.6519 - val_binary_accuracy: 0.6545 - val_f1: 0.3808 - val_loss: 0.6418 - val_prc_auc: 0.3286 - val_precision: 0.2967 - val_recall: 0.5316\n","Epoch 3/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6554 - binary_accuracy: 0.6236 - f1: 0.6395 - loss: 0.6620 - prc_auc: 0.6640 - precision: 0.6427 - recall: 0.6411\n","Epoch 3: Validation Metrics:\n","loss: 0.6586182713508606\n","val_binary_accuracy: 0.6515601873397827\n","val_precision: 0.3007968068122864\n","val_recall: 0.5613383054733276\n","val_auc: 0.6620931625366211\n","val_prc_auc: 0.3556230664253235\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6554 - binary_accuracy: 0.6234 - f1: 0.6392 - loss: 0.6619 - prc_auc: 0.6632 - precision: 0.6418 - recall: 0.6414 - val_auc: 0.6621 - val_binary_accuracy: 0.6516 - val_f1: 0.3917 - val_loss: 0.6323 - val_prc_auc: 0.3556 - val_precision: 0.3008 - val_recall: 0.5613\n","Epoch 4/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6660 - binary_accuracy: 0.6277 - f1: 0.6462 - loss: 0.6555 - prc_auc: 0.6803 - precision: 0.6440 - recall: 0.6523\n","Epoch 4: Validation Metrics:\n","loss: 0.6523508429527283\n","val_binary_accuracy: 0.6456166505813599\n","val_precision: 0.2992278039455414\n","val_recall: 0.5762081742286682\n","val_auc: 0.666761577129364\n","val_prc_auc: 0.35651764273643494\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6660 - binary_accuracy: 0.6276 - f1: 0.6459 - loss: 0.6554 - prc_auc: 0.6795 - precision: 0.6432 - recall: 0.6525 - val_auc: 0.6668 - val_binary_accuracy: 0.6456 - val_f1: 0.3939 - val_loss: 0.6266 - val_prc_auc: 0.3565 - val_precision: 0.2992 - val_recall: 0.5762\n","Epoch 5/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6740 - binary_accuracy: 0.6285 - f1: 0.6480 - loss: 0.6502 - prc_auc: 0.6906 - precision: 0.6430 - recall: 0.6562\n","Epoch 5: Validation Metrics:\n","loss: 0.6474187970161438\n","val_binary_accuracy: 0.647845447063446\n","val_precision: 0.30401530861854553\n","val_recall: 0.5910780429840088\n","val_auc: 0.6706792712211609\n","val_prc_auc: 0.3531359136104584\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - auc: 0.6740 - binary_accuracy: 0.6284 - f1: 0.6477 - loss: 0.6501 - prc_auc: 0.6897 - precision: 0.6423 - recall: 0.6563 - val_auc: 0.6707 - val_binary_accuracy: 0.6478 - val_f1: 0.4015 - val_loss: 0.6233 - val_prc_auc: 0.3531 - val_precision: 0.3040 - val_recall: 0.5911\n","Epoch 6/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6811 - binary_accuracy: 0.6311 - f1: 0.6500 - loss: 0.6456 - prc_auc: 0.6956 - precision: 0.6457 - recall: 0.6574\n","Epoch 6: Validation Metrics:\n","loss: 0.6432554125785828\n","val_binary_accuracy: 0.6441307663917542\n","val_precision: 0.30263158679008484\n","val_recall: 0.5985130071640015\n","val_auc: 0.6740498542785645\n","val_prc_auc: 0.353038489818573\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6810 - binary_accuracy: 0.6310 - f1: 0.6497 - loss: 0.6455 - prc_auc: 0.6947 - precision: 0.6450 - recall: 0.6574 - val_auc: 0.6740 - val_binary_accuracy: 0.6441 - val_f1: 0.4020 - val_loss: 0.6208 - val_prc_auc: 0.3530 - val_precision: 0.3026 - val_recall: 0.5985\n","Epoch 7/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6856 - binary_accuracy: 0.6357 - f1: 0.6540 - loss: 0.6416 - prc_auc: 0.7007 - precision: 0.6501 - recall: 0.6608\n","Epoch 7: Validation Metrics:\n","loss: 0.6396260857582092\n","val_binary_accuracy: 0.6419019103050232\n","val_precision: 0.3009345829486847\n","val_recall: 0.5985130071640015\n","val_auc: 0.6776102781295776\n","val_prc_auc: 0.35581910610198975\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6856 - binary_accuracy: 0.6355 - f1: 0.6536 - loss: 0.6415 - prc_auc: 0.6998 - precision: 0.6494 - recall: 0.6607 - val_auc: 0.6776 - val_binary_accuracy: 0.6419 - val_f1: 0.4005 - val_loss: 0.6193 - val_prc_auc: 0.3558 - val_precision: 0.3009 - val_recall: 0.5985\n","Epoch 8/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6906 - binary_accuracy: 0.6337 - f1: 0.6516 - loss: 0.6378 - prc_auc: 0.7053 - precision: 0.6487 - recall: 0.6575\n","Epoch 8: Validation Metrics:\n","loss: 0.6363212466239929\n","val_binary_accuracy: 0.6426448822021484\n","val_precision: 0.302238792181015\n","val_recall: 0.6022304892539978\n","val_auc: 0.6807529926300049\n","val_prc_auc: 0.35690346360206604\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6905 - binary_accuracy: 0.6337 - f1: 0.6513 - loss: 0.6378 - prc_auc: 0.7044 - precision: 0.6480 - recall: 0.6574 - val_auc: 0.6808 - val_binary_accuracy: 0.6426 - val_f1: 0.4025 - val_loss: 0.6180 - val_prc_auc: 0.3569 - val_precision: 0.3022 - val_recall: 0.6022\n","Epoch 9/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6944 - binary_accuracy: 0.6378 - f1: 0.6549 - loss: 0.6344 - prc_auc: 0.7099 - precision: 0.6529 - recall: 0.6597\n","Epoch 9: Validation Metrics:\n","loss: 0.6332008242607117\n","val_binary_accuracy: 0.647845447063446\n","val_precision: 0.3076923191547394\n","val_recall: 0.6096654534339905\n","val_auc: 0.6839233636856079\n","val_prc_auc: 0.35804903507232666\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6943 - binary_accuracy: 0.6377 - f1: 0.6545 - loss: 0.6343 - prc_auc: 0.7090 - precision: 0.6522 - recall: 0.6596 - val_auc: 0.6839 - val_binary_accuracy: 0.6478 - val_f1: 0.4090 - val_loss: 0.6172 - val_prc_auc: 0.3580 - val_precision: 0.3077 - val_recall: 0.6097\n","Epoch 10/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6984 - binary_accuracy: 0.6390 - f1: 0.6569 - loss: 0.6312 - prc_auc: 0.7139 - precision: 0.6532 - recall: 0.6635\n","Epoch 10: Validation Metrics:\n","loss: 0.6304170489311218\n","val_binary_accuracy: 0.6471025347709656\n","val_precision: 0.30783581733703613\n","val_recall: 0.613382875919342\n","val_auc: 0.685606062412262\n","val_prc_auc: 0.35936903953552246\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.6983 - binary_accuracy: 0.6388 - f1: 0.6565 - loss: 0.6312 - prc_auc: 0.7130 - precision: 0.6525 - recall: 0.6634 - val_auc: 0.6856 - val_binary_accuracy: 0.6471 - val_f1: 0.4099 - val_loss: 0.6164 - val_prc_auc: 0.3594 - val_precision: 0.3078 - val_recall: 0.6134\n","Epoch 11/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7020 - binary_accuracy: 0.6443 - f1: 0.6608 - loss: 0.6284 - prc_auc: 0.7172 - precision: 0.6597 - recall: 0.6658\n","Epoch 11: Validation Metrics:\n","loss: 0.6279206275939941\n","val_binary_accuracy: 0.6448736786842346\n","val_precision: 0.30612245202064514\n","val_recall: 0.613382875919342\n","val_auc: 0.6881378889083862\n","val_prc_auc: 0.3618399202823639\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7019 - binary_accuracy: 0.6442 - f1: 0.6605 - loss: 0.6284 - prc_auc: 0.7163 - precision: 0.6590 - recall: 0.6659 - val_auc: 0.6881 - val_binary_accuracy: 0.6449 - val_f1: 0.4084 - val_loss: 0.6157 - val_prc_auc: 0.3618 - val_precision: 0.3061 - val_recall: 0.6134\n","Epoch 12/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7052 - binary_accuracy: 0.6430 - f1: 0.6599 - loss: 0.6259 - prc_auc: 0.7202 - precision: 0.6582 - recall: 0.6658\n","Epoch 12: Validation Metrics:\n","loss: 0.6255955100059509\n","val_binary_accuracy: 0.647845447063446\n","val_precision: 0.30983301997184753\n","val_recall: 0.6208178400993347\n","val_auc: 0.6897256970405579\n","val_prc_auc: 0.3638025224208832\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7051 - binary_accuracy: 0.6430 - f1: 0.6596 - loss: 0.6259 - prc_auc: 0.7193 - precision: 0.6575 - recall: 0.6658 - val_auc: 0.6897 - val_binary_accuracy: 0.6478 - val_f1: 0.4134 - val_loss: 0.6152 - val_prc_auc: 0.3638 - val_precision: 0.3098 - val_recall: 0.6208\n","Epoch 13/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7079 - binary_accuracy: 0.6440 - f1: 0.6609 - loss: 0.6236 - prc_auc: 0.7230 - precision: 0.6591 - recall: 0.6669\n","Epoch 13: Validation Metrics:\n","loss: 0.6234154105186462\n","val_binary_accuracy: 0.647845447063446\n","val_precision: 0.31123387813568115\n","val_recall: 0.6282528042793274\n","val_auc: 0.6917104125022888\n","val_prc_auc: 0.3664246201515198\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - auc: 0.7078 - binary_accuracy: 0.6440 - f1: 0.6607 - loss: 0.6236 - prc_auc: 0.7221 - precision: 0.6584 - recall: 0.6670 - val_auc: 0.6917 - val_binary_accuracy: 0.6478 - val_f1: 0.4163 - val_loss: 0.6146 - val_prc_auc: 0.3664 - val_precision: 0.3112 - val_recall: 0.6283\n","Epoch 14/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7099 - binary_accuracy: 0.6474 - f1: 0.6659 - loss: 0.6214 - prc_auc: 0.7250 - precision: 0.6604 - recall: 0.6753\n","Epoch 14: Validation Metrics:\n","loss: 0.6213994026184082\n","val_binary_accuracy: 0.6493313312530518\n","val_precision: 0.31376147270202637\n","val_recall: 0.6356877088546753\n","val_auc: 0.6933672428131104\n","val_prc_auc: 0.36882123351097107\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - auc: 0.7098 - binary_accuracy: 0.6474 - f1: 0.6656 - loss: 0.6214 - prc_auc: 0.7242 - precision: 0.6598 - recall: 0.6753 - val_auc: 0.6934 - val_binary_accuracy: 0.6493 - val_f1: 0.4201 - val_loss: 0.6141 - val_prc_auc: 0.3688 - val_precision: 0.3138 - val_recall: 0.6357\n","Epoch 15/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7126 - binary_accuracy: 0.6448 - f1: 0.6632 - loss: 0.6194 - prc_auc: 0.7271 - precision: 0.6576 - recall: 0.6724\n","Epoch 15: Validation Metrics:\n","loss: 0.6194703578948975\n","val_binary_accuracy: 0.6530460715293884\n","val_precision: 0.3180147111415863\n","val_recall: 0.643122673034668\n","val_auc: 0.6946909427642822\n","val_prc_auc: 0.37050536274909973\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7125 - binary_accuracy: 0.6448 - f1: 0.6630 - loss: 0.6194 - prc_auc: 0.7263 - precision: 0.6570 - recall: 0.6724 - val_auc: 0.6947 - val_binary_accuracy: 0.6530 - val_f1: 0.4256 - val_loss: 0.6138 - val_prc_auc: 0.3705 - val_precision: 0.3180 - val_recall: 0.6431\n","Epoch 16/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7150 - binary_accuracy: 0.6448 - f1: 0.6637 - loss: 0.6175 - prc_auc: 0.7298 - precision: 0.6570 - recall: 0.6740\n","Epoch 16: Validation Metrics:\n","loss: 0.6176316142082214\n","val_binary_accuracy: 0.6552748680114746\n","val_precision: 0.319778174161911\n","val_recall: 0.643122673034668\n","val_auc: 0.6955952644348145\n","val_prc_auc: 0.3714311718940735\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7149 - binary_accuracy: 0.6448 - f1: 0.6636 - loss: 0.6175 - prc_auc: 0.7289 - precision: 0.6565 - recall: 0.6741 - val_auc: 0.6956 - val_binary_accuracy: 0.6553 - val_f1: 0.4272 - val_loss: 0.6133 - val_prc_auc: 0.3714 - val_precision: 0.3198 - val_recall: 0.6431\n","Epoch 17/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7169 - binary_accuracy: 0.6490 - f1: 0.6683 - loss: 0.6157 - prc_auc: 0.7317 - precision: 0.6604 - recall: 0.6798\n","Epoch 17: Validation Metrics:\n","loss: 0.6158849000930786\n","val_binary_accuracy: 0.6545319557189941\n","val_precision: 0.31985294818878174\n","val_recall: 0.6468401551246643\n","val_auc: 0.6970000863075256\n","val_prc_auc: 0.37366336584091187\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7168 - binary_accuracy: 0.6491 - f1: 0.6681 - loss: 0.6158 - prc_auc: 0.7309 - precision: 0.6599 - recall: 0.6799 - val_auc: 0.6970 - val_binary_accuracy: 0.6545 - val_f1: 0.4280 - val_loss: 0.6128 - val_prc_auc: 0.3737 - val_precision: 0.3199 - val_recall: 0.6468\n","Epoch 18/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7187 - binary_accuracy: 0.6500 - f1: 0.6700 - loss: 0.6141 - prc_auc: 0.7333 - precision: 0.6606 - recall: 0.6832\n","Epoch 18: Validation Metrics:\n","loss: 0.6142465472221375\n","val_binary_accuracy: 0.6515601873397827\n","val_precision: 0.31684982776641846\n","val_recall: 0.643122673034668\n","val_auc: 0.6978234052658081\n","val_prc_auc: 0.3744064271450043\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7186 - binary_accuracy: 0.6501 - f1: 0.6699 - loss: 0.6141 - prc_auc: 0.7325 - precision: 0.6601 - recall: 0.6834 - val_auc: 0.6978 - val_binary_accuracy: 0.6516 - val_f1: 0.4245 - val_loss: 0.6122 - val_prc_auc: 0.3744 - val_precision: 0.3168 - val_recall: 0.6431\n","Epoch 19/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7207 - binary_accuracy: 0.6529 - f1: 0.6724 - loss: 0.6125 - prc_auc: 0.7352 - precision: 0.6634 - recall: 0.6852\n","Epoch 19: Validation Metrics:\n","loss: 0.6126731634140015\n","val_binary_accuracy: 0.6537889838218689\n","val_precision: 0.31792977452278137\n","val_recall: 0.6394051909446716\n","val_auc: 0.6985896229743958\n","val_prc_auc: 0.3757040202617645\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7206 - binary_accuracy: 0.6530 - f1: 0.6723 - loss: 0.6125 - prc_auc: 0.7344 - precision: 0.6629 - recall: 0.6853 - val_auc: 0.6986 - val_binary_accuracy: 0.6538 - val_f1: 0.4247 - val_loss: 0.6117 - val_prc_auc: 0.3757 - val_precision: 0.3179 - val_recall: 0.6394\n","Epoch 20/20\n","\u001b[1m67/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7227 - binary_accuracy: 0.6535 - f1: 0.6745 - loss: 0.6110 - prc_auc: 0.7369 - precision: 0.6620 - recall: 0.6898\n","Epoch 20: Validation Metrics:\n","loss: 0.611150324344635\n","val_binary_accuracy: 0.6560178399085999\n","val_precision: 0.3197025954723358\n","val_recall: 0.6394051909446716\n","val_auc: 0.6993972659111023\n","val_prc_auc: 0.37719666957855225\n","\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - auc: 0.7227 - binary_accuracy: 0.6536 - f1: 0.6743 - loss: 0.6110 - prc_auc: 0.7361 - precision: 0.6616 - recall: 0.6898 - val_auc: 0.6994 - val_binary_accuracy: 0.6560 - val_f1: 0.4263 - val_loss: 0.6113 - val_prc_auc: 0.3772 - val_precision: 0.3197 - val_recall: 0.6394\n","Starting training for label: 5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - auc: 0.5737 - binary_accuracy: 0.5424 - f1: 0.2463 - loss: 0.6905 - prc_auc: 0.5614 - precision: 0.6449 - recall: 0.1566  \n","Epoch 1: Validation Metrics:\n","loss: 0.6882450580596924\n","val_binary_accuracy: 0.8320950865745544\n","val_precision: 0.10160427540540695\n","val_recall: 0.2467532455921173\n","val_auc: 0.6379294395446777\n","val_prc_auc: 0.09341102838516235\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 5s/step - auc: 0.5758 - binary_accuracy: 0.5434 - f1: 0.2515 - loss: 0.6904 - prc_auc: 0.5632 - precision: 0.6465 - recall: 0.1607 - val_auc: 0.6379 - val_binary_accuracy: 0.8321 - val_f1: 0.1439 - val_loss: 0.6603 - val_prc_auc: 0.0934 - val_precision: 0.1016 - val_recall: 0.2468\n","Epoch 2/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7036 - binary_accuracy: 0.6217 - f1: 0.4721 - loss: 0.6787 - prc_auc: 0.6875 - precision: 0.7651 - recall: 0.3423\n","Epoch 2: Validation Metrics:\n","loss: 0.6783104538917542\n","val_binary_accuracy: 0.8254086375236511\n","val_precision: 0.10499999672174454\n","val_recall: 0.27272728085517883\n","val_auc: 0.6648143529891968\n","val_prc_auc: 0.11022500693798065\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - auc: 0.7021 - binary_accuracy: 0.6207 - f1: 0.4727 - loss: 0.6787 - prc_auc: 0.6855 - precision: 0.7614 - recall: 0.3437 - val_auc: 0.6648 - val_binary_accuracy: 0.8254 - val_f1: 0.1516 - val_loss: 0.6471 - val_prc_auc: 0.1102 - val_precision: 0.1050 - val_recall: 0.2727\n","Epoch 3/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7131 - binary_accuracy: 0.6223 - f1: 0.4906 - loss: 0.6708 - prc_auc: 0.7040 - precision: 0.7361 - recall: 0.3692\n","Epoch 3: Validation Metrics:\n","loss: 0.6707847714424133\n","val_binary_accuracy: 0.8112927079200745\n","val_precision: 0.1066666692495346\n","val_recall: 0.31168830394744873\n","val_auc: 0.6771361231803894\n","val_prc_auc: 0.12146077305078506\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - auc: 0.7117 - binary_accuracy: 0.6221 - f1: 0.4923 - loss: 0.6708 - prc_auc: 0.7024 - precision: 0.7348 - recall: 0.3714 - val_auc: 0.6771 - val_binary_accuracy: 0.8113 - val_f1: 0.1589 - val_loss: 0.6395 - val_prc_auc: 0.1215 - val_precision: 0.1067 - val_recall: 0.3117\n","Epoch 4/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7162 - binary_accuracy: 0.6376 - f1: 0.5277 - loss: 0.6640 - prc_auc: 0.7117 - precision: 0.7433 - recall: 0.4105\n","Epoch 4: Validation Metrics:\n","loss: 0.6639463901519775\n","val_binary_accuracy: 0.7949479818344116\n","val_precision: 0.11284046620130539\n","val_recall: 0.37662336230278015\n","val_auc: 0.680206298828125\n","val_prc_auc: 0.13973721861839294\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - auc: 0.7153 - binary_accuracy: 0.6370 - f1: 0.5286 - loss: 0.6640 - prc_auc: 0.7107 - precision: 0.7411 - recall: 0.4121 - val_auc: 0.6802 - val_binary_accuracy: 0.7949 - val_f1: 0.1737 - val_loss: 0.6348 - val_prc_auc: 0.1397 - val_precision: 0.1128 - val_recall: 0.3766\n","Epoch 5/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7175 - binary_accuracy: 0.6449 - f1: 0.5584 - loss: 0.6577 - prc_auc: 0.7201 - precision: 0.7247 - recall: 0.4553\n","Epoch 5: Validation Metrics:\n","loss: 0.6575242280960083\n","val_binary_accuracy: 0.7756314873695374\n","val_precision: 0.10801393538713455\n","val_recall: 0.4025973975658417\n","val_auc: 0.685742974281311\n","val_prc_auc: 0.16686683893203735\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - auc: 0.7170 - binary_accuracy: 0.6440 - f1: 0.5583 - loss: 0.6577 - prc_auc: 0.7197 - precision: 0.7234 - recall: 0.4555 - val_auc: 0.6857 - val_binary_accuracy: 0.7756 - val_f1: 0.1703 - val_loss: 0.6310 - val_prc_auc: 0.1669 - val_precision: 0.1080 - val_recall: 0.4026\n","Epoch 6/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7236 - binary_accuracy: 0.6469 - f1: 0.5749 - loss: 0.6519 - prc_auc: 0.7309 - precision: 0.7111 - recall: 0.4831\n","Epoch 6: Validation Metrics:\n","loss: 0.6513107419013977\n","val_binary_accuracy: 0.7637444138526917\n","val_precision: 0.11003236472606659\n","val_recall: 0.44155845046043396\n","val_auc: 0.686162531375885\n","val_prc_auc: 0.18282927572727203\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - auc: 0.7229 - binary_accuracy: 0.6455 - f1: 0.5740 - loss: 0.6518 - prc_auc: 0.7307 - precision: 0.7093 - recall: 0.4826 - val_auc: 0.6862 - val_binary_accuracy: 0.7637 - val_f1: 0.1762 - val_loss: 0.6267 - val_prc_auc: 0.1828 - val_precision: 0.1100 - val_recall: 0.4416\n","Epoch 7/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7265 - binary_accuracy: 0.6475 - f1: 0.5761 - loss: 0.6463 - prc_auc: 0.7384 - precision: 0.7115 - recall: 0.4847\n","Epoch 7: Validation Metrics:\n","loss: 0.6453767418861389\n","val_binary_accuracy: 0.7540861964225769\n","val_precision: 0.10559006035327911\n","val_recall: 0.44155845046043396\n","val_auc: 0.6906245350837708\n","val_prc_auc: 0.19396263360977173\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - auc: 0.7259 - binary_accuracy: 0.6462 - f1: 0.5755 - loss: 0.6462 - prc_auc: 0.7383 - precision: 0.7096 - recall: 0.4846 - val_auc: 0.6906 - val_binary_accuracy: 0.7541 - val_f1: 0.1704 - val_loss: 0.6217 - val_prc_auc: 0.1940 - val_precision: 0.1056 - val_recall: 0.4416\n","Epoch 8/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7284 - binary_accuracy: 0.6391 - f1: 0.5727 - loss: 0.6411 - prc_auc: 0.7421 - precision: 0.6900 - recall: 0.4902\n","Epoch 8: Validation Metrics:\n","loss: 0.6398450136184692\n","val_binary_accuracy: 0.7451708912849426\n","val_precision: 0.10179640352725983\n","val_recall: 0.44155845046043396\n","val_auc: 0.6925792694091797\n","val_prc_auc: 0.20880258083343506\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - auc: 0.7278 - binary_accuracy: 0.6386 - f1: 0.5729 - loss: 0.6410 - prc_auc: 0.7420 - precision: 0.6897 - recall: 0.4905 - val_auc: 0.6926 - val_binary_accuracy: 0.7452 - val_f1: 0.1655 - val_loss: 0.6165 - val_prc_auc: 0.2088 - val_precision: 0.1018 - val_recall: 0.4416\n","Epoch 9/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7315 - binary_accuracy: 0.6435 - f1: 0.5815 - loss: 0.6363 - prc_auc: 0.7464 - precision: 0.6924 - recall: 0.5018\n","Epoch 9: Validation Metrics:\n","loss: 0.6345623731613159\n","val_binary_accuracy: 0.7392273545265198\n","val_precision: 0.09941520541906357\n","val_recall: 0.44155845046043396\n","val_auc: 0.6942525506019592\n","val_prc_auc: 0.21650147438049316\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - auc: 0.7308 - binary_accuracy: 0.6428 - f1: 0.5812 - loss: 0.6362 - prc_auc: 0.7463 - precision: 0.6918 - recall: 0.5017 - val_auc: 0.6943 - val_binary_accuracy: 0.7392 - val_f1: 0.1623 - val_loss: 0.6116 - val_prc_auc: 0.2165 - val_precision: 0.0994 - val_recall: 0.4416\n","Epoch 10/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7334 - binary_accuracy: 0.6542 - f1: 0.5987 - loss: 0.6317 - prc_auc: 0.7494 - precision: 0.7017 - recall: 0.5231\n","Epoch 10: Validation Metrics:\n","loss: 0.629466712474823\n","val_binary_accuracy: 0.7340267300605774\n","val_precision: 0.09971509873867035\n","val_recall: 0.4545454680919647\n","val_auc: 0.6962021589279175\n","val_prc_auc: 0.22805416584014893\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 218ms/step - auc: 0.7328 - binary_accuracy: 0.6535 - f1: 0.5986 - loss: 0.6315 - prc_auc: 0.7493 - precision: 0.7011 - recall: 0.5231 - val_auc: 0.6962 - val_binary_accuracy: 0.7340 - val_f1: 0.1636 - val_loss: 0.6072 - val_prc_auc: 0.2281 - val_precision: 0.0997 - val_recall: 0.4545\n","Epoch 11/20\n","\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7358 - binary_accuracy: 0.6561 - f1: 0.6018 - loss: 0.6274 - prc_auc: 0.7524 - precision: 0.7032 - recall: 0.5269\n","Epoch 11: Validation Metrics:\n","loss: 0.6246426105499268\n","val_binary_accuracy: 0.7288261651992798\n","val_precision: 0.09776536375284195\n","val_recall: 0.4545454680919647\n","val_auc: 0.6983206272125244\n","val_prc_auc: 0.22344347834587097\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - auc: 0.7351 - binary_accuracy: 0.6556 - f1: 0.6018 - loss: 0.6272 - prc_auc: 0.7523 - precision: 0.7027 - recall: 0.5272 - val_auc: 0.6983 - val_binary_accuracy: 0.7288 - val_f1: 0.1609 - val_loss: 0.6025 - val_prc_auc: 0.2234 - val_precision: 0.0978 - val_recall: 0.4545\n","Starting training for label: 6\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - auc: 0.8715 - binary_accuracy: 0.7631 - f1: 0.7863 - loss: 0.6318 - prc_auc: 0.8564 - precision: 0.7128 - recall: 0.9007\n","Epoch 1: Validation Metrics:\n","loss: 0.5916174650192261\n","val_binary_accuracy: 0.8907875418663025\n","val_precision: 0.43192487955093384\n","val_recall: 0.7796609997749329\n","val_auc: 0.8827707171440125\n","val_prc_auc: 0.47065263986587524\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - auc: 0.8715 - binary_accuracy: 0.7653 - f1: 0.7879 - loss: 0.6305 - prc_auc: 0.8567 - precision: 0.7163 - recall: 0.8991 - val_auc: 0.8828 - val_binary_accuracy: 0.8908 - val_f1: 0.5559 - val_loss: 0.5335 - val_prc_auc: 0.4707 - val_precision: 0.4319 - val_recall: 0.7797\n","Epoch 2/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8910 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.4886 - prc_auc: 0.8880 - precision: 0.8983 - recall: 0.8074\n","Epoch 2: Validation Metrics:\n","loss: 0.46636077761650085\n","val_binary_accuracy: 0.8945022225379944\n","val_precision: 0.4423076808452606\n","val_recall: 0.7796609997749329\n","val_auc: 0.8904861211776733\n","val_prc_auc: 0.5553263425827026\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 170ms/step - auc: 0.8905 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.4872 - prc_auc: 0.8877 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8905 - val_binary_accuracy: 0.8945 - val_f1: 0.5644 - val_loss: 0.4250 - val_prc_auc: 0.5553 - val_precision: 0.4423 - val_recall: 0.7797\n","Epoch 3/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9016 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.4105 - prc_auc: 0.9004 - precision: 0.8983 - recall: 0.8074\n","Epoch 3: Validation Metrics:\n","loss: 0.40166133642196655\n","val_binary_accuracy: 0.8952451944351196\n","val_precision: 0.4444444477558136\n","val_recall: 0.7796609997749329\n","val_auc: 0.8920146226882935\n","val_prc_auc: 0.5688374638557434\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - auc: 0.9013 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.4099 - prc_auc: 0.9000 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8920 - val_binary_accuracy: 0.8952 - val_f1: 0.5662 - val_loss: 0.3773 - val_prc_auc: 0.5688 - val_precision: 0.4444 - val_recall: 0.7797\n","Epoch 4/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9054 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3797 - prc_auc: 0.9059 - precision: 0.8983 - recall: 0.8074\n","Epoch 4: Validation Metrics:\n","loss: 0.37739554047584534\n","val_binary_accuracy: 0.8937593102455139\n","val_precision: 0.440191388130188\n","val_recall: 0.7796609997749329\n","val_auc: 0.8944473266601562\n","val_prc_auc: 0.5992476940155029\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - auc: 0.9054 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3796 - prc_auc: 0.9058 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8944 - val_binary_accuracy: 0.8938 - val_f1: 0.5627 - val_loss: 0.3655 - val_prc_auc: 0.5992 - val_precision: 0.4402 - val_recall: 0.7797\n","Epoch 5/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9077 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3709 - prc_auc: 0.9130 - precision: 0.8983 - recall: 0.8074\n","Epoch 5: Validation Metrics:\n","loss: 0.3698519766330719\n","val_binary_accuracy: 0.8937593102455139\n","val_precision: 0.440191388130188\n","val_recall: 0.7796609997749329\n","val_auc: 0.8966349363327026\n","val_prc_auc: 0.6075026988983154\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - auc: 0.9079 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3708 - prc_auc: 0.9133 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8966 - val_binary_accuracy: 0.8938 - val_f1: 0.5627 - val_loss: 0.3633 - val_prc_auc: 0.6075 - val_precision: 0.4402 - val_recall: 0.7797\n","Epoch 6/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9119 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3674 - prc_auc: 0.9167 - precision: 0.8983 - recall: 0.8074\n","Epoch 6: Validation Metrics:\n","loss: 0.36647289991378784\n","val_binary_accuracy: 0.8937593102455139\n","val_precision: 0.440191388130188\n","val_recall: 0.7796609997749329\n","val_auc: 0.8977736234664917\n","val_prc_auc: 0.6314054727554321\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9121 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3674 - prc_auc: 0.9171 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8978 - val_binary_accuracy: 0.8938 - val_f1: 0.5627 - val_loss: 0.3615 - val_prc_auc: 0.6314 - val_precision: 0.4402 - val_recall: 0.7797\n","Epoch 7/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9145 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3649 - prc_auc: 0.9195 - precision: 0.8983 - recall: 0.8074\n","Epoch 7: Validation Metrics:\n","loss: 0.36398038268089294\n","val_binary_accuracy: 0.8952451944351196\n","val_precision: 0.4444444477558136\n","val_recall: 0.7796609997749329\n","val_auc: 0.8985328078269958\n","val_prc_auc: 0.6347890496253967\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9147 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3648 - prc_auc: 0.9199 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8985 - val_binary_accuracy: 0.8952 - val_f1: 0.5662 - val_loss: 0.3593 - val_prc_auc: 0.6348 - val_precision: 0.4444 - val_recall: 0.7797\n","Epoch 8/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9163 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3626 - prc_auc: 0.9214 - precision: 0.8983 - recall: 0.8074\n","Epoch 8: Validation Metrics:\n","loss: 0.361771821975708\n","val_binary_accuracy: 0.8967310786247253\n","val_precision: 0.44878047704696655\n","val_recall: 0.7796609997749329\n","val_auc: 0.8999475240707397\n","val_prc_auc: 0.6214747428894043\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9165 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3625 - prc_auc: 0.9219 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.8999 - val_binary_accuracy: 0.8967 - val_f1: 0.5697 - val_loss: 0.3573 - val_prc_auc: 0.6215 - val_precision: 0.4488 - val_recall: 0.7797\n","Epoch 9/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9184 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3605 - prc_auc: 0.9237 - precision: 0.8983 - recall: 0.8074\n","Epoch 9: Validation Metrics:\n","loss: 0.3597531318664551\n","val_binary_accuracy: 0.8967310786247253\n","val_precision: 0.44878047704696655\n","val_recall: 0.7796609997749329\n","val_auc: 0.901748776435852\n","val_prc_auc: 0.6547173261642456\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9186 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3604 - prc_auc: 0.9241 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.9017 - val_binary_accuracy: 0.8967 - val_f1: 0.5697 - val_loss: 0.3548 - val_prc_auc: 0.6547 - val_precision: 0.4488 - val_recall: 0.7797\n","Epoch 10/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9203 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3584 - prc_auc: 0.9246 - precision: 0.8983 - recall: 0.8074\n","Epoch 10: Validation Metrics:\n","loss: 0.3578144609928131\n","val_binary_accuracy: 0.8959881067276001\n","val_precision: 0.446601927280426\n","val_recall: 0.7796609997749329\n","val_auc: 0.903163492679596\n","val_prc_auc: 0.6470475196838379\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9205 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3584 - prc_auc: 0.9251 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.9032 - val_binary_accuracy: 0.8960 - val_f1: 0.5679 - val_loss: 0.3529 - val_prc_auc: 0.6470 - val_precision: 0.4466 - val_recall: 0.7797\n","Epoch 11/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9218 - binary_accuracy: 0.8688 - f1: 0.8503 - loss: 0.3564 - prc_auc: 0.9253 - precision: 0.8983 - recall: 0.8074\n","Epoch 11: Validation Metrics:\n","loss: 0.3559476137161255\n","val_binary_accuracy: 0.8959881067276001\n","val_precision: 0.446601927280426\n","val_recall: 0.7796609997749329\n","val_auc: 0.9041019678115845\n","val_prc_auc: 0.6578114628791809\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step - auc: 0.9219 - binary_accuracy: 0.8686 - f1: 0.8508 - loss: 0.3564 - prc_auc: 0.9256 - precision: 0.8985 - recall: 0.8082 - val_auc: 0.9041 - val_binary_accuracy: 0.8960 - val_f1: 0.5679 - val_loss: 0.3509 - val_prc_auc: 0.6578 - val_precision: 0.4466 - val_recall: 0.7797\n","Epoch 12/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9226 - binary_accuracy: 0.8693 - f1: 0.8507 - loss: 0.3545 - prc_auc: 0.9265 - precision: 0.8992 - recall: 0.8074\n","Epoch 12: Validation Metrics:\n","loss: 0.3541385233402252\n","val_binary_accuracy: 0.8959881067276001\n","val_precision: 0.446601927280426\n","val_recall: 0.7796609997749329\n","val_auc: 0.9062482714653015\n","val_prc_auc: 0.6689431071281433\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 169ms/step - auc: 0.9227 - binary_accuracy: 0.8691 - f1: 0.8513 - loss: 0.3545 - prc_auc: 0.9269 - precision: 0.8995 - recall: 0.8082 - val_auc: 0.9062 - val_binary_accuracy: 0.8960 - val_f1: 0.5679 - val_loss: 0.3490 - val_prc_auc: 0.6689 - val_precision: 0.4466 - val_recall: 0.7797\n","Epoch 13/20\n","\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9233 - binary_accuracy: 0.8693 - f1: 0.8507 - loss: 0.3527 - prc_auc: 0.9266 - precision: 0.8992 - recall: 0.8074\n","Epoch 13: Validation Metrics:\n","loss: 0.35237717628479004\n","val_binary_accuracy: 0.8952451944351196\n","val_precision: 0.4439024329185486\n","val_recall: 0.7711864113807678\n","val_auc: 0.9077595472335815\n","val_prc_auc: 0.6671762466430664\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - auc: 0.9235 - binary_accuracy: 0.8691 - f1: 0.8513 - loss: 0.3527 - prc_auc: 0.9269 - precision: 0.8995 - recall: 0.8082 - val_auc: 0.9078 - val_binary_accuracy: 0.8952 - val_f1: 0.5635 - val_loss: 0.3469 - val_prc_auc: 0.6672 - val_precision: 0.4439 - val_recall: 0.7712\n","Starting training for label: 7\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.5972 - binary_accuracy: 0.5525 - f1: 0.6079 - loss: 0.6885 - prc_auc: 0.6083 - precision: 0.5672 - recall: 0.6572\n","Epoch 1: Validation Metrics:\n","loss: 0.6833682656288147\n","val_binary_accuracy: 0.7109955549240112\n","val_precision: 0.043478261679410934\n","val_recall: 0.53125\n","val_auc: 0.7381088137626648\n","val_prc_auc: 0.06966588646173477\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4s/step - auc: 0.6055 - binary_accuracy: 0.5597 - f1: 0.6108 - loss: 0.6879 - prc_auc: 0.6147 - precision: 0.5716 - recall: 0.6580 - val_auc: 0.7381 - val_binary_accuracy: 0.7110 - val_f1: 0.0804 - val_loss: 0.6778 - val_prc_auc: 0.0697 - val_precision: 0.0435 - val_recall: 0.5312\n","Epoch 2/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7630 - binary_accuracy: 0.7094 - f1: 0.6980 - loss: 0.6626 - prc_auc: 0.7856 - precision: 0.7692 - recall: 0.6404\n","Epoch 2: Validation Metrics:\n","loss: 0.6590996980667114\n","val_binary_accuracy: 0.8365527391433716\n","val_precision: 0.07657657563686371\n","val_recall: 0.53125\n","val_auc: 0.7558860778808594\n","val_prc_auc: 0.06848561018705368\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 478ms/step - auc: 0.7622 - binary_accuracy: 0.7100 - f1: 0.6964 - loss: 0.6622 - prc_auc: 0.7824 - precision: 0.7690 - recall: 0.6378 - val_auc: 0.7559 - val_binary_accuracy: 0.8366 - val_f1: 0.1339 - val_loss: 0.6514 - val_prc_auc: 0.0685 - val_precision: 0.0766 - val_recall: 0.5312\n","Epoch 3/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7761 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.6417 - prc_auc: 0.7941 - precision: 0.8221 - recall: 0.6209\n","Epoch 3: Validation Metrics:\n","loss: 0.6391515135765076\n","val_binary_accuracy: 0.8387815952301025\n","val_precision: 0.077625572681427\n","val_recall: 0.53125\n","val_auc: 0.7796090245246887\n","val_prc_auc: 0.07900981605052948\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - auc: 0.7753 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.6414 - prc_auc: 0.7912 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.7796 - val_binary_accuracy: 0.8388 - val_f1: 0.1355 - val_loss: 0.6284 - val_prc_auc: 0.0790 - val_precision: 0.0776 - val_recall: 0.5312\n","Epoch 4/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7810 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.6244 - prc_auc: 0.8056 - precision: 0.8221 - recall: 0.6209\n","Epoch 4: Validation Metrics:\n","loss: 0.622529923915863\n","val_binary_accuracy: 0.8387815952301025\n","val_precision: 0.077625572681427\n","val_recall: 0.53125\n","val_auc: 0.7879090905189514\n","val_prc_auc: 0.08725094050168991\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 472ms/step - auc: 0.7803 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.6242 - prc_auc: 0.8028 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.7879 - val_binary_accuracy: 0.8388 - val_f1: 0.1355 - val_loss: 0.6094 - val_prc_auc: 0.0873 - val_precision: 0.0776 - val_recall: 0.5312\n","Epoch 5/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7848 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.6100 - prc_auc: 0.8062 - precision: 0.8221 - recall: 0.6209\n","Epoch 5: Validation Metrics:\n","loss: 0.6088076233863831\n","val_binary_accuracy: 0.8387815952301025\n","val_precision: 0.077625572681427\n","val_recall: 0.53125\n","val_auc: 0.7938546538352966\n","val_prc_auc: 0.07654690742492676\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 474ms/step - auc: 0.7842 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.6099 - prc_auc: 0.8036 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.7939 - val_binary_accuracy: 0.8388 - val_f1: 0.1355 - val_loss: 0.5944 - val_prc_auc: 0.0765 - val_precision: 0.0776 - val_recall: 0.5312\n","Epoch 6/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7899 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.5981 - prc_auc: 0.8103 - precision: 0.8221 - recall: 0.6209\n","Epoch 6: Validation Metrics:\n","loss: 0.5975006222724915\n","val_binary_accuracy: 0.8372957110404968\n","val_precision: 0.07692307978868484\n","val_recall: 0.53125\n","val_auc: 0.8055080771446228\n","val_prc_auc: 0.0814356654882431\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - auc: 0.7895 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.5981 - prc_auc: 0.8076 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.8055 - val_binary_accuracy: 0.8373 - val_f1: 0.1344 - val_loss: 0.5828 - val_prc_auc: 0.0814 - val_precision: 0.0769 - val_recall: 0.5312\n","Epoch 7/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7904 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.5883 - prc_auc: 0.8097 - precision: 0.8221 - recall: 0.6209\n","Epoch 7: Validation Metrics:\n","loss: 0.5881944894790649\n","val_binary_accuracy: 0.8350668549537659\n","val_precision: 0.0758928582072258\n","val_recall: 0.53125\n","val_auc: 0.8110492825508118\n","val_prc_auc: 0.07571469247341156\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 474ms/step - auc: 0.7904 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.5883 - prc_auc: 0.8076 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.8110 - val_binary_accuracy: 0.8351 - val_f1: 0.1328 - val_loss: 0.5743 - val_prc_auc: 0.0757 - val_precision: 0.0759 - val_recall: 0.5312\n","Epoch 8/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7949 - binary_accuracy: 0.7291 - f1: 0.7063 - loss: 0.5802 - prc_auc: 0.8136 - precision: 0.8221 - recall: 0.6209\n","Epoch 8: Validation Metrics:\n","loss: 0.5805858373641968\n","val_binary_accuracy: 0.8350668549537659\n","val_precision: 0.0758928582072258\n","val_recall: 0.53125\n","val_auc: 0.8148187398910522\n","val_prc_auc: 0.07735147327184677\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - auc: 0.7950 - binary_accuracy: 0.7293 - f1: 0.7049 - loss: 0.5802 - prc_auc: 0.8119 - precision: 0.8201 - recall: 0.6197 - val_auc: 0.8148 - val_binary_accuracy: 0.8351 - val_f1: 0.1328 - val_loss: 0.5681 - val_prc_auc: 0.0774 - val_precision: 0.0759 - val_recall: 0.5312\n","Starting training for label: 8\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - auc: 0.5605 - binary_accuracy: 0.5134 - f1: 0.0781 - loss: 0.6916 - prc_auc: 0.5622 - precision: 0.3551 - recall: 0.0448  \n","Epoch 1: Validation Metrics:\n","loss: 0.6834548115730286\n","val_binary_accuracy: 0.8699851632118225\n","val_precision: 0.12209302186965942\n","val_recall: 0.46666666865348816\n","val_auc: 0.7570928931236267\n","val_prc_auc: 0.1005389392375946\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8s/step - auc: 0.5696 - binary_accuracy: 0.5173 - f1: 0.0925 - loss: 0.6910 - prc_auc: 0.5709 - precision: 0.3931 - recall: 0.0535 - val_auc: 0.7571 - val_binary_accuracy: 0.8700 - val_f1: 0.1935 - val_loss: 0.6042 - val_prc_auc: 0.1005 - val_precision: 0.1221 - val_recall: 0.4667\n","Epoch 2/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7205 - binary_accuracy: 0.6716 - f1: 0.6025 - loss: 0.6646 - prc_auc: 0.7334 - precision: 0.7702 - recall: 0.4956\n","Epoch 2: Validation Metrics:\n","loss: 0.6550549268722534\n","val_binary_accuracy: 0.8580980896949768\n","val_precision: 0.11578947305679321\n","val_recall: 0.4888888895511627\n","val_auc: 0.7686566114425659\n","val_prc_auc: 0.09990306943655014\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 324ms/step - auc: 0.7240 - binary_accuracy: 0.6759 - f1: 0.6082 - loss: 0.6632 - prc_auc: 0.7359 - precision: 0.7745 - recall: 0.5014 - val_auc: 0.7687 - val_binary_accuracy: 0.8581 - val_f1: 0.1872 - val_loss: 0.5625 - val_prc_auc: 0.0999 - val_precision: 0.1158 - val_recall: 0.4889\n","Epoch 3/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7202 - binary_accuracy: 0.6701 - f1: 0.6129 - loss: 0.6484 - prc_auc: 0.7260 - precision: 0.7508 - recall: 0.5180\n","Epoch 3: Validation Metrics:\n","loss: 0.6370830535888672\n","val_binary_accuracy: 0.8551263213157654\n","val_precision: 0.11734694242477417\n","val_recall: 0.5111111402511597\n","val_auc: 0.768417477607727\n","val_prc_auc: 0.1029236689209938\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step - auc: 0.7241 - binary_accuracy: 0.6741 - f1: 0.6174 - loss: 0.6467 - prc_auc: 0.7304 - precision: 0.7556 - recall: 0.5221 - val_auc: 0.7684 - val_binary_accuracy: 0.8551 - val_f1: 0.1909 - val_loss: 0.5344 - val_prc_auc: 0.1029 - val_precision: 0.1173 - val_recall: 0.5111\n","Epoch 4/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7205 - binary_accuracy: 0.6701 - f1: 0.6129 - loss: 0.6379 - prc_auc: 0.7225 - precision: 0.7508 - recall: 0.5180\n","Epoch 4: Validation Metrics:\n","loss: 0.6248860359191895\n","val_binary_accuracy: 0.8551263213157654\n","val_precision: 0.11734694242477417\n","val_recall: 0.5111111402511597\n","val_auc: 0.773780882358551\n","val_prc_auc: 0.10262910276651382\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 320ms/step - auc: 0.7245 - binary_accuracy: 0.6741 - f1: 0.6174 - loss: 0.6359 - prc_auc: 0.7273 - precision: 0.7556 - recall: 0.5221 - val_auc: 0.7738 - val_binary_accuracy: 0.8551 - val_f1: 0.1909 - val_loss: 0.5174 - val_prc_auc: 0.1026 - val_precision: 0.1173 - val_recall: 0.5111\n","Epoch 5/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7210 - binary_accuracy: 0.6701 - f1: 0.6129 - loss: 0.6309 - prc_auc: 0.7251 - precision: 0.7508 - recall: 0.5180\n","Epoch 5: Validation Metrics:\n","loss: 0.6163709759712219\n","val_binary_accuracy: 0.8551263213157654\n","val_precision: 0.11734694242477417\n","val_recall: 0.5111111402511597\n","val_auc: 0.7747373580932617\n","val_prc_auc: 0.10086656361818314\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 323ms/step - auc: 0.7254 - binary_accuracy: 0.6741 - f1: 0.6174 - loss: 0.6287 - prc_auc: 0.7296 - precision: 0.7556 - recall: 0.5221 - val_auc: 0.7747 - val_binary_accuracy: 0.8551 - val_f1: 0.1909 - val_loss: 0.5085 - val_prc_auc: 0.1009 - val_precision: 0.1173 - val_recall: 0.5111\n","Epoch 6/20\n","\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7227 - binary_accuracy: 0.6701 - f1: 0.6129 - loss: 0.6261 - prc_auc: 0.7261 - precision: 0.7508 - recall: 0.5180\n","Epoch 6: Validation Metrics:\n","loss: 0.6102516651153564\n","val_binary_accuracy: 0.8543833494186401\n","val_precision: 0.11675126850605011\n","val_recall: 0.5111111402511597\n","val_auc: 0.7714834809303284\n","val_prc_auc: 0.10185828059911728\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 321ms/step - auc: 0.7269 - binary_accuracy: 0.6741 - f1: 0.6174 - loss: 0.6237 - prc_auc: 0.7300 - precision: 0.7556 - recall: 0.5221 - val_auc: 0.7715 - val_binary_accuracy: 0.8544 - val_f1: 0.1901 - val_loss: 0.5047 - val_prc_auc: 0.1019 - val_precision: 0.1168 - val_recall: 0.5111\n","Starting training for label: 9\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761ms/step - auc: 0.6497 - binary_accuracy: 0.6084 - f1: 0.5516 - loss: 0.6878 - prc_auc: 0.6194 - precision: 0.5979 - recall: 0.5241\n","Epoch 1: Validation Metrics:\n","loss: 0.6851732730865479\n","val_binary_accuracy: 0.8454680442810059\n","val_precision: 0.05970149114727974\n","val_recall: 0.3870967626571655\n","val_auc: 0.742855429649353\n","val_prc_auc: 0.05753886327147484\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5s/step - auc: 0.6529 - binary_accuracy: 0.6101 - f1: 0.5514 - loss: 0.6875 - prc_auc: 0.6259 - precision: 0.6073 - recall: 0.5170 - val_auc: 0.7429 - val_binary_accuracy: 0.8455 - val_f1: 0.1034 - val_loss: 0.6608 - val_prc_auc: 0.0575 - val_precision: 0.0597 - val_recall: 0.3871\n","Epoch 2/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7103 - binary_accuracy: 0.6176 - f1: 0.4323 - loss: 0.6763 - prc_auc: 0.6556 - precision: 0.6890 - recall: 0.3151\n","Epoch 2: Validation Metrics:\n","loss: 0.6731534600257874\n","val_binary_accuracy: 0.8439821600914001\n","val_precision: 0.06341463327407837\n","val_recall: 0.4193548262119293\n","val_auc: 0.7405862808227539\n","val_prc_auc: 0.05712178349494934\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 473ms/step - auc: 0.7122 - binary_accuracy: 0.6187 - f1: 0.4392 - loss: 0.6759 - prc_auc: 0.6623 - precision: 0.6976 - recall: 0.3207 - val_auc: 0.7406 - val_binary_accuracy: 0.8440 - val_f1: 0.1102 - val_loss: 0.6460 - val_prc_auc: 0.0571 - val_precision: 0.0634 - val_recall: 0.4194\n","Epoch 3/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7208 - binary_accuracy: 0.6201 - f1: 0.4378 - loss: 0.6687 - prc_auc: 0.6723 - precision: 0.6920 - recall: 0.3203\n","Epoch 3: Validation Metrics:\n","loss: 0.6640258431434631\n","val_binary_accuracy: 0.8424962759017944\n","val_precision: 0.06280193477869034\n","val_recall: 0.4193548262119293\n","val_auc: 0.7310191988945007\n","val_prc_auc: 0.05669990926980972\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - auc: 0.7224 - binary_accuracy: 0.6213 - f1: 0.4450 - loss: 0.6681 - prc_auc: 0.6787 - precision: 0.7007 - recall: 0.3262 - val_auc: 0.7310 - val_binary_accuracy: 0.8425 - val_f1: 0.1092 - val_loss: 0.6377 - val_prc_auc: 0.0567 - val_precision: 0.0628 - val_recall: 0.4194\n","Epoch 4/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7087 - binary_accuracy: 0.6201 - f1: 0.4378 - loss: 0.6631 - prc_auc: 0.6587 - precision: 0.6920 - recall: 0.3203\n","Epoch 4: Validation Metrics:\n","loss: 0.6568123698234558\n","val_binary_accuracy: 0.8380386233329773\n","val_precision: 0.061032865196466446\n","val_recall: 0.4193548262119293\n","val_auc: 0.7299153804779053\n","val_prc_auc: 0.05506695806980133\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 471ms/step - auc: 0.7112 - binary_accuracy: 0.6213 - f1: 0.4450 - loss: 0.6624 - prc_auc: 0.6651 - precision: 0.7007 - recall: 0.3262 - val_auc: 0.7299 - val_binary_accuracy: 0.8380 - val_f1: 0.1066 - val_loss: 0.6336 - val_prc_auc: 0.0551 - val_precision: 0.0610 - val_recall: 0.4194\n","Epoch 5/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7041 - binary_accuracy: 0.6201 - f1: 0.4433 - loss: 0.6590 - prc_auc: 0.6618 - precision: 0.6858 - recall: 0.3278\n","Epoch 5: Validation Metrics:\n","loss: 0.6510169506072998\n","val_binary_accuracy: 0.8350668549537659\n","val_precision: 0.059907834976911545\n","val_recall: 0.4193548262119293\n","val_auc: 0.7305654287338257\n","val_prc_auc: 0.05708356201648712\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 469ms/step - auc: 0.7069 - binary_accuracy: 0.6213 - f1: 0.4505 - loss: 0.6581 - prc_auc: 0.6683 - precision: 0.6943 - recall: 0.3337 - val_auc: 0.7306 - val_binary_accuracy: 0.8351 - val_f1: 0.1048 - val_loss: 0.6326 - val_prc_auc: 0.0571 - val_precision: 0.0599 - val_recall: 0.4194\n","Epoch 6/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7059 - binary_accuracy: 0.6153 - f1: 0.4403 - loss: 0.6558 - prc_auc: 0.6673 - precision: 0.6717 - recall: 0.3278\n","Epoch 6: Validation Metrics:\n","loss: 0.6462740302085876\n","val_binary_accuracy: 0.8335809707641602\n","val_precision: 0.05936073139309883\n","val_recall: 0.4193548262119293\n","val_auc: 0.7285170555114746\n","val_prc_auc: 0.08668334782123566\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - auc: 0.7087 - binary_accuracy: 0.6166 - f1: 0.4475 - loss: 0.6547 - prc_auc: 0.6731 - precision: 0.6804 - recall: 0.3337 - val_auc: 0.7285 - val_binary_accuracy: 0.8336 - val_f1: 0.1040 - val_loss: 0.6332 - val_prc_auc: 0.0867 - val_precision: 0.0594 - val_recall: 0.4194\n","Epoch 7/20\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - auc: 0.7074 - binary_accuracy: 0.6148 - f1: 0.4406 - loss: 0.6534 - prc_auc: 0.6636 - precision: 0.6692 - recall: 0.3288\n","Epoch 7: Validation Metrics:\n","loss: 0.6423513293266296\n","val_binary_accuracy: 0.8335809707641602\n","val_precision: 0.05936073139309883\n","val_recall: 0.4193548262119293\n","val_auc: 0.7273274064064026\n","val_prc_auc: 0.06364229321479797\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - auc: 0.7107 - binary_accuracy: 0.6161 - f1: 0.4483 - loss: 0.6521 - prc_auc: 0.6701 - precision: 0.6774 - recall: 0.3355 - val_auc: 0.7273 - val_binary_accuracy: 0.8336 - val_f1: 0.1040 - val_loss: 0.6346 - val_prc_auc: 0.0636 - val_precision: 0.0594 - val_recall: 0.4194\n","Starting training for label: 10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - auc: 0.5096 - binary_accuracy: 0.5147 - f1: 0.3260 - loss: 0.6922 - prc_auc: 0.4554 - precision: 0.4588 - recall: 0.2812\n","Epoch 1: Validation Metrics:\n","loss: 0.6904188990592957\n","val_binary_accuracy: 0.38335809111595154\n","val_precision: 0.05737704783678055\n","val_recall: 0.662162184715271\n","val_auc: 0.5740746259689331\n","val_prc_auc: 0.08140554279088974\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - auc: 0.5118 - binary_accuracy: 0.5157 - f1: 0.3300 - loss: 0.6921 - prc_auc: 0.4602 - precision: 0.4640 - recall: 0.2830 - val_auc: 0.5741 - val_binary_accuracy: 0.3834 - val_f1: 0.1056 - val_loss: 0.6941 - val_prc_auc: 0.0814 - val_precision: 0.0574 - val_recall: 0.6622\n","Epoch 2/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6737 - binary_accuracy: 0.5787 - f1: 0.6211 - loss: 0.6791 - prc_auc: 0.6320 - precision: 0.5177 - recall: 0.7818\n","Epoch 2: Validation Metrics:\n","loss: 0.6768972873687744\n","val_binary_accuracy: 0.31797918677330017\n","val_precision: 0.052966102957725525\n","val_recall: 0.6756756901741028\n","val_auc: 0.5626593232154846\n","val_prc_auc: 0.08679566532373428\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - auc: 0.6737 - binary_accuracy: 0.5805 - f1: 0.6257 - loss: 0.6788 - prc_auc: 0.6347 - precision: 0.5228 - recall: 0.7843 - val_auc: 0.5627 - val_binary_accuracy: 0.3180 - val_f1: 0.0982 - val_loss: 0.7215 - val_prc_auc: 0.0868 - val_precision: 0.0530 - val_recall: 0.6757\n","Epoch 3/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6743 - binary_accuracy: 0.5766 - f1: 0.6321 - loss: 0.6740 - prc_auc: 0.6293 - precision: 0.5172 - recall: 0.8230\n","Epoch 3: Validation Metrics:\n","loss: 0.6701498031616211\n","val_binary_accuracy: 0.3417533338069916\n","val_precision: 0.05482456088066101\n","val_recall: 0.6756756901741028\n","val_auc: 0.5550898313522339\n","val_prc_auc: 0.08680018037557602\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6741 - binary_accuracy: 0.5783 - f1: 0.6357 - loss: 0.6736 - prc_auc: 0.6325 - precision: 0.5219 - recall: 0.8224 - val_auc: 0.5551 - val_binary_accuracy: 0.3418 - val_f1: 0.1014 - val_loss: 0.7173 - val_prc_auc: 0.0868 - val_precision: 0.0548 - val_recall: 0.6757\n","Epoch 4/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6750 - binary_accuracy: 0.5834 - f1: 0.6320 - loss: 0.6672 - prc_auc: 0.6286 - precision: 0.5229 - recall: 0.8097\n","Epoch 4: Validation Metrics:\n","loss: 0.6644189357757568\n","val_binary_accuracy: 0.37147101759910583\n","val_precision: 0.05632184073328972\n","val_recall: 0.662162184715271\n","val_auc: 0.558452308177948\n","val_prc_auc: 0.09508121013641357\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6748 - binary_accuracy: 0.5854 - f1: 0.6357 - loss: 0.6669 - prc_auc: 0.6323 - precision: 0.5281 - recall: 0.8087 - val_auc: 0.5585 - val_binary_accuracy: 0.3715 - val_f1: 0.1038 - val_loss: 0.7063 - val_prc_auc: 0.0951 - val_precision: 0.0563 - val_recall: 0.6622\n","Epoch 5/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6780 - binary_accuracy: 0.5790 - f1: 0.6188 - loss: 0.6609 - prc_auc: 0.6270 - precision: 0.5201 - recall: 0.7726\n","Epoch 5: Validation Metrics:\n","loss: 0.6595498323440552\n","val_binary_accuracy: 0.38855868577957153\n","val_precision: 0.05680473521351814\n","val_recall: 0.6486486196517944\n","val_auc: 0.5572996139526367\n","val_prc_auc: 0.0891939178109169\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - auc: 0.6778 - binary_accuracy: 0.5818 - f1: 0.6234 - loss: 0.6608 - prc_auc: 0.6311 - precision: 0.5261 - recall: 0.7733 - val_auc: 0.5573 - val_binary_accuracy: 0.3886 - val_f1: 0.1045 - val_loss: 0.7006 - val_prc_auc: 0.0892 - val_precision: 0.0568 - val_recall: 0.6486\n","Epoch 6/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6807 - binary_accuracy: 0.6024 - f1: 0.6293 - loss: 0.6561 - prc_auc: 0.6276 - precision: 0.5397 - recall: 0.7636\n","Epoch 6: Validation Metrics:\n","loss: 0.6556586027145386\n","val_binary_accuracy: 0.4197622537612915\n","val_precision: 0.05867665261030197\n","val_recall: 0.6351351141929626\n","val_auc: 0.5588932037353516\n","val_prc_auc: 0.09487530589103699\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6805 - binary_accuracy: 0.6042 - f1: 0.6332 - loss: 0.6561 - prc_auc: 0.6317 - precision: 0.5450 - recall: 0.7639 - val_auc: 0.5589 - val_binary_accuracy: 0.4198 - val_f1: 0.1074 - val_loss: 0.6970 - val_prc_auc: 0.0949 - val_precision: 0.0587 - val_recall: 0.6351\n","Epoch 7/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6854 - binary_accuracy: 0.6127 - f1: 0.6265 - loss: 0.6524 - prc_auc: 0.6367 - precision: 0.5509 - recall: 0.7350\n","Epoch 7: Validation Metrics:\n","loss: 0.652476966381073\n","val_binary_accuracy: 0.4338781535625458\n","val_precision: 0.058974359184503555\n","val_recall: 0.6216216087341309\n","val_auc: 0.5583726167678833\n","val_prc_auc: 0.08879799395799637\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6852 - binary_accuracy: 0.6138 - f1: 0.6300 - loss: 0.6524 - prc_auc: 0.6407 - precision: 0.5559 - recall: 0.7351 - val_auc: 0.5584 - val_binary_accuracy: 0.4339 - val_f1: 0.1077 - val_loss: 0.6937 - val_prc_auc: 0.0888 - val_precision: 0.0590 - val_recall: 0.6216\n","Epoch 8/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6877 - binary_accuracy: 0.6256 - f1: 0.6331 - loss: 0.6491 - prc_auc: 0.6402 - precision: 0.5637 - recall: 0.7312\n","Epoch 8: Validation Metrics:\n","loss: 0.6497081518173218\n","val_binary_accuracy: 0.43907874822616577\n","val_precision: 0.05721716582775116\n","val_recall: 0.5945945978164673\n","val_auc: 0.5609542727470398\n","val_prc_auc: 0.08681881427764893\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - auc: 0.6875 - binary_accuracy: 0.6264 - f1: 0.6365 - loss: 0.6492 - prc_auc: 0.6439 - precision: 0.5685 - recall: 0.7313 - val_auc: 0.5610 - val_binary_accuracy: 0.4391 - val_f1: 0.1044 - val_loss: 0.6913 - val_prc_auc: 0.0868 - val_precision: 0.0572 - val_recall: 0.5946\n","Epoch 9/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6904 - binary_accuracy: 0.6215 - f1: 0.6278 - loss: 0.6464 - prc_auc: 0.6429 - precision: 0.5607 - recall: 0.7226\n","Epoch 9: Validation Metrics:\n","loss: 0.6472720503807068\n","val_binary_accuracy: 0.4509658217430115\n","val_precision: 0.05725698918104172\n","val_recall: 0.5810810923576355\n","val_auc: 0.5616022944450378\n","val_prc_auc: 0.09126543998718262\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6901 - binary_accuracy: 0.6222 - f1: 0.6311 - loss: 0.6464 - prc_auc: 0.6464 - precision: 0.5655 - recall: 0.7225 - val_auc: 0.5616 - val_binary_accuracy: 0.4510 - val_f1: 0.1042 - val_loss: 0.6889 - val_prc_auc: 0.0913 - val_precision: 0.0573 - val_recall: 0.5811\n","Epoch 10/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6922 - binary_accuracy: 0.6204 - f1: 0.6249 - loss: 0.6438 - prc_auc: 0.6454 - precision: 0.5608 - recall: 0.7156\n","Epoch 10: Validation Metrics:\n","loss: 0.6450235843658447\n","val_binary_accuracy: 0.4591381847858429\n","val_precision: 0.05810810625553131\n","val_recall: 0.5810810923576355\n","val_auc: 0.5643326044082642\n","val_prc_auc: 0.09345922619104385\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6919 - binary_accuracy: 0.6209 - f1: 0.6278 - loss: 0.6439 - prc_auc: 0.6488 - precision: 0.5654 - recall: 0.7149 - val_auc: 0.5643 - val_binary_accuracy: 0.4591 - val_f1: 0.1057 - val_loss: 0.6877 - val_prc_auc: 0.0935 - val_precision: 0.0581 - val_recall: 0.5811\n","Epoch 11/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6952 - binary_accuracy: 0.6238 - f1: 0.6244 - loss: 0.6417 - prc_auc: 0.6477 - precision: 0.5650 - recall: 0.7080\n","Epoch 11: Validation Metrics:\n","loss: 0.6429784893989563\n","val_binary_accuracy: 0.4658246636390686\n","val_precision: 0.05761316791176796\n","val_recall: 0.5675675868988037\n","val_auc: 0.5652568936347961\n","val_prc_auc: 0.09335371106863022\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 225ms/step - auc: 0.6950 - binary_accuracy: 0.6241 - f1: 0.6273 - loss: 0.6418 - prc_auc: 0.6513 - precision: 0.5696 - recall: 0.7074 - val_auc: 0.5653 - val_binary_accuracy: 0.4658 - val_f1: 0.1046 - val_loss: 0.6863 - val_prc_auc: 0.0934 - val_precision: 0.0576 - val_recall: 0.5676\n","Epoch 12/20\n","\u001b[1m18/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6986 - binary_accuracy: 0.6239 - f1: 0.6242 - loss: 0.6396 - prc_auc: 0.6516 - precision: 0.5653 - recall: 0.7072\n","Epoch 12: Validation Metrics:\n","loss: 0.6410331130027771\n","val_binary_accuracy: 0.4777117371559143\n","val_precision: 0.05890602990984917\n","val_recall: 0.5675675868988037\n","val_auc: 0.5661492943763733\n","val_prc_auc: 0.09201421588659286\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 224ms/step - auc: 0.6982 - binary_accuracy: 0.6244 - f1: 0.6271 - loss: 0.6398 - prc_auc: 0.6550 - precision: 0.5701 - recall: 0.7063 - val_auc: 0.5661 - val_binary_accuracy: 0.4777 - val_f1: 0.1067 - val_loss: 0.6852 - val_prc_auc: 0.0920 - val_precision: 0.0589 - val_recall: 0.5676\n","Starting training for label: 11\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - auc: 0.5818 - binary_accuracy: 0.5481 - f1: 0.6686 - loss: 0.6892 - prc_auc: 0.5685 - precision: 0.5338 - recall: 0.8953\n","Epoch 1: Validation Metrics:\n","loss: 0.6862813234329224\n","val_binary_accuracy: 0.4487369954586029\n","val_precision: 0.14407815039157867\n","val_recall: 0.7421383857727051\n","val_auc: 0.6282049417495728\n","val_prc_auc: 0.17848166823387146\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 925ms/step - auc: 0.5824 - binary_accuracy: 0.5483 - f1: 0.6686 - loss: 0.6892 - prc_auc: 0.5692 - precision: 0.5338 - recall: 0.8949 - val_auc: 0.6282 - val_binary_accuracy: 0.4487 - val_f1: 0.2413 - val_loss: 0.6982 - val_prc_auc: 0.1785 - val_precision: 0.1441 - val_recall: 0.7421\n","Epoch 2/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6814 - binary_accuracy: 0.6089 - f1: 0.6644 - loss: 0.6731 - prc_auc: 0.6828 - precision: 0.5906 - recall: 0.7602\n","Epoch 2: Validation Metrics:\n","loss: 0.6722832322120667\n","val_binary_accuracy: 0.518573522567749\n","val_precision: 0.15417255461215973\n","val_recall: 0.6855345964431763\n","val_auc: 0.627926766872406\n","val_prc_auc: 0.176310196518898\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.6809 - binary_accuracy: 0.6087 - f1: 0.6642 - loss: 0.6731 - prc_auc: 0.6820 - precision: 0.5903 - recall: 0.7601 - val_auc: 0.6279 - val_binary_accuracy: 0.5186 - val_f1: 0.2517 - val_loss: 0.6769 - val_prc_auc: 0.1763 - val_precision: 0.1542 - val_recall: 0.6855\n","Epoch 3/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6887 - binary_accuracy: 0.6299 - f1: 0.6696 - loss: 0.6624 - prc_auc: 0.6885 - precision: 0.6145 - recall: 0.7362\n","Epoch 3: Validation Metrics:\n","loss: 0.6628629565238953\n","val_binary_accuracy: 0.5490341782569885\n","val_precision: 0.16366367042064667\n","val_recall: 0.6855345964431763\n","val_auc: 0.6292726397514343\n","val_prc_auc: 0.1777155101299286\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6878 - binary_accuracy: 0.6294 - f1: 0.6692 - loss: 0.6624 - prc_auc: 0.6870 - precision: 0.6136 - recall: 0.7364 - val_auc: 0.6293 - val_binary_accuracy: 0.5490 - val_f1: 0.2642 - val_loss: 0.6648 - val_prc_auc: 0.1777 - val_precision: 0.1637 - val_recall: 0.6855\n","Epoch 4/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6929 - binary_accuracy: 0.6493 - f1: 0.6794 - loss: 0.6540 - prc_auc: 0.6902 - precision: 0.6366 - recall: 0.7290\n","Epoch 4: Validation Metrics:\n","loss: 0.655677080154419\n","val_binary_accuracy: 0.5661218166351318\n","val_precision: 0.16640502214431763\n","val_recall: 0.6666666865348816\n","val_auc: 0.6286817789077759\n","val_prc_auc: 0.17594686150550842\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6921 - binary_accuracy: 0.6485 - f1: 0.6787 - loss: 0.6541 - prc_auc: 0.6888 - precision: 0.6353 - recall: 0.7292 - val_auc: 0.6287 - val_binary_accuracy: 0.5661 - val_f1: 0.2663 - val_loss: 0.6566 - val_prc_auc: 0.1759 - val_precision: 0.1664 - val_recall: 0.6667\n","Epoch 5/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6949 - binary_accuracy: 0.6594 - f1: 0.6781 - loss: 0.6473 - prc_auc: 0.6906 - precision: 0.6554 - recall: 0.7036\n","Epoch 5: Validation Metrics:\n","loss: 0.6500255465507507\n","val_binary_accuracy: 0.580980658531189\n","val_precision: 0.16748768091201782\n","val_recall: 0.6415094137191772\n","val_auc: 0.6301892399787903\n","val_prc_auc: 0.17842844128608704\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6942 - binary_accuracy: 0.6584 - f1: 0.6774 - loss: 0.6474 - prc_auc: 0.6893 - precision: 0.6538 - recall: 0.7040 - val_auc: 0.6302 - val_binary_accuracy: 0.5810 - val_f1: 0.2656 - val_loss: 0.6511 - val_prc_auc: 0.1784 - val_precision: 0.1675 - val_recall: 0.6415\n","Epoch 6/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6979 - binary_accuracy: 0.6658 - f1: 0.6776 - loss: 0.6417 - prc_auc: 0.6917 - precision: 0.6680 - recall: 0.6889\n","Epoch 6: Validation Metrics:\n","loss: 0.6454295516014099\n","val_binary_accuracy: 0.5928677320480347\n","val_precision: 0.16638079285621643\n","val_recall: 0.6100628972053528\n","val_auc: 0.6312648057937622\n","val_prc_auc: 0.1808699071407318\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6972 - binary_accuracy: 0.6646 - f1: 0.6768 - loss: 0.6418 - prc_auc: 0.6905 - precision: 0.6660 - recall: 0.6893 - val_auc: 0.6313 - val_binary_accuracy: 0.5929 - val_f1: 0.2615 - val_loss: 0.6465 - val_prc_auc: 0.1809 - val_precision: 0.1664 - val_recall: 0.6101\n","Epoch 7/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7020 - binary_accuracy: 0.6696 - f1: 0.6761 - loss: 0.6372 - prc_auc: 0.6941 - precision: 0.6774 - recall: 0.6765\n","Epoch 7: Validation Metrics:\n","loss: 0.6417936086654663\n","val_binary_accuracy: 0.6040118932723999\n","val_precision: 0.16843971610069275\n","val_recall: 0.597484290599823\n","val_auc: 0.6328914165496826\n","val_prc_auc: 0.18187673389911652\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.7012 - binary_accuracy: 0.6685 - f1: 0.6754 - loss: 0.6375 - prc_auc: 0.6929 - precision: 0.6752 - recall: 0.6772 - val_auc: 0.6329 - val_binary_accuracy: 0.6040 - val_f1: 0.2628 - val_loss: 0.6442 - val_prc_auc: 0.1819 - val_precision: 0.1684 - val_recall: 0.5975\n","Epoch 8/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7052 - binary_accuracy: 0.6702 - f1: 0.6756 - loss: 0.6336 - prc_auc: 0.6966 - precision: 0.6790 - recall: 0.6738\n","Epoch 8: Validation Metrics:\n","loss: 0.6386963129043579\n","val_binary_accuracy: 0.6121842265129089\n","val_precision: 0.1717902421951294\n","val_recall: 0.597484290599823\n","val_auc: 0.633744478225708\n","val_prc_auc: 0.18552446365356445\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.7044 - binary_accuracy: 0.6691 - f1: 0.6749 - loss: 0.6338 - prc_auc: 0.6954 - precision: 0.6769 - recall: 0.6745 - val_auc: 0.6337 - val_binary_accuracy: 0.6122 - val_f1: 0.2669 - val_loss: 0.6426 - val_prc_auc: 0.1855 - val_precision: 0.1718 - val_recall: 0.5975\n","Epoch 9/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7094 - binary_accuracy: 0.6757 - f1: 0.6784 - loss: 0.6304 - prc_auc: 0.6992 - precision: 0.6878 - recall: 0.6708\n","Epoch 9: Validation Metrics:\n","loss: 0.6359076499938965\n","val_binary_accuracy: 0.6166418790817261\n","val_precision: 0.17247706651687622\n","val_recall: 0.5911949872970581\n","val_auc: 0.6355460286140442\n","val_prc_auc: 0.18756739795207977\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.7086 - binary_accuracy: 0.6745 - f1: 0.6776 - loss: 0.6307 - prc_auc: 0.6980 - precision: 0.6856 - recall: 0.6714 - val_auc: 0.6355 - val_binary_accuracy: 0.6166 - val_f1: 0.2670 - val_loss: 0.6406 - val_prc_auc: 0.1876 - val_precision: 0.1725 - val_recall: 0.5912\n","Epoch 10/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7130 - binary_accuracy: 0.6755 - f1: 0.6759 - loss: 0.6276 - prc_auc: 0.7015 - precision: 0.6898 - recall: 0.6641\n","Epoch 10: Validation Metrics:\n","loss: 0.6334189772605896\n","val_binary_accuracy: 0.6196136474609375\n","val_precision: 0.17254173755645752\n","val_recall: 0.5849056839942932\n","val_auc: 0.6363645792007446\n","val_prc_auc: 0.18808336555957794\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.7122 - binary_accuracy: 0.6744 - f1: 0.6752 - loss: 0.6279 - prc_auc: 0.7003 - precision: 0.6877 - recall: 0.6647 - val_auc: 0.6364 - val_binary_accuracy: 0.6196 - val_f1: 0.2665 - val_loss: 0.6391 - val_prc_auc: 0.1881 - val_precision: 0.1725 - val_recall: 0.5849\n","Epoch 11/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7168 - binary_accuracy: 0.6789 - f1: 0.6770 - loss: 0.6250 - prc_auc: 0.7042 - precision: 0.6962 - recall: 0.6604\n","Epoch 11: Validation Metrics:\n","loss: 0.6311021447181702\n","val_binary_accuracy: 0.6203566193580627\n","val_precision: 0.17164179682731628\n","val_recall: 0.5786163806915283\n","val_auc: 0.6384787559509277\n","val_prc_auc: 0.18960312008857727\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.7160 - binary_accuracy: 0.6777 - f1: 0.6762 - loss: 0.6253 - prc_auc: 0.7029 - precision: 0.6938 - recall: 0.6609 - val_auc: 0.6385 - val_binary_accuracy: 0.6204 - val_f1: 0.2647 - val_loss: 0.6379 - val_prc_auc: 0.1896 - val_precision: 0.1716 - val_recall: 0.5786\n","Epoch 12/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7196 - binary_accuracy: 0.6775 - f1: 0.6739 - loss: 0.6226 - prc_auc: 0.7066 - precision: 0.6969 - recall: 0.6539\n","Epoch 12: Validation Metrics:\n","loss: 0.6289516687393188\n","val_binary_accuracy: 0.6248142719268799\n","val_precision: 0.16984732449054718\n","val_recall: 0.5597484111785889\n","val_auc: 0.6387568712234497\n","val_prc_auc: 0.18986065685749054\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.7189 - binary_accuracy: 0.6763 - f1: 0.6732 - loss: 0.6229 - prc_auc: 0.7054 - precision: 0.6945 - recall: 0.6547 - val_auc: 0.6388 - val_binary_accuracy: 0.6248 - val_f1: 0.2606 - val_loss: 0.6369 - val_prc_auc: 0.1899 - val_precision: 0.1698 - val_recall: 0.5597\n","Epoch 13/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7222 - binary_accuracy: 0.6752 - f1: 0.6695 - loss: 0.6205 - prc_auc: 0.7082 - precision: 0.6966 - recall: 0.6460\n","Epoch 13: Validation Metrics:\n","loss: 0.6269354224205017\n","val_binary_accuracy: 0.6263001561164856\n","val_precision: 0.1704980880022049\n","val_recall: 0.5597484111785889\n","val_auc: 0.6400841474533081\n","val_prc_auc: 0.19227519631385803\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - auc: 0.7219 - binary_accuracy: 0.6746 - f1: 0.6692 - loss: 0.6207 - prc_auc: 0.7076 - precision: 0.6955 - recall: 0.6464 - val_auc: 0.6401 - val_binary_accuracy: 0.6263 - val_f1: 0.2614 - val_loss: 0.6364 - val_prc_auc: 0.1923 - val_precision: 0.1705 - val_recall: 0.5597\n","Epoch 14/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7261 - binary_accuracy: 0.6743 - f1: 0.6667 - loss: 0.6183 - prc_auc: 0.7114 - precision: 0.6989 - recall: 0.6389\n","Epoch 14: Validation Metrics:\n","loss: 0.6249828934669495\n","val_binary_accuracy: 0.6255571842193604\n","val_precision: 0.16763006150722504\n","val_recall: 0.5471698045730591\n","val_auc: 0.6411464810371399\n","val_prc_auc: 0.1935814619064331\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.7253 - binary_accuracy: 0.6732 - f1: 0.6661 - loss: 0.6186 - prc_auc: 0.7103 - precision: 0.6965 - recall: 0.6400 - val_auc: 0.6411 - val_binary_accuracy: 0.6256 - val_f1: 0.2566 - val_loss: 0.6355 - val_prc_auc: 0.1936 - val_precision: 0.1676 - val_recall: 0.5472\n","Starting training for label: 12\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - auc: 0.5524 - binary_accuracy: 0.5307 - f1: 0.5757 - loss: 0.6883 - prc_auc: 0.5378 - precision: 0.5205 - recall: 0.6502\n","Epoch 1: Validation Metrics:\n","loss: 0.6796839833259583\n","val_binary_accuracy: 0.5089153051376343\n","val_precision: 0.38404256105422974\n","val_recall: 0.8148984313011169\n","val_auc: 0.6445945501327515\n","val_prc_auc: 0.4647180438041687\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 372ms/step - auc: 0.5529 - binary_accuracy: 0.5311 - f1: 0.5761 - loss: 0.6882 - prc_auc: 0.5383 - precision: 0.5209 - recall: 0.6507 - val_auc: 0.6446 - val_binary_accuracy: 0.5089 - val_f1: 0.5221 - val_loss: 0.6867 - val_prc_auc: 0.4647 - val_precision: 0.3840 - val_recall: 0.8149\n","Epoch 2/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6511 - binary_accuracy: 0.5927 - f1: 0.6464 - loss: 0.6666 - prc_auc: 0.6273 - precision: 0.5656 - recall: 0.7558\n","Epoch 2: Validation Metrics:\n","loss: 0.659728467464447\n","val_binary_accuracy: 0.5349182486534119\n","val_precision: 0.3949483335018158\n","val_recall: 0.7765237092971802\n","val_auc: 0.6585297584533691\n","val_prc_auc: 0.48282361030578613\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.6512 - binary_accuracy: 0.5928 - f1: 0.6465 - loss: 0.6665 - prc_auc: 0.6273 - precision: 0.5657 - recall: 0.7559 - val_auc: 0.6585 - val_binary_accuracy: 0.5349 - val_f1: 0.5236 - val_loss: 0.6750 - val_prc_auc: 0.4828 - val_precision: 0.3949 - val_recall: 0.7765\n","Epoch 3/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6623 - binary_accuracy: 0.6127 - f1: 0.6479 - loss: 0.6568 - prc_auc: 0.6400 - precision: 0.5879 - recall: 0.7236\n","Epoch 3: Validation Metrics:\n","loss: 0.6497390866279602\n","val_binary_accuracy: 0.5653789043426514\n","val_precision: 0.4116915464401245\n","val_recall: 0.747178316116333\n","val_auc: 0.6688001751899719\n","val_prc_auc: 0.49132081866264343\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.6624 - binary_accuracy: 0.6128 - f1: 0.6480 - loss: 0.6568 - prc_auc: 0.6401 - precision: 0.5880 - recall: 0.7237 - val_auc: 0.6688 - val_binary_accuracy: 0.5654 - val_f1: 0.5309 - val_loss: 0.6663 - val_prc_auc: 0.4913 - val_precision: 0.4117 - val_recall: 0.7472\n","Epoch 4/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6741 - binary_accuracy: 0.6250 - f1: 0.6445 - loss: 0.6493 - prc_auc: 0.6506 - precision: 0.6053 - recall: 0.6907\n","Epoch 4: Validation Metrics:\n","loss: 0.6422013640403748\n","val_binary_accuracy: 0.5876671671867371\n","val_precision: 0.42553192377090454\n","val_recall: 0.722347617149353\n","val_auc: 0.6778008937835693\n","val_prc_auc: 0.4998237192630768\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.6742 - binary_accuracy: 0.6251 - f1: 0.6447 - loss: 0.6492 - prc_auc: 0.6506 - precision: 0.6054 - recall: 0.6908 - val_auc: 0.6778 - val_binary_accuracy: 0.5877 - val_f1: 0.5356 - val_loss: 0.6594 - val_prc_auc: 0.4998 - val_precision: 0.4255 - val_recall: 0.7223\n","Epoch 5/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6837 - binary_accuracy: 0.6333 - f1: 0.6420 - loss: 0.6428 - prc_auc: 0.6598 - precision: 0.6185 - recall: 0.6684\n","Epoch 5: Validation Metrics:\n","loss: 0.6358217000961304\n","val_binary_accuracy: 0.6032689213752747\n","val_precision: 0.4365411400794983\n","val_recall: 0.7065462470054626\n","val_auc: 0.6849790811538696\n","val_prc_auc: 0.5037465691566467\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.6838 - binary_accuracy: 0.6333 - f1: 0.6421 - loss: 0.6427 - prc_auc: 0.6598 - precision: 0.6185 - recall: 0.6685 - val_auc: 0.6850 - val_binary_accuracy: 0.6033 - val_f1: 0.5397 - val_loss: 0.6531 - val_prc_auc: 0.5037 - val_precision: 0.4365 - val_recall: 0.7065\n","Epoch 6/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6928 - binary_accuracy: 0.6371 - f1: 0.6416 - loss: 0.6369 - prc_auc: 0.6687 - precision: 0.6249 - recall: 0.6602\n","Epoch 6: Validation Metrics:\n","loss: 0.6299322247505188\n","val_binary_accuracy: 0.6151559948921204\n","val_precision: 0.4466571807861328\n","val_recall: 0.7088035941123962\n","val_auc: 0.692266047000885\n","val_prc_auc: 0.5089378952980042\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.6929 - binary_accuracy: 0.6371 - f1: 0.6417 - loss: 0.6368 - prc_auc: 0.6688 - precision: 0.6249 - recall: 0.6605 - val_auc: 0.6923 - val_binary_accuracy: 0.6152 - val_f1: 0.5480 - val_loss: 0.6473 - val_prc_auc: 0.5089 - val_precision: 0.4467 - val_recall: 0.7088\n","Epoch 7/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7012 - binary_accuracy: 0.6376 - f1: 0.6380 - loss: 0.6314 - prc_auc: 0.6775 - precision: 0.6277 - recall: 0.6492\n","Epoch 7: Validation Metrics:\n","loss: 0.6245667934417725\n","val_binary_accuracy: 0.6248142719268799\n","val_precision: 0.4552023112773895\n","val_recall: 0.7110609412193298\n","val_auc: 0.698361873626709\n","val_prc_auc: 0.5154218673706055\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7013 - binary_accuracy: 0.6376 - f1: 0.6381 - loss: 0.6314 - prc_auc: 0.6776 - precision: 0.6278 - recall: 0.6495 - val_auc: 0.6984 - val_binary_accuracy: 0.6248 - val_f1: 0.5551 - val_loss: 0.6427 - val_prc_auc: 0.5154 - val_precision: 0.4552 - val_recall: 0.7111\n","Epoch 8/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7080 - binary_accuracy: 0.6416 - f1: 0.6419 - loss: 0.6264 - prc_auc: 0.6854 - precision: 0.6317 - recall: 0.6530\n","Epoch 8: Validation Metrics:\n","loss: 0.6196359992027283\n","val_binary_accuracy: 0.6307578086853027\n","val_precision: 0.4607558250427246\n","val_recall: 0.715575635433197\n","val_auc: 0.704198956489563\n","val_prc_auc: 0.5211309790611267\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7081 - binary_accuracy: 0.6417 - f1: 0.6421 - loss: 0.6264 - prc_auc: 0.6855 - precision: 0.6318 - recall: 0.6533 - val_auc: 0.7042 - val_binary_accuracy: 0.6308 - val_f1: 0.5606 - val_loss: 0.6383 - val_prc_auc: 0.5211 - val_precision: 0.4608 - val_recall: 0.7156\n","Epoch 9/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7145 - binary_accuracy: 0.6540 - f1: 0.6552 - loss: 0.6217 - prc_auc: 0.6926 - precision: 0.6430 - recall: 0.6684\n","Epoch 9: Validation Metrics:\n","loss: 0.6150161623954773\n","val_binary_accuracy: 0.6329866051673889\n","val_precision: 0.46277371048927307\n","val_recall: 0.715575635433197\n","val_auc: 0.7098147869110107\n","val_prc_auc: 0.5257191061973572\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7146 - binary_accuracy: 0.6540 - f1: 0.6554 - loss: 0.6216 - prc_auc: 0.6927 - precision: 0.6431 - recall: 0.6686 - val_auc: 0.7098 - val_binary_accuracy: 0.6330 - val_f1: 0.5621 - val_loss: 0.6347 - val_prc_auc: 0.5257 - val_precision: 0.4628 - val_recall: 0.7156\n","Epoch 10/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7208 - binary_accuracy: 0.6620 - f1: 0.6637 - loss: 0.6173 - prc_auc: 0.6996 - precision: 0.6503 - recall: 0.6781\n","Epoch 10: Validation Metrics:\n","loss: 0.6106942892074585\n","val_binary_accuracy: 0.6367013454437256\n","val_precision: 0.46607670187950134\n","val_recall: 0.7133182883262634\n","val_auc: 0.7143682241439819\n","val_prc_auc: 0.5290864109992981\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7209 - binary_accuracy: 0.6621 - f1: 0.6638 - loss: 0.6172 - prc_auc: 0.6997 - precision: 0.6504 - recall: 0.6782 - val_auc: 0.7144 - val_binary_accuracy: 0.6367 - val_f1: 0.5638 - val_loss: 0.6314 - val_prc_auc: 0.5291 - val_precision: 0.4661 - val_recall: 0.7133\n","Epoch 11/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7269 - binary_accuracy: 0.6647 - f1: 0.6666 - loss: 0.6132 - prc_auc: 0.7058 - precision: 0.6527 - recall: 0.6815\n","Epoch 11: Validation Metrics:\n","loss: 0.6067057847976685\n","val_binary_accuracy: 0.639673113822937\n","val_precision: 0.46893492341041565\n","val_recall: 0.715575635433197\n","val_auc: 0.718466579914093\n","val_prc_auc: 0.5321775078773499\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7269 - binary_accuracy: 0.6648 - f1: 0.6667 - loss: 0.6132 - prc_auc: 0.7059 - precision: 0.6528 - recall: 0.6817 - val_auc: 0.7185 - val_binary_accuracy: 0.6397 - val_f1: 0.5666 - val_loss: 0.6287 - val_prc_auc: 0.5322 - val_precision: 0.4689 - val_recall: 0.7156\n","Epoch 12/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7316 - binary_accuracy: 0.6695 - f1: 0.6720 - loss: 0.6095 - prc_auc: 0.7111 - precision: 0.6568 - recall: 0.6882\n","Epoch 12: Validation Metrics:\n","loss: 0.603014349937439\n","val_binary_accuracy: 0.6389301419258118\n","val_precision: 0.4683357775211334\n","val_recall: 0.7178329825401306\n","val_auc: 0.7225925922393799\n","val_prc_auc: 0.5364657640457153\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7317 - binary_accuracy: 0.6696 - f1: 0.6721 - loss: 0.6094 - prc_auc: 0.7112 - precision: 0.6568 - recall: 0.6884 - val_auc: 0.7226 - val_binary_accuracy: 0.6389 - val_f1: 0.5668 - val_loss: 0.6265 - val_prc_auc: 0.5365 - val_precision: 0.4683 - val_recall: 0.7178\n","Epoch 13/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7363 - binary_accuracy: 0.6701 - f1: 0.6724 - loss: 0.6060 - prc_auc: 0.7154 - precision: 0.6576 - recall: 0.6884\n","Epoch 13: Validation Metrics:\n","loss: 0.5995961427688599\n","val_binary_accuracy: 0.6441307663917542\n","val_precision: 0.4735293984413147\n","val_recall: 0.7268623113632202\n","val_auc: 0.7258573770523071\n","val_prc_auc: 0.537824273109436\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7364 - binary_accuracy: 0.6702 - f1: 0.6725 - loss: 0.6060 - prc_auc: 0.7155 - precision: 0.6577 - recall: 0.6885 - val_auc: 0.7259 - val_binary_accuracy: 0.6441 - val_f1: 0.5735 - val_loss: 0.6245 - val_prc_auc: 0.5378 - val_precision: 0.4735 - val_recall: 0.7269\n","Epoch 14/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7400 - binary_accuracy: 0.6745 - f1: 0.6764 - loss: 0.6029 - prc_auc: 0.7188 - precision: 0.6624 - recall: 0.6914\n","Epoch 14: Validation Metrics:\n","loss: 0.5964499115943909\n","val_binary_accuracy: 0.6419019103050232\n","val_precision: 0.47144949436187744\n","val_recall: 0.7268623113632202\n","val_auc: 0.7286208868026733\n","val_prc_auc: 0.5415434837341309\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7401 - binary_accuracy: 0.6746 - f1: 0.6765 - loss: 0.6028 - prc_auc: 0.7189 - precision: 0.6624 - recall: 0.6915 - val_auc: 0.7286 - val_binary_accuracy: 0.6419 - val_f1: 0.5719 - val_loss: 0.6229 - val_prc_auc: 0.5415 - val_precision: 0.4714 - val_recall: 0.7269\n","Epoch 15/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7432 - binary_accuracy: 0.6776 - f1: 0.6791 - loss: 0.5999 - prc_auc: 0.7218 - precision: 0.6655 - recall: 0.6937\n","Epoch 15: Validation Metrics:\n","loss: 0.5935050845146179\n","val_binary_accuracy: 0.6419019103050232\n","val_precision: 0.4712812900543213\n","val_recall: 0.722347617149353\n","val_auc: 0.7312082648277283\n","val_prc_auc: 0.542849063873291\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7433 - binary_accuracy: 0.6777 - f1: 0.6792 - loss: 0.5998 - prc_auc: 0.7219 - precision: 0.6656 - recall: 0.6938 - val_auc: 0.7312 - val_binary_accuracy: 0.6419 - val_f1: 0.5704 - val_loss: 0.6215 - val_prc_auc: 0.5428 - val_precision: 0.4713 - val_recall: 0.7223\n","Epoch 16/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7462 - binary_accuracy: 0.6805 - f1: 0.6827 - loss: 0.5971 - prc_auc: 0.7246 - precision: 0.6676 - recall: 0.6989\n","Epoch 16: Validation Metrics:\n","loss: 0.5906784534454346\n","val_binary_accuracy: 0.6433877944946289\n","val_precision: 0.4725925922393799\n","val_recall: 0.7200902700424194\n","val_auc: 0.7332080602645874\n","val_prc_auc: 0.5452155470848083\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7463 - binary_accuracy: 0.6805 - f1: 0.6828 - loss: 0.5971 - prc_auc: 0.7247 - precision: 0.6677 - recall: 0.6990 - val_auc: 0.7332 - val_binary_accuracy: 0.6434 - val_f1: 0.5707 - val_loss: 0.6205 - val_prc_auc: 0.5452 - val_precision: 0.4726 - val_recall: 0.7201\n","Epoch 17/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7491 - binary_accuracy: 0.6833 - f1: 0.6853 - loss: 0.5946 - prc_auc: 0.7266 - precision: 0.6708 - recall: 0.7007\n","Epoch 17: Validation Metrics:\n","loss: 0.5881058573722839\n","val_binary_accuracy: 0.6441307663917542\n","val_precision: 0.47337278723716736\n","val_recall: 0.722347617149353\n","val_auc: 0.735206663608551\n","val_prc_auc: 0.5462995171546936\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7492 - binary_accuracy: 0.6834 - f1: 0.6854 - loss: 0.5946 - prc_auc: 0.7267 - precision: 0.6709 - recall: 0.7009 - val_auc: 0.7352 - val_binary_accuracy: 0.6441 - val_f1: 0.5719 - val_loss: 0.6192 - val_prc_auc: 0.5463 - val_precision: 0.4734 - val_recall: 0.7223\n","Epoch 18/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7515 - binary_accuracy: 0.6879 - f1: 0.6896 - loss: 0.5923 - prc_auc: 0.7290 - precision: 0.6754 - recall: 0.7047\n","Epoch 18: Validation Metrics:\n","loss: 0.5857424736022949\n","val_binary_accuracy: 0.6485884189605713\n","val_precision: 0.47787609696388245\n","val_recall: 0.7313769459724426\n","val_auc: 0.7369153499603271\n","val_prc_auc: 0.5484206676483154\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7516 - binary_accuracy: 0.6879 - f1: 0.6897 - loss: 0.5923 - prc_auc: 0.7291 - precision: 0.6755 - recall: 0.7048 - val_auc: 0.7369 - val_binary_accuracy: 0.6486 - val_f1: 0.5781 - val_loss: 0.6185 - val_prc_auc: 0.5484 - val_precision: 0.4779 - val_recall: 0.7314\n","Epoch 19/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7538 - binary_accuracy: 0.6878 - f1: 0.6885 - loss: 0.5901 - prc_auc: 0.7308 - precision: 0.6766 - recall: 0.7011\n","Epoch 19: Validation Metrics:\n","loss: 0.5835205912590027\n","val_binary_accuracy: 0.6493313312530518\n","val_precision: 0.47864505648612976\n","val_recall: 0.7336342930793762\n","val_auc: 0.7383689880371094\n","val_prc_auc: 0.5498771071434021\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7538 - binary_accuracy: 0.6879 - f1: 0.6886 - loss: 0.5900 - prc_auc: 0.7309 - precision: 0.6766 - recall: 0.7012 - val_auc: 0.7384 - val_binary_accuracy: 0.6493 - val_f1: 0.5793 - val_loss: 0.6177 - val_prc_auc: 0.5499 - val_precision: 0.4786 - val_recall: 0.7336\n","Epoch 20/20\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7559 - binary_accuracy: 0.6902 - f1: 0.6912 - loss: 0.5880 - prc_auc: 0.7326 - precision: 0.6784 - recall: 0.7048\n","Epoch 20: Validation Metrics:\n","loss: 0.5814315676689148\n","val_binary_accuracy: 0.6508172154426575\n","val_precision: 0.4801762104034424\n","val_recall: 0.7381489872932434\n","val_auc: 0.7396776080131531\n","val_prc_auc: 0.5505101680755615\n","\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - auc: 0.7560 - binary_accuracy: 0.6902 - f1: 0.6913 - loss: 0.5880 - prc_auc: 0.7327 - precision: 0.6785 - recall: 0.7050 - val_auc: 0.7397 - val_binary_accuracy: 0.6508 - val_f1: 0.5819 - val_loss: 0.6172 - val_prc_auc: 0.5505 - val_precision: 0.4802 - val_recall: 0.7381\n","Starting training for label: 13\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - auc: 0.6490 - binary_accuracy: 0.6009 - f1: 0.6431 - loss: 0.6809 - prc_auc: 0.6348 - precision: 0.5829 - recall: 0.7469  \n","Epoch 1: Validation Metrics:\n","loss: 0.6619481444358826\n","val_binary_accuracy: 0.8863298892974854\n","val_precision: 0.3791208863258362\n","val_recall: 0.6330274939537048\n","val_auc: 0.8312467932701111\n","val_prc_auc: 0.39914271235466003\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - auc: 0.6527 - binary_accuracy: 0.6041 - f1: 0.6446 - loss: 0.6802 - prc_auc: 0.6397 - precision: 0.5871 - recall: 0.7443 - val_auc: 0.8312 - val_binary_accuracy: 0.8863 - val_f1: 0.4742 - val_loss: 0.6266 - val_prc_auc: 0.3991 - val_precision: 0.3791 - val_recall: 0.6330\n","Epoch 2/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8319 - binary_accuracy: 0.7748 - f1: 0.7169 - loss: 0.6119 - prc_auc: 0.8203 - precision: 0.8749 - recall: 0.6077\n","Epoch 2: Validation Metrics:\n","loss: 0.5971382856369019\n","val_binary_accuracy: 0.8900445699691772\n","val_precision: 0.38983049988746643\n","val_recall: 0.6330274939537048\n","val_auc: 0.8440923094749451\n","val_prc_auc: 0.43468910455703735\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - auc: 0.8316 - binary_accuracy: 0.7746 - f1: 0.7181 - loss: 0.6108 - prc_auc: 0.8214 - precision: 0.8753 - recall: 0.6091 - val_auc: 0.8441 - val_binary_accuracy: 0.8900 - val_f1: 0.4825 - val_loss: 0.5643 - val_prc_auc: 0.4347 - val_precision: 0.3898 - val_recall: 0.6330\n","Epoch 3/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8432 - binary_accuracy: 0.7785 - f1: 0.7231 - loss: 0.5621 - prc_auc: 0.8359 - precision: 0.8751 - recall: 0.6165\n","Epoch 3: Validation Metrics:\n","loss: 0.5509186387062073\n","val_binary_accuracy: 0.8855869174003601\n","val_precision: 0.37704917788505554\n","val_recall: 0.6330274939537048\n","val_auc: 0.8482975363731384\n","val_prc_auc: 0.47203701734542847\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.8429 - binary_accuracy: 0.7781 - f1: 0.7240 - loss: 0.5613 - prc_auc: 0.8366 - precision: 0.8753 - recall: 0.6177 - val_auc: 0.8483 - val_binary_accuracy: 0.8856 - val_f1: 0.4726 - val_loss: 0.5222 - val_prc_auc: 0.4720 - val_precision: 0.3770 - val_recall: 0.6330\n","Epoch 4/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8484 - binary_accuracy: 0.7833 - f1: 0.7305 - loss: 0.5273 - prc_auc: 0.8413 - precision: 0.8762 - recall: 0.6268\n","Epoch 4: Validation Metrics:\n","loss: 0.519798994064331\n","val_binary_accuracy: 0.8803863525390625\n","val_precision: 0.3645833432674408\n","val_recall: 0.642201840877533\n","val_auc: 0.8514459133148193\n","val_prc_auc: 0.49623000621795654\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - auc: 0.8481 - binary_accuracy: 0.7829 - f1: 0.7315 - loss: 0.5268 - prc_auc: 0.8421 - precision: 0.8764 - recall: 0.6282 - val_auc: 0.8514 - val_binary_accuracy: 0.8804 - val_f1: 0.4651 - val_loss: 0.4980 - val_prc_auc: 0.4962 - val_precision: 0.3646 - val_recall: 0.6422\n","Epoch 5/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8523 - binary_accuracy: 0.7875 - f1: 0.7384 - loss: 0.5049 - prc_auc: 0.8466 - precision: 0.8714 - recall: 0.6413\n","Epoch 5: Validation Metrics:\n","loss: 0.5006253719329834\n","val_binary_accuracy: 0.8759286999702454\n","val_precision: 0.35499998927116394\n","val_recall: 0.6513761281967163\n","val_auc: 0.8544792532920837\n","val_prc_auc: 0.510674238204956\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - auc: 0.8521 - binary_accuracy: 0.7875 - f1: 0.7399 - loss: 0.5046 - prc_auc: 0.8476 - precision: 0.8719 - recall: 0.6432 - val_auc: 0.8545 - val_binary_accuracy: 0.8759 - val_f1: 0.4595 - val_loss: 0.4858 - val_prc_auc: 0.5107 - val_precision: 0.3550 - val_recall: 0.6514\n","Epoch 6/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8563 - binary_accuracy: 0.7974 - f1: 0.7557 - loss: 0.4912 - prc_auc: 0.8512 - precision: 0.8669 - recall: 0.6705\n","Epoch 6: Validation Metrics:\n","loss: 0.488993376493454\n","val_binary_accuracy: 0.8684992790222168\n","val_precision: 0.3380952477455139\n","val_recall: 0.6513761281967163\n","val_auc: 0.8559402227401733\n","val_prc_auc: 0.5247306227684021\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.8561 - binary_accuracy: 0.7973 - f1: 0.7568 - loss: 0.4911 - prc_auc: 0.8522 - precision: 0.8676 - recall: 0.6717 - val_auc: 0.8559 - val_binary_accuracy: 0.8685 - val_f1: 0.4451 - val_loss: 0.4797 - val_prc_auc: 0.5247 - val_precision: 0.3381 - val_recall: 0.6514\n","Epoch 7/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8604 - binary_accuracy: 0.7959 - f1: 0.7544 - loss: 0.4821 - prc_auc: 0.8529 - precision: 0.8634 - recall: 0.6705\n","Epoch 7: Validation Metrics:\n","loss: 0.4812525808811188\n","val_binary_accuracy: 0.8662704229354858\n","val_precision: 0.33640551567077637\n","val_recall: 0.6697247624397278\n","val_auc: 0.8570751547813416\n","val_prc_auc: 0.5276156067848206\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.8601 - binary_accuracy: 0.7957 - f1: 0.7554 - loss: 0.4820 - prc_auc: 0.8540 - precision: 0.8638 - recall: 0.6717 - val_auc: 0.8571 - val_binary_accuracy: 0.8663 - val_f1: 0.4479 - val_loss: 0.4754 - val_prc_auc: 0.5276 - val_precision: 0.3364 - val_recall: 0.6697\n","Starting training for label: 14\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - auc: 0.5630 - binary_accuracy: 0.5308 - f1: 0.6069 - loss: 0.6910 - prc_auc: 0.5128 - precision: 0.5112 - recall: 0.7606\n","Epoch 1: Validation Metrics:\n","loss: 0.6896523833274841\n","val_binary_accuracy: 0.4234769642353058\n","val_precision: 0.13732394576072693\n","val_recall: 0.7405063509941101\n","val_auc: 0.5923715233802795\n","val_prc_auc: 0.16495108604431152\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 914ms/step - auc: 0.5629 - binary_accuracy: 0.5312 - f1: 0.6066 - loss: 0.6910 - prc_auc: 0.5133 - precision: 0.5119 - recall: 0.7581 - val_auc: 0.5924 - val_binary_accuracy: 0.4235 - val_f1: 0.2317 - val_loss: 0.7069 - val_prc_auc: 0.1650 - val_precision: 0.1373 - val_recall: 0.7405\n","Epoch 2/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6131 - binary_accuracy: 0.5710 - f1: 0.6315 - loss: 0.6826 - prc_auc: 0.5572 - precision: 0.5385 - recall: 0.7646\n","Epoch 2: Validation Metrics:\n","loss: 0.6818176507949829\n","val_binary_accuracy: 0.43610697984695435\n","val_precision: 0.14097969233989716\n","val_recall: 0.746835470199585\n","val_auc: 0.5998939871788025\n","val_prc_auc: 0.1677187830209732\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6129 - binary_accuracy: 0.5712 - f1: 0.6315 - loss: 0.6826 - prc_auc: 0.5587 - precision: 0.5394 - recall: 0.7630 - val_auc: 0.5999 - val_binary_accuracy: 0.4361 - val_f1: 0.2372 - val_loss: 0.7060 - val_prc_auc: 0.1677 - val_precision: 0.1410 - val_recall: 0.7468\n","Epoch 3/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6165 - binary_accuracy: 0.5869 - f1: 0.6374 - loss: 0.6781 - prc_auc: 0.5575 - precision: 0.5519 - recall: 0.7554\n","Epoch 3: Validation Metrics:\n","loss: 0.6775140166282654\n","val_binary_accuracy: 0.45170876383781433\n","val_precision: 0.1437346488237381\n","val_recall: 0.7405063509941101\n","val_auc: 0.6037697792053223\n","val_prc_auc: 0.1660049855709076\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6165 - binary_accuracy: 0.5871 - f1: 0.6376 - loss: 0.6781 - prc_auc: 0.5593 - precision: 0.5529 - recall: 0.7541 - val_auc: 0.6038 - val_binary_accuracy: 0.4517 - val_f1: 0.2407 - val_loss: 0.7033 - val_prc_auc: 0.1660 - val_precision: 0.1437 - val_recall: 0.7405\n","Epoch 4/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6207 - binary_accuracy: 0.5986 - f1: 0.6424 - loss: 0.6750 - prc_auc: 0.5630 - precision: 0.5624 - recall: 0.7496\n","Epoch 4: Validation Metrics:\n","loss: 0.6744703054428101\n","val_binary_accuracy: 0.4591381847858429\n","val_precision: 0.14463840425014496\n","val_recall: 0.7341772317886353\n","val_auc: 0.6071820259094238\n","val_prc_auc: 0.17807935178279877\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - auc: 0.6209 - binary_accuracy: 0.5987 - f1: 0.6425 - loss: 0.6749 - prc_auc: 0.5650 - precision: 0.5632 - recall: 0.7486 - val_auc: 0.6072 - val_binary_accuracy: 0.4591 - val_f1: 0.2417 - val_loss: 0.7011 - val_prc_auc: 0.1781 - val_precision: 0.1446 - val_recall: 0.7342\n","Epoch 5/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6264 - binary_accuracy: 0.6068 - f1: 0.6459 - loss: 0.6725 - prc_auc: 0.5681 - precision: 0.5701 - recall: 0.7458\n","Epoch 5: Validation Metrics:\n","loss: 0.6720775365829468\n","val_binary_accuracy: 0.4628528952598572\n","val_precision: 0.14465409517288208\n","val_recall: 0.7278481125831604\n","val_auc: 0.6093849539756775\n","val_prc_auc: 0.1761244237422943\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6265 - binary_accuracy: 0.6066 - f1: 0.6460 - loss: 0.6725 - prc_auc: 0.5700 - precision: 0.5708 - recall: 0.7447 - val_auc: 0.6094 - val_binary_accuracy: 0.4629 - val_f1: 0.2413 - val_loss: 0.6997 - val_prc_auc: 0.1761 - val_precision: 0.1447 - val_recall: 0.7278\n","Epoch 6/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6280 - binary_accuracy: 0.6088 - f1: 0.6478 - loss: 0.6705 - prc_auc: 0.5707 - precision: 0.5718 - recall: 0.7479\n","Epoch 6: Validation Metrics:\n","loss: 0.6700787544250488\n","val_binary_accuracy: 0.4658246636390686\n","val_precision: 0.14538559317588806\n","val_recall: 0.7278481125831604\n","val_auc: 0.6125175356864929\n","val_prc_auc: 0.1821492314338684\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - auc: 0.6282 - binary_accuracy: 0.6087 - f1: 0.6478 - loss: 0.6705 - prc_auc: 0.5728 - precision: 0.5725 - recall: 0.7468 - val_auc: 0.6125 - val_binary_accuracy: 0.4658 - val_f1: 0.2424 - val_loss: 0.6989 - val_prc_auc: 0.1821 - val_precision: 0.1454 - val_recall: 0.7278\n","Epoch 7/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6332 - binary_accuracy: 0.6135 - f1: 0.6497 - loss: 0.6689 - prc_auc: 0.5755 - precision: 0.5761 - recall: 0.7458\n","Epoch 7: Validation Metrics:\n","loss: 0.6683483123779297\n","val_binary_accuracy: 0.47028231620788574\n","val_precision: 0.14649681746959686\n","val_recall: 0.7278481125831604\n","val_auc: 0.6136097311973572\n","val_prc_auc: 0.1772075891494751\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6334 - binary_accuracy: 0.6132 - f1: 0.6496 - loss: 0.6688 - prc_auc: 0.5776 - precision: 0.5766 - recall: 0.7446 - val_auc: 0.6136 - val_binary_accuracy: 0.4703 - val_f1: 0.2439 - val_loss: 0.6983 - val_prc_auc: 0.1772 - val_precision: 0.1465 - val_recall: 0.7278\n","Epoch 8/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6361 - binary_accuracy: 0.6171 - f1: 0.6521 - loss: 0.6673 - prc_auc: 0.5779 - precision: 0.5793 - recall: 0.7467\n","Epoch 8: Validation Metrics:\n","loss: 0.6667386889457703\n","val_binary_accuracy: 0.4710252583026886\n","val_precision: 0.1466836780309677\n","val_recall: 0.7278481125831604\n","val_auc: 0.6146725416183472\n","val_prc_auc: 0.18044596910476685\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - auc: 0.6364 - binary_accuracy: 0.6168 - f1: 0.6521 - loss: 0.6673 - prc_auc: 0.5800 - precision: 0.5799 - recall: 0.7456 - val_auc: 0.6147 - val_binary_accuracy: 0.4710 - val_f1: 0.2442 - val_loss: 0.6982 - val_prc_auc: 0.1804 - val_precision: 0.1467 - val_recall: 0.7278\n","Epoch 9/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6393 - binary_accuracy: 0.6192 - f1: 0.6523 - loss: 0.6659 - prc_auc: 0.5834 - precision: 0.5816 - recall: 0.7433\n","Epoch 9: Validation Metrics:\n","loss: 0.6652296781539917\n","val_binary_accuracy: 0.4695393741130829\n","val_precision: 0.14720812439918518\n","val_recall: 0.7341772317886353\n","val_auc: 0.6176106929779053\n","val_prc_auc: 0.18231980502605438\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6395 - binary_accuracy: 0.6189 - f1: 0.6522 - loss: 0.6659 - prc_auc: 0.5854 - precision: 0.5821 - recall: 0.7423 - val_auc: 0.6176 - val_binary_accuracy: 0.4695 - val_f1: 0.2452 - val_loss: 0.6980 - val_prc_auc: 0.1823 - val_precision: 0.1472 - val_recall: 0.7342\n","Epoch 10/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6435 - binary_accuracy: 0.6247 - f1: 0.6566 - loss: 0.6645 - prc_auc: 0.5874 - precision: 0.5864 - recall: 0.7468\n","Epoch 10: Validation Metrics:\n","loss: 0.6637483835220337\n","val_binary_accuracy: 0.4762258529663086\n","val_precision: 0.1480051428079605\n","val_recall: 0.7278481125831604\n","val_auc: 0.6189053654670715\n","val_prc_auc: 0.18287822604179382\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6437 - binary_accuracy: 0.6243 - f1: 0.6565 - loss: 0.6645 - prc_auc: 0.5894 - precision: 0.5869 - recall: 0.7456 - val_auc: 0.6189 - val_binary_accuracy: 0.4762 - val_f1: 0.2460 - val_loss: 0.6980 - val_prc_auc: 0.1829 - val_precision: 0.1480 - val_recall: 0.7278\n","Epoch 11/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6469 - binary_accuracy: 0.6213 - f1: 0.6518 - loss: 0.6631 - prc_auc: 0.5902 - precision: 0.5843 - recall: 0.7377\n","Epoch 11: Validation Metrics:\n","loss: 0.6622835993766785\n","val_binary_accuracy: 0.4799405634403229\n","val_precision: 0.15077319741249084\n","val_recall: 0.7405063509941101\n","val_auc: 0.6201226711273193\n","val_prc_auc: 0.1858810931444168\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6470 - binary_accuracy: 0.6210 - f1: 0.6517 - loss: 0.6631 - prc_auc: 0.5922 - precision: 0.5849 - recall: 0.7367 - val_auc: 0.6201 - val_binary_accuracy: 0.4799 - val_f1: 0.2505 - val_loss: 0.6984 - val_prc_auc: 0.1859 - val_precision: 0.1508 - val_recall: 0.7405\n","Epoch 12/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6485 - binary_accuracy: 0.6205 - f1: 0.6509 - loss: 0.6618 - prc_auc: 0.5921 - precision: 0.5838 - recall: 0.7362\n","Epoch 12: Validation Metrics:\n","loss: 0.6608355641365051\n","val_binary_accuracy: 0.47919762134552\n","val_precision: 0.15057915449142456\n","val_recall: 0.7405063509941101\n","val_auc: 0.6215371489524841\n","val_prc_auc: 0.1856003701686859\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6487 - binary_accuracy: 0.6202 - f1: 0.6507 - loss: 0.6618 - prc_auc: 0.5942 - precision: 0.5843 - recall: 0.7350 - val_auc: 0.6215 - val_binary_accuracy: 0.4792 - val_f1: 0.2503 - val_loss: 0.6994 - val_prc_auc: 0.1856 - val_precision: 0.1506 - val_recall: 0.7405\n","Epoch 13/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6522 - binary_accuracy: 0.6244 - f1: 0.6545 - loss: 0.6605 - prc_auc: 0.5962 - precision: 0.5870 - recall: 0.7404\n","Epoch 13: Validation Metrics:\n","loss: 0.6594221591949463\n","val_binary_accuracy: 0.48365527391433716\n","val_precision: 0.15265201032161713\n","val_recall: 0.746835470199585\n","val_auc: 0.6242061853408813\n","val_prc_auc: 0.1832316815853119\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6524 - binary_accuracy: 0.6240 - f1: 0.6543 - loss: 0.6605 - prc_auc: 0.5981 - precision: 0.5874 - recall: 0.7392 - val_auc: 0.6242 - val_binary_accuracy: 0.4837 - val_f1: 0.2535 - val_loss: 0.6995 - val_prc_auc: 0.1832 - val_precision: 0.1527 - val_recall: 0.7468\n","Epoch 14/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6557 - binary_accuracy: 0.6240 - f1: 0.6533 - loss: 0.6592 - prc_auc: 0.6011 - precision: 0.5870 - recall: 0.7374\n","Epoch 14: Validation Metrics:\n","loss: 0.6580180525779724\n","val_binary_accuracy: 0.48514115810394287\n","val_precision: 0.15304799377918243\n","val_recall: 0.746835470199585\n","val_auc: 0.625434160232544\n","val_prc_auc: 0.18821898102760315\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6558 - binary_accuracy: 0.6235 - f1: 0.6531 - loss: 0.6592 - prc_auc: 0.6030 - precision: 0.5874 - recall: 0.7361 - val_auc: 0.6254 - val_binary_accuracy: 0.4851 - val_f1: 0.2540 - val_loss: 0.7001 - val_prc_auc: 0.1882 - val_precision: 0.1530 - val_recall: 0.7468\n","Epoch 15/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6586 - binary_accuracy: 0.6241 - f1: 0.6530 - loss: 0.6580 - prc_auc: 0.6029 - precision: 0.5873 - recall: 0.7363\n","Epoch 15: Validation Metrics:\n","loss: 0.6565904021263123\n","val_binary_accuracy: 0.4866270422935486\n","val_precision: 0.1525423675775528\n","val_recall: 0.7405063509941101\n","val_auc: 0.6262040734291077\n","val_prc_auc: 0.18753904104232788\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6587 - binary_accuracy: 0.6236 - f1: 0.6528 - loss: 0.6579 - prc_auc: 0.6048 - precision: 0.5877 - recall: 0.7350 - val_auc: 0.6262 - val_binary_accuracy: 0.4866 - val_f1: 0.2530 - val_loss: 0.7005 - val_prc_auc: 0.1875 - val_precision: 0.1525 - val_recall: 0.7405\n","Epoch 16/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6599 - binary_accuracy: 0.6254 - f1: 0.6540 - loss: 0.6566 - prc_auc: 0.6049 - precision: 0.5886 - recall: 0.7368\n","Epoch 16: Validation Metrics:\n","loss: 0.655131459236145\n","val_binary_accuracy: 0.4858841001987457\n","val_precision: 0.15143603086471558\n","val_recall: 0.7341772317886353\n","val_auc: 0.628524124622345\n","val_prc_auc: 0.18777979910373688\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6602 - binary_accuracy: 0.6251 - f1: 0.6538 - loss: 0.6566 - prc_auc: 0.6069 - precision: 0.5892 - recall: 0.7354 - val_auc: 0.6285 - val_binary_accuracy: 0.4859 - val_f1: 0.2511 - val_loss: 0.7010 - val_prc_auc: 0.1878 - val_precision: 0.1514 - val_recall: 0.7342\n","Epoch 17/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6635 - binary_accuracy: 0.6259 - f1: 0.6543 - loss: 0.6554 - prc_auc: 0.6086 - precision: 0.5890 - recall: 0.7368\n","Epoch 17: Validation Metrics:\n","loss: 0.6537138223648071\n","val_binary_accuracy: 0.4866270422935486\n","val_precision: 0.15163399279117584\n","val_recall: 0.7341772317886353\n","val_auc: 0.630407452583313\n","val_prc_auc: 0.18805545568466187\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6637 - binary_accuracy: 0.6255 - f1: 0.6541 - loss: 0.6553 - prc_auc: 0.6105 - precision: 0.5896 - recall: 0.7354 - val_auc: 0.6304 - val_binary_accuracy: 0.4866 - val_f1: 0.2514 - val_loss: 0.7022 - val_prc_auc: 0.1881 - val_precision: 0.1516 - val_recall: 0.7342\n","Epoch 18/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6655 - binary_accuracy: 0.6276 - f1: 0.6547 - loss: 0.6542 - prc_auc: 0.6105 - precision: 0.5910 - recall: 0.7351\n","Epoch 18: Validation Metrics:\n","loss: 0.6523533463478088\n","val_binary_accuracy: 0.4881129264831543\n","val_precision: 0.15203145146369934\n","val_recall: 0.7341772317886353\n","val_auc: 0.6317606568336487\n","val_prc_auc: 0.18829867243766785\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6657 - binary_accuracy: 0.6272 - f1: 0.6545 - loss: 0.6541 - prc_auc: 0.6124 - precision: 0.5916 - recall: 0.7335 - val_auc: 0.6318 - val_binary_accuracy: 0.4881 - val_f1: 0.2519 - val_loss: 0.7028 - val_prc_auc: 0.1883 - val_precision: 0.1520 - val_recall: 0.7342\n","Epoch 19/20\n","\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6688 - binary_accuracy: 0.6259 - f1: 0.6519 - loss: 0.6529 - prc_auc: 0.6135 - precision: 0.5903 - recall: 0.7291\n","Epoch 19: Validation Metrics:\n","loss: 0.6509448289871216\n","val_binary_accuracy: 0.4881129264831543\n","val_precision: 0.15203145146369934\n","val_recall: 0.7341772317886353\n","val_auc: 0.6341260075569153\n","val_prc_auc: 0.18964801728725433\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - auc: 0.6690 - binary_accuracy: 0.6256 - f1: 0.6516 - loss: 0.6528 - prc_auc: 0.6154 - precision: 0.5909 - recall: 0.7275 - val_auc: 0.6341 - val_binary_accuracy: 0.4881 - val_f1: 0.2519 - val_loss: 0.7033 - val_prc_auc: 0.1896 - val_precision: 0.1520 - val_recall: 0.7342\n","Starting training for label: 15\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - auc: 0.7351 - binary_accuracy: 0.5843 - f1: 0.3151 - loss: 0.6777 - prc_auc: 0.7316 - precision: 0.6829 - recall: 0.2142\n","Epoch 1: Validation Metrics:\n","loss: 0.6613065004348755\n","val_binary_accuracy: 0.8781574964523315\n","val_precision: 0.2774193584918976\n","val_recall: 0.4526315927505493\n","val_auc: 0.801775336265564\n","val_prc_auc: 0.36171427369117737\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - auc: 0.7376 - binary_accuracy: 0.5874 - f1: 0.3240 - loss: 0.6770 - prc_auc: 0.7342 - precision: 0.6896 - recall: 0.2213 - val_auc: 0.8018 - val_binary_accuracy: 0.8782 - val_f1: 0.3440 - val_loss: 0.5919 - val_prc_auc: 0.3617 - val_precision: 0.2774 - val_recall: 0.4526\n","Epoch 2/20\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8508 - binary_accuracy: 0.7766 - f1: 0.7382 - loss: 0.6083 - prc_auc: 0.8532 - precision: 0.8973 - recall: 0.6272\n","Epoch 2: Validation Metrics:\n","loss: 0.5994918942451477\n","val_binary_accuracy: 0.8751857280731201\n","val_precision: 0.28654971718788147\n","val_recall: 0.5157894492149353\n","val_auc: 0.8046826124191284\n","val_prc_auc: 0.37243616580963135\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - auc: 0.8503 - binary_accuracy: 0.7758 - f1: 0.7371 - loss: 0.6080 - prc_auc: 0.8526 - precision: 0.8962 - recall: 0.6262 - val_auc: 0.8047 - val_binary_accuracy: 0.8752 - val_f1: 0.3684 - val_loss: 0.5404 - val_prc_auc: 0.3724 - val_precision: 0.2865 - val_recall: 0.5158\n","Epoch 3/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8545 - binary_accuracy: 0.7959 - f1: 0.7694 - loss: 0.5567 - prc_auc: 0.8601 - precision: 0.8890 - recall: 0.6785\n","Epoch 3: Validation Metrics:\n","loss: 0.553427517414093\n","val_binary_accuracy: 0.8736998438835144\n","val_precision: 0.29050278663635254\n","val_recall: 0.5473684072494507\n","val_auc: 0.804892897605896\n","val_prc_auc: 0.3690352439880371\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8539 - binary_accuracy: 0.7947 - f1: 0.7679 - loss: 0.5565 - prc_auc: 0.8591 - precision: 0.8876 - recall: 0.6770 - val_auc: 0.8049 - val_binary_accuracy: 0.8737 - val_f1: 0.3796 - val_loss: 0.5033 - val_prc_auc: 0.3690 - val_precision: 0.2905 - val_recall: 0.5474\n","Epoch 4/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8546 - binary_accuracy: 0.8075 - f1: 0.7877 - loss: 0.5178 - prc_auc: 0.8619 - precision: 0.8832 - recall: 0.7115\n","Epoch 4: Validation Metrics:\n","loss: 0.5203036069869995\n","val_binary_accuracy: 0.8684992790222168\n","val_precision: 0.28421053290367126\n","val_recall: 0.5684210658073425\n","val_auc: 0.803626537322998\n","val_prc_auc: 0.3737490773200989\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - auc: 0.8542 - binary_accuracy: 0.8065 - f1: 0.7864 - loss: 0.5180 - prc_auc: 0.8611 - precision: 0.8824 - recall: 0.7099 - val_auc: 0.8036 - val_binary_accuracy: 0.8685 - val_f1: 0.3789 - val_loss: 0.4808 - val_prc_auc: 0.3737 - val_precision: 0.2842 - val_recall: 0.5684\n","Epoch 5/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8549 - binary_accuracy: 0.8122 - f1: 0.7948 - loss: 0.4912 - prc_auc: 0.8628 - precision: 0.8817 - recall: 0.7240\n","Epoch 5: Validation Metrics:\n","loss: 0.49859127402305603\n","val_binary_accuracy: 0.8677563071250916\n","val_precision: 0.2893401086330414\n","val_recall: 0.6000000238418579\n","val_auc: 0.8065253496170044\n","val_prc_auc: 0.3792789578437805\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8546 - binary_accuracy: 0.8112 - f1: 0.7935 - loss: 0.4918 - prc_auc: 0.8621 - precision: 0.8809 - recall: 0.7224 - val_auc: 0.8065 - val_binary_accuracy: 0.8678 - val_f1: 0.3904 - val_loss: 0.4691 - val_prc_auc: 0.3793 - val_precision: 0.2893 - val_recall: 0.6000\n","Epoch 6/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8570 - binary_accuracy: 0.8145 - f1: 0.7979 - loss: 0.4741 - prc_auc: 0.8677 - precision: 0.8824 - recall: 0.7286\n","Epoch 6: Validation Metrics:\n","loss: 0.4847043454647064\n","val_binary_accuracy: 0.8662704229354858\n","val_precision: 0.286432147026062\n","val_recall: 0.6000000238418579\n","val_auc: 0.8072195053100586\n","val_prc_auc: 0.37622398138046265\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8567 - binary_accuracy: 0.8137 - f1: 0.7968 - loss: 0.4750 - prc_auc: 0.8669 - precision: 0.8817 - recall: 0.7272 - val_auc: 0.8072 - val_binary_accuracy: 0.8663 - val_f1: 0.3878 - val_loss: 0.4626 - val_prc_auc: 0.3762 - val_precision: 0.2864 - val_recall: 0.6000\n","Epoch 7/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8589 - binary_accuracy: 0.8120 - f1: 0.7960 - loss: 0.4629 - prc_auc: 0.8704 - precision: 0.8762 - recall: 0.7297\n","Epoch 7: Validation Metrics:\n","loss: 0.4753507971763611\n","val_binary_accuracy: 0.8647845387458801\n","val_precision: 0.28358209133148193\n","val_recall: 0.6000000238418579\n","val_auc: 0.8094996809959412\n","val_prc_auc: 0.3750562071800232\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - auc: 0.8586 - binary_accuracy: 0.8114 - f1: 0.7951 - loss: 0.4639 - prc_auc: 0.8696 - precision: 0.8758 - recall: 0.7285 - val_auc: 0.8095 - val_binary_accuracy: 0.8648 - val_f1: 0.3851 - val_loss: 0.4590 - val_prc_auc: 0.3751 - val_precision: 0.2836 - val_recall: 0.6000\n","Epoch 8/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8612 - binary_accuracy: 0.8128 - f1: 0.7970 - loss: 0.4549 - prc_auc: 0.8724 - precision: 0.8765 - recall: 0.7312\n","Epoch 8: Validation Metrics:\n","loss: 0.4683554768562317\n","val_binary_accuracy: 0.8655275106430054\n","val_precision: 0.2849999964237213\n","val_recall: 0.6000000238418579\n","val_auc: 0.8117548823356628\n","val_prc_auc: 0.3765868544578552\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8609 - binary_accuracy: 0.8122 - f1: 0.7962 - loss: 0.4560 - prc_auc: 0.8715 - precision: 0.8761 - recall: 0.7301 - val_auc: 0.8118 - val_binary_accuracy: 0.8655 - val_f1: 0.3864 - val_loss: 0.4557 - val_prc_auc: 0.3766 - val_precision: 0.2850 - val_recall: 0.6000\n","Epoch 9/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8639 - binary_accuracy: 0.8128 - f1: 0.7970 - loss: 0.4487 - prc_auc: 0.8763 - precision: 0.8765 - recall: 0.7312\n","Epoch 9: Validation Metrics:\n","loss: 0.46261927485466003\n","val_binary_accuracy: 0.8670133948326111\n","val_precision: 0.28999999165534973\n","val_recall: 0.6105263233184814\n","val_auc: 0.8137111663818359\n","val_prc_auc: 0.3821750283241272\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - auc: 0.8636 - binary_accuracy: 0.8122 - f1: 0.7962 - loss: 0.4498 - prc_auc: 0.8754 - precision: 0.8761 - recall: 0.7301 - val_auc: 0.8137 - val_binary_accuracy: 0.8670 - val_f1: 0.3932 - val_loss: 0.4525 - val_prc_auc: 0.3822 - val_precision: 0.2900 - val_recall: 0.6105\n","Epoch 10/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8685 - binary_accuracy: 0.8178 - f1: 0.8014 - loss: 0.4435 - prc_auc: 0.8808 - precision: 0.8867 - recall: 0.7312\n","Epoch 10: Validation Metrics:\n","loss: 0.4576684534549713\n","val_binary_accuracy: 0.8662704229354858\n","val_precision: 0.2885572016239166\n","val_recall: 0.6105263233184814\n","val_auc: 0.8141781091690063\n","val_prc_auc: 0.38289642333984375\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8681 - binary_accuracy: 0.8170 - f1: 0.8003 - loss: 0.4447 - prc_auc: 0.8798 - precision: 0.8857 - recall: 0.7301 - val_auc: 0.8142 - val_binary_accuracy: 0.8663 - val_f1: 0.3919 - val_loss: 0.4499 - val_prc_auc: 0.3829 - val_precision: 0.2886 - val_recall: 0.6105\n","Epoch 11/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8720 - binary_accuracy: 0.8194 - f1: 0.8035 - loss: 0.4391 - prc_auc: 0.8828 - precision: 0.8872 - recall: 0.7344\n","Epoch 11: Validation Metrics:\n","loss: 0.45324423909187317\n","val_binary_accuracy: 0.8670133948326111\n","val_precision: 0.28999999165534973\n","val_recall: 0.6105263233184814\n","val_auc: 0.816786527633667\n","val_prc_auc: 0.3929247260093689\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8716 - binary_accuracy: 0.8186 - f1: 0.8025 - loss: 0.4402 - prc_auc: 0.8818 - precision: 0.8862 - recall: 0.7334 - val_auc: 0.8168 - val_binary_accuracy: 0.8670 - val_f1: 0.3932 - val_loss: 0.4467 - val_prc_auc: 0.3929 - val_precision: 0.2900 - val_recall: 0.6105\n","Epoch 12/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8748 - binary_accuracy: 0.8194 - f1: 0.8035 - loss: 0.4351 - prc_auc: 0.8864 - precision: 0.8872 - recall: 0.7344\n","Epoch 12: Validation Metrics:\n","loss: 0.4491729438304901\n","val_binary_accuracy: 0.8662704229354858\n","val_precision: 0.2885572016239166\n","val_recall: 0.6105263233184814\n","val_auc: 0.8180317878723145\n","val_prc_auc: 0.39488115906715393\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step - auc: 0.8744 - binary_accuracy: 0.8186 - f1: 0.8025 - loss: 0.4362 - prc_auc: 0.8856 - precision: 0.8862 - recall: 0.7334 - val_auc: 0.8180 - val_binary_accuracy: 0.8663 - val_f1: 0.3919 - val_loss: 0.4436 - val_prc_auc: 0.3949 - val_precision: 0.2886 - val_recall: 0.6105\n","Epoch 13/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8774 - binary_accuracy: 0.8194 - f1: 0.8035 - loss: 0.4314 - prc_auc: 0.8881 - precision: 0.8872 - recall: 0.7344\n","Epoch 13: Validation Metrics:\n","loss: 0.4454088509082794\n","val_binary_accuracy: 0.8662704229354858\n","val_precision: 0.2885572016239166\n","val_recall: 0.6105263233184814\n","val_auc: 0.8200429081916809\n","val_prc_auc: 0.38294923305511475\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8770 - binary_accuracy: 0.8186 - f1: 0.8025 - loss: 0.4325 - prc_auc: 0.8873 - precision: 0.8862 - recall: 0.7334 - val_auc: 0.8200 - val_binary_accuracy: 0.8663 - val_f1: 0.3919 - val_loss: 0.4411 - val_prc_auc: 0.3829 - val_precision: 0.2886 - val_recall: 0.6105\n","Epoch 14/20\n","\u001b[1m23/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8801 - binary_accuracy: 0.8194 - f1: 0.8035 - loss: 0.4279 - prc_auc: 0.8901 - precision: 0.8872 - recall: 0.7344\n","Epoch 14: Validation Metrics:\n","loss: 0.4418432116508484\n","val_binary_accuracy: 0.8655275106430054\n","val_precision: 0.2871287167072296\n","val_recall: 0.6105263233184814\n","val_auc: 0.8213471174240112\n","val_prc_auc: 0.38713252544403076\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - auc: 0.8798 - binary_accuracy: 0.8186 - f1: 0.8025 - loss: 0.4290 - prc_auc: 0.8893 - precision: 0.8862 - recall: 0.7334 - val_auc: 0.8213 - val_binary_accuracy: 0.8655 - val_f1: 0.3906 - val_loss: 0.4389 - val_prc_auc: 0.3871 - val_precision: 0.2871 - val_recall: 0.6105\n","Starting training for label: 16\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989ms/step - auc: 0.5086 - binary_accuracy: 0.5280 - f1: 0.2436 - loss: 0.6921 - prc_auc: 0.4985 - precision: 0.5594 - recall: 0.1967\n","Epoch 1: Validation Metrics:\n","loss: 0.6909034252166748\n","val_binary_accuracy: 0.32689449191093445\n","val_precision: 0.2073940485715866\n","val_recall: 0.8949416279792786\n","val_auc: 0.584227442741394\n","val_prc_auc: 0.23695555329322815\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - auc: 0.5090 - binary_accuracy: 0.5280 - f1: 0.2475 - loss: 0.6921 - prc_auc: 0.4990 - precision: 0.5589 - recall: 0.2010 - val_auc: 0.5842 - val_binary_accuracy: 0.3269 - val_f1: 0.3367 - val_loss: 0.7022 - val_prc_auc: 0.2370 - val_precision: 0.2074 - val_recall: 0.8949\n","Epoch 2/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5657 - binary_accuracy: 0.5174 - f1: 0.5814 - loss: 0.6885 - prc_auc: 0.5547 - precision: 0.5056 - recall: 0.6910\n","Epoch 2: Validation Metrics:\n","loss: 0.6866263151168823\n","val_binary_accuracy: 0.355126291513443\n","val_precision: 0.21260583400726318\n","val_recall: 0.8793774247169495\n","val_auc: 0.597703218460083\n","val_prc_auc: 0.24211493134498596\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5657 - binary_accuracy: 0.5179 - f1: 0.5821 - loss: 0.6885 - prc_auc: 0.5549 - precision: 0.5062 - recall: 0.6918 - val_auc: 0.5977 - val_binary_accuracy: 0.3551 - val_f1: 0.3424 - val_loss: 0.6965 - val_prc_auc: 0.2421 - val_precision: 0.2126 - val_recall: 0.8794\n","Epoch 3/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5843 - binary_accuracy: 0.5331 - f1: 0.5792 - loss: 0.6864 - prc_auc: 0.5661 - precision: 0.5182 - recall: 0.6625\n","Epoch 3: Validation Metrics:\n","loss: 0.6843359470367432\n","val_binary_accuracy: 0.3826151490211487\n","val_precision: 0.21751968562602997\n","val_recall: 0.8599221706390381\n","val_auc: 0.5988930463790894\n","val_prc_auc: 0.24055078625679016\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5843 - binary_accuracy: 0.5335 - f1: 0.5799 - loss: 0.6864 - prc_auc: 0.5665 - precision: 0.5188 - recall: 0.6633 - val_auc: 0.5989 - val_binary_accuracy: 0.3826 - val_f1: 0.3472 - val_loss: 0.6945 - val_prc_auc: 0.2406 - val_precision: 0.2175 - val_recall: 0.8599\n","Epoch 4/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5923 - binary_accuracy: 0.5492 - f1: 0.5827 - loss: 0.6845 - prc_auc: 0.5716 - precision: 0.5322 - recall: 0.6491\n","Epoch 4: Validation Metrics:\n","loss: 0.6824015974998474\n","val_binary_accuracy: 0.39301633834838867\n","val_precision: 0.21717171370983124\n","val_recall: 0.8365758657455444\n","val_auc: 0.599164605140686\n","val_prc_auc: 0.24097467958927155\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5923 - binary_accuracy: 0.5495 - f1: 0.5833 - loss: 0.6845 - prc_auc: 0.5722 - precision: 0.5326 - recall: 0.6500 - val_auc: 0.5992 - val_binary_accuracy: 0.3930 - val_f1: 0.3448 - val_loss: 0.6934 - val_prc_auc: 0.2410 - val_precision: 0.2172 - val_recall: 0.8366\n","Epoch 5/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5989 - binary_accuracy: 0.5459 - f1: 0.5742 - loss: 0.6827 - prc_auc: 0.5775 - precision: 0.5303 - recall: 0.6308\n","Epoch 5: Validation Metrics:\n","loss: 0.680636465549469\n","val_binary_accuracy: 0.4115898907184601\n","val_precision: 0.22048066556453705\n","val_recall: 0.8210116624832153\n","val_auc: 0.600445568561554\n","val_prc_auc: 0.2407056838274002\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.5989 - binary_accuracy: 0.5463 - f1: 0.5750 - loss: 0.6827 - prc_auc: 0.5781 - precision: 0.5308 - recall: 0.6319 - val_auc: 0.6004 - val_binary_accuracy: 0.4116 - val_f1: 0.3476 - val_loss: 0.6924 - val_prc_auc: 0.2407 - val_precision: 0.2205 - val_recall: 0.8210\n","Epoch 6/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6031 - binary_accuracy: 0.5544 - f1: 0.5787 - loss: 0.6810 - prc_auc: 0.5827 - precision: 0.5381 - recall: 0.6306\n","Epoch 6: Validation Metrics:\n","loss: 0.6789484024047852\n","val_binary_accuracy: 0.4286775588989258\n","val_precision: 0.22413793206214905\n","val_recall: 0.8093385100364685\n","val_auc: 0.6037077307701111\n","val_prc_auc: 0.24453477561473846\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6032 - binary_accuracy: 0.5546 - f1: 0.5795 - loss: 0.6809 - prc_auc: 0.5834 - precision: 0.5385 - recall: 0.6316 - val_auc: 0.6037 - val_binary_accuracy: 0.4287 - val_f1: 0.3511 - val_loss: 0.6917 - val_prc_auc: 0.2445 - val_precision: 0.2241 - val_recall: 0.8093\n","Epoch 7/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6082 - binary_accuracy: 0.5612 - f1: 0.5802 - loss: 0.6794 - prc_auc: 0.5862 - precision: 0.5451 - recall: 0.6248\n","Epoch 7: Validation Metrics:\n","loss: 0.6773069500923157\n","val_binary_accuracy: 0.4383358061313629\n","val_precision: 0.22612513601779938\n","val_recall: 0.801556408405304\n","val_auc: 0.6042079925537109\n","val_prc_auc: 0.24220961332321167\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6083 - binary_accuracy: 0.5615 - f1: 0.5810 - loss: 0.6793 - prc_auc: 0.5869 - precision: 0.5456 - recall: 0.6258 - val_auc: 0.6042 - val_binary_accuracy: 0.4383 - val_f1: 0.3527 - val_loss: 0.6908 - val_prc_auc: 0.2422 - val_precision: 0.2261 - val_recall: 0.8016\n","Epoch 8/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6125 - binary_accuracy: 0.5617 - f1: 0.5760 - loss: 0.6778 - prc_auc: 0.5913 - precision: 0.5463 - recall: 0.6136\n","Epoch 8: Validation Metrics:\n","loss: 0.6757633686065674\n","val_binary_accuracy: 0.4472511112689972\n","val_precision: 0.22485876083374023\n","val_recall: 0.774319052696228\n","val_auc: 0.6057300567626953\n","val_prc_auc: 0.24481992423534393\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6125 - binary_accuracy: 0.5621 - f1: 0.5769 - loss: 0.6777 - prc_auc: 0.5919 - precision: 0.5468 - recall: 0.6148 - val_auc: 0.6057 - val_binary_accuracy: 0.4473 - val_f1: 0.3485 - val_loss: 0.6903 - val_prc_auc: 0.2448 - val_precision: 0.2249 - val_recall: 0.7743\n","Epoch 9/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6142 - binary_accuracy: 0.5667 - f1: 0.5757 - loss: 0.6763 - prc_auc: 0.5930 - precision: 0.5516 - recall: 0.6056\n","Epoch 9: Validation Metrics:\n","loss: 0.6742855906486511\n","val_binary_accuracy: 0.4576523005962372\n","val_precision: 0.2246798574924469\n","val_recall: 0.7509727478027344\n","val_auc: 0.6066073179244995\n","val_prc_auc: 0.2422935962677002\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - auc: 0.6143 - binary_accuracy: 0.5669 - f1: 0.5764 - loss: 0.6762 - prc_auc: 0.5937 - precision: 0.5520 - recall: 0.6067 - val_auc: 0.6066 - val_binary_accuracy: 0.4577 - val_f1: 0.3459 - val_loss: 0.6895 - val_prc_auc: 0.2423 - val_precision: 0.2247 - val_recall: 0.7510\n","Epoch 10/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6182 - binary_accuracy: 0.5695 - f1: 0.5747 - loss: 0.6748 - prc_auc: 0.5961 - precision: 0.5553 - recall: 0.5992\n","Epoch 10: Validation Metrics:\n","loss: 0.6729227304458618\n","val_binary_accuracy: 0.46879643201828003\n","val_precision: 0.2267303168773651\n","val_recall: 0.7392995953559875\n","val_auc: 0.6057729721069336\n","val_prc_auc: 0.24112780392169952\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6182 - binary_accuracy: 0.5697 - f1: 0.5756 - loss: 0.6748 - prc_auc: 0.5968 - precision: 0.5557 - recall: 0.6005 - val_auc: 0.6058 - val_binary_accuracy: 0.4688 - val_f1: 0.3470 - val_loss: 0.6888 - val_prc_auc: 0.2411 - val_precision: 0.2267 - val_recall: 0.7393\n","Epoch 11/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6204 - binary_accuracy: 0.5743 - f1: 0.5764 - loss: 0.6735 - prc_auc: 0.5969 - precision: 0.5606 - recall: 0.5965\n","Epoch 11: Validation Metrics:\n","loss: 0.6716288328170776\n","val_binary_accuracy: 0.47845467925071716\n","val_precision: 0.23095525801181793\n","val_recall: 0.7431906461715698\n","val_auc: 0.6061874628067017\n","val_prc_auc: 0.24106888473033905\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6205 - binary_accuracy: 0.5746 - f1: 0.5773 - loss: 0.6735 - prc_auc: 0.5976 - precision: 0.5610 - recall: 0.5980 - val_auc: 0.6062 - val_binary_accuracy: 0.4785 - val_f1: 0.3524 - val_loss: 0.6884 - val_prc_auc: 0.2411 - val_precision: 0.2310 - val_recall: 0.7432\n","Epoch 12/20\n","\u001b[1m64/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6227 - binary_accuracy: 0.5805 - f1: 0.5792 - loss: 0.6723 - prc_auc: 0.6000 - precision: 0.5674 - recall: 0.5949\n","Epoch 12: Validation Metrics:\n","loss: 0.6704056262969971\n","val_binary_accuracy: 0.4866270422935486\n","val_precision: 0.23009949922561646\n","val_recall: 0.7198443412780762\n","val_auc: 0.6064411401748657\n","val_prc_auc: 0.24060788750648499\n","\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - auc: 0.6228 - binary_accuracy: 0.5807 - f1: 0.5801 - loss: 0.6723 - prc_auc: 0.6007 - precision: 0.5677 - recall: 0.5962 - val_auc: 0.6064 - val_binary_accuracy: 0.4866 - val_f1: 0.3487 - val_loss: 0.6877 - val_prc_auc: 0.2406 - val_precision: 0.2301 - val_recall: 0.7198\n","Starting training for label: 17\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - auc: 0.8318 - binary_accuracy: 0.7502 - f1: 0.7973 - loss: 0.6616 - prc_auc: 0.8154 - precision: 0.7017 - recall: 0.9347  \n","Epoch 1: Validation Metrics:\n","loss: 0.6327184438705444\n","val_binary_accuracy: 0.8878157734870911\n","val_precision: 0.40625\n","val_recall: 0.8348624110221863\n","val_auc: 0.9195597767829895\n","val_prc_auc: 0.6012390851974487\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - auc: 0.8344 - binary_accuracy: 0.7533 - f1: 0.7991 - loss: 0.6606 - prc_auc: 0.8184 - precision: 0.7048 - recall: 0.9341 - val_auc: 0.9196 - val_binary_accuracy: 0.8878 - val_f1: 0.5465 - val_loss: 0.5984 - val_prc_auc: 0.6012 - val_precision: 0.4062 - val_recall: 0.8349\n","Epoch 2/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9269 - binary_accuracy: 0.9029 - f1: 0.9037 - loss: 0.5418 - prc_auc: 0.9231 - precision: 0.9172 - recall: 0.8909\n","Epoch 2: Validation Metrics:\n","loss: 0.5178496837615967\n","val_binary_accuracy: 0.8967310786247253\n","val_precision: 0.4292452931404114\n","val_recall: 0.8348624110221863\n","val_auc: 0.926334798336029\n","val_prc_auc: 0.6290379762649536\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - auc: 0.9270 - binary_accuracy: 0.9029 - f1: 0.9035 - loss: 0.5401 - prc_auc: 0.9233 - precision: 0.9166 - recall: 0.8911 - val_auc: 0.9263 - val_binary_accuracy: 0.8967 - val_f1: 0.5670 - val_loss: 0.4914 - val_prc_auc: 0.6290 - val_precision: 0.4292 - val_recall: 0.8349\n","Epoch 3/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.9335 - binary_accuracy: 0.8961 - f1: 0.8950 - loss: 0.4420 - prc_auc: 0.9308 - precision: 0.9242 - recall: 0.8681\n","Epoch 3: Validation Metrics:\n","loss: 0.4227276146411896\n","val_binary_accuracy: 0.9004457592964172\n","val_precision: 0.4396135210990906\n","val_recall: 0.8348624110221863\n","val_auc: 0.9312223196029663\n","val_prc_auc: 0.6367896199226379\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - auc: 0.9335 - binary_accuracy: 0.8963 - f1: 0.8952 - loss: 0.4407 - prc_auc: 0.9308 - precision: 0.9235 - recall: 0.8691 - val_auc: 0.9312 - val_binary_accuracy: 0.9004 - val_f1: 0.5759 - val_loss: 0.4001 - val_prc_auc: 0.6368 - val_precision: 0.4396 - val_recall: 0.8349\n","Epoch 4/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9370 - binary_accuracy: 0.8968 - f1: 0.8958 - loss: 0.3668 - prc_auc: 0.9338 - precision: 0.9243 - recall: 0.8694\n","Epoch 4: Validation Metrics:\n","loss: 0.35464152693748474\n","val_binary_accuracy: 0.8997028470039368\n","val_precision: 0.4375\n","val_recall: 0.8348624110221863\n","val_auc: 0.9332730174064636\n","val_prc_auc: 0.6256558895111084\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.9371 - binary_accuracy: 0.8970 - f1: 0.8960 - loss: 0.3659 - prc_auc: 0.9339 - precision: 0.9236 - recall: 0.8705 - val_auc: 0.9333 - val_binary_accuracy: 0.8997 - val_f1: 0.5741 - val_loss: 0.3417 - val_prc_auc: 0.6257 - val_precision: 0.4375 - val_recall: 0.8349\n","Epoch 5/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9405 - binary_accuracy: 0.8968 - f1: 0.8958 - loss: 0.3228 - prc_auc: 0.9353 - precision: 0.9243 - recall: 0.8694\n","Epoch 5: Validation Metrics:\n","loss: 0.31703492999076843\n","val_binary_accuracy: 0.8997028470039368\n","val_precision: 0.4375\n","val_recall: 0.8348624110221863\n","val_auc: 0.9351383447647095\n","val_prc_auc: 0.6357747316360474\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - auc: 0.9405 - binary_accuracy: 0.8970 - f1: 0.8960 - loss: 0.3224 - prc_auc: 0.9354 - precision: 0.9236 - recall: 0.8705 - val_auc: 0.9351 - val_binary_accuracy: 0.8997 - val_f1: 0.5741 - val_loss: 0.3161 - val_prc_auc: 0.6358 - val_precision: 0.4375 - val_recall: 0.8349\n","Epoch 6/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9423 - binary_accuracy: 0.8989 - f1: 0.8980 - loss: 0.3022 - prc_auc: 0.9382 - precision: 0.9246 - recall: 0.8734\n","Epoch 6: Validation Metrics:\n","loss: 0.3001079261302948\n","val_binary_accuracy: 0.8989598751068115\n","val_precision: 0.4354066848754883\n","val_recall: 0.8348624110221863\n","val_auc: 0.936606764793396\n","val_prc_auc: 0.6370850205421448\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.9423 - binary_accuracy: 0.8991 - f1: 0.8982 - loss: 0.3020 - prc_auc: 0.9382 - precision: 0.9239 - recall: 0.8744 - val_auc: 0.9366 - val_binary_accuracy: 0.8990 - val_f1: 0.5723 - val_loss: 0.3070 - val_prc_auc: 0.6371 - val_precision: 0.4354 - val_recall: 0.8349\n","Epoch 7/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9431 - binary_accuracy: 0.9023 - f1: 0.9018 - loss: 0.2931 - prc_auc: 0.9412 - precision: 0.9251 - recall: 0.8801\n","Epoch 7: Validation Metrics:\n","loss: 0.2926512658596039\n","val_binary_accuracy: 0.8974739909172058\n","val_precision: 0.43127962946891785\n","val_recall: 0.8348624110221863\n","val_auc: 0.9375226497650146\n","val_prc_auc: 0.6514776945114136\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.9432 - binary_accuracy: 0.9025 - f1: 0.9020 - loss: 0.2930 - prc_auc: 0.9412 - precision: 0.9244 - recall: 0.8811 - val_auc: 0.9375 - val_binary_accuracy: 0.8975 - val_f1: 0.5687 - val_loss: 0.3038 - val_prc_auc: 0.6515 - val_precision: 0.4313 - val_recall: 0.8349\n","Epoch 8/20\n","\u001b[1m27/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.9444 - binary_accuracy: 0.9027 - f1: 0.9023 - loss: 0.2884 - prc_auc: 0.9425 - precision: 0.9239 - recall: 0.8823\n","Epoch 8: Validation Metrics:\n","loss: 0.28869426250457764\n","val_binary_accuracy: 0.8967310786247253\n","val_precision: 0.4292452931404114\n","val_recall: 0.8348624110221863\n","val_auc: 0.9384311437606812\n","val_prc_auc: 0.6410298943519592\n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - auc: 0.9445 - binary_accuracy: 0.9029 - f1: 0.9025 - loss: 0.2884 - prc_auc: 0.9425 - precision: 0.9232 - recall: 0.8832 - val_auc: 0.9384 - val_binary_accuracy: 0.8967 - val_f1: 0.5670 - val_loss: 0.3015 - val_prc_auc: 0.6410 - val_precision: 0.4292 - val_recall: 0.8349\n","Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - auc: 0.6444 - binary_accuracy: 0.6012 - f1: 0.6050 - loss: 0.6733 - prc_auc: 0.6080 - precision: 0.5849 - recall: 0.6356\n","Epoch 1: Validation Metrics:\n","loss: 0.6629716157913208\n","val_binary_accuracy: 0.5527488589286804\n","val_precision: 0.42070484161376953\n","val_recall: 0.8340611457824707\n","val_auc: 0.6662634015083313\n","val_prc_auc: 0.46142011880874634\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 358ms/step - auc: 0.6444 - binary_accuracy: 0.6013 - f1: 0.6055 - loss: 0.6732 - prc_auc: 0.6081 - precision: 0.5849 - recall: 0.6367 - val_auc: 0.6663 - val_binary_accuracy: 0.5527 - val_f1: 0.5593 - val_loss: 0.6560 - val_prc_auc: 0.4614 - val_precision: 0.4207 - val_recall: 0.8341\n","Epoch 2/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6865 - binary_accuracy: 0.6421 - f1: 0.6818 - loss: 0.6433 - prc_auc: 0.6529 - precision: 0.6049 - recall: 0.7819\n","Epoch 2: Validation Metrics:\n","loss: 0.6431522965431213\n","val_binary_accuracy: 0.580980658531189\n","val_precision: 0.4361445903778076\n","val_recall: 0.7903929948806763\n","val_auc: 0.6760247945785522\n","val_prc_auc: 0.4840693175792694\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.6863 - binary_accuracy: 0.6418 - f1: 0.6818 - loss: 0.6433 - prc_auc: 0.6529 - precision: 0.6048 - recall: 0.7821 - val_auc: 0.6760 - val_binary_accuracy: 0.5810 - val_f1: 0.5621 - val_loss: 0.6433 - val_prc_auc: 0.4841 - val_precision: 0.4361 - val_recall: 0.7904\n","Epoch 3/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6969 - binary_accuracy: 0.6406 - f1: 0.6690 - loss: 0.6347 - prc_auc: 0.6750 - precision: 0.6103 - recall: 0.7414\n","Epoch 3: Validation Metrics:\n","loss: 0.6370037198066711\n","val_binary_accuracy: 0.5936107039451599\n","val_precision: 0.4433121085166931\n","val_recall: 0.7598253488540649\n","val_auc: 0.6826857328414917\n","val_prc_auc: 0.5011992454528809\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.6968 - binary_accuracy: 0.6404 - f1: 0.6692 - loss: 0.6347 - prc_auc: 0.6750 - precision: 0.6101 - recall: 0.7419 - val_auc: 0.6827 - val_binary_accuracy: 0.5936 - val_f1: 0.5599 - val_loss: 0.6369 - val_prc_auc: 0.5012 - val_precision: 0.4433 - val_recall: 0.7598\n","Epoch 4/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7044 - binary_accuracy: 0.6477 - f1: 0.6691 - loss: 0.6295 - prc_auc: 0.6884 - precision: 0.6213 - recall: 0.7265\n","Epoch 4: Validation Metrics:\n","loss: 0.6328534483909607\n","val_binary_accuracy: 0.6092124581336975\n","val_precision: 0.4545454680919647\n","val_recall: 0.7423580884933472\n","val_auc: 0.6865742206573486\n","val_prc_auc: 0.5120150446891785\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7043 - binary_accuracy: 0.6475 - f1: 0.6692 - loss: 0.6296 - prc_auc: 0.6883 - precision: 0.6211 - recall: 0.7270 - val_auc: 0.6866 - val_binary_accuracy: 0.6092 - val_f1: 0.5638 - val_loss: 0.6322 - val_prc_auc: 0.5120 - val_precision: 0.4545 - val_recall: 0.7424\n","Epoch 5/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7106 - binary_accuracy: 0.6473 - f1: 0.6647 - loss: 0.6253 - prc_auc: 0.6971 - precision: 0.6234 - recall: 0.7133\n","Epoch 5: Validation Metrics:\n","loss: 0.6293087005615234\n","val_binary_accuracy: 0.6158989667892456\n","val_precision: 0.4591977894306183\n","val_recall: 0.7248908281326294\n","val_auc: 0.6906620264053345\n","val_prc_auc: 0.5201238989830017\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7104 - binary_accuracy: 0.6471 - f1: 0.6648 - loss: 0.6254 - prc_auc: 0.6970 - precision: 0.6232 - recall: 0.7139 - val_auc: 0.6907 - val_binary_accuracy: 0.6159 - val_f1: 0.5622 - val_loss: 0.6283 - val_prc_auc: 0.5201 - val_precision: 0.4592 - val_recall: 0.7249\n","Epoch 6/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7160 - binary_accuracy: 0.6508 - f1: 0.6621 - loss: 0.6216 - prc_auc: 0.7045 - precision: 0.6312 - recall: 0.6988\n","Epoch 6: Validation Metrics:\n","loss: 0.6260778903961182\n","val_binary_accuracy: 0.6203566193580627\n","val_precision: 0.4625176787376404\n","val_recall: 0.7139738202095032\n","val_auc: 0.6926733255386353\n","val_prc_auc: 0.5236415266990662\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7159 - binary_accuracy: 0.6506 - f1: 0.6623 - loss: 0.6217 - prc_auc: 0.7044 - precision: 0.6310 - recall: 0.6994 - val_auc: 0.6927 - val_binary_accuracy: 0.6204 - val_f1: 0.5614 - val_loss: 0.6251 - val_prc_auc: 0.5236 - val_precision: 0.4625 - val_recall: 0.7140\n","Epoch 7/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7209 - binary_accuracy: 0.6531 - f1: 0.6616 - loss: 0.6182 - prc_auc: 0.7104 - precision: 0.6360 - recall: 0.6922\n","Epoch 7: Validation Metrics:\n","loss: 0.6231098175048828\n","val_binary_accuracy: 0.6240713000297546\n","val_precision: 0.46521738171577454\n","val_recall: 0.7008733749389648\n","val_auc: 0.6952586770057678\n","val_prc_auc: 0.5282989740371704\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7207 - binary_accuracy: 0.6528 - f1: 0.6617 - loss: 0.6183 - prc_auc: 0.7103 - precision: 0.6357 - recall: 0.6928 - val_auc: 0.6953 - val_binary_accuracy: 0.6241 - val_f1: 0.5592 - val_loss: 0.6224 - val_prc_auc: 0.5283 - val_precision: 0.4652 - val_recall: 0.7009\n","Epoch 8/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7247 - binary_accuracy: 0.6599 - f1: 0.6668 - loss: 0.6152 - prc_auc: 0.7145 - precision: 0.6441 - recall: 0.6939\n","Epoch 8: Validation Metrics:\n","loss: 0.620431661605835\n","val_binary_accuracy: 0.6277860403060913\n","val_precision: 0.4681481420993805\n","val_recall: 0.6899563074111938\n","val_auc: 0.6974396109580994\n","val_prc_auc: 0.5312554836273193\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7245 - binary_accuracy: 0.6596 - f1: 0.6668 - loss: 0.6153 - prc_auc: 0.7144 - precision: 0.6437 - recall: 0.6944 - val_auc: 0.6974 - val_binary_accuracy: 0.6278 - val_f1: 0.5578 - val_loss: 0.6200 - val_prc_auc: 0.5313 - val_precision: 0.4681 - val_recall: 0.6900\n","Epoch 9/20\n","\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7277 - binary_accuracy: 0.6633 - f1: 0.6688 - loss: 0.6124 - prc_auc: 0.7174 - precision: 0.6484 - recall: 0.6933\n","Epoch 9: Validation Metrics:\n","loss: 0.6179921627044678\n","val_binary_accuracy: 0.6329866051673889\n","val_precision: 0.47280967235565186\n","val_recall: 0.6834061145782471\n","val_auc: 0.6987428665161133\n","val_prc_auc: 0.5340985655784607\n","\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7275 - binary_accuracy: 0.6630 - f1: 0.6688 - loss: 0.6125 - prc_auc: 0.7173 - precision: 0.6480 - recall: 0.6938 - val_auc: 0.6987 - val_binary_accuracy: 0.6330 - val_f1: 0.5589 - val_loss: 0.6181 - val_prc_auc: 0.5341 - val_precision: 0.4728 - val_recall: 0.6834\n","Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250222_221335_outside_top_20_basic_nli.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - auc: 0.6827 - binary_accuracy: 0.6112 - f1: 0.4893 - loss: 0.6647 - prc_auc: 0.6841 - precision: 0.7048 - recall: 0.3976\n","Epoch 1: Validation Metrics:\n","loss: 0.6416540741920471\n","val_binary_accuracy: 0.6887072920799255\n","val_precision: 0.5376344323158264\n","val_recall: 0.5506607890129089\n","val_auc: 0.7168380618095398\n","val_prc_auc: 0.5761913657188416\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 361ms/step - auc: 0.6829 - binary_accuracy: 0.6115 - f1: 0.4904 - loss: 0.6645 - prc_auc: 0.6843 - precision: 0.7045 - recall: 0.3990 - val_auc: 0.7168 - val_binary_accuracy: 0.6887 - val_f1: 0.5441 - val_loss: 0.6127 - val_prc_auc: 0.5762 - val_precision: 0.5376 - val_recall: 0.5507\n","Epoch 2/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7357 - binary_accuracy: 0.6783 - f1: 0.6615 - loss: 0.6110 - prc_auc: 0.7333 - precision: 0.7069 - recall: 0.6226\n","Epoch 2: Validation Metrics:\n","loss: 0.6079253554344177\n","val_binary_accuracy: 0.7013372778892517\n","val_precision: 0.5582959651947021\n","val_recall: 0.5484581589698792\n","val_auc: 0.7235917448997498\n","val_prc_auc: 0.5841764211654663\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7357 - binary_accuracy: 0.6782 - f1: 0.6615 - loss: 0.6109 - prc_auc: 0.7332 - precision: 0.7065 - recall: 0.6228 - val_auc: 0.7236 - val_binary_accuracy: 0.7013 - val_f1: 0.5533 - val_loss: 0.6017 - val_prc_auc: 0.5842 - val_precision: 0.5583 - val_recall: 0.5485\n","Epoch 3/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7452 - binary_accuracy: 0.6903 - f1: 0.6703 - loss: 0.6015 - prc_auc: 0.7428 - precision: 0.7259 - recall: 0.6237\n","Epoch 3: Validation Metrics:\n","loss: 0.6012043356895447\n","val_binary_accuracy: 0.6991084814071655\n","val_precision: 0.5545657277107239\n","val_recall: 0.5484581589698792\n","val_auc: 0.726909339427948\n","val_prc_auc: 0.5878338813781738\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7452 - binary_accuracy: 0.6902 - f1: 0.6703 - loss: 0.6015 - prc_auc: 0.7427 - precision: 0.7255 - recall: 0.6239 - val_auc: 0.7269 - val_binary_accuracy: 0.6991 - val_f1: 0.5515 - val_loss: 0.5981 - val_prc_auc: 0.5878 - val_precision: 0.5546 - val_recall: 0.5485\n","Epoch 4/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7511 - binary_accuracy: 0.6939 - f1: 0.6749 - loss: 0.5961 - prc_auc: 0.7489 - precision: 0.7292 - recall: 0.6293\n","Epoch 4: Validation Metrics:\n","loss: 0.5968433022499084\n","val_binary_accuracy: 0.7013372778892517\n","val_precision: 0.5580357313156128\n","val_recall: 0.5506607890129089\n","val_auc: 0.7290156483650208\n","val_prc_auc: 0.5900874733924866\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - auc: 0.7511 - binary_accuracy: 0.6938 - f1: 0.6749 - loss: 0.5961 - prc_auc: 0.7488 - precision: 0.7288 - recall: 0.6296 - val_auc: 0.7290 - val_binary_accuracy: 0.7013 - val_f1: 0.5543 - val_loss: 0.5953 - val_prc_auc: 0.5901 - val_precision: 0.5580 - val_recall: 0.5507\n","Epoch 5/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7550 - binary_accuracy: 0.6971 - f1: 0.6803 - loss: 0.5920 - prc_auc: 0.7524 - precision: 0.7296 - recall: 0.6385\n","Epoch 5: Validation Metrics:\n","loss: 0.5933305025100708\n","val_binary_accuracy: 0.7005943655967712\n","val_precision: 0.5570470094680786\n","val_recall: 0.5484581589698792\n","val_auc: 0.7302342057228088\n","val_prc_auc: 0.5894700288772583\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7549 - binary_accuracy: 0.6970 - f1: 0.6802 - loss: 0.5920 - prc_auc: 0.7523 - precision: 0.7292 - recall: 0.6388 - val_auc: 0.7302 - val_binary_accuracy: 0.7006 - val_f1: 0.5527 - val_loss: 0.5929 - val_prc_auc: 0.5895 - val_precision: 0.5570 - val_recall: 0.5485\n","Epoch 6/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7590 - binary_accuracy: 0.6976 - f1: 0.6815 - loss: 0.5885 - prc_auc: 0.7559 - precision: 0.7290 - recall: 0.6410\n","Epoch 6: Validation Metrics:\n","loss: 0.5902768969535828\n","val_binary_accuracy: 0.6991084814071655\n","val_precision: 0.5543237328529358\n","val_recall: 0.5506607890129089\n","val_auc: 0.7314121723175049\n","val_prc_auc: 0.5903857350349426\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7589 - binary_accuracy: 0.6975 - f1: 0.6815 - loss: 0.5885 - prc_auc: 0.7558 - precision: 0.7286 - recall: 0.6412 - val_auc: 0.7314 - val_binary_accuracy: 0.6991 - val_f1: 0.5525 - val_loss: 0.5909 - val_prc_auc: 0.5904 - val_precision: 0.5543 - val_recall: 0.5507\n","Epoch 7/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7618 - binary_accuracy: 0.6989 - f1: 0.6854 - loss: 0.5855 - prc_auc: 0.7586 - precision: 0.7266 - recall: 0.6497\n","Epoch 7: Validation Metrics:\n","loss: 0.5875967144966125\n","val_binary_accuracy: 0.6968796253204346\n","val_precision: 0.5502183437347412\n","val_recall: 0.5550661087036133\n","val_auc: 0.7321109175682068\n","val_prc_auc: 0.5916274785995483\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7618 - binary_accuracy: 0.6989 - f1: 0.6854 - loss: 0.5855 - prc_auc: 0.7585 - precision: 0.7263 - recall: 0.6499 - val_auc: 0.7321 - val_binary_accuracy: 0.6969 - val_f1: 0.5526 - val_loss: 0.5891 - val_prc_auc: 0.5916 - val_precision: 0.5502 - val_recall: 0.5551\n","Epoch 8/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7643 - binary_accuracy: 0.6987 - f1: 0.6866 - loss: 0.5828 - prc_auc: 0.7608 - precision: 0.7237 - recall: 0.6538\n","Epoch 8: Validation Metrics:\n","loss: 0.5851530432701111\n","val_binary_accuracy: 0.6953937411308289\n","val_precision: 0.5474137663841248\n","val_recall: 0.5594713687896729\n","val_auc: 0.7327887415885925\n","val_prc_auc: 0.5921351909637451\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7642 - binary_accuracy: 0.6986 - f1: 0.6866 - loss: 0.5828 - prc_auc: 0.7606 - precision: 0.7235 - recall: 0.6540 - val_auc: 0.7328 - val_binary_accuracy: 0.6954 - val_f1: 0.5534 - val_loss: 0.5877 - val_prc_auc: 0.5921 - val_precision: 0.5474 - val_recall: 0.5595\n","Epoch 9/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7666 - binary_accuracy: 0.7032 - f1: 0.6928 - loss: 0.5803 - prc_auc: 0.7629 - precision: 0.7262 - recall: 0.6628\n","Epoch 9: Validation Metrics:\n","loss: 0.5828912854194641\n","val_binary_accuracy: 0.6961367130279541\n","val_precision: 0.5481798648834229\n","val_recall: 0.5638766288757324\n","val_auc: 0.7335110902786255\n","val_prc_auc: 0.5924369692802429\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7665 - binary_accuracy: 0.7032 - f1: 0.6927 - loss: 0.5804 - prc_auc: 0.7628 - precision: 0.7259 - recall: 0.6630 - val_auc: 0.7335 - val_binary_accuracy: 0.6961 - val_f1: 0.5559 - val_loss: 0.5863 - val_prc_auc: 0.5924 - val_precision: 0.5482 - val_recall: 0.5639\n","Epoch 10/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7683 - binary_accuracy: 0.7045 - f1: 0.6949 - loss: 0.5781 - prc_auc: 0.7650 - precision: 0.7261 - recall: 0.6666\n","Epoch 10: Validation Metrics:\n","loss: 0.5807836651802063\n","val_binary_accuracy: 0.6939078569412231\n","val_precision: 0.5448718070983887\n","val_recall: 0.5616739988327026\n","val_auc: 0.7341345548629761\n","val_prc_auc: 0.5928149223327637\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7683 - binary_accuracy: 0.7044 - f1: 0.6948 - loss: 0.5781 - prc_auc: 0.7649 - precision: 0.7258 - recall: 0.6667 - val_auc: 0.7341 - val_binary_accuracy: 0.6939 - val_f1: 0.5531 - val_loss: 0.5850 - val_prc_auc: 0.5928 - val_precision: 0.5449 - val_recall: 0.5617\n","Epoch 11/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7704 - binary_accuracy: 0.7046 - f1: 0.6955 - loss: 0.5760 - prc_auc: 0.7669 - precision: 0.7256 - recall: 0.6683\n","Epoch 11: Validation Metrics:\n","loss: 0.5787578821182251\n","val_binary_accuracy: 0.6939078569412231\n","val_precision: 0.5448718070983887\n","val_recall: 0.5616739988327026\n","val_auc: 0.7351951599121094\n","val_prc_auc: 0.594664454460144\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7703 - binary_accuracy: 0.7045 - f1: 0.6954 - loss: 0.5760 - prc_auc: 0.7668 - precision: 0.7253 - recall: 0.6684 - val_auc: 0.7352 - val_binary_accuracy: 0.6939 - val_f1: 0.5531 - val_loss: 0.5836 - val_prc_auc: 0.5947 - val_precision: 0.5449 - val_recall: 0.5617\n","Epoch 12/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7721 - binary_accuracy: 0.7060 - f1: 0.6976 - loss: 0.5740 - prc_auc: 0.7693 - precision: 0.7260 - recall: 0.6718\n","Epoch 12: Validation Metrics:\n","loss: 0.5768108367919922\n","val_binary_accuracy: 0.6953937411308289\n","val_precision: 0.5466101765632629\n","val_recall: 0.5682819485664368\n","val_auc: 0.7357383966445923\n","val_prc_auc: 0.5949180722236633\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7721 - binary_accuracy: 0.7059 - f1: 0.6975 - loss: 0.5740 - prc_auc: 0.7692 - precision: 0.7257 - recall: 0.6718 - val_auc: 0.7357 - val_binary_accuracy: 0.6954 - val_f1: 0.5572 - val_loss: 0.5825 - val_prc_auc: 0.5949 - val_precision: 0.5466 - val_recall: 0.5683\n","Epoch 13/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7743 - binary_accuracy: 0.7083 - f1: 0.7007 - loss: 0.5721 - prc_auc: 0.7719 - precision: 0.7272 - recall: 0.6765\n","Epoch 13: Validation Metrics:\n","loss: 0.5749539136886597\n","val_binary_accuracy: 0.6968796253204346\n","val_precision: 0.5491452813148499\n","val_recall: 0.566079318523407\n","val_auc: 0.7370211482048035\n","val_prc_auc: 0.5959850549697876\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7742 - binary_accuracy: 0.7082 - f1: 0.7006 - loss: 0.5721 - prc_auc: 0.7717 - precision: 0.7270 - recall: 0.6766 - val_auc: 0.7370 - val_binary_accuracy: 0.6969 - val_f1: 0.5575 - val_loss: 0.5814 - val_prc_auc: 0.5960 - val_precision: 0.5491 - val_recall: 0.5661\n","Epoch 14/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7762 - binary_accuracy: 0.7080 - f1: 0.7007 - loss: 0.5702 - prc_auc: 0.7740 - precision: 0.7263 - recall: 0.6773\n","Epoch 14: Validation Metrics:\n","loss: 0.5731423497200012\n","val_binary_accuracy: 0.6968796253204346\n","val_precision: 0.5491452813148499\n","val_recall: 0.566079318523407\n","val_auc: 0.7374941110610962\n","val_prc_auc: 0.5968993306159973\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7761 - binary_accuracy: 0.7079 - f1: 0.7007 - loss: 0.5703 - prc_auc: 0.7738 - precision: 0.7261 - recall: 0.6774 - val_auc: 0.7375 - val_binary_accuracy: 0.6969 - val_f1: 0.5575 - val_loss: 0.5805 - val_prc_auc: 0.5969 - val_precision: 0.5491 - val_recall: 0.5661\n","Epoch 15/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7780 - binary_accuracy: 0.7087 - f1: 0.7015 - loss: 0.5685 - prc_auc: 0.7764 - precision: 0.7270 - recall: 0.6782\n","Epoch 15: Validation Metrics:\n","loss: 0.5714037418365479\n","val_binary_accuracy: 0.6968796253204346\n","val_precision: 0.54935622215271\n","val_recall: 0.5638766288757324\n","val_auc: 0.7384163737297058\n","val_prc_auc: 0.5970084071159363\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7780 - binary_accuracy: 0.7086 - f1: 0.7014 - loss: 0.5685 - prc_auc: 0.7763 - precision: 0.7267 - recall: 0.6783 - val_auc: 0.7384 - val_binary_accuracy: 0.6969 - val_f1: 0.5565 - val_loss: 0.5796 - val_prc_auc: 0.5970 - val_precision: 0.5494 - val_recall: 0.5639\n","Epoch 16/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7796 - binary_accuracy: 0.7077 - f1: 0.7000 - loss: 0.5667 - prc_auc: 0.7779 - precision: 0.7267 - recall: 0.6758\n","Epoch 16: Validation Metrics:\n","loss: 0.569694459438324\n","val_binary_accuracy: 0.6968796253204346\n","val_precision: 0.5495689511299133\n","val_recall: 0.5616739988327026\n","val_auc: 0.7388929128646851\n","val_prc_auc: 0.5968690514564514\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7795 - binary_accuracy: 0.7076 - f1: 0.7000 - loss: 0.5668 - prc_auc: 0.7777 - precision: 0.7265 - recall: 0.6759 - val_auc: 0.7389 - val_binary_accuracy: 0.6969 - val_f1: 0.5556 - val_loss: 0.5786 - val_prc_auc: 0.5969 - val_precision: 0.5496 - val_recall: 0.5617\n","Epoch 17/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7812 - binary_accuracy: 0.7092 - f1: 0.7012 - loss: 0.5651 - prc_auc: 0.7796 - precision: 0.7289 - recall: 0.6761\n","Epoch 17: Validation Metrics:\n","loss: 0.5680372714996338\n","val_binary_accuracy: 0.6939078569412231\n","val_precision: 0.545064389705658\n","val_recall: 0.5594713687896729\n","val_auc: 0.7395448684692383\n","val_prc_auc: 0.597510814666748\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7812 - binary_accuracy: 0.7092 - f1: 0.7012 - loss: 0.5651 - prc_auc: 0.7795 - precision: 0.7286 - recall: 0.6762 - val_auc: 0.7395 - val_binary_accuracy: 0.6939 - val_f1: 0.5522 - val_loss: 0.5778 - val_prc_auc: 0.5975 - val_precision: 0.5451 - val_recall: 0.5595\n","Epoch 18/20\n","\u001b[1m113/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7826 - binary_accuracy: 0.7129 - f1: 0.7049 - loss: 0.5635 - prc_auc: 0.7812 - precision: 0.7325 - recall: 0.6797\n","Epoch 18: Validation Metrics:\n","loss: 0.5663985013961792\n","val_binary_accuracy: 0.6946508288383484\n","val_precision: 0.5460385680198669\n","val_recall: 0.5616739988327026\n","val_auc: 0.7404844164848328\n","val_prc_auc: 0.5983206033706665\n","\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - auc: 0.7826 - binary_accuracy: 0.7128 - f1: 0.7048 - loss: 0.5635 - prc_auc: 0.7811 - precision: 0.7322 - recall: 0.6798 - val_auc: 0.7405 - val_binary_accuracy: 0.6947 - val_f1: 0.5537 - val_loss: 0.5770 - val_prc_auc: 0.5983 - val_precision: 0.5460 - val_recall: 0.5617\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 368ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 280ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 288ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step\n","[[0 0 0 ... 0 1 1]\n"," [0 0 0 ... 0 1 1]\n"," [0 0 0 ... 0 1 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 1 0]\n"," [1 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS1,\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","#   )\n","\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS2,\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","#   )\n","\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS3,\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","#   )\n","\n","# #####################################################################################################################################################\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","\n","from google.colab import runtime\n","runtime.unassign()\n"],"metadata":{"id":"ARos-vMkU5iw","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ccf04eb279484992b3ab4444deffd9f3","836895a195614e8585c0c8315df9e203","51dc24b26c5846bba54742c60fb1e449","4a635675b4b048debccc0fb05b95e193","de1d8a62e5c845c487226b5d3741a697","9034f266f79b45dc9c9723fc44b5687f","daf01074d3d14b3daa06e1d93a95526a","1e6fa649ff634430a323f4261896847e","971bf3ff9bcc4d37b5b060be80847f46","bcc3b9c3d8d74dc2a985396514794c3d","cbe9938fd3284759942233b8d5c00143","bf93bcacabdd4a1f9ad4d891f09260a1","ec281bf2782c4074a513917c2c36598a","21c2fda734624ee084a2d98ae3112815","52d8ce05f4c74f44bfb8dd743dc984cb","a7d0932d36954aeb8b097e3a95219c86","3fe5a80af61341478805a294f2960765","e4f6244917ab4320b888fffeaf510204","1cb8c61c5efe4f499822578421e28aaa","73a148b3d03a43c683918016d08022bb","cb6b25945be6437ea606b0ee83e810ea","22602b2c18eb4f6f8211bc92bf364cf7","832b77df399142d8b9d723d6c959118a","ad6c09136a154b5ab1e22bd625fcab8d","eafc4af6bff9483e9af1a6e3264d2ee5","fe3b00f874674dee97b2d9aacb813207","343d8886b97f4b61905c85010696d913","250521bb8d8a47f0a9c903b3118b4ed6","05af75900b3a4851a7d2e77f4d1ac888","f39489081dfb465fa50ada5aaa4421d1","aeb858e5c9a14456966f6d835805ddfb","edc6e8e284274038bf43aa9c7842af4a","da043eb6203346e7b205146011a77ab9","422cf6b8a8b641549989c163554764ad","537a8f7dd930428eba40fe3841cd2bf6","d0885150fd0d487c800cbfaf5d9ddd63","da0b9d44a2834e668c1cdbbd9aedf1b8","7a4e916433e14febbaf17bd192ee82d8","613db4b7577240b8a7e10b92ab07df24","09d7493be2884f4eb0bf82af6b81a331","bdc8d61906ad493199f3877d0ae6c2f6","2be275799c1449af942628c9ddc2cb93","2e28561ff3434f55921db84a20564782","509b89f35c724b758de0a2333ae1977f","caea72a479794d7aa90ba7a0e8ace7f6","b58fe5004d0e4500901a663968fcade2","8a23b889b58a460786833df1333ab872","b2a9c07aaa874ec7a7e7d2428c6ff406","65684ee8400b4db4b641a44da07ce6c4","c518c43599bd43df821a816a42298b1c","24fc9d0919eb47adb8f6b99df3e2a0e9","67d64a2ae82f4338a83de95fe26f3ba0","b8bf0aadbc37400f8c2deb94f3b14f76","f85c497d3e6d4fea829937c8c654a1c2","feb6859745a743378ab162d46667d3b1","49ec40c3c4f04e1d84f21994098b91b6","28f370263b2149b7abfe54f845d8de14","def0e8563b1b4f8cbe12b0b7067abec7","c3e0be24e7b84e8497003c78540a03d9","5e5355f4479949b69d531d578c3633c5","1e664bc40dd54d68a46a1b8d9abdbdb9","909a22ff6b6243f187c8579d274476ff","f24cc12671504ea3ab78444b25bbf95f","f9271dc9c7f74230885f45b4c5f5b5c1","fce988744caa45e2a683f84ec3efc8c7","7e0b6d1909fa409e9318b5b04f613f91","53f0b3c79c784c11bfbbafef2928bc34","b1e28497887b4eabb0b3af3078f7cfd7","b318a93f98f24a84a7b51fadbd44dcd1","1bd96184841b4ab9be30ea36cc1d356a","5e7593d188b24b76825c84810885f75e","6efaa3f968e7404187b9aaedaa4d3ed6","1edef61bfa3641b387e32e3a42fd4657","5b352bbe409d45c9b33c8c6ed51d0b43","e8c4d5e5e1c2418da5f19d406a6d285f","e7789427c7c14126b735d65a9ca58778","f95ef765dd66491daf610e0ad3bdfe03","c1644eea704c4784a257654aae2ba7d9","fc6fee65997445f29ac87b6b0926a0f8","40d33a173ef2462fb91251d0a163632d","eb61704ce32c40df9db5ced7a236dbb9","fcd9911466634f4aa1649d66f6353de1","a216558fc8f047e7ae5c216d468386f3","707d7e3900ac430a9782be75bd0eae8c","ce9b3cb41b0d4dc88226330b3be05565","70f986ec02e54a078f022075995b93ae","1691ad62a7c24acab3def60323fea468","63a5b9f5f3204bed870a29f8c2f580ae","3d302daad61d449d8d7fb10f731d13b2","0d7aa28196ec45c1bf1f55f5c943d616","74dfbe15b6124f63994a1ce82c522b61","50598175aec34cf0b04d9372edca3f00","6383c05f294640d894ea60f5ca2b3b5c","12ce0b4287634be3a8b38cd921b79720","92486ca3383748a3a8acd39bb45a39d2","41c58315af11486b8f68f84fd070ebbd","bec838229faf4b60a5514cb5f67ccbc9","792c9cad1b1e45d78a0dc93ad3b455b2","5685778154594b16836a94bb5275bdaa","677ed44b74604f4c8bfda6bc74310832","bcbecfa0c1e4429e93250eee0e2da748","cea196c97a734ae3911e63dac2ac5c65","8bdc7154dbd0444e9a85a7553983960e","a40c3a0f655c4e1893d3f4e692b76444","571e702ed4bb47c1912bf0c3ae440fa3","f2ffb498e1874587a4192b8afba0b78b","f1f01e020d2540f2b99e5dee6d84dd12","cb00f64df1b645dba309b988d0ec8a11","1ed5f5c1a46845d2a325967d1da4a86b","6924a13879d649dc8271c785c607a82f","71642e6ce884417797c3718879cf6e2d","a00e0cee92434c3fbb1674618896c985","c1ae79a6f49b42069fff84605079a47d","7ded4c8a54674148bf5854314eacd74b","6b2c6e36344a499e9811a1bdd5b10859","b8aaf495d90744838fac8556d859b1a1","68c1a0b29ace4eb18ac62a9bc1e7bbab","3077a6fec03c4c97a1fab3ae2b8c8485","a24d71197d7a410f92291a055ff527dc","70fb81a9395a492dbba8b83f246e362f","68ae6530d4ed4b1f9c5c475b04adf84a","6d65a8413ee84599901e66b322696215","49b9a034959340058247e7130efd6691","3111dec24bc5473ba268b9746574af67","f229e64462c04f68a6cb88c3d1847e9b","d78288a5a8994a998c5d2d96a0640cb9","6f14ed022d37408fae02d01851bb4b07","6d1c3083c6a643faada7a4931a117ce0","493999a8bbc64d5892e4cf9db3a0b58c","967b0e1247ed4fd6bd35175291a55c76","9ddd190ae2dd4c2a97ab503982711e60","cf5b6cdd17a445c784b6094a72dc1366","e86cb7c9806c4feeb34a3d0dd2092ff3","74dd3a58f7d84b899918f3d17ed42ed8","4064e90126904b59834089521634e812","57e596e03ead43ec9a1ca7c6751c145d","81e67cc6a8b54341ae714d0817a6efc0","b4c84a5f9a6b460e94783cc156443210","42f4775c673342c59ceba157c1f8844f","2ce741a4f9b240cc87867480d7230f33","4239ded27f774dee87d080fb9787eea4","a35d0357ac884d54aec072b206e7535c","b04d10e149ee4d7694dfca8ee5029f5c","bfc64a146b8c4b938b522fc97510541a","4ec9a6d2df174dc59b2718223e72e9da","24e369e44af74a018c94e746f7acad48","a17debfd92de44d9b23eeefb75225a28","95f5784aea704f67ba10073af0222906","a9e42f2cf8d443bfb1aa95d0862e2acc","d84c06b39d4e4daea721497db2998800","d1fa2ce5c8ec4abf99f7cce9134705a9","d9b790dd18854493bd80a68771b457bc","ca107895440a4c36af97b5db8de966f9","33b2a2280e604f80a35bf884957a0cce","1e80575a87344138b346e5a6aa02c4e2","d2099194d95d480f9a5df7d1ea3fb610","5ff38cb00f2540d096a9909a5b484796","8d3471bf474941cfbace94ca8d0fbca6","84f14ff84eba4d679a0408dc38a3fa2f","963b5569231a46daa7fdee8ef84b8189","6cf3e3d516074575bf0d11dad1521485","23c010ad3b5b4ae389b7d46629f253a2","fe692b61a8e04f16b0d718bad4c2ea71","9225bbd0fb1e4ab4868ee8792cd19d80","9aa6846c58cf4bdc9f39f689efaabd43","5d7ab395ea204de5be665a42cfa90f54","00791fef3d0c4d778041fd78349713d8","b87fa2973ae44f51a9b366e54c7cd0da","fd21113757cf42798b9ddc64e4c30317","21f8458fb65a425bae8220b67e36250a","ff6d3f8e1c934bc284c114988985ec2b","5fb8db3cb5f44fb38bb8368a3c4c14e6","5649c4d6ba3445afa44bd41295b43957","a3c50c8713ef4ac08e73465626048a78","f8c17a10a03a48069557f257f21d8459","06d0d2b4db2f4d66b50c8dfd53161493","9336a90fffe640ff81176b1213e7d5dc","6a8c195e925544a9ad51c7e81ee18384","9cf3d1b386d242a8ba54a92eccc6a43b","79f9a3c0025048dabbcf3253b4eb5c7a","dda6ae87efc14bd98eeda352ceda26a3","374fed6d5e2544e191ad1e08ab0fc565","7f1f1d094b7d4f8699853f183fee8c6a","bbf1a760145646b0b959bdca8b230df3","3220883a6a074709bd35da9f2ca59d6d","d614cfca2441438f96a6d19e99abe375","1f1f72f6631c48e99c4192eb481743df","aad853de1c5a4de2ac40e03898f83b7b","a7822304c12d40978b33cd205d4ac1e9","d7fdc1ef098744aa9d753b3216549b68","9631324e1e5444928a39fe91f0347d0c","c53a8fd59ff44c17bb00dbf0565f252a","fe9cc3fe801349f89824a8bbbd859915","f1a0c9d8c5ae45dfb73c46fc957891d3","e32ebb8aa5a24256b75a3ed4bd2161b6","0da362670eb440658e73bdfd7e13c8d9","de55984aa91e46dda25fb6cb806d79af","9b632f78b50d4a03a3f5efb0ea861329","7c993ee3dca74c7fabea6eaa6dba8941","222fc8937918437780ea04f4fe16e7ed","760aaab16b544c1fa63bfe841f02eee8","f59d0ade57054f25b52d393c0204a981","56027c61842f4043a2677041d3ab88a9","3e762003ea694b87b2e48a6b9b223ab7","5864d12e8a5c40ddbc83f37edb0d26cb","885187f76ce84a9280fd0e250e3b4b76","1690ddabdf3d4ab491bb211c402be8ec","0215a5f131cd43db8f37a3f509fc1236","92d397a0ae6249229ff276c347635bb9","32baae8c556e4249b2a27259dd41d07c","79f8df41bfbd4ca6a7a8b893c2679f0b","4be694bd26c24b96812055f1072308d6","360cdc5b28ae45b481a29698c9f123ea","1cf5fa0962f542008b97942ac986832a","d788339bd0ae49da936e5f98dc4b97bd","bfe76fd999cb4b00b3fe71ae0350d41f","6a86a1ec6ddd43c8a51b831a4ef295a7","c4aa2d0c5f924134b6bab6218601aaa9","c48898c115584761a5bb379c2204a905","b6dce6643af34f0894eeb706027d9338","076b0a045ef145d9b50fbfcc6e45def8","535fa29e2352482eacfee35308893c78","b03ab33e3eae4c42abedb76b03c7d1e8","a460371e426b45ee81687188f44ab7c7","a0b9124bbc6d410ba2ef6958a0092290","d83ca7ff81734fe2b1dd9b7b1d23b9d8","574cee6b2deb42d794bf21d7ea7a63d2","aeb91f3c6cd44930a1f2bf0113424093","500d6b56b521466eb85f2ff63a2f00d9","0ea9644a6620472298f0deba77ffefb2","2f30e50b6cc443cd8926fc5d42b0d56d","7cdc09cbcda642b6b4c9cb46aad2ef7d","02a1abff8e4d4453b48da02c4f89db72","53084811783b44ababf1d1ee45cef78e","1c55f2ba3efb4fecb50da5761a1aa644","ba1bf99522e244f1a3321ad0a8986468","16df382a6f724aa599751c3780646308","439aaff96c5c480a8a92b0ca8604e706","1d151db52d5e493cbb775d7519453f85","98c4b45d991b4ae3aabefb91a524f588","2eee22eb65d44063bd58942226c66a53","23ee00d77956404bb5dcbcbae3ac7359","e625654715a645c598dbf3e8b3d82b29","1b73ee7e7c964a029e5cfaf7577b0271","6a4bb5349d334ba89a4ff598a58ec869","c1b3b1fa8fbc454c8bb686b85e8cf2c6","90eb93fbe8824653a242b1c5cf8ef58c","434eac6ce2824698a10c35abfcf85f7b","53c257828eff4d76a7311582d54897c0","08a4a442f7684b83b2512f27674af64c","882397236b394fa2900f09dc4311b54c","b99169cd5d13443caf1acd9a86df300e","cc598401f15e4a68a1f9c89947178fd8","bf38e228e6f04f3eb3bb3b34e30d5b8d","c4a0be73470840df89dd39a385e147d0","48e65eded86c4810b5b6836625c813e9","99475dd37a6c400293f99771d82c728c","f8b6ac486d014079a1231a3328cb952f","0e67b02275ad4e81a8bd13498d34b36d","73d90ef2491a48df936ddb1a4e84aea5","98eee075a07d4ce79820a5547a938183","05773aff8dd2434284468c20cae6ac69","601cd6589bf84dcfab179021242e51cf","05eb30b6c16c4f2abba71898d774497e"]},"executionInfo":{"status":"ok","timestamp":1740613716663,"user_tz":-120,"elapsed":2102056,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"4aa4e943-febb-4963-e500-319c714c4c25"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-MiniLM-L6-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n","[[0 1 0 0 1]\n"," [0 1 0 0 0]\n"," [0 1 0 0 0]\n"," ...\n"," [0 1 1 0 0]\n"," [1 1 1 0 1]\n"," [0 1 0 1 0]]\n","Training and evaluating model: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccf04eb279484992b3ab4444deffd9f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf93bcacabdd4a1f9ad4d891f09260a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832b77df399142d8b9d723d6c959118a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422cf6b8a8b641549989c163554764ad"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caea72a479794d7aa90ba7a0e8ace7f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ec40c3c4f04e1d84f21994098b91b6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step\n","[[0 1 0 1 1]\n"," [1 1 0 1 1]\n"," [1 1 1 1 1]\n"," ...\n"," [0 1 1 1 1]\n"," [1 1 1 1 1]\n"," [0 1 0 1 1]]\n","Training and evaluating model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f0b3c79c784c11bfbbafef2928bc34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1644eea704c4784a257654aae2ba7d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d302daad61d449d8d7fb10f731d13b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"677ed44b74604f4c8bfda6bc74310832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71642e6ce884417797c3718879cf6e2d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d65a8413ee84599901e66b322696215"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 863ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 856ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 866ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 866ms/step\n","[[1 0 0 1 0]\n"," [0 0 0 0 0]\n"," [1 0 0 1 0]\n"," ...\n"," [0 0 0 1 0]\n"," [0 0 0 1 0]\n"," [0 0 0 0 0]]\n","Training and evaluating model: sentence-transformers/paraphrase-albert-small-v2\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e86cb7c9806c4feeb34a3d0dd2092ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc64a146b8c4b938b522fc97510541a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e80575a87344138b346e5a6aa02c4e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7ab395ea204de5be665a42cfa90f54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9336a90fffe640ff81176b1213e7d5dc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aad853de1c5a4de2ac40e03898f83b7b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 269ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 134ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step\n","[[0 0 0 0 0]\n"," [0 0 0 0 1]\n"," [0 1 0 1 0]\n"," ...\n"," [0 1 0 0 1]\n"," [0 0 0 0 1]\n"," [0 0 0 0 0]]\n","Training and evaluating model: roberta-base\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c993ee3dca74c7fabea6eaa6dba8941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32baae8c556e4249b2a27259dd41d07c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076b0a045ef145d9b50fbfcc6e45def8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cdc09cbcda642b6b4c9cb46aad2ef7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e625654715a645c598dbf3e8b3d82b29"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf38e228e6f04f3eb3bb3b34e30d5b8d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 904ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 868ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 868ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 862ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 864ms/step\n","[[0 0 0 1 1]\n"," [0 0 0 1 1]\n"," [0 0 0 1 1]\n"," ...\n"," [0 0 0 1 1]\n"," [0 0 0 1 1]\n"," [0 0 0 1 1]]\n","Training and evaluating model: sentence-transformers/all-MiniLM-L6-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 199ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","[[1 1 0 ... 0 1 1]\n"," [0 1 1 ... 0 0 1]\n"," [0 1 0 ... 0 1 0]\n"," ...\n"," [0 1 0 ... 0 0 1]\n"," [0 1 0 ... 0 1 1]\n"," [0 1 0 ... 0 0 1]]\n","Training and evaluating model: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n","[[1 1 1 ... 0 1 1]\n"," [0 1 0 ... 0 0 1]\n"," [0 1 1 ... 0 0 1]\n"," ...\n"," [0 1 0 ... 0 0 1]\n"," [0 1 0 ... 0 0 1]\n"," [0 1 0 ... 0 0 1]]\n","Training and evaluating model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 330ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 238ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 235ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 232ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 233ms/step\n","[[0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 1 1]\n"," [1 0 0 ... 1 1 1]\n"," ...\n"," [1 0 0 ... 1 1 1]\n"," [1 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 0 1]]\n","Training and evaluating model: sentence-transformers/paraphrase-albert-small-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step\n","[[0 0 1 ... 1 1 1]\n"," [0 0 0 ... 0 1 1]\n"," [0 0 1 ... 1 1 1]\n"," ...\n"," [0 0 0 ... 0 1 1]\n"," [0 0 0 ... 1 1 1]\n"," [0 0 0 ... 0 1 1]]\n","Training and evaluating model: roberta-base\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 297ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 241ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 236ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 234ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 232ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 233ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 231ms/step\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 233ms/step\n","[[0 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 1 0]\n"," [0 0 0 ... 1 1 0]\n"," ...\n"," [0 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 1 1]\n"," [0 0 0 ... 1 1 1]]\n","Training and evaluating model: sentence-transformers/all-MiniLM-L6-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step\n","[[0 1 0 ... 1 0 1]\n"," [0 1 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 1]\n"," ...\n"," [0 1 0 ... 0 0 1]\n"," [1 1 0 ... 1 0 1]\n"," [1 1 0 ... 0 0 1]]\n","Training and evaluating model: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 118ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step\n","[[1 1 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 1]\n"," [0 1 1 ... 0 0 1]\n"," ...\n"," [1 1 0 ... 0 0 1]\n"," [0 1 1 ... 0 0 1]\n"," [0 1 1 ... 0 0 1]]\n","Training and evaluating model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 310ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 282ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 271ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 259ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]\n"," [0 1 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 1 0 0]\n"," [1 0 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 0]]\n","Training and evaluating model: sentence-transformers/paraphrase-albert-small-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFAlbertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 229ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step\n","[[0 1 0 ... 1 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 1 0 ... 1 0 0]\n"," ...\n"," [0 0 0 ... 1 0 0]\n"," [1 1 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 0]]\n","Training and evaluating model: roberta-base\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 10\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 11\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 12\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 13\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 14\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 15\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 16\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 17\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 18\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 19\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 294ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 272ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 268ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 262ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 261ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 259ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 259ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 263ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 264ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 263ms/step\n","\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 262ms/step\n","[[0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," ...\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]\n"," [0 0 0 ... 1 0 1]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}]},{"cell_type":"markdown","source":["SINGLE MODEL CLASSIFIER - TRAIN AND EVALUATE DA MODELS"],"metadata":{"id":"L0Vx8AGaJbjR"}},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","transformer_evaluator = TransformerEvaluator()\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS1,\n","#     transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","#   )\n","\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS2,\n","#     transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","#   )\n","\n","# transformer_evaluator.evaluate_models(\n","#     epochs=20,\n","#     batch_size=32,\n","#     number_of_tags=NUMBER_OF_TAGS3,\n","#     transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","#     train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","#     val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","#     test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","#   )\n","\n","# # #####################################################################################################################################################\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_5_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_10_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250222_221335_outside_top_20_basic_nli'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","\n","from google.colab import runtime\n","runtime.unassign()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c40551fd6a204496aab63746030dc133","86e119d5fbc747c4a2f7d59f1522a520","c5b3c566654b4744993d2c81a97eaece","34341afe13524ef7b58c4c034f59b712","7d759b781df44d619cccc2637fbabdfd","7b5e2b4c459849c9a84b9f76cb7d33a4","d34ab93ae1c241fd8df8c5ad3ab78f5b","17ace896a7704f6a8ac6b0aea63fc040","ef5a943ccd764c1cbb33f22d4ae586e3","8d32a13856244321805488f47acd5e30","6d681b94b74b4d1883dfa22210e6bce6","0e22bbe20e7c40449a08f8ea798aa541","027b5fd9790c4119a4db1714c7803114","8d2935eab487460db1980d1d3bc88d11","9a07ef28e915401985ede6e114d23ac3","a7020ce267484634b191980c8bb27cde","871ee480fc6b4f25b8d3202c7bbb2108","8cf608532abc445288921239fc584581","691b378f0dac47589d0e083d36a55918","9df2db4569194334abc01be470ba2cb8","10e43c6bab1346a582d417d5c0d4a12b","8b4f524b85154eb18d54b72698497f8d","4f356e8df36c4a98a6d44c45d288ad59","80402d63b1fb475abd5d6a2f0aa2c01d","d42d416adbf54582b1b83126c706a282","3a34f246f2944fc5aed970fe56e503b8","e40a241647734799ae4d1aa3d6f61cac","95dc6be54e324831831e6b5400840869","95ac6de2264a43ecab04912f2e5e0d0e","05124c8c36ed45e09676865b96c352ee","974950d387554c92b2f5336ff0f72f0f","011a1cfcbd37422bb330a1e443061f29","a1a57919da584dd9900b0b1157b57219","e09d175a5e2b4f899c0ce23f26177709","2ee658396d5c4fa5abe1ca349ee42c0a","7f16de82fa3b496c9f9dde188b7243cc","9acb0d31d3ed4c23803f5cf2d02d1028","a150344daae14523a5d5ade8bd1ddad9","edf31995e80c4da69ac8fb3d38016191","8a59f4de8f67445798277f33237661c8","0ef0bce0f70849299fdf61cd603389da","cf23cdc7fbc3415bb89e7a0a6a766745","ff9e189837474f3db7e4fcd40e807901","aa85b43b497e48808561dfd234e34d48","5204ebb5e3d54229a31a7e7c3d14f1dd","ebbc42abcdc642629b954ea41b8d7dda","5030c9c0c7e94015bb50d2d830957d7e","6e4351a9d7ba46509edacd81745a5651","11a0c92e8aaf4292befa68d47fce9613","3982539096a04f738e6887c56590cf0f","ef6316aec90d4955bfe3eb412ef1f76b","e68870ff030e41b4aad049f69e4b8601","7bf0776dfa69482a92a787667468eeed","b095222e42f34fb9b3f7a99d65f3056c","7c3c3dc1b0384894865f38e1e00d9c2c","530960d0c3ba435cac9da593c9eed4f0","48b9698da35a4f25b4269430ade864cf","5992c320a8244327a29e8cacb09d2610","21bf43765df046d3b88aa2adb9a13a38","eec97ce4407c4fed9796aa533413bdcc","a854e24919c649d09e34218e71a8e81a","d5cc28f8fcc34aae9ee9f9c4ce99f727","72e04e288198402abb0a98f3000d829b","d4c71eabba65455790d9aa732d1eec4e","49891c85dba14f66869945fb5c333b86","82b56546da3f43f58ac5a710bd0e0b6d"]},"id":"6dqgS2f63ILl","outputId":"4766653c-57c7-42c3-af12-da2dd659e550"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40551fd6a204496aab63746030dc133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e22bbe20e7c40449a08f8ea798aa541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f356e8df36c4a98a6d44c45d288ad59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09d175a5e2b4f899c0ce23f26177709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5204ebb5e3d54229a31a7e7c3d14f1dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"530960d0c3ba435cac9da593c9eed4f0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.5482 - binary_accuracy: 0.6643 - label_wise_accuracy: 0.6754 - label_wise_f1_score: 0.0288 - label_wise_macro_f1: 0.0787 - loss: 0.6611 - prc_auc: 0.3609 - precision: 0.4279 - recall: 0.0912 - subset_accuracy: 0.0417 - subset_f1: 0.1077 - subset_precision: 0.1259 - subset_recall: 0.0955\n","Epoch 1: Validation Metrics:\n","loss: 0.6399968266487122\n","val_label_wise_f1_score: [0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.84375 0.59375 0.71875 0.625   0.46875]\n","val_binary_accuracy: 0.6798214912414551\n","val_precision: 0.0\n","val_recall: 0.0\n","val_label_wise_macro_f1: 0.0\n","val_subset_accuracy: 0.0\n","val_subset_precision: 0.0\n","val_subset_recall: 0.0\n","val_subset_f1: 0.0\n","val_auc: 0.6405999660491943\n","val_prc_auc: 0.4752018451690674\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - auc: 0.5483 - binary_accuracy: 0.6643 - label_wise_accuracy: 0.6753 - label_wise_f1_score: 0.0286 - label_wise_macro_f1: 0.0783 - loss: 0.6609 - prc_auc: 0.3609 - precision: 0.4279 - recall: 0.0907 - subset_accuracy: 0.0416 - subset_f1: 0.1072 - subset_precision: 0.1253 - subset_recall: 0.0951 - val_auc: 0.6406 - val_binary_accuracy: 0.6798 - val_label_wise_accuracy: 0.6500 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 0.0000e+00 - val_loss: 0.6099 - val_prc_auc: 0.4752 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_subset_accuracy: 0.0000e+00 - val_subset_f1: 0.0000e+00 - val_subset_precision: 0.0000e+00 - val_subset_recall: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.6508 - binary_accuracy: 0.6778 - label_wise_accuracy: 0.6796 - label_wise_f1_score: 0.0078 - label_wise_macro_f1: 0.0025 - loss: 0.6075 - prc_auc: 0.4943 - precision: 0.5187 - recall: 0.0015 - subset_accuracy: 0.0014 - subset_f1: 0.0021 - subset_precision: 0.0024 - subset_recall: 0.0019\n","Epoch 2: Validation Metrics:\n","loss: 0.6039007902145386\n","val_label_wise_f1_score: [0.         0.         0.19999996 0.         0.11111109]\n","val_label_wise_accuracy: [0.84375 0.59375 0.75    0.625   0.5    ]\n","val_binary_accuracy: 0.6837500333786011\n","val_precision: 0.8055555820465088\n","val_recall: 0.016174010932445526\n","val_label_wise_macro_f1: 0.02424181066453457\n","val_subset_accuracy: 0.015178571455180645\n","val_subset_precision: 0.02589285559952259\n","val_subset_recall: 0.02023809216916561\n","val_subset_f1: 0.022265834733843803\n","val_auc: 0.6706148386001587\n","val_prc_auc: 0.5146211981773376\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - auc: 0.6508 - binary_accuracy: 0.6778 - label_wise_accuracy: 0.6795 - label_wise_f1_score: 0.0082 - label_wise_macro_f1: 0.0025 - loss: 0.6074 - prc_auc: 0.4944 - precision: 0.5211 - recall: 0.0015 - subset_accuracy: 0.0014 - subset_f1: 0.0021 - subset_precision: 0.0024 - subset_recall: 0.0019 - val_auc: 0.6706 - val_binary_accuracy: 0.6838 - val_label_wise_accuracy: 0.6625 - val_label_wise_f1_score: 0.0622 - val_label_wise_macro_f1: 0.0242 - val_loss: 0.5957 - val_prc_auc: 0.5146 - val_precision: 0.8056 - val_recall: 0.0162 - val_subset_accuracy: 0.0152 - val_subset_f1: 0.0223 - val_subset_precision: 0.0259 - val_subset_recall: 0.0202\n","Epoch 3/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.6783 - binary_accuracy: 0.6852 - label_wise_accuracy: 0.6894 - label_wise_f1_score: 0.0634 - label_wise_macro_f1: 0.0442 - loss: 0.5932 - prc_auc: 0.5274 - precision: 0.8203 - recall: 0.0308 - subset_accuracy: 0.0223 - subset_f1: 0.0402 - subset_precision: 0.0496 - subset_recall: 0.0350\n","Epoch 3: Validation Metrics:\n","loss: 0.5896905660629272\n","val_label_wise_f1_score: [0.         0.         0.19999996 0.15384614 0.69230765]\n","val_label_wise_accuracy: [0.84375 0.59375 0.75    0.65625 0.75   ]\n","val_binary_accuracy: 0.7001785635948181\n","val_precision: 0.7766990065574646\n","val_recall: 0.08923591673374176\n","val_label_wise_macro_f1: 0.11683852225542068\n","val_subset_accuracy: 0.07232142984867096\n","val_subset_precision: 0.1428571343421936\n","val_subset_recall: 0.10401786118745804\n","val_subset_f1: 0.11953115463256836\n","val_auc: 0.6933333873748779\n","val_prc_auc: 0.534949779510498\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - auc: 0.6784 - binary_accuracy: 0.6852 - label_wise_accuracy: 0.6896 - label_wise_f1_score: 0.0644 - label_wise_macro_f1: 0.0444 - loss: 0.5932 - prc_auc: 0.5275 - precision: 0.8202 - recall: 0.0309 - subset_accuracy: 0.0224 - subset_f1: 0.0404 - subset_precision: 0.0498 - subset_recall: 0.0351 - val_auc: 0.6933 - val_binary_accuracy: 0.7002 - val_label_wise_accuracy: 0.7188 - val_label_wise_f1_score: 0.2092 - val_label_wise_macro_f1: 0.1168 - val_loss: 0.5818 - val_prc_auc: 0.5349 - val_precision: 0.7767 - val_recall: 0.0892 - val_subset_accuracy: 0.0723 - val_subset_f1: 0.1195 - val_subset_precision: 0.1429 - val_subset_recall: 0.1040\n","Epoch 4/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7024 - binary_accuracy: 0.7012 - label_wise_accuracy: 0.7051 - label_wise_f1_score: 0.1647 - label_wise_macro_f1: 0.1445 - loss: 0.5788 - prc_auc: 0.5468 - precision: 0.7544 - recall: 0.1094 - subset_accuracy: 0.0842 - subset_f1: 0.1460 - subset_precision: 0.1761 - subset_recall: 0.1260\n","Epoch 4: Validation Metrics:\n","loss: 0.5753670930862427\n","val_label_wise_f1_score: [0.         0.         0.36363634 0.28571427 0.74074066]\n","val_label_wise_accuracy: [0.84375 0.59375 0.78125 0.6875  0.78125]\n","val_binary_accuracy: 0.7116071581840515\n","val_precision: 0.7031963467597961\n","val_recall: 0.17177914083003998\n","val_label_wise_macro_f1: 0.20802390575408936\n","val_subset_accuracy: 0.11339285969734192\n","val_subset_precision: 0.27142855525016785\n","val_subset_recall: 0.18790178000926971\n","val_subset_f1: 0.2212795913219452\n","val_auc: 0.7159169316291809\n","val_prc_auc: 0.5523268580436707\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7024 - binary_accuracy: 0.7012 - label_wise_accuracy: 0.7053 - label_wise_f1_score: 0.1655 - label_wise_macro_f1: 0.1446 - loss: 0.5788 - prc_auc: 0.5468 - precision: 0.7543 - recall: 0.1095 - subset_accuracy: 0.0843 - subset_f1: 0.1462 - subset_precision: 0.1763 - subset_recall: 0.1261 - val_auc: 0.7159 - val_binary_accuracy: 0.7116 - val_label_wise_accuracy: 0.7375 - val_label_wise_f1_score: 0.2780 - val_label_wise_macro_f1: 0.2080 - val_loss: 0.5688 - val_prc_auc: 0.5523 - val_precision: 0.7032 - val_recall: 0.1718 - val_subset_accuracy: 0.1134 - val_subset_f1: 0.2213 - val_subset_precision: 0.2714 - val_subset_recall: 0.1879\n","Epoch 5/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7242 - binary_accuracy: 0.7118 - label_wise_accuracy: 0.7151 - label_wise_f1_score: 0.2330 - label_wise_macro_f1: 0.2224 - loss: 0.5656 - prc_auc: 0.5647 - precision: 0.7030 - recall: 0.1849 - subset_accuracy: 0.1336 - subset_f1: 0.2426 - subset_precision: 0.2939 - subset_recall: 0.2079\n","Epoch 5: Validation Metrics:\n","loss: 0.5626412630081177\n","val_label_wise_f1_score: [0.         0.         0.33333328 0.49999997 0.7142857 ]\n","val_label_wise_accuracy: [0.84375 0.59375 0.75    0.75    0.75   ]\n","val_binary_accuracy: 0.7151785492897034\n","val_precision: 0.6633663177490234\n","val_recall: 0.22420524060726166\n","val_label_wise_macro_f1: 0.25067633390426636\n","val_subset_accuracy: 0.14553570747375488\n","val_subset_precision: 0.34776782989501953\n","val_subset_recall: 0.24392855167388916\n","val_subset_f1: 0.2857776880264282\n","val_auc: 0.7303380370140076\n","val_prc_auc: 0.5650767087936401\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7242 - binary_accuracy: 0.7118 - label_wise_accuracy: 0.7153 - label_wise_f1_score: 0.2335 - label_wise_macro_f1: 0.2225 - loss: 0.5656 - prc_auc: 0.5648 - precision: 0.7030 - recall: 0.1849 - subset_accuracy: 0.1336 - subset_f1: 0.2428 - subset_precision: 0.2940 - subset_recall: 0.2080 - val_auc: 0.7303 - val_binary_accuracy: 0.7152 - val_label_wise_accuracy: 0.7375 - val_label_wise_f1_score: 0.3095 - val_label_wise_macro_f1: 0.2507 - val_loss: 0.5585 - val_prc_auc: 0.5651 - val_precision: 0.6634 - val_recall: 0.2242 - val_subset_accuracy: 0.1455 - val_subset_f1: 0.2858 - val_subset_precision: 0.3478 - val_subset_recall: 0.2439\n","Epoch 6/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7386 - binary_accuracy: 0.7174 - label_wise_accuracy: 0.7205 - label_wise_f1_score: 0.2742 - label_wise_macro_f1: 0.2650 - loss: 0.5548 - prc_auc: 0.5787 - precision: 0.6786 - recall: 0.2359 - subset_accuracy: 0.1603 - subset_f1: 0.3025 - subset_precision: 0.3653 - subset_recall: 0.2598\n","Epoch 6: Validation Metrics:\n","loss: 0.552379310131073\n","val_label_wise_f1_score: [0.         0.         0.33333328 0.49999997 0.7586207 ]\n","val_label_wise_accuracy: [0.84375 0.59375 0.75    0.75    0.78125]\n","val_binary_accuracy: 0.7192856669425964\n","val_precision: 0.6511628031730652\n","val_recall: 0.26547685265541077\n","val_label_wise_macro_f1: 0.28608399629592896\n","val_subset_accuracy: 0.17232142388820648\n","val_subset_precision: 0.4044642448425293\n","val_subset_recall: 0.28968751430511475\n","val_subset_f1: 0.3363637626171112\n","val_auc: 0.7390941381454468\n","val_prc_auc: 0.5746116042137146\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7386 - binary_accuracy: 0.7175 - label_wise_accuracy: 0.7207 - label_wise_f1_score: 0.2745 - label_wise_macro_f1: 0.2651 - loss: 0.5548 - prc_auc: 0.5787 - precision: 0.6786 - recall: 0.2359 - subset_accuracy: 0.1603 - subset_f1: 0.3026 - subset_precision: 0.3654 - subset_recall: 0.2599 - val_auc: 0.7391 - val_binary_accuracy: 0.7193 - val_label_wise_accuracy: 0.7437 - val_label_wise_f1_score: 0.3184 - val_label_wise_macro_f1: 0.2861 - val_loss: 0.5510 - val_prc_auc: 0.5746 - val_precision: 0.6512 - val_recall: 0.2655 - val_subset_accuracy: 0.1723 - val_subset_f1: 0.3364 - val_subset_precision: 0.4045 - val_subset_recall: 0.2897\n","Epoch 7/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7487 - binary_accuracy: 0.7249 - label_wise_accuracy: 0.7259 - label_wise_f1_score: 0.3097 - label_wise_macro_f1: 0.3067 - loss: 0.5463 - prc_auc: 0.5904 - precision: 0.6794 - recall: 0.2788 - subset_accuracy: 0.1802 - subset_f1: 0.3507 - subset_precision: 0.4184 - subset_recall: 0.3035\n","Epoch 7: Validation Metrics:\n","loss: 0.5442932844161987\n","val_label_wise_f1_score: [0.         0.         0.33333328 0.6666666  0.79999995]\n","val_label_wise_accuracy: [0.84375 0.59375 0.75    0.8125  0.8125 ]\n","val_binary_accuracy: 0.7226786017417908\n","val_precision: 0.6477832794189453\n","val_recall: 0.2933630645275116\n","val_label_wise_macro_f1: 0.31353139877319336\n","val_subset_accuracy: 0.1830357164144516\n","val_subset_precision: 0.4392857253551483\n","val_subset_recall: 0.3154315650463104\n","val_subset_f1: 0.3659325838088989\n","val_auc: 0.7442679405212402\n","val_prc_auc: 0.5811998844146729\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7487 - binary_accuracy: 0.7249 - label_wise_accuracy: 0.7262 - label_wise_f1_score: 0.3101 - label_wise_macro_f1: 0.3067 - loss: 0.5463 - prc_auc: 0.5904 - precision: 0.6794 - recall: 0.2788 - subset_accuracy: 0.1803 - subset_f1: 0.3507 - subset_precision: 0.4185 - subset_recall: 0.3036 - val_auc: 0.7443 - val_binary_accuracy: 0.7227 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.3600 - val_label_wise_macro_f1: 0.3135 - val_loss: 0.5456 - val_prc_auc: 0.5812 - val_precision: 0.6478 - val_recall: 0.2934 - val_subset_accuracy: 0.1830 - val_subset_f1: 0.3659 - val_subset_precision: 0.4393 - val_subset_recall: 0.3154\n","Epoch 8/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7559 - binary_accuracy: 0.7290 - label_wise_accuracy: 0.7303 - label_wise_f1_score: 0.3373 - label_wise_macro_f1: 0.3346 - loss: 0.5394 - prc_auc: 0.5999 - precision: 0.6758 - recall: 0.3071 - subset_accuracy: 0.1952 - subset_f1: 0.3834 - subset_precision: 0.4522 - subset_recall: 0.3344\n","Epoch 8: Validation Metrics:\n","loss: 0.5378352999687195\n","val_label_wise_f1_score: [0.         0.14285713 0.33333328 0.6666666  0.7741935 ]\n","val_label_wise_accuracy: [0.84375 0.625   0.75    0.8125  0.78125]\n","val_binary_accuracy: 0.727857232093811\n","val_precision: 0.6516347527503967\n","val_recall: 0.3223647475242615\n","val_label_wise_macro_f1: 0.3437283933162689\n","val_subset_accuracy: 0.19910714030265808\n","val_subset_precision: 0.4714285135269165\n","val_subset_recall: 0.34891366958618164\n","val_subset_f1: 0.3995026648044586\n","val_auc: 0.747957170009613\n","val_prc_auc: 0.5863195657730103\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7559 - binary_accuracy: 0.7290 - label_wise_accuracy: 0.7305 - label_wise_f1_score: 0.3377 - label_wise_macro_f1: 0.3346 - loss: 0.5394 - prc_auc: 0.5999 - precision: 0.6758 - recall: 0.3072 - subset_accuracy: 0.1953 - subset_f1: 0.3835 - subset_precision: 0.4522 - subset_recall: 0.3345 - val_auc: 0.7480 - val_binary_accuracy: 0.7279 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.3834 - val_label_wise_macro_f1: 0.3437 - val_loss: 0.5416 - val_prc_auc: 0.5863 - val_precision: 0.6516 - val_recall: 0.3224 - val_subset_accuracy: 0.1991 - val_subset_f1: 0.3995 - val_subset_precision: 0.4714 - val_subset_recall: 0.3489\n","Epoch 9/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7618 - binary_accuracy: 0.7329 - label_wise_accuracy: 0.7333 - label_wise_f1_score: 0.3561 - label_wise_macro_f1: 0.3572 - loss: 0.5338 - prc_auc: 0.6080 - precision: 0.6775 - recall: 0.3278 - subset_accuracy: 0.2105 - subset_f1: 0.4068 - subset_precision: 0.4741 - subset_recall: 0.3579\n","Epoch 9: Validation Metrics:\n","loss: 0.5325508117675781\n","val_label_wise_f1_score: [0.         0.26666665 0.4615384  0.6666666  0.7741935 ]\n","val_label_wise_accuracy: [0.84375 0.65625 0.78125 0.8125  0.78125]\n","val_binary_accuracy: 0.7312498688697815\n","val_precision: 0.6538461446762085\n","val_recall: 0.34132739901542664\n","val_label_wise_macro_f1: 0.36636781692504883\n","val_subset_accuracy: 0.20624999701976776\n","val_subset_precision: 0.49017852544784546\n","val_subset_recall: 0.36863094568252563\n","val_subset_f1: 0.4192577302455902\n","val_auc: 0.7508229613304138\n","val_prc_auc: 0.5898792147636414\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - auc: 0.7618 - binary_accuracy: 0.7329 - label_wise_accuracy: 0.7336 - label_wise_f1_score: 0.3566 - label_wise_macro_f1: 0.3571 - loss: 0.5338 - prc_auc: 0.6080 - precision: 0.6775 - recall: 0.3278 - subset_accuracy: 0.2105 - subset_f1: 0.4069 - subset_precision: 0.4742 - subset_recall: 0.3579 - val_auc: 0.7508 - val_binary_accuracy: 0.7312 - val_label_wise_accuracy: 0.7750 - val_label_wise_f1_score: 0.4338 - val_label_wise_macro_f1: 0.3664 - val_loss: 0.5387 - val_prc_auc: 0.5899 - val_precision: 0.6538 - val_recall: 0.3413 - val_subset_accuracy: 0.2062 - val_subset_f1: 0.4193 - val_subset_precision: 0.4902 - val_subset_recall: 0.3686\n","Epoch 10/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7667 - binary_accuracy: 0.7374 - label_wise_accuracy: 0.7375 - label_wise_f1_score: 0.3802 - label_wise_macro_f1: 0.3812 - loss: 0.5290 - prc_auc: 0.6151 - precision: 0.6814 - recall: 0.3491 - subset_accuracy: 0.2259 - subset_f1: 0.4319 - subset_precision: 0.4980 - subset_recall: 0.3831\n","Epoch 10: Validation Metrics:\n","loss: 0.5280991196632385\n","val_label_wise_f1_score: [0.         0.26666665 0.4615384  0.6666666  0.7741935 ]\n","val_label_wise_accuracy: [0.84375 0.65625 0.78125 0.8125  0.78125]\n","val_binary_accuracy: 0.7324999570846558\n","val_precision: 0.653167188167572\n","val_recall: 0.350808709859848\n","val_label_wise_macro_f1: 0.3787326216697693\n","val_subset_accuracy: 0.21339285373687744\n","val_subset_precision: 0.4999999403953552\n","val_subset_recall: 0.3781547546386719\n","val_subset_f1: 0.42903465032577515\n","val_auc: 0.7528624534606934\n","val_prc_auc: 0.5927297472953796\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7667 - binary_accuracy: 0.7374 - label_wise_accuracy: 0.7378 - label_wise_f1_score: 0.3806 - label_wise_macro_f1: 0.3812 - loss: 0.5290 - prc_auc: 0.6151 - precision: 0.6814 - recall: 0.3491 - subset_accuracy: 0.2259 - subset_f1: 0.4319 - subset_precision: 0.4980 - subset_recall: 0.3831 - val_auc: 0.7529 - val_binary_accuracy: 0.7325 - val_label_wise_accuracy: 0.7750 - val_label_wise_f1_score: 0.4338 - val_label_wise_macro_f1: 0.3787 - val_loss: 0.5365 - val_prc_auc: 0.5927 - val_precision: 0.6532 - val_recall: 0.3508 - val_subset_accuracy: 0.2134 - val_subset_f1: 0.4290 - val_subset_precision: 0.5000 - val_subset_recall: 0.3782\n","Epoch 11/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7710 - binary_accuracy: 0.7403 - label_wise_accuracy: 0.7396 - label_wise_f1_score: 0.3962 - label_wise_macro_f1: 0.3997 - loss: 0.5249 - prc_auc: 0.6212 - precision: 0.6833 - recall: 0.3632 - subset_accuracy: 0.2304 - subset_f1: 0.4466 - subset_precision: 0.5131 - subset_recall: 0.3970\n","Epoch 11: Validation Metrics:\n","loss: 0.5242623090744019\n","val_label_wise_f1_score: [0.         0.26666665 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.84375 0.65625 0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7342857122421265\n","val_precision: 0.6538849472999573\n","val_recall: 0.36140546202659607\n","val_label_wise_macro_f1: 0.39075079560279846\n","val_subset_accuracy: 0.21875\n","val_subset_precision: 0.5081844925880432\n","val_subset_recall: 0.38909226655960083\n","val_subset_f1: 0.43924641609191895\n","val_auc: 0.7542988657951355\n","val_prc_auc: 0.5953841805458069\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7710 - binary_accuracy: 0.7403 - label_wise_accuracy: 0.7398 - label_wise_f1_score: 0.3964 - label_wise_macro_f1: 0.3997 - loss: 0.5249 - prc_auc: 0.6212 - precision: 0.6832 - recall: 0.3632 - subset_accuracy: 0.2304 - subset_f1: 0.4466 - subset_precision: 0.5131 - subset_recall: 0.3971 - val_auc: 0.7543 - val_binary_accuracy: 0.7343 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.4205 - val_label_wise_macro_f1: 0.3908 - val_loss: 0.5349 - val_prc_auc: 0.5954 - val_precision: 0.6539 - val_recall: 0.3614 - val_subset_accuracy: 0.2188 - val_subset_f1: 0.4392 - val_subset_precision: 0.5082 - val_subset_recall: 0.3891\n","Epoch 12/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7748 - binary_accuracy: 0.7436 - label_wise_accuracy: 0.7424 - label_wise_f1_score: 0.4112 - label_wise_macro_f1: 0.4170 - loss: 0.5213 - prc_auc: 0.6270 - precision: 0.6865 - recall: 0.3774 - subset_accuracy: 0.2400 - subset_f1: 0.4615 - subset_precision: 0.5283 - subset_recall: 0.4114\n","Epoch 12: Validation Metrics:\n","loss: 0.5208857655525208\n","val_label_wise_f1_score: [0.         0.26666665 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.84375 0.65625 0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7357142567634583\n","val_precision: 0.6547972559928894\n","val_recall: 0.36921361088752747\n","val_label_wise_macro_f1: 0.3980616331100464\n","val_subset_accuracy: 0.2232142835855484\n","val_subset_precision: 0.5166666507720947\n","val_subset_recall: 0.39586305618286133\n","val_subset_f1: 0.4468238353729248\n","val_auc: 0.755469799041748\n","val_prc_auc: 0.5973968505859375\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7748 - binary_accuracy: 0.7436 - label_wise_accuracy: 0.7426 - label_wise_f1_score: 0.4113 - label_wise_macro_f1: 0.4169 - loss: 0.5213 - prc_auc: 0.6270 - precision: 0.6865 - recall: 0.3774 - subset_accuracy: 0.2400 - subset_f1: 0.4615 - subset_precision: 0.5283 - subset_recall: 0.4114 - val_auc: 0.7555 - val_binary_accuracy: 0.7357 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.4205 - val_label_wise_macro_f1: 0.3981 - val_loss: 0.5336 - val_prc_auc: 0.5974 - val_precision: 0.6548 - val_recall: 0.3692 - val_subset_accuracy: 0.2232 - val_subset_f1: 0.4468 - val_subset_precision: 0.5167 - val_subset_recall: 0.3959\n","Epoch 13/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7782 - binary_accuracy: 0.7463 - label_wise_accuracy: 0.7445 - label_wise_f1_score: 0.4229 - label_wise_macro_f1: 0.4276 - loss: 0.5180 - prc_auc: 0.6320 - precision: 0.6897 - recall: 0.3878 - subset_accuracy: 0.2464 - subset_f1: 0.4726 - subset_precision: 0.5387 - subset_recall: 0.4226\n","Epoch 13: Validation Metrics:\n","loss: 0.5178340673446655\n","val_label_wise_f1_score: [0.         0.37499994 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.6875  0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7392856478691101\n","val_precision: 0.6602502465248108\n","val_recall: 0.38259899616241455\n","val_label_wise_macro_f1: 0.41427963972091675\n","val_subset_accuracy: 0.23035714030265808\n","val_subset_precision: 0.526190459728241\n","val_subset_recall: 0.4093303680419922\n","val_subset_f1: 0.45895543694496155\n","val_auc: 0.7562393546104431\n","val_prc_auc: 0.5987769365310669\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7782 - binary_accuracy: 0.7463 - label_wise_accuracy: 0.7446 - label_wise_f1_score: 0.4231 - label_wise_macro_f1: 0.4275 - loss: 0.5180 - prc_auc: 0.6320 - precision: 0.6896 - recall: 0.3878 - subset_accuracy: 0.2464 - subset_f1: 0.4726 - subset_precision: 0.5387 - subset_recall: 0.4226 - val_auc: 0.7562 - val_binary_accuracy: 0.7393 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.4421 - val_label_wise_macro_f1: 0.4143 - val_loss: 0.5326 - val_prc_auc: 0.5988 - val_precision: 0.6603 - val_recall: 0.3826 - val_subset_accuracy: 0.2304 - val_subset_f1: 0.4590 - val_subset_precision: 0.5262 - val_subset_recall: 0.4093\n","Epoch 14/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7813 - binary_accuracy: 0.7489 - label_wise_accuracy: 0.7465 - label_wise_f1_score: 0.4348 - label_wise_macro_f1: 0.4408 - loss: 0.5150 - prc_auc: 0.6367 - precision: 0.6928 - recall: 0.3981 - subset_accuracy: 0.2506 - subset_f1: 0.4834 - subset_precision: 0.5501 - subset_recall: 0.4327\n","Epoch 14: Validation Metrics:\n","loss: 0.5150238871574402\n","val_label_wise_f1_score: [0.         0.37499994 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.6875  0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7398213148117065\n","val_precision: 0.6587901711463928\n","val_recall: 0.38873395323753357\n","val_label_wise_macro_f1: 0.42057666182518005\n","val_subset_accuracy: 0.23125000298023224\n","val_subset_precision: 0.5313987731933594\n","val_subset_recall: 0.41587796807289124\n","val_subset_f1: 0.46511682868003845\n","val_auc: 0.7569764852523804\n","val_prc_auc: 0.6003369092941284\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7813 - binary_accuracy: 0.7489 - label_wise_accuracy: 0.7466 - label_wise_f1_score: 0.4348 - label_wise_macro_f1: 0.4408 - loss: 0.5150 - prc_auc: 0.6367 - precision: 0.6927 - recall: 0.3981 - subset_accuracy: 0.2505 - subset_f1: 0.4833 - subset_precision: 0.5500 - subset_recall: 0.4327 - val_auc: 0.7570 - val_binary_accuracy: 0.7398 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.4421 - val_label_wise_macro_f1: 0.4206 - val_loss: 0.5318 - val_prc_auc: 0.6003 - val_precision: 0.6588 - val_recall: 0.3887 - val_subset_accuracy: 0.2313 - val_subset_f1: 0.4651 - val_subset_precision: 0.5314 - val_subset_recall: 0.4159\n","Epoch 15/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7843 - binary_accuracy: 0.7508 - label_wise_accuracy: 0.7479 - label_wise_f1_score: 0.4421 - label_wise_macro_f1: 0.4486 - loss: 0.5123 - prc_auc: 0.6411 - precision: 0.6949 - recall: 0.4054 - subset_accuracy: 0.2578 - subset_f1: 0.4903 - subset_precision: 0.5560 - subset_recall: 0.4401\n","Epoch 15: Validation Metrics:\n","loss: 0.5123973488807678\n","val_label_wise_f1_score: [0.         0.37499994 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.6875  0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7387499809265137\n","val_precision: 0.6536312699317932\n","val_recall: 0.3915225863456726\n","val_label_wise_macro_f1: 0.42396149039268494\n","val_subset_accuracy: 0.23125000298023224\n","val_subset_precision: 0.530505895614624\n","val_subset_recall: 0.4179612994194031\n","val_subset_f1: 0.4662024974822998\n","val_auc: 0.7575957775115967\n","val_prc_auc: 0.6009462475776672\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7843 - binary_accuracy: 0.7508 - label_wise_accuracy: 0.7480 - label_wise_f1_score: 0.4421 - label_wise_macro_f1: 0.4486 - loss: 0.5123 - prc_auc: 0.6411 - precision: 0.6948 - recall: 0.4053 - subset_accuracy: 0.2577 - subset_f1: 0.4903 - subset_precision: 0.5560 - subset_recall: 0.4401 - val_auc: 0.7576 - val_binary_accuracy: 0.7387 - val_label_wise_accuracy: 0.7625 - val_label_wise_f1_score: 0.4421 - val_label_wise_macro_f1: 0.4240 - val_loss: 0.5312 - val_prc_auc: 0.6009 - val_precision: 0.6536 - val_recall: 0.3915 - val_subset_accuracy: 0.2313 - val_subset_f1: 0.4662 - val_subset_precision: 0.5305 - val_subset_recall: 0.4180\n","Epoch 16/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7871 - binary_accuracy: 0.7534 - label_wise_accuracy: 0.7501 - label_wise_f1_score: 0.4503 - label_wise_macro_f1: 0.4560 - loss: 0.5096 - prc_auc: 0.6453 - precision: 0.7003 - recall: 0.4117 - subset_accuracy: 0.2593 - subset_f1: 0.4960 - subset_precision: 0.5617 - subset_recall: 0.4457\n","Epoch 16: Validation Metrics:\n","loss: 0.5099084973335266\n","val_label_wise_f1_score: [0.         0.35294116 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7378572225570679\n","val_precision: 0.6489459276199341\n","val_recall: 0.394868940114975\n","val_label_wise_macro_f1: 0.42702025175094604\n","val_subset_accuracy: 0.23125000298023224\n","val_subset_precision: 0.530505895614624\n","val_subset_recall: 0.42168155312538147\n","val_subset_f1: 0.46855735778808594\n","val_auc: 0.7582230567932129\n","val_prc_auc: 0.6021468639373779\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7871 - binary_accuracy: 0.7534 - label_wise_accuracy: 0.7501 - label_wise_f1_score: 0.4502 - label_wise_macro_f1: 0.4560 - loss: 0.5096 - prc_auc: 0.6453 - precision: 0.7002 - recall: 0.4117 - subset_accuracy: 0.2593 - subset_f1: 0.4960 - subset_precision: 0.5616 - subset_recall: 0.4457 - val_auc: 0.7582 - val_binary_accuracy: 0.7379 - val_label_wise_accuracy: 0.7563 - val_label_wise_f1_score: 0.4377 - val_label_wise_macro_f1: 0.4270 - val_loss: 0.5307 - val_prc_auc: 0.6021 - val_precision: 0.6489 - val_recall: 0.3949 - val_subset_accuracy: 0.2313 - val_subset_f1: 0.4686 - val_subset_precision: 0.5305 - val_subset_recall: 0.4217\n","Epoch 17/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7897 - binary_accuracy: 0.7552 - label_wise_accuracy: 0.7517 - label_wise_f1_score: 0.4586 - label_wise_macro_f1: 0.4658 - loss: 0.5071 - prc_auc: 0.6493 - precision: 0.7015 - recall: 0.4198 - subset_accuracy: 0.2625 - subset_f1: 0.5034 - subset_precision: 0.5676 - subset_recall: 0.4539\n","Epoch 17: Validation Metrics:\n","loss: 0.5075421929359436\n","val_label_wise_f1_score: [0.         0.35294116 0.4615384  0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.78125 0.75    0.78125]\n","val_binary_accuracy: 0.7383928894996643\n","val_precision: 0.6485507488250732\n","val_recall: 0.399330735206604\n","val_label_wise_macro_f1: 0.4302454888820648\n","val_subset_accuracy: 0.22946429252624512\n","val_subset_precision: 0.5358630418777466\n","val_subset_recall: 0.4255506098270416\n","val_subset_f1: 0.47300583124160767\n","val_auc: 0.7586479783058167\n","val_prc_auc: 0.6030049920082092\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7897 - binary_accuracy: 0.7552 - label_wise_accuracy: 0.7517 - label_wise_f1_score: 0.4584 - label_wise_macro_f1: 0.4658 - loss: 0.5071 - prc_auc: 0.6493 - precision: 0.7014 - recall: 0.4197 - subset_accuracy: 0.2625 - subset_f1: 0.5034 - subset_precision: 0.5676 - subset_recall: 0.4539 - val_auc: 0.7586 - val_binary_accuracy: 0.7384 - val_label_wise_accuracy: 0.7563 - val_label_wise_f1_score: 0.4377 - val_label_wise_macro_f1: 0.4302 - val_loss: 0.5302 - val_prc_auc: 0.6030 - val_precision: 0.6486 - val_recall: 0.3993 - val_subset_accuracy: 0.2295 - val_subset_f1: 0.4730 - val_subset_precision: 0.5359 - val_subset_recall: 0.4256\n","Epoch 18/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7924 - binary_accuracy: 0.7570 - label_wise_accuracy: 0.7531 - label_wise_f1_score: 0.4654 - label_wise_macro_f1: 0.4749 - loss: 0.5047 - prc_auc: 0.6533 - precision: 0.7040 - recall: 0.4259 - subset_accuracy: 0.2665 - subset_f1: 0.5093 - subset_precision: 0.5719 - subset_recall: 0.4608\n","Epoch 18: Validation Metrics:\n","loss: 0.505268931388855\n","val_label_wise_f1_score: [0.         0.35294116 0.42857137 0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.75    0.75    0.78125]\n","val_binary_accuracy: 0.7396427989006042\n","val_precision: 0.6496872305870056\n","val_recall: 0.405465692281723\n","val_label_wise_macro_f1: 0.43370506167411804\n","val_subset_accuracy: 0.23303571343421936\n","val_subset_precision: 0.5407737493515015\n","val_subset_recall: 0.43105655908584595\n","val_subset_f1: 0.4784136712551117\n","val_auc: 0.7590139508247375\n","val_prc_auc: 0.603619396686554\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7924 - binary_accuracy: 0.7570 - label_wise_accuracy: 0.7531 - label_wise_f1_score: 0.4652 - label_wise_macro_f1: 0.4748 - loss: 0.5047 - prc_auc: 0.6533 - precision: 0.7039 - recall: 0.4258 - subset_accuracy: 0.2665 - subset_f1: 0.5093 - subset_precision: 0.5719 - subset_recall: 0.4608 - val_auc: 0.7590 - val_binary_accuracy: 0.7396 - val_label_wise_accuracy: 0.7500 - val_label_wise_f1_score: 0.4311 - val_label_wise_macro_f1: 0.4337 - val_loss: 0.5299 - val_prc_auc: 0.6036 - val_precision: 0.6497 - val_recall: 0.4055 - val_subset_accuracy: 0.2330 - val_subset_f1: 0.4784 - val_subset_precision: 0.5408 - val_subset_recall: 0.4311\n","Epoch 19/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7947 - binary_accuracy: 0.7583 - label_wise_accuracy: 0.7544 - label_wise_f1_score: 0.4707 - label_wise_macro_f1: 0.4805 - loss: 0.5024 - prc_auc: 0.6569 - precision: 0.7048 - recall: 0.4314 - subset_accuracy: 0.2709 - subset_f1: 0.5154 - subset_precision: 0.5779 - subset_recall: 0.4668\n","Epoch 19: Validation Metrics:\n","loss: 0.5030683875083923\n","val_label_wise_f1_score: [0.         0.35294116 0.42857137 0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.75    0.75    0.78125]\n","val_binary_accuracy: 0.7394642233848572\n","val_precision: 0.6483126282691956\n","val_recall: 0.4071388840675354\n","val_label_wise_macro_f1: 0.4357386827468872\n","val_subset_accuracy: 0.23482142388820648\n","val_subset_precision: 0.5425595045089722\n","val_subset_recall: 0.4326934814453125\n","val_subset_f1: 0.47999683022499084\n","val_auc: 0.759320080280304\n","val_prc_auc: 0.6039748787879944\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7947 - binary_accuracy: 0.7583 - label_wise_accuracy: 0.7544 - label_wise_f1_score: 0.4704 - label_wise_macro_f1: 0.4804 - loss: 0.5024 - prc_auc: 0.6569 - precision: 0.7047 - recall: 0.4313 - subset_accuracy: 0.2708 - subset_f1: 0.5153 - subset_precision: 0.5778 - subset_recall: 0.4668 - val_auc: 0.7593 - val_binary_accuracy: 0.7395 - val_label_wise_accuracy: 0.7500 - val_label_wise_f1_score: 0.4311 - val_label_wise_macro_f1: 0.4357 - val_loss: 0.5296 - val_prc_auc: 0.6040 - val_precision: 0.6483 - val_recall: 0.4071 - val_subset_accuracy: 0.2348 - val_subset_f1: 0.4800 - val_subset_precision: 0.5426 - val_subset_recall: 0.4327\n","Epoch 20/20\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7971 - binary_accuracy: 0.7597 - label_wise_accuracy: 0.7556 - label_wise_f1_score: 0.4742 - label_wise_macro_f1: 0.4842 - loss: 0.5001 - prc_auc: 0.6605 - precision: 0.7066 - recall: 0.4359 - subset_accuracy: 0.2733 - subset_f1: 0.5196 - subset_precision: 0.5820 - subset_recall: 0.4711\n","Epoch 20: Validation Metrics:\n","loss: 0.5009210109710693\n","val_label_wise_f1_score: [0.         0.35294116 0.42857137 0.59999996 0.7741935 ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.75    0.75    0.78125]\n","val_binary_accuracy: 0.7399999499320984\n","val_precision: 0.6474190950393677\n","val_recall: 0.4127161204814911\n","val_label_wise_macro_f1: 0.44326359033584595\n","val_subset_accuracy: 0.23303571343421936\n","val_subset_precision: 0.546130895614624\n","val_subset_recall: 0.438943475484848\n","val_subset_f1: 0.48529112339019775\n","val_auc: 0.7595558762550354\n","val_prc_auc: 0.6046469211578369\n","\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - auc: 0.7971 - binary_accuracy: 0.7596 - label_wise_accuracy: 0.7555 - label_wise_f1_score: 0.4739 - label_wise_macro_f1: 0.4842 - loss: 0.5001 - prc_auc: 0.6605 - precision: 0.7065 - recall: 0.4359 - subset_accuracy: 0.2732 - subset_f1: 0.5196 - subset_precision: 0.5820 - subset_recall: 0.4711 - val_auc: 0.7596 - val_binary_accuracy: 0.7400 - val_label_wise_accuracy: 0.7500 - val_label_wise_f1_score: 0.4311 - val_label_wise_macro_f1: 0.4433 - val_loss: 0.5294 - val_prc_auc: 0.6046 - val_precision: 0.6474 - val_recall: 0.4127 - val_subset_accuracy: 0.2330 - val_subset_f1: 0.4853 - val_subset_precision: 0.5461 - val_subset_recall: 0.4389\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - auc: 0.7672 - binary_accuracy: 0.7925 - label_wise_accuracy: 0.7868 - label_wise_f1_score: 0.4307 - label_wise_macro_f1: 0.4406 - loss: 0.4620 - prc_auc: 0.4789 - precision: 0.4808 - recall: 0.4592 - subset_accuracy: 0.3483 - subset_f1: 0.4288 - subset_precision: 0.4030 - subset_recall: 0.4592\n","Evaluation Metrics:\n","Loss: 0.46570196747779846\n","Label F1 Scores: [0.24999997 0.         0.37499994 0.7142857  0.37499994]\n","Label Accuracies: [0.8125  0.84375 0.6875  0.875   0.6875 ]\n","Accuracy: 0.7869319319725037\n","Precision: 0.46640700101852417\n","Recall: 0.4535984992980957\n","F1 Score: 0.43339595198631287\n","Subset Accuracy: 0.33617424964904785\n","Subset Precision: 0.3944128453731537\n","Subset Recall: 0.4535984694957733\n","Subset F1: 0.42155686020851135\n","AUC: 0.764324963092804\n","PRC AUC: 0.4578784108161926\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.5410 - binary_accuracy: 0.7004 - label_wise_accuracy: 0.7650 - label_wise_f1_score: 0.0350 - label_wise_macro_f1: 0.0915 - loss: 0.6420 - prc_auc: 0.2230 - precision: 0.2331 - recall: 0.1837 - subset_accuracy: 0.0176 - subset_f1: 0.1487 - subset_precision: 0.1418 - subset_recall: 0.1914\n","Epoch 1: Validation Metrics:\n","loss: 0.5843154191970825\n","val_label_wise_f1_score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.8125  0.59375 0.90625 0.9375  0.78125 0.84375 0.84375 1.      0.46875\n"," 0.625  ]\n","val_binary_accuracy: 0.7909375429153442\n","val_precision: 0.0\n","val_recall: 0.0\n","val_label_wise_macro_f1: 0.0\n","val_subset_accuracy: 0.0\n","val_subset_precision: 0.0\n","val_subset_recall: 0.0\n","val_subset_f1: 0.0\n","val_auc: 0.6885631680488586\n","val_prc_auc: 0.3402233123779297\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 135ms/step - auc: 0.5412 - binary_accuracy: 0.7008 - label_wise_accuracy: 0.7651 - label_wise_f1_score: 0.0348 - label_wise_macro_f1: 0.0912 - loss: 0.6416 - prc_auc: 0.2230 - precision: 0.2331 - recall: 0.1830 - subset_accuracy: 0.0175 - subset_f1: 0.1482 - subset_precision: 0.1413 - subset_recall: 0.1906 - val_auc: 0.6886 - val_binary_accuracy: 0.7909 - val_label_wise_accuracy: 0.7812 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 0.0000e+00 - val_loss: 0.4853 - val_prc_auc: 0.3402 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_subset_accuracy: 0.0000e+00 - val_subset_f1: 0.0000e+00 - val_subset_precision: 0.0000e+00 - val_subset_recall: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6927 - binary_accuracy: 0.7942 - label_wise_accuracy: 0.7939 - label_wise_f1_score: 0.0000e+00 - label_wise_macro_f1: 0.0000e+00 - loss: 0.4728 - prc_auc: 0.3545 - precision: 0.0000e+00 - recall: 0.0000e+00 - subset_accuracy: 0.0000e+00 - subset_f1: 0.0000e+00 - subset_precision: 0.0000e+00 - subset_recall: 0.0000e+00\n","Epoch 2: Validation Metrics:\n","loss: 0.46689531207084656\n","val_label_wise_f1_score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.8125  0.59375 0.90625 0.9375  0.78125 0.84375 0.84375 1.      0.46875\n"," 0.625  ]\n","val_binary_accuracy: 0.7909375429153442\n","val_precision: 0.0\n","val_recall: 0.0\n","val_label_wise_macro_f1: 0.0\n","val_subset_accuracy: 0.0\n","val_subset_precision: 0.0\n","val_subset_recall: 0.0\n","val_subset_f1: 0.0\n","val_auc: 0.7155392169952393\n","val_prc_auc: 0.4066471755504608\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - auc: 0.6928 - binary_accuracy: 0.7942 - label_wise_accuracy: 0.7938 - label_wise_f1_score: 0.0000e+00 - label_wise_macro_f1: 0.0000e+00 - loss: 0.4728 - prc_auc: 0.3546 - precision: 0.0000e+00 - recall: 0.0000e+00 - subset_accuracy: 0.0000e+00 - subset_f1: 0.0000e+00 - subset_precision: 0.0000e+00 - subset_recall: 0.0000e+00 - val_auc: 0.7155 - val_binary_accuracy: 0.7909 - val_label_wise_accuracy: 0.7812 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 0.0000e+00 - val_loss: 0.4619 - val_prc_auc: 0.4066 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_subset_accuracy: 0.0000e+00 - val_subset_f1: 0.0000e+00 - val_subset_precision: 0.0000e+00 - val_subset_recall: 0.0000e+00\n","Epoch 3/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7195 - binary_accuracy: 0.7945 - label_wise_accuracy: 0.7947 - label_wise_f1_score: 0.0052 - label_wise_macro_f1: 0.0017 - loss: 0.4556 - prc_auc: 0.4116 - precision: 0.5333 - recall: 0.0015 - subset_accuracy: 0.0016 - subset_f1: 0.0024 - subset_precision: 0.0030 - subset_recall: 0.0022\n","Epoch 3: Validation Metrics:\n","loss: 0.45219486951828003\n","val_label_wise_f1_score: [0.         0.14285713 0.         0.         0.         0.\n"," 0.         0.         0.         0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.90625 0.9375  0.78125 0.84375 0.78125 1.      0.46875\n"," 0.625  ]\n","val_binary_accuracy: 0.7928906679153442\n","val_precision: 0.8205128312110901\n","val_recall: 0.011958146467804909\n","val_label_wise_macro_f1: 0.011956583708524704\n","val_subset_accuracy: 0.00390625\n","val_subset_precision: 0.02499999850988388\n","val_subset_recall: 0.013411457650363445\n","val_subset_f1: 0.01703932322561741\n","val_auc: 0.7365497946739197\n","val_prc_auc: 0.4338901937007904\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - auc: 0.7195 - binary_accuracy: 0.7945 - label_wise_accuracy: 0.7946 - label_wise_f1_score: 0.0053 - label_wise_macro_f1: 0.0017 - loss: 0.4556 - prc_auc: 0.4117 - precision: 0.5350 - recall: 0.0015 - subset_accuracy: 0.0016 - subset_f1: 0.0024 - subset_precision: 0.0031 - subset_recall: 0.0022 - val_auc: 0.7365 - val_binary_accuracy: 0.7929 - val_label_wise_accuracy: 0.7781 - val_label_wise_f1_score: 0.0143 - val_label_wise_macro_f1: 0.0120 - val_loss: 0.4499 - val_prc_auc: 0.4339 - val_precision: 0.8205 - val_recall: 0.0120 - val_subset_accuracy: 0.0039 - val_subset_f1: 0.0170 - val_subset_precision: 0.0250 - val_subset_recall: 0.0134\n","Epoch 4/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7447 - binary_accuracy: 0.7982 - label_wise_accuracy: 0.7994 - label_wise_f1_score: 0.0365 - label_wise_macro_f1: 0.0263 - loss: 0.4430 - prc_auc: 0.4409 - precision: 0.7842 - recall: 0.0260 - subset_accuracy: 0.0128 - subset_f1: 0.0383 - subset_precision: 0.0536 - subset_recall: 0.0308\n","Epoch 4: Validation Metrics:\n","loss: 0.4395812451839447\n","val_label_wise_f1_score: [0.         0.24999999 0.         0.         0.         0.\n"," 0.         0.         0.11111109 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.90625 0.9375  0.78125 0.84375 0.78125 1.      0.5\n"," 0.625  ]\n","val_binary_accuracy: 0.7974220514297485\n","val_precision: 0.710659921169281\n","val_recall: 0.05231688916683197\n","val_label_wise_macro_f1: 0.05062127113342285\n","val_subset_accuracy: 0.02968749962747097\n","val_subset_precision: 0.10859373956918716\n","val_subset_recall: 0.0638541728258133\n","val_subset_f1: 0.0796453133225441\n","val_auc: 0.759274959564209\n","val_prc_auc: 0.4591175615787506\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7447 - binary_accuracy: 0.7982 - label_wise_accuracy: 0.7993 - label_wise_f1_score: 0.0365 - label_wise_macro_f1: 0.0264 - loss: 0.4430 - prc_auc: 0.4409 - precision: 0.7842 - recall: 0.0261 - subset_accuracy: 0.0129 - subset_f1: 0.0384 - subset_precision: 0.0538 - subset_recall: 0.0308 - val_auc: 0.7593 - val_binary_accuracy: 0.7974 - val_label_wise_accuracy: 0.7812 - val_label_wise_f1_score: 0.0361 - val_label_wise_macro_f1: 0.0506 - val_loss: 0.4384 - val_prc_auc: 0.4591 - val_precision: 0.7107 - val_recall: 0.0523 - val_subset_accuracy: 0.0297 - val_subset_f1: 0.0796 - val_subset_precision: 0.1086 - val_subset_recall: 0.0639\n","Epoch 5/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7685 - binary_accuracy: 0.8027 - label_wise_accuracy: 0.8034 - label_wise_f1_score: 0.0836 - label_wise_macro_f1: 0.0705 - loss: 0.4313 - prc_auc: 0.4680 - precision: 0.7095 - recall: 0.0695 - subset_accuracy: 0.0322 - subset_f1: 0.0995 - subset_precision: 0.1390 - subset_recall: 0.0789\n","Epoch 5: Validation Metrics:\n","loss: 0.42831850051879883\n","val_label_wise_f1_score: [0.         0.24999999 0.         0.         0.         0.\n"," 0.         0.         0.29999995 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.90625 0.9375  0.78125 0.84375 0.78125 1.      0.5625\n"," 0.625  ]\n","val_binary_accuracy: 0.8034372329711914\n","val_precision: 0.7061855792999268\n","val_recall: 0.10239163041114807\n","val_label_wise_macro_f1: 0.10396859794855118\n","val_subset_accuracy: 0.05156249925494194\n","val_subset_precision: 0.2050780951976776\n","val_subset_recall: 0.12106770277023315\n","val_subset_f1: 0.15126004815101624\n","val_auc: 0.7740026712417603\n","val_prc_auc: 0.4798480272293091\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7685 - binary_accuracy: 0.8027 - label_wise_accuracy: 0.8033 - label_wise_f1_score: 0.0834 - label_wise_macro_f1: 0.0706 - loss: 0.4313 - prc_auc: 0.4680 - precision: 0.7095 - recall: 0.0696 - subset_accuracy: 0.0322 - subset_f1: 0.0996 - subset_precision: 0.1391 - subset_recall: 0.0790 - val_auc: 0.7740 - val_binary_accuracy: 0.8034 - val_label_wise_accuracy: 0.7875 - val_label_wise_f1_score: 0.0550 - val_label_wise_macro_f1: 0.1040 - val_loss: 0.4291 - val_prc_auc: 0.4798 - val_precision: 0.7062 - val_recall: 0.1024 - val_subset_accuracy: 0.0516 - val_subset_f1: 0.1513 - val_subset_precision: 0.2051 - val_subset_recall: 0.1211\n","Epoch 6/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7834 - binary_accuracy: 0.8075 - label_wise_accuracy: 0.8079 - label_wise_f1_score: 0.1389 - label_wise_macro_f1: 0.1264 - loss: 0.4220 - prc_auc: 0.4878 - precision: 0.6879 - recall: 0.1182 - subset_accuracy: 0.0597 - subset_f1: 0.1673 - subset_precision: 0.2233 - subset_recall: 0.1354\n","Epoch 6: Validation Metrics:\n","loss: 0.4195311963558197\n","val_label_wise_f1_score: [0.         0.4444444  0.         0.66666657 0.         0.33333328\n"," 0.2222222  0.         0.29999995 0.        ]\n","val_label_wise_accuracy: [0.8125  0.6875  0.90625 0.96875 0.78125 0.875   0.78125 1.      0.5625\n"," 0.625  ]\n","val_binary_accuracy: 0.8071874380111694\n","val_precision: 0.6918818950653076\n","val_recall: 0.1401345282793045\n","val_label_wise_macro_f1: 0.15240970253944397\n","val_subset_accuracy: 0.06562499701976776\n","val_subset_precision: 0.27291664481163025\n","val_subset_recall: 0.16164064407348633\n","val_subset_f1: 0.20203101634979248\n","val_auc: 0.7825954556465149\n","val_prc_auc: 0.4930711090564728\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7834 - binary_accuracy: 0.8075 - label_wise_accuracy: 0.8078 - label_wise_f1_score: 0.1392 - label_wise_macro_f1: 0.1265 - loss: 0.4220 - prc_auc: 0.4878 - precision: 0.6878 - recall: 0.1183 - subset_accuracy: 0.0597 - subset_f1: 0.1674 - subset_precision: 0.2235 - subset_recall: 0.1355 - val_auc: 0.7826 - val_binary_accuracy: 0.8072 - val_label_wise_accuracy: 0.8000 - val_label_wise_f1_score: 0.1967 - val_label_wise_macro_f1: 0.1524 - val_loss: 0.4223 - val_prc_auc: 0.4931 - val_precision: 0.6919 - val_recall: 0.1401 - val_subset_accuracy: 0.0656 - val_subset_f1: 0.2020 - val_subset_precision: 0.2729 - val_subset_recall: 0.1616\n","Epoch 7/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7924 - binary_accuracy: 0.8112 - label_wise_accuracy: 0.8111 - label_wise_f1_score: 0.1757 - label_wise_macro_f1: 0.1662 - loss: 0.4150 - prc_auc: 0.5009 - precision: 0.6798 - recall: 0.1562 - subset_accuracy: 0.0748 - subset_f1: 0.2172 - subset_precision: 0.2906 - subset_recall: 0.1752\n","Epoch 7: Validation Metrics:\n","loss: 0.4130265414714813\n","val_label_wise_f1_score: [0.         0.42105258 0.         0.66666657 0.         0.33333328\n"," 0.2222222  0.         0.38095236 0.        ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.90625 0.96875 0.78125 0.875   0.78125 1.      0.59375\n"," 0.625  ]\n","val_binary_accuracy: 0.8100781440734863\n","val_precision: 0.6798825263977051\n","val_recall: 0.1730194389820099\n","val_label_wise_macro_f1: 0.18601219356060028\n","val_subset_accuracy: 0.07656250149011612\n","val_subset_precision: 0.3291666507720947\n","val_subset_recall: 0.1955859661102295\n","val_subset_f1: 0.24449202418327332\n","val_auc: 0.7882890105247498\n","val_prc_auc: 0.5018068552017212\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7924 - binary_accuracy: 0.8112 - label_wise_accuracy: 0.8111 - label_wise_f1_score: 0.1758 - label_wise_macro_f1: 0.1662 - loss: 0.4150 - prc_auc: 0.5010 - precision: 0.6798 - recall: 0.1563 - subset_accuracy: 0.0748 - subset_f1: 0.2173 - subset_precision: 0.2907 - subset_recall: 0.1752 - val_auc: 0.7883 - val_binary_accuracy: 0.8101 - val_label_wise_accuracy: 0.8000 - val_label_wise_f1_score: 0.2024 - val_label_wise_macro_f1: 0.1860 - val_loss: 0.4175 - val_prc_auc: 0.5018 - val_precision: 0.6799 - val_recall: 0.1730 - val_subset_accuracy: 0.0766 - val_subset_f1: 0.2445 - val_subset_precision: 0.3292 - val_subset_recall: 0.1956\n","Epoch 8/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7990 - binary_accuracy: 0.8132 - label_wise_accuracy: 0.8128 - label_wise_f1_score: 0.1956 - label_wise_macro_f1: 0.1872 - loss: 0.4097 - prc_auc: 0.5107 - precision: 0.6750 - recall: 0.1780 - subset_accuracy: 0.0830 - subset_f1: 0.2461 - subset_precision: 0.3285 - subset_recall: 0.1984\n","Epoch 8: Validation Metrics:\n","loss: 0.40801605582237244\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.         0.33333328\n"," 0.2222222  0.         0.38095236 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.90625 0.96875 0.75    0.875   0.78125 1.      0.59375\n"," 0.625  ]\n","val_binary_accuracy: 0.811328113079071\n","val_precision: 0.6675224900245667\n","val_recall: 0.19431987404823303\n","val_label_wise_macro_f1: 0.20450079441070557\n","val_subset_accuracy: 0.08359374850988388\n","val_subset_precision: 0.36510413885116577\n","val_subset_recall: 0.21953126788139343\n","val_subset_f1: 0.27310946583747864\n","val_auc: 0.7925489544868469\n","val_prc_auc: 0.5078843832015991\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7990 - binary_accuracy: 0.8132 - label_wise_accuracy: 0.8127 - label_wise_f1_score: 0.1957 - label_wise_macro_f1: 0.1872 - loss: 0.4096 - prc_auc: 0.5107 - precision: 0.6749 - recall: 0.1781 - subset_accuracy: 0.0830 - subset_f1: 0.2462 - subset_precision: 0.3286 - subset_recall: 0.1985 - val_auc: 0.7925 - val_binary_accuracy: 0.8113 - val_label_wise_accuracy: 0.7937 - val_label_wise_f1_score: 0.2003 - val_label_wise_macro_f1: 0.2045 - val_loss: 0.4140 - val_prc_auc: 0.5079 - val_precision: 0.6675 - val_recall: 0.1943 - val_subset_accuracy: 0.0836 - val_subset_f1: 0.2731 - val_subset_precision: 0.3651 - val_subset_recall: 0.2195\n","Epoch 9/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8045 - binary_accuracy: 0.8148 - label_wise_accuracy: 0.8144 - label_wise_f1_score: 0.2146 - label_wise_macro_f1: 0.2104 - loss: 0.4054 - prc_auc: 0.5188 - precision: 0.6684 - recall: 0.1984 - subset_accuracy: 0.0897 - subset_f1: 0.2733 - subset_precision: 0.3622 - subset_recall: 0.2212\n","Epoch 9: Validation Metrics:\n","loss: 0.403984397649765\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.         0.74999994\n"," 0.2222222  0.         0.4545454  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.90625 0.96875 0.75    0.9375  0.78125 1.      0.625\n"," 0.625  ]\n","val_binary_accuracy: 0.8129687309265137\n","val_precision: 0.665105402469635\n","val_recall: 0.21225710213184357\n","val_label_wise_macro_f1: 0.2190893143415451\n","val_subset_accuracy: 0.09296874701976776\n","val_subset_precision: 0.3928385078907013\n","val_subset_recall: 0.24005210399627686\n","val_subset_f1: 0.29694896936416626\n","val_auc: 0.7958993911743164\n","val_prc_auc: 0.5125653743743896\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8045 - binary_accuracy: 0.8148 - label_wise_accuracy: 0.8143 - label_wise_f1_score: 0.2148 - label_wise_macro_f1: 0.2105 - loss: 0.4054 - prc_auc: 0.5188 - precision: 0.6683 - recall: 0.1985 - subset_accuracy: 0.0897 - subset_f1: 0.2733 - subset_precision: 0.3623 - subset_recall: 0.2212 - val_auc: 0.7959 - val_binary_accuracy: 0.8130 - val_label_wise_accuracy: 0.8031 - val_label_wise_f1_score: 0.2493 - val_label_wise_macro_f1: 0.2191 - val_loss: 0.4113 - val_prc_auc: 0.5126 - val_precision: 0.6651 - val_recall: 0.2123 - val_subset_accuracy: 0.0930 - val_subset_f1: 0.2969 - val_subset_precision: 0.3928 - val_subset_recall: 0.2401\n","Epoch 10/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8091 - binary_accuracy: 0.8164 - label_wise_accuracy: 0.8160 - label_wise_f1_score: 0.2303 - label_wise_macro_f1: 0.2268 - loss: 0.4018 - prc_auc: 0.5256 - precision: 0.6671 - recall: 0.2155 - subset_accuracy: 0.0958 - subset_f1: 0.2947 - subset_precision: 0.3879 - subset_recall: 0.2396\n","Epoch 10: Validation Metrics:\n","loss: 0.40061596035957336\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.         0.74999994\n"," 0.2222222  0.         0.4545454  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.75    0.9375  0.78125 1.      0.625\n"," 0.625  ]\n","val_binary_accuracy: 0.813906192779541\n","val_precision: 0.6622516512870789\n","val_recall: 0.22421523928642273\n","val_label_wise_macro_f1: 0.22949472069740295\n","val_subset_accuracy: 0.09609375149011612\n","val_subset_precision: 0.41119784116744995\n","val_subset_recall: 0.2539193034172058\n","val_subset_f1: 0.31289106607437134\n","val_auc: 0.7985239624977112\n","val_prc_auc: 0.5164597630500793\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8091 - binary_accuracy: 0.8164 - label_wise_accuracy: 0.8159 - label_wise_f1_score: 0.2304 - label_wise_macro_f1: 0.2268 - loss: 0.4018 - prc_auc: 0.5256 - precision: 0.6670 - recall: 0.2155 - subset_accuracy: 0.0958 - subset_f1: 0.2948 - subset_precision: 0.3879 - subset_recall: 0.2396 - val_auc: 0.7985 - val_binary_accuracy: 0.8139 - val_label_wise_accuracy: 0.8000 - val_label_wise_f1_score: 0.2493 - val_label_wise_macro_f1: 0.2295 - val_loss: 0.4092 - val_prc_auc: 0.5165 - val_precision: 0.6623 - val_recall: 0.2242 - val_subset_accuracy: 0.0961 - val_subset_f1: 0.3129 - val_subset_precision: 0.4112 - val_subset_recall: 0.2539\n","Epoch 11/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8129 - binary_accuracy: 0.8175 - label_wise_accuracy: 0.8174 - label_wise_f1_score: 0.2460 - label_wise_macro_f1: 0.2406 - loss: 0.3988 - prc_auc: 0.5318 - precision: 0.6659 - recall: 0.2272 - subset_accuracy: 0.1003 - subset_f1: 0.3095 - subset_precision: 0.4054 - subset_recall: 0.2521\n","Epoch 11: Validation Metrics:\n","loss: 0.3977283239364624\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.         0.74999994\n"," 0.2222222  0.         0.5217391  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.75    0.9375  0.78125 1.      0.65625\n"," 0.625  ]\n","val_binary_accuracy: 0.8149999380111694\n","val_precision: 0.6607515811920166\n","val_recall: 0.2365470826625824\n","val_label_wise_macro_f1: 0.24079492688179016\n","val_subset_accuracy: 0.09921874850988388\n","val_subset_precision: 0.4286457896232605\n","val_subset_recall: 0.26657551527023315\n","val_subset_f1: 0.3274891972541809\n","val_auc: 0.800703763961792\n","val_prc_auc: 0.5195963978767395\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8129 - binary_accuracy: 0.8175 - label_wise_accuracy: 0.8173 - label_wise_f1_score: 0.2460 - label_wise_macro_f1: 0.2406 - loss: 0.3988 - prc_auc: 0.5318 - precision: 0.6658 - recall: 0.2272 - subset_accuracy: 0.1003 - subset_f1: 0.3095 - subset_precision: 0.4054 - subset_recall: 0.2521 - val_auc: 0.8007 - val_binary_accuracy: 0.8150 - val_label_wise_accuracy: 0.8031 - val_label_wise_f1_score: 0.2561 - val_label_wise_macro_f1: 0.2408 - val_loss: 0.4076 - val_prc_auc: 0.5196 - val_precision: 0.6608 - val_recall: 0.2365 - val_subset_accuracy: 0.0992 - val_subset_f1: 0.3275 - val_subset_precision: 0.4286 - val_subset_recall: 0.2666\n","Epoch 12/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8161 - binary_accuracy: 0.8183 - label_wise_accuracy: 0.8186 - label_wise_f1_score: 0.2598 - label_wise_macro_f1: 0.2529 - loss: 0.3962 - prc_auc: 0.5372 - precision: 0.6637 - recall: 0.2382 - subset_accuracy: 0.1045 - subset_f1: 0.3232 - subset_precision: 0.4211 - subset_recall: 0.2642\n","Epoch 12: Validation Metrics:\n","loss: 0.39521998167037964\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.         0.74999994\n"," 0.2222222  0.         0.5217391  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.75    0.9375  0.78125 1.      0.65625\n"," 0.625  ]\n","val_binary_accuracy: 0.8160156011581421\n","val_precision: 0.6603396534919739\n","val_recall: 0.2470104694366455\n","val_label_wise_macro_f1: 0.25289398431777954\n","val_subset_accuracy: 0.10390625149011612\n","val_subset_precision: 0.4449218213558197\n","val_subset_recall: 0.2806640565395355\n","val_subset_f1: 0.3429487645626068\n","val_auc: 0.8023594617843628\n","val_prc_auc: 0.5221713185310364\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8161 - binary_accuracy: 0.8183 - label_wise_accuracy: 0.8185 - label_wise_f1_score: 0.2598 - label_wise_macro_f1: 0.2529 - loss: 0.3962 - prc_auc: 0.5372 - precision: 0.6637 - recall: 0.2382 - subset_accuracy: 0.1045 - subset_f1: 0.3232 - subset_precision: 0.4211 - subset_recall: 0.2642 - val_auc: 0.8024 - val_binary_accuracy: 0.8160 - val_label_wise_accuracy: 0.8031 - val_label_wise_f1_score: 0.2561 - val_label_wise_macro_f1: 0.2529 - val_loss: 0.4062 - val_prc_auc: 0.5222 - val_precision: 0.6603 - val_recall: 0.2470 - val_subset_accuracy: 0.1039 - val_subset_f1: 0.3429 - val_subset_precision: 0.4449 - val_subset_recall: 0.2807\n","Epoch 13/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8190 - binary_accuracy: 0.8197 - label_wise_accuracy: 0.8198 - label_wise_f1_score: 0.2711 - label_wise_macro_f1: 0.2663 - loss: 0.3939 - prc_auc: 0.5422 - precision: 0.6654 - recall: 0.2499 - subset_accuracy: 0.1072 - subset_f1: 0.3355 - subset_precision: 0.4344 - subset_recall: 0.2754\n","Epoch 13: Validation Metrics:\n","loss: 0.39301368594169617\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.2222222  0.74999994\n"," 0.19999997 0.         0.5217391  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.78125 0.9375  0.75    1.      0.65625\n"," 0.625  ]\n","val_binary_accuracy: 0.8167968988418579\n","val_precision: 0.6599034070968628\n","val_recall: 0.25523167848587036\n","val_label_wise_macro_f1: 0.2615123391151428\n","val_subset_accuracy: 0.10546875\n","val_subset_precision: 0.4566405713558197\n","val_subset_recall: 0.28867191076278687\n","val_subset_f1: 0.3523750901222229\n","val_auc: 0.8038033246994019\n","val_prc_auc: 0.5243945717811584\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8190 - binary_accuracy: 0.8197 - label_wise_accuracy: 0.8197 - label_wise_f1_score: 0.2711 - label_wise_macro_f1: 0.2663 - loss: 0.3939 - prc_auc: 0.5422 - precision: 0.6653 - recall: 0.2500 - subset_accuracy: 0.1072 - subset_f1: 0.3356 - subset_precision: 0.4345 - subset_recall: 0.2755 - val_auc: 0.8038 - val_binary_accuracy: 0.8168 - val_label_wise_accuracy: 0.8031 - val_label_wise_f1_score: 0.2761 - val_label_wise_macro_f1: 0.2615 - val_loss: 0.4051 - val_prc_auc: 0.5244 - val_precision: 0.6599 - val_recall: 0.2552 - val_subset_accuracy: 0.1055 - val_subset_f1: 0.3524 - val_subset_precision: 0.4566 - val_subset_recall: 0.2887\n","Epoch 14/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8214 - binary_accuracy: 0.8214 - label_wise_accuracy: 0.8213 - label_wise_f1_score: 0.2855 - label_wise_macro_f1: 0.2837 - loss: 0.3918 - prc_auc: 0.5467 - precision: 0.6688 - recall: 0.2624 - subset_accuracy: 0.1137 - subset_f1: 0.3502 - subset_precision: 0.4486 - subset_recall: 0.2893\n","Epoch 14: Validation Metrics:\n","loss: 0.39103633165359497\n","val_label_wise_f1_score: [0.         0.39999995 0.         0.66666657 0.2222222  0.74999994\n"," 0.19999997 0.         0.5217391  0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.78125 0.9375  0.75    1.      0.65625\n"," 0.625  ]\n","val_binary_accuracy: 0.8171094059944153\n","val_precision: 0.6566885113716125\n","val_recall: 0.26233184337615967\n","val_label_wise_macro_f1: 0.2701409161090851\n","val_subset_accuracy: 0.10625000298023224\n","val_subset_precision: 0.46471351385116577\n","val_subset_recall: 0.29631513357162476\n","val_subset_f1: 0.36056798696517944\n","val_auc: 0.8050282597541809\n","val_prc_auc: 0.5263727307319641\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8214 - binary_accuracy: 0.8214 - label_wise_accuracy: 0.8212 - label_wise_f1_score: 0.2854 - label_wise_macro_f1: 0.2837 - loss: 0.3918 - prc_auc: 0.5467 - precision: 0.6688 - recall: 0.2624 - subset_accuracy: 0.1137 - subset_f1: 0.3503 - subset_precision: 0.4487 - subset_recall: 0.2893 - val_auc: 0.8050 - val_binary_accuracy: 0.8171 - val_label_wise_accuracy: 0.8031 - val_label_wise_f1_score: 0.2761 - val_label_wise_macro_f1: 0.2701 - val_loss: 0.4042 - val_prc_auc: 0.5264 - val_precision: 0.6567 - val_recall: 0.2623 - val_subset_accuracy: 0.1063 - val_subset_f1: 0.3606 - val_subset_precision: 0.4647 - val_subset_recall: 0.2963\n","Epoch 15/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8235 - binary_accuracy: 0.8226 - label_wise_accuracy: 0.8223 - label_wise_f1_score: 0.2953 - label_wise_macro_f1: 0.2937 - loss: 0.3900 - prc_auc: 0.5508 - precision: 0.6708 - recall: 0.2712 - subset_accuracy: 0.1177 - subset_f1: 0.3613 - subset_precision: 0.4613 - subset_recall: 0.2989\n","Epoch 15: Validation Metrics:\n","loss: 0.38924551010131836\n","val_label_wise_f1_score: [0.         0.47619042 0.         0.66666657 0.2222222  0.74999994\n"," 0.19999997 0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.875   0.96875 0.78125 0.9375  0.75    1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.8174217939376831\n","val_precision: 0.6547945141792297\n","val_recall: 0.26793721318244934\n","val_label_wise_macro_f1: 0.27623772621154785\n","val_subset_accuracy: 0.109375\n","val_subset_precision: 0.4704427123069763\n","val_subset_recall: 0.30178388953208923\n","val_subset_f1: 0.36640727519989014\n","val_auc: 0.805900514125824\n","val_prc_auc: 0.5278650522232056\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8235 - binary_accuracy: 0.8226 - label_wise_accuracy: 0.8222 - label_wise_f1_score: 0.2952 - label_wise_macro_f1: 0.2937 - loss: 0.3900 - prc_auc: 0.5508 - precision: 0.6708 - recall: 0.2712 - subset_accuracy: 0.1177 - subset_f1: 0.3613 - subset_precision: 0.4613 - subset_recall: 0.2990 - val_auc: 0.8059 - val_binary_accuracy: 0.8174 - val_label_wise_accuracy: 0.8094 - val_label_wise_f1_score: 0.2898 - val_label_wise_macro_f1: 0.2762 - val_loss: 0.4034 - val_prc_auc: 0.5279 - val_precision: 0.6548 - val_recall: 0.2679 - val_subset_accuracy: 0.1094 - val_subset_f1: 0.3664 - val_subset_precision: 0.4704 - val_subset_recall: 0.3018\n","Epoch 16/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8254 - binary_accuracy: 0.8231 - label_wise_accuracy: 0.8229 - label_wise_f1_score: 0.3037 - label_wise_macro_f1: 0.3038 - loss: 0.3883 - prc_auc: 0.5546 - precision: 0.6695 - recall: 0.2775 - subset_accuracy: 0.1182 - subset_f1: 0.3685 - subset_precision: 0.4698 - subset_recall: 0.3052\n","Epoch 16: Validation Metrics:\n","loss: 0.38760432600975037\n","val_label_wise_f1_score: [0.         0.47619042 0.         0.66666657 0.2222222  0.74999994\n"," 0.19999997 0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.8125  0.65625 0.875   0.96875 0.78125 0.9375  0.75    1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.8181249499320984\n","val_precision: 0.6550801992416382\n","val_recall: 0.27466368675231934\n","val_label_wise_macro_f1: 0.285866916179657\n","val_subset_accuracy: 0.11171875149011612\n","val_subset_precision: 0.47669273614883423\n","val_subset_recall: 0.30845052003860474\n","val_subset_f1: 0.3730877637863159\n","val_auc: 0.8069067001342773\n","val_prc_auc: 0.5294071435928345\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8254 - binary_accuracy: 0.8231 - label_wise_accuracy: 0.8228 - label_wise_f1_score: 0.3036 - label_wise_macro_f1: 0.3038 - loss: 0.3883 - prc_auc: 0.5546 - precision: 0.6694 - recall: 0.2776 - subset_accuracy: 0.1182 - subset_f1: 0.3686 - subset_precision: 0.4698 - subset_recall: 0.3053 - val_auc: 0.8069 - val_binary_accuracy: 0.8181 - val_label_wise_accuracy: 0.8094 - val_label_wise_f1_score: 0.2898 - val_label_wise_macro_f1: 0.2859 - val_loss: 0.4027 - val_prc_auc: 0.5294 - val_precision: 0.6551 - val_recall: 0.2747 - val_subset_accuracy: 0.1117 - val_subset_f1: 0.3731 - val_subset_precision: 0.4767 - val_subset_recall: 0.3085\n","Epoch 17/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8272 - binary_accuracy: 0.8246 - label_wise_accuracy: 0.8241 - label_wise_f1_score: 0.3135 - label_wise_macro_f1: 0.3164 - loss: 0.3867 - prc_auc: 0.5580 - precision: 0.6743 - recall: 0.2861 - subset_accuracy: 0.1217 - subset_f1: 0.3785 - subset_precision: 0.4810 - subset_recall: 0.3140\n","Epoch 17: Validation Metrics:\n","loss: 0.38608330488204956\n","val_label_wise_f1_score: [0.28571427 0.47619042 0.         0.66666657 0.2222222  0.74999994\n"," 0.3636363  0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.84375 0.65625 0.875   0.96875 0.78125 0.9375  0.78125 1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.8185938596725464\n","val_precision: 0.6560846567153931\n","val_recall: 0.27802690863609314\n","val_label_wise_macro_f1: 0.2913973927497864\n","val_subset_accuracy: 0.11015625298023224\n","val_subset_precision: 0.4807291626930237\n","val_subset_recall: 0.31290361285209656\n","val_subset_f1: 0.37761014699935913\n","val_auc: 0.8076137900352478\n","val_prc_auc: 0.53045654296875\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8272 - binary_accuracy: 0.8246 - label_wise_accuracy: 0.8241 - label_wise_f1_score: 0.3136 - label_wise_macro_f1: 0.3164 - loss: 0.3867 - prc_auc: 0.5580 - precision: 0.6743 - recall: 0.2862 - subset_accuracy: 0.1217 - subset_f1: 0.3785 - subset_precision: 0.4810 - subset_recall: 0.3141 - val_auc: 0.8076 - val_binary_accuracy: 0.8186 - val_label_wise_accuracy: 0.8156 - val_label_wise_f1_score: 0.3348 - val_label_wise_macro_f1: 0.2914 - val_loss: 0.4021 - val_prc_auc: 0.5305 - val_precision: 0.6561 - val_recall: 0.2780 - val_subset_accuracy: 0.1102 - val_subset_f1: 0.3776 - val_subset_precision: 0.4807 - val_subset_recall: 0.3129\n","Epoch 18/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8288 - binary_accuracy: 0.8251 - label_wise_accuracy: 0.8247 - label_wise_f1_score: 0.3191 - label_wise_macro_f1: 0.3218 - loss: 0.3852 - prc_auc: 0.5615 - precision: 0.6746 - recall: 0.2905 - subset_accuracy: 0.1223 - subset_f1: 0.3827 - subset_precision: 0.4845 - subset_recall: 0.3183\n","Epoch 18: Validation Metrics:\n","loss: 0.3846650719642639\n","val_label_wise_f1_score: [0.24999996 0.39999995 0.         0.66666657 0.2222222  0.74999994\n"," 0.3636363  0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.78125 0.9375  0.78125 1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.8184374570846558\n","val_precision: 0.6530434489250183\n","val_recall: 0.2806427478790283\n","val_label_wise_macro_f1: 0.2965328097343445\n","val_subset_accuracy: 0.109375\n","val_subset_precision: 0.48255205154418945\n","val_subset_recall: 0.31572914123535156\n","val_subset_f1: 0.3802243769168854\n","val_auc: 0.8082742094993591\n","val_prc_auc: 0.5317577719688416\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8288 - binary_accuracy: 0.8251 - label_wise_accuracy: 0.8246 - label_wise_f1_score: 0.3192 - label_wise_macro_f1: 0.3218 - loss: 0.3852 - prc_auc: 0.5615 - precision: 0.6746 - recall: 0.2905 - subset_accuracy: 0.1223 - subset_f1: 0.3828 - subset_precision: 0.4846 - subset_recall: 0.3183 - val_auc: 0.8083 - val_binary_accuracy: 0.8184 - val_label_wise_accuracy: 0.8094 - val_label_wise_f1_score: 0.3236 - val_label_wise_macro_f1: 0.2965 - val_loss: 0.4016 - val_prc_auc: 0.5318 - val_precision: 0.6530 - val_recall: 0.2806 - val_subset_accuracy: 0.1094 - val_subset_f1: 0.3802 - val_subset_precision: 0.4826 - val_subset_recall: 0.3157\n","Epoch 19/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8303 - binary_accuracy: 0.8258 - label_wise_accuracy: 0.8256 - label_wise_f1_score: 0.3262 - label_wise_macro_f1: 0.3277 - loss: 0.3839 - prc_auc: 0.5645 - precision: 0.6758 - recall: 0.2953 - subset_accuracy: 0.1259 - subset_f1: 0.3880 - subset_precision: 0.4894 - subset_recall: 0.3234\n","Epoch 19: Validation Metrics:\n","loss: 0.3833323121070862\n","val_label_wise_f1_score: [0.24999996 0.39999995 0.         0.66666657 0.2222222  0.74999994\n"," 0.3636363  0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.78125 0.9375  0.78125 1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.818281352519989\n","val_precision: 0.650343656539917\n","val_recall: 0.2828848958015442\n","val_label_wise_macro_f1: 0.2989732623100281\n","val_subset_accuracy: 0.10859374701976776\n","val_subset_precision: 0.48359376192092896\n","val_subset_recall: 0.3175520598888397\n","val_subset_f1: 0.38190096616744995\n","val_auc: 0.8088993430137634\n","val_prc_auc: 0.5327499508857727\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8303 - binary_accuracy: 0.8258 - label_wise_accuracy: 0.8255 - label_wise_f1_score: 0.3262 - label_wise_macro_f1: 0.3277 - loss: 0.3839 - prc_auc: 0.5645 - precision: 0.6758 - recall: 0.2953 - subset_accuracy: 0.1259 - subset_f1: 0.3881 - subset_precision: 0.4895 - subset_recall: 0.3234 - val_auc: 0.8089 - val_binary_accuracy: 0.8183 - val_label_wise_accuracy: 0.8094 - val_label_wise_f1_score: 0.3236 - val_label_wise_macro_f1: 0.2990 - val_loss: 0.4012 - val_prc_auc: 0.5327 - val_precision: 0.6503 - val_recall: 0.2829 - val_subset_accuracy: 0.1086 - val_subset_f1: 0.3819 - val_subset_precision: 0.4836 - val_subset_recall: 0.3176\n","Epoch 20/20\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8317 - binary_accuracy: 0.8264 - label_wise_accuracy: 0.8264 - label_wise_f1_score: 0.3328 - label_wise_macro_f1: 0.3340 - loss: 0.3826 - prc_auc: 0.5676 - precision: 0.6769 - recall: 0.2993 - subset_accuracy: 0.1270 - subset_f1: 0.3929 - subset_precision: 0.4948 - subset_recall: 0.3279\n","Epoch 20: Validation Metrics:\n","loss: 0.38206836581230164\n","val_label_wise_f1_score: [0.24999996 0.39999995 0.         0.66666657 0.2222222  0.74999994\n"," 0.3636363  0.         0.58333325 0.        ]\n","val_label_wise_accuracy: [0.8125  0.625   0.875   0.96875 0.78125 0.9375  0.78125 1.      0.6875\n"," 0.625  ]\n","val_binary_accuracy: 0.8182812929153442\n","val_precision: 0.6493173837661743\n","val_recall: 0.28437966108322144\n","val_label_wise_macro_f1: 0.30205681920051575\n","val_subset_accuracy: 0.10859374701976776\n","val_subset_precision: 0.48450523614883423\n","val_subset_recall: 0.31898435950279236\n","val_subset_f1: 0.38321587443351746\n","val_auc: 0.8094521164894104\n","val_prc_auc: 0.5336782336235046\n","\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8317 - binary_accuracy: 0.8264 - label_wise_accuracy: 0.8262 - label_wise_f1_score: 0.3327 - label_wise_macro_f1: 0.3340 - loss: 0.3826 - prc_auc: 0.5676 - precision: 0.6768 - recall: 0.2993 - subset_accuracy: 0.1270 - subset_f1: 0.3930 - subset_precision: 0.4948 - subset_recall: 0.3280 - val_auc: 0.8095 - val_binary_accuracy: 0.8183 - val_label_wise_accuracy: 0.8094 - val_label_wise_f1_score: 0.3236 - val_label_wise_macro_f1: 0.3021 - val_loss: 0.4008 - val_prc_auc: 0.5337 - val_precision: 0.6493 - val_recall: 0.2844 - val_subset_accuracy: 0.1086 - val_subset_f1: 0.3832 - val_subset_precision: 0.4845 - val_subset_recall: 0.3190\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - auc: 0.7823 - binary_accuracy: 0.8722 - label_wise_accuracy: 0.8734 - label_wise_f1_score: 0.2904 - label_wise_macro_f1: 0.2695 - loss: 0.3268 - prc_auc: 0.3169 - precision: 0.3720 - recall: 0.3089 - subset_accuracy: 0.1939 - subset_f1: 0.2776 - subset_precision: 0.2587 - subset_recall: 0.3009\n","Evaluation Metrics:\n","Loss: 0.3231959044933319\n","Label F1 Scores: [0.5714285  0.18181816 0.         0.49999994 0.         0.44444442\n"," 0.2857142  0.33333328 0.19999997 0.        ]\n","Label Accuracies: [0.90625 0.71875 0.84375 0.9375  0.90625 0.84375 0.84375 0.875   0.75\n"," 0.96875]\n","Accuracy: 0.8738541007041931\n","Precision: 0.3778040111064911\n","Recall: 0.3187251091003418\n","F1 Score: 0.29167380928993225\n","Subset Accuracy: 0.19583334028720856\n","Subset Precision: 0.2644096910953522\n","Subset Recall: 0.3124999701976776\n","Subset F1: 0.28583580255508423\n","AUC: 0.7879455089569092\n","PRC AUC: 0.3203599750995636\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.5467 - binary_accuracy: 0.7257 - label_wise_accuracy: 0.8185 - label_wise_f1_score: 0.0329 - label_wise_macro_f1: 0.0767 - loss: 0.6404 - prc_auc: 0.1421 - precision: 0.1463 - recall: 0.2179 - subset_accuracy: 0.0081 - subset_f1: 0.1415 - subset_precision: 0.1203 - subset_recall: 0.2404\n","Epoch 1: Validation Metrics:\n","loss: 0.5641104578971863\n","val_label_wise_f1_score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.9375  0.875   0.96875 0.9375  0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.625   0.9375  0.9375  0.90625 0.78125 0.84375\n"," 0.53125 0.65625]\n","val_binary_accuracy: 0.8672991991043091\n","val_precision: 0.0\n","val_recall: 0.0\n","val_label_wise_macro_f1: 0.0\n","val_subset_accuracy: 0.0\n","val_subset_precision: 0.0\n","val_subset_recall: 0.0\n","val_subset_f1: 0.0\n","val_auc: 0.7054406404495239\n","val_prc_auc: 0.27422553300857544\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 138ms/step - auc: 0.5468 - binary_accuracy: 0.7262 - label_wise_accuracy: 0.8187 - label_wise_f1_score: 0.0327 - label_wise_macro_f1: 0.0764 - loss: 0.6400 - prc_auc: 0.1421 - precision: 0.1464 - recall: 0.2172 - subset_accuracy: 0.0081 - subset_f1: 0.1411 - subset_precision: 0.1200 - subset_recall: 0.2395 - val_auc: 0.7054 - val_binary_accuracy: 0.8673 - val_label_wise_accuracy: 0.8594 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 0.0000e+00 - val_loss: 0.3975 - val_prc_auc: 0.2742 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_subset_accuracy: 0.0000e+00 - val_subset_f1: 0.0000e+00 - val_subset_precision: 0.0000e+00 - val_subset_recall: 0.0000e+00\n","Epoch 2/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7142 - binary_accuracy: 0.8702 - label_wise_accuracy: 0.8704 - label_wise_f1_score: 0.0000e+00 - label_wise_macro_f1: 0.0000e+00 - loss: 0.3656 - prc_auc: 0.2821 - precision: 0.0000e+00 - recall: 0.0000e+00 - subset_accuracy: 0.0000e+00 - subset_f1: 0.0000e+00 - subset_precision: 0.0000e+00 - subset_recall: 0.0000e+00\n","Epoch 2: Validation Metrics:\n","loss: 0.35097047686576843\n","val_label_wise_f1_score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.9375  0.875   0.96875 0.9375  0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.625   0.9375  0.9375  0.90625 0.78125 0.84375\n"," 0.53125 0.65625]\n","val_binary_accuracy: 0.8672991991043091\n","val_precision: 0.0\n","val_recall: 0.0\n","val_label_wise_macro_f1: 0.0\n","val_subset_accuracy: 0.0\n","val_subset_precision: 0.0\n","val_subset_recall: 0.0\n","val_subset_f1: 0.0\n","val_auc: 0.7585037350654602\n","val_prc_auc: 0.3371100425720215\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - auc: 0.7143 - binary_accuracy: 0.8702 - label_wise_accuracy: 0.8704 - label_wise_f1_score: 0.0000e+00 - label_wise_macro_f1: 0.0000e+00 - loss: 0.3656 - prc_auc: 0.2822 - precision: 0.0000e+00 - recall: 0.0000e+00 - subset_accuracy: 0.0000e+00 - subset_f1: 0.0000e+00 - subset_precision: 0.0000e+00 - subset_recall: 0.0000e+00 - val_auc: 0.7585 - val_binary_accuracy: 0.8673 - val_label_wise_accuracy: 0.8594 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 0.0000e+00 - val_loss: 0.3427 - val_prc_auc: 0.3371 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_subset_accuracy: 0.0000e+00 - val_subset_f1: 0.0000e+00 - val_subset_precision: 0.0000e+00 - val_subset_recall: 0.0000e+00\n","Epoch 3/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7615 - binary_accuracy: 0.8702 - label_wise_accuracy: 0.8704 - label_wise_f1_score: 1.0721e-04 - label_wise_macro_f1: 2.0961e-05 - loss: 0.3364 - prc_auc: 0.3462 - precision: 0.1813 - recall: 2.7596e-05 - subset_accuracy: 0.0000e+00 - subset_f1: 3.8000e-05 - subset_precision: 7.1575e-05 - subset_recall: 2.6679e-05\n","Epoch 3: Validation Metrics:\n","loss: 0.33317500352859497\n","val_label_wise_f1_score: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.9375  0.875   0.96875 0.9375  0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.625   0.9375  0.9375  0.90625 0.78125 0.84375\n"," 0.53125 0.65625]\n","val_binary_accuracy: 0.8674107789993286\n","val_precision: 0.800000011920929\n","val_recall: 0.001121390494517982\n","val_label_wise_macro_f1: 0.0007401228649541736\n","val_subset_accuracy: 0.0007440476329065859\n","val_subset_precision: 0.0029761900659650564\n","val_subset_recall: 0.0018601190531626344\n","val_subset_f1: 0.0022321383003145456\n","val_auc: 0.7749953866004944\n","val_prc_auc: 0.36753860116004944\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.7616 - binary_accuracy: 0.8702 - label_wise_accuracy: 0.8704 - label_wise_f1_score: 1.0659e-04 - label_wise_macro_f1: 2.1462e-05 - loss: 0.3364 - prc_auc: 0.3462 - precision: 0.1860 - recall: 2.8255e-05 - subset_accuracy: 0.0000e+00 - subset_f1: 3.8913e-05 - subset_precision: 7.3284e-05 - subset_recall: 2.7320e-05 - val_auc: 0.7750 - val_binary_accuracy: 0.8674 - val_label_wise_accuracy: 0.8594 - val_label_wise_f1_score: 0.0000e+00 - val_label_wise_macro_f1: 7.4012e-04 - val_loss: 0.3342 - val_prc_auc: 0.3675 - val_precision: 0.8000 - val_recall: 0.0011 - val_subset_accuracy: 7.4405e-04 - val_subset_f1: 0.0022 - val_subset_precision: 0.0030 - val_subset_recall: 0.0019\n","Epoch 4/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7801 - binary_accuracy: 0.8708 - label_wise_accuracy: 0.8715 - label_wise_f1_score: 0.0078 - label_wise_macro_f1: 0.0042 - loss: 0.3272 - prc_auc: 0.3755 - precision: 0.7899 - recall: 0.0062 - subset_accuracy: 0.0024 - subset_f1: 0.0103 - subset_precision: 0.0161 - subset_recall: 0.0080\n","Epoch 4: Validation Metrics:\n","loss: 0.32418572902679443\n","val_label_wise_f1_score: [0.        0.        0.        0.        0.        0.        0.\n"," 0.        0.        0.        0.        0.        0.        0.\n"," 0.        0.        0.        0.        0.        0.4285714]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.9375  0.875   0.96875 0.9375  0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.625   0.9375  0.9375  0.90625 0.78125 0.84375\n"," 0.53125 0.75   ]\n","val_binary_accuracy: 0.8697172999382019\n","val_precision: 0.8037382960319519\n","val_recall: 0.024109896272420883\n","val_label_wise_macro_f1: 0.01635364629328251\n","val_subset_accuracy: 0.00818452425301075\n","val_subset_precision: 0.0639880895614624\n","val_subset_recall: 0.02936507761478424\n","val_subset_f1: 0.039574336260557175\n","val_auc: 0.7906278967857361\n","val_prc_auc: 0.3906109631061554\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.7801 - binary_accuracy: 0.8708 - label_wise_accuracy: 0.8715 - label_wise_f1_score: 0.0078 - label_wise_macro_f1: 0.0042 - loss: 0.3272 - prc_auc: 0.3755 - precision: 0.7900 - recall: 0.0062 - subset_accuracy: 0.0024 - subset_f1: 0.0103 - subset_precision: 0.0161 - subset_recall: 0.0080 - val_auc: 0.7906 - val_binary_accuracy: 0.8697 - val_label_wise_accuracy: 0.8641 - val_label_wise_f1_score: 0.0214 - val_label_wise_macro_f1: 0.0164 - val_loss: 0.3260 - val_prc_auc: 0.3906 - val_precision: 0.8037 - val_recall: 0.0241 - val_subset_accuracy: 0.0082 - val_subset_f1: 0.0396 - val_subset_precision: 0.0640 - val_subset_recall: 0.0294\n","Epoch 5/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.7979 - binary_accuracy: 0.8730 - label_wise_accuracy: 0.8736 - label_wise_f1_score: 0.0248 - label_wise_macro_f1: 0.0206 - loss: 0.3182 - prc_auc: 0.4037 - precision: 0.7645 - recall: 0.0321 - subset_accuracy: 0.0150 - subset_f1: 0.0535 - subset_precision: 0.0830 - subset_recall: 0.0408\n","Epoch 5: Validation Metrics:\n","loss: 0.3155127465724945\n","val_label_wise_f1_score: [0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.24999996 0.         0.         0.         0.         0.\n"," 0.         0.4285714 ]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.9375  0.875   0.96875 0.9375  0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.625   0.9375  0.9375  0.90625 0.78125 0.84375\n"," 0.46875 0.75   ]\n","val_binary_accuracy: 0.8721726536750793\n","val_precision: 0.7147541046142578\n","val_recall: 0.06111578270792961\n","val_label_wise_macro_f1: 0.040062204003334045\n","val_subset_accuracy: 0.0245535708963871\n","val_subset_precision: 0.1562499850988388\n","val_subset_recall: 0.07533777505159378\n","val_subset_f1: 0.10091601312160492\n","val_auc: 0.8036989569664001\n","val_prc_auc: 0.41308194398880005\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.7979 - binary_accuracy: 0.8730 - label_wise_accuracy: 0.8735 - label_wise_f1_score: 0.0249 - label_wise_macro_f1: 0.0207 - loss: 0.3181 - prc_auc: 0.4037 - precision: 0.7644 - recall: 0.0322 - subset_accuracy: 0.0151 - subset_f1: 0.0535 - subset_precision: 0.0831 - subset_recall: 0.0408 - val_auc: 0.8037 - val_binary_accuracy: 0.8722 - val_label_wise_accuracy: 0.8609 - val_label_wise_f1_score: 0.0339 - val_label_wise_macro_f1: 0.0401 - val_loss: 0.3187 - val_prc_auc: 0.4131 - val_precision: 0.7148 - val_recall: 0.0611 - val_subset_accuracy: 0.0246 - val_subset_f1: 0.1009 - val_subset_precision: 0.1562 - val_subset_recall: 0.0753\n","Epoch 6/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8121 - binary_accuracy: 0.8753 - label_wise_accuracy: 0.8762 - label_wise_f1_score: 0.0607 - label_wise_macro_f1: 0.0484 - loss: 0.3101 - prc_auc: 0.4302 - precision: 0.7074 - recall: 0.0676 - subset_accuracy: 0.0289 - subset_f1: 0.1085 - subset_precision: 0.1636 - subset_recall: 0.0822\n","Epoch 6: Validation Metrics:\n","loss: 0.3079805076122284\n","val_label_wise_f1_score: [0.         0.         0.         0.66666657 0.         0.\n"," 0.66666657 0.         0.         0.         0.         0.\n"," 0.3157894  0.         0.         0.         0.         0.33333328\n"," 0.1111111  0.4285714 ]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.96875 0.875   0.96875 0.96875 0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.59375 0.9375  0.9375  0.90625 0.78125 0.875\n"," 0.5     0.75   ]\n","val_binary_accuracy: 0.8743303418159485\n","val_precision: 0.6702702641487122\n","val_recall: 0.10428931564092636\n","val_label_wise_macro_f1: 0.08717577159404755\n","val_subset_accuracy: 0.0386904776096344\n","val_subset_precision: 0.2374751716852188\n","val_subset_recall: 0.12085073441267014\n","val_subset_f1: 0.1594986468553543\n","val_auc: 0.8134203553199768\n","val_prc_auc: 0.42925310134887695\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8121 - binary_accuracy: 0.8753 - label_wise_accuracy: 0.8761 - label_wise_f1_score: 0.0611 - label_wise_macro_f1: 0.0485 - loss: 0.3101 - prc_auc: 0.4303 - precision: 0.7073 - recall: 0.0677 - subset_accuracy: 0.0289 - subset_f1: 0.1086 - subset_precision: 0.1637 - subset_recall: 0.0823 - val_auc: 0.8134 - val_binary_accuracy: 0.8743 - val_label_wise_accuracy: 0.8656 - val_label_wise_f1_score: 0.1261 - val_label_wise_macro_f1: 0.0872 - val_loss: 0.3127 - val_prc_auc: 0.4293 - val_precision: 0.6703 - val_recall: 0.1043 - val_subset_accuracy: 0.0387 - val_subset_f1: 0.1595 - val_subset_precision: 0.2375 - val_subset_recall: 0.1209\n","Epoch 7/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8223 - binary_accuracy: 0.8784 - label_wise_accuracy: 0.8789 - label_wise_f1_score: 0.1025 - label_wise_macro_f1: 0.0971 - loss: 0.3036 - prc_auc: 0.4492 - precision: 0.6906 - recall: 0.1153 - subset_accuracy: 0.0450 - subset_f1: 0.1741 - subset_precision: 0.2513 - subset_recall: 0.1346\n","Epoch 7: Validation Metrics:\n","loss: 0.3019615709781647\n","val_label_wise_f1_score: [0.         0.         0.         0.66666657 0.         0.\n"," 0.66666657 0.         0.         0.         0.         0.\n"," 0.29999995 0.         0.         0.         0.         0.49999994\n"," 0.19999996 0.37499997]\n","val_label_wise_accuracy: [0.9375  0.6875  0.9375  0.96875 0.875   0.96875 0.96875 0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.9375  0.9375  0.90625 0.78125 0.875\n"," 0.5     0.6875 ]\n","val_binary_accuracy: 0.8752978444099426\n","val_precision: 0.6397919654846191\n","val_recall: 0.13793103396892548\n","val_label_wise_macro_f1: 0.11876227706670761\n","val_subset_accuracy: 0.0476190485060215\n","val_subset_precision: 0.2976810336112976\n","val_subset_recall: 0.15751104056835175\n","val_subset_f1: 0.20523668825626373\n","val_auc: 0.8202480673789978\n","val_prc_auc: 0.44022658467292786\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8223 - binary_accuracy: 0.8784 - label_wise_accuracy: 0.8788 - label_wise_f1_score: 0.1027 - label_wise_macro_f1: 0.0971 - loss: 0.3035 - prc_auc: 0.4492 - precision: 0.6905 - recall: 0.1154 - subset_accuracy: 0.0450 - subset_f1: 0.1741 - subset_precision: 0.2513 - subset_recall: 0.1346 - val_auc: 0.8202 - val_binary_accuracy: 0.8753 - val_label_wise_accuracy: 0.8609 - val_label_wise_f1_score: 0.1354 - val_label_wise_macro_f1: 0.1188 - val_loss: 0.3083 - val_prc_auc: 0.4402 - val_precision: 0.6398 - val_recall: 0.1379 - val_subset_accuracy: 0.0476 - val_subset_f1: 0.2052 - val_subset_precision: 0.2977 - val_subset_recall: 0.1575\n","Epoch 8/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8296 - binary_accuracy: 0.8802 - label_wise_accuracy: 0.8806 - label_wise_f1_score: 0.1268 - label_wise_macro_f1: 0.1241 - loss: 0.2985 - prc_auc: 0.4622 - precision: 0.6776 - recall: 0.1480 - subset_accuracy: 0.0598 - subset_f1: 0.2192 - subset_precision: 0.3113 - subset_recall: 0.1709\n","Epoch 8: Validation Metrics:\n","loss: 0.2973564565181732\n","val_label_wise_f1_score: [0.         0.         0.         0.66666657 0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.         0.         0.         0.         0.49999994\n"," 0.28571424 0.4705882 ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  0.96875 0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.9375  0.9375  0.90625 0.78125 0.875\n"," 0.53125 0.71875]\n","val_binary_accuracy: 0.8757069110870361\n","val_precision: 0.6252771615982056\n","val_recall: 0.15811605751514435\n","val_label_wise_macro_f1: 0.13609068095684052\n","val_subset_accuracy: 0.0491071417927742\n","val_subset_precision: 0.3361234664916992\n","val_subset_recall: 0.17858706414699554\n","val_subset_f1: 0.23228570818901062\n","val_auc: 0.8251452445983887\n","val_prc_auc: 0.44790151715278625\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8297 - binary_accuracy: 0.8802 - label_wise_accuracy: 0.8805 - label_wise_f1_score: 0.1270 - label_wise_macro_f1: 0.1241 - loss: 0.2985 - prc_auc: 0.4622 - precision: 0.6776 - recall: 0.1480 - subset_accuracy: 0.0598 - subset_f1: 0.2192 - subset_precision: 0.3113 - subset_recall: 0.1709 - val_auc: 0.8251 - val_binary_accuracy: 0.8757 - val_label_wise_accuracy: 0.8641 - val_label_wise_f1_score: 0.1611 - val_label_wise_macro_f1: 0.1361 - val_loss: 0.3050 - val_prc_auc: 0.4479 - val_precision: 0.6253 - val_recall: 0.1581 - val_subset_accuracy: 0.0491 - val_subset_f1: 0.2323 - val_subset_precision: 0.3361 - val_subset_recall: 0.1786\n","Epoch 9/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8353 - binary_accuracy: 0.8816 - label_wise_accuracy: 0.8818 - label_wise_f1_score: 0.1439 - label_wise_macro_f1: 0.1416 - loss: 0.2947 - prc_auc: 0.4722 - precision: 0.6756 - recall: 0.1694 - subset_accuracy: 0.0684 - subset_f1: 0.2474 - subset_precision: 0.3459 - subset_recall: 0.1943\n","Epoch 9: Validation Metrics:\n","loss: 0.29374605417251587\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.         0.         0.         0.         0.49999994\n"," 0.28571424 0.4705882 ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.9375  0.9375  0.90625 0.78125 0.875\n"," 0.53125 0.71875]\n","val_binary_accuracy: 0.8764136433601379\n","val_precision: 0.6233635544776917\n","val_recall: 0.17353518307209015\n","val_label_wise_macro_f1: 0.14625303447246552\n","val_subset_accuracy: 0.0580357126891613\n","val_subset_precision: 0.36216509342193604\n","val_subset_recall: 0.19639460742473602\n","val_subset_f1: 0.25373145937919617\n","val_auc: 0.8288931250572205\n","val_prc_auc: 0.4542071521282196\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8353 - binary_accuracy: 0.8816 - label_wise_accuracy: 0.8817 - label_wise_f1_score: 0.1441 - label_wise_macro_f1: 0.1416 - loss: 0.2947 - prc_auc: 0.4722 - precision: 0.6756 - recall: 0.1694 - subset_accuracy: 0.0684 - subset_f1: 0.2474 - subset_precision: 0.3459 - subset_recall: 0.1943 - val_auc: 0.8289 - val_binary_accuracy: 0.8764 - val_label_wise_accuracy: 0.8656 - val_label_wise_f1_score: 0.1778 - val_label_wise_macro_f1: 0.1463 - val_loss: 0.3025 - val_prc_auc: 0.4542 - val_precision: 0.6234 - val_recall: 0.1735 - val_subset_accuracy: 0.0580 - val_subset_f1: 0.2537 - val_subset_precision: 0.3622 - val_subset_recall: 0.1964\n","Epoch 10/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8396 - binary_accuracy: 0.8823 - label_wise_accuracy: 0.8824 - label_wise_f1_score: 0.1545 - label_wise_macro_f1: 0.1538 - loss: 0.2916 - prc_auc: 0.4801 - precision: 0.6687 - recall: 0.1854 - subset_accuracy: 0.0746 - subset_f1: 0.2686 - subset_precision: 0.3696 - subset_recall: 0.2129\n","Epoch 10: Validation Metrics:\n","loss: 0.2908521890640259\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.         0.         0.         0.         0.49999994\n"," 0.36363634 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.9375  0.9375  0.90625 0.78125 0.875\n"," 0.5625  0.78125]\n","val_binary_accuracy: 0.8765996098518372\n","val_precision: 0.6179245114326477\n","val_recall: 0.18362769484519958\n","val_label_wise_macro_f1: 0.15167666971683502\n","val_subset_accuracy: 0.0595238097012043\n","val_subset_precision: 0.3812003433704376\n","val_subset_recall: 0.20815052092075348\n","val_subset_f1: 0.2681892514228821\n","val_auc: 0.8319183588027954\n","val_prc_auc: 0.4591233432292938\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8396 - binary_accuracy: 0.8823 - label_wise_accuracy: 0.8823 - label_wise_f1_score: 0.1547 - label_wise_macro_f1: 0.1538 - loss: 0.2916 - prc_auc: 0.4801 - precision: 0.6687 - recall: 0.1854 - subset_accuracy: 0.0745 - subset_f1: 0.2686 - subset_precision: 0.3696 - subset_recall: 0.2129 - val_auc: 0.8319 - val_binary_accuracy: 0.8766 - val_label_wise_accuracy: 0.8703 - val_label_wise_f1_score: 0.1898 - val_label_wise_macro_f1: 0.1517 - val_loss: 0.3005 - val_prc_auc: 0.4591 - val_precision: 0.6179 - val_recall: 0.1836 - val_subset_accuracy: 0.0595 - val_subset_f1: 0.2682 - val_subset_precision: 0.3812 - val_subset_recall: 0.2082\n","Epoch 11/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8432 - binary_accuracy: 0.8830 - label_wise_accuracy: 0.8832 - label_wise_f1_score: 0.1660 - label_wise_macro_f1: 0.1653 - loss: 0.2890 - prc_auc: 0.4869 - precision: 0.6646 - recall: 0.1995 - subset_accuracy: 0.0793 - subset_f1: 0.2858 - subset_precision: 0.3909 - subset_recall: 0.2274\n","Epoch 11: Validation Metrics:\n","loss: 0.2884190082550049\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.         0.         0.         0.         0.6666666\n"," 0.36363634 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.9375  0.9375  0.90625 0.78125 0.90625\n"," 0.5625  0.78125]\n","val_binary_accuracy: 0.8771577477455139\n","val_precision: 0.6201269030570984\n","val_recall: 0.19175778329372406\n","val_label_wise_macro_f1: 0.15674184262752533\n","val_subset_accuracy: 0.0602678582072258\n","val_subset_precision: 0.3946676254272461\n","val_subset_recall: 0.21689310669898987\n","val_subset_f1: 0.2787480652332306\n","val_auc: 0.834149956703186\n","val_prc_auc: 0.4631916284561157\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8432 - binary_accuracy: 0.8830 - label_wise_accuracy: 0.8831 - label_wise_f1_score: 0.1662 - label_wise_macro_f1: 0.1653 - loss: 0.2890 - prc_auc: 0.4869 - precision: 0.6646 - recall: 0.1995 - subset_accuracy: 0.0793 - subset_f1: 0.2858 - subset_precision: 0.3909 - subset_recall: 0.2274 - val_auc: 0.8341 - val_binary_accuracy: 0.8772 - val_label_wise_accuracy: 0.8719 - val_label_wise_f1_score: 0.1981 - val_label_wise_macro_f1: 0.1567 - val_loss: 0.2989 - val_prc_auc: 0.4632 - val_precision: 0.6201 - val_recall: 0.1918 - val_subset_accuracy: 0.0603 - val_subset_f1: 0.2787 - val_subset_precision: 0.3947 - val_subset_recall: 0.2169\n","Epoch 12/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8463 - binary_accuracy: 0.8840 - label_wise_accuracy: 0.8840 - label_wise_f1_score: 0.1759 - label_wise_macro_f1: 0.1759 - loss: 0.2868 - prc_auc: 0.4930 - precision: 0.6684 - recall: 0.2111 - subset_accuracy: 0.0844 - subset_f1: 0.3017 - subset_precision: 0.4104 - subset_recall: 0.2409\n","Epoch 12: Validation Metrics:\n","loss: 0.28632181882858276\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.66666657 0.         0.         0.         0.6666666\n"," 0.36363634 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.96875 0.9375  0.90625 0.78125 0.90625\n"," 0.5625  0.78125]\n","val_binary_accuracy: 0.8782364726066589\n","val_precision: 0.6260720491409302\n","val_recall: 0.2046537697315216\n","val_label_wise_macro_f1: 0.1685795783996582\n","val_subset_accuracy: 0.065476194024086\n","val_subset_precision: 0.4124627709388733\n","val_subset_recall: 0.2329636812210083\n","val_subset_f1: 0.29636308550834656\n","val_auc: 0.8362055420875549\n","val_prc_auc: 0.46723616123199463\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 90ms/step - auc: 0.8463 - binary_accuracy: 0.8840 - label_wise_accuracy: 0.8840 - label_wise_f1_score: 0.1762 - label_wise_macro_f1: 0.1759 - loss: 0.2868 - prc_auc: 0.4930 - precision: 0.6684 - recall: 0.2111 - subset_accuracy: 0.0844 - subset_f1: 0.3017 - subset_precision: 0.4104 - subset_recall: 0.2409 - val_auc: 0.8362 - val_binary_accuracy: 0.8782 - val_label_wise_accuracy: 0.8734 - val_label_wise_f1_score: 0.2314 - val_label_wise_macro_f1: 0.1686 - val_loss: 0.2975 - val_prc_auc: 0.4672 - val_precision: 0.6261 - val_recall: 0.2047 - val_subset_accuracy: 0.0655 - val_subset_f1: 0.2964 - val_subset_precision: 0.4125 - val_subset_recall: 0.2330\n","Epoch 13/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8489 - binary_accuracy: 0.8845 - label_wise_accuracy: 0.8845 - label_wise_f1_score: 0.1822 - label_wise_macro_f1: 0.1831 - loss: 0.2849 - prc_auc: 0.4983 - precision: 0.6667 - recall: 0.2202 - subset_accuracy: 0.0855 - subset_f1: 0.3133 - subset_precision: 0.4244 - subset_recall: 0.2507\n","Epoch 13: Validation Metrics:\n","loss: 0.2844926118850708\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 0.66666657 0.         0.         0.         0.6666666\n"," 0.43478256 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  0.96875 0.9375  0.90625 0.78125 0.90625\n"," 0.59375 0.78125]\n","val_binary_accuracy: 0.8786457777023315\n","val_precision: 0.6278290152549744\n","val_recall: 0.20998036861419678\n","val_label_wise_macro_f1: 0.17285539209842682\n","val_subset_accuracy: 0.0677083358168602\n","val_subset_precision: 0.4214533865451813\n","val_subset_recall: 0.24001972377300262\n","val_subset_f1: 0.30445152521133423\n","val_auc: 0.8379818201065063\n","val_prc_auc: 0.47068265080451965\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8489 - binary_accuracy: 0.8845 - label_wise_accuracy: 0.8844 - label_wise_f1_score: 0.1825 - label_wise_macro_f1: 0.1831 - loss: 0.2849 - prc_auc: 0.4983 - precision: 0.6667 - recall: 0.2201 - subset_accuracy: 0.0855 - subset_f1: 0.3133 - subset_precision: 0.4244 - subset_recall: 0.2506 - val_auc: 0.8380 - val_binary_accuracy: 0.8786 - val_label_wise_accuracy: 0.8750 - val_label_wise_f1_score: 0.2350 - val_label_wise_macro_f1: 0.1729 - val_loss: 0.2963 - val_prc_auc: 0.4707 - val_precision: 0.6278 - val_recall: 0.2100 - val_subset_accuracy: 0.0677 - val_subset_f1: 0.3045 - val_subset_precision: 0.4215 - val_subset_recall: 0.2400\n","Epoch 14/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8513 - binary_accuracy: 0.8854 - label_wise_accuracy: 0.8851 - label_wise_f1_score: 0.1879 - label_wise_macro_f1: 0.1898 - loss: 0.2832 - prc_auc: 0.5031 - precision: 0.6705 - recall: 0.2300 - subset_accuracy: 0.0891 - subset_f1: 0.3262 - subset_precision: 0.4407 - subset_recall: 0.2615\n","Epoch 14: Validation Metrics:\n","loss: 0.28285714983940125\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.         0.         0.6666666\n"," 0.43478256 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.90625 0.78125 0.90625\n"," 0.59375 0.78125]\n","val_binary_accuracy: 0.8790177702903748\n","val_precision: 0.6287816762924194\n","val_recall: 0.2155873328447342\n","val_label_wise_macro_f1: 0.1786465048789978\n","val_subset_accuracy: 0.0684523805975914\n","val_subset_precision: 0.4278894066810608\n","val_subset_recall: 0.24496763944625854\n","val_subset_f1: 0.31011271476745605\n","val_auc: 0.8393768072128296\n","val_prc_auc: 0.4736846387386322\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - auc: 0.8513 - binary_accuracy: 0.8854 - label_wise_accuracy: 0.8851 - label_wise_f1_score: 0.1883 - label_wise_macro_f1: 0.1898 - loss: 0.2832 - prc_auc: 0.5031 - precision: 0.6705 - recall: 0.2299 - subset_accuracy: 0.0891 - subset_f1: 0.3262 - subset_precision: 0.4407 - subset_recall: 0.2615 - val_auc: 0.8394 - val_binary_accuracy: 0.8790 - val_label_wise_accuracy: 0.8766 - val_label_wise_f1_score: 0.2517 - val_label_wise_macro_f1: 0.1786 - val_loss: 0.2952 - val_prc_auc: 0.4737 - val_precision: 0.6288 - val_recall: 0.2156 - val_subset_accuracy: 0.0685 - val_subset_f1: 0.3101 - val_subset_precision: 0.4279 - val_subset_recall: 0.2450\n","Epoch 15/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8533 - binary_accuracy: 0.8857 - label_wise_accuracy: 0.8854 - label_wise_f1_score: 0.1925 - label_wise_macro_f1: 0.1948 - loss: 0.2816 - prc_auc: 0.5076 - precision: 0.6689 - recall: 0.2359 - subset_accuracy: 0.0906 - subset_f1: 0.3341 - subset_precision: 0.4479 - subset_recall: 0.2692\n","Epoch 15: Validation Metrics:\n","loss: 0.2813757658004761\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.         0.         0.6666666\n"," 0.43478256 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.90625 0.78125 0.90625\n"," 0.59375 0.78125]\n","val_binary_accuracy: 0.8796502351760864\n","val_precision: 0.6332263350486755\n","val_recall: 0.2211942821741104\n","val_label_wise_macro_f1: 0.18373773992061615\n","val_subset_accuracy: 0.0677083358168602\n","val_subset_precision: 0.436445951461792\n","val_subset_recall: 0.2500457465648651\n","val_subset_f1: 0.3166358470916748\n","val_auc: 0.8405364155769348\n","val_prc_auc: 0.4761143624782562\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8533 - binary_accuracy: 0.8857 - label_wise_accuracy: 0.8853 - label_wise_f1_score: 0.1928 - label_wise_macro_f1: 0.1948 - loss: 0.2816 - prc_auc: 0.5076 - precision: 0.6689 - recall: 0.2359 - subset_accuracy: 0.0906 - subset_f1: 0.3341 - subset_precision: 0.4479 - subset_recall: 0.2691 - val_auc: 0.8405 - val_binary_accuracy: 0.8797 - val_label_wise_accuracy: 0.8766 - val_label_wise_f1_score: 0.2517 - val_label_wise_macro_f1: 0.1837 - val_loss: 0.2943 - val_prc_auc: 0.4761 - val_precision: 0.6332 - val_recall: 0.2212 - val_subset_accuracy: 0.0677 - val_subset_f1: 0.3166 - val_subset_precision: 0.4364 - val_subset_recall: 0.2500\n","Epoch 16/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8552 - binary_accuracy: 0.8861 - label_wise_accuracy: 0.8858 - label_wise_f1_score: 0.1986 - label_wise_macro_f1: 0.2009 - loss: 0.2802 - prc_auc: 0.5118 - precision: 0.6693 - recall: 0.2420 - subset_accuracy: 0.0931 - subset_f1: 0.3424 - subset_precision: 0.4557 - subset_recall: 0.2769\n","Epoch 16: Validation Metrics:\n","loss: 0.2800242602825165\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.         0.         0.6666666\n"," 0.43478256 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.90625 0.78125 0.90625\n"," 0.59375 0.78125]\n","val_binary_accuracy: 0.8804687261581421\n","val_precision: 0.6387147307395935\n","val_recall: 0.22848331928253174\n","val_label_wise_macro_f1: 0.19173140823841095\n","val_subset_accuracy: 0.0721726194024086\n","val_subset_precision: 0.4471726715564728\n","val_subset_recall: 0.25933924317359924\n","val_subset_f1: 0.3269909620285034\n","val_auc: 0.8417329788208008\n","val_prc_auc: 0.4787224531173706\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8552 - binary_accuracy: 0.8861 - label_wise_accuracy: 0.8857 - label_wise_f1_score: 0.1989 - label_wise_macro_f1: 0.2009 - loss: 0.2802 - prc_auc: 0.5118 - precision: 0.6693 - recall: 0.2419 - subset_accuracy: 0.0931 - subset_f1: 0.3424 - subset_precision: 0.4556 - subset_recall: 0.2769 - val_auc: 0.8417 - val_binary_accuracy: 0.8805 - val_label_wise_accuracy: 0.8766 - val_label_wise_f1_score: 0.2517 - val_label_wise_macro_f1: 0.1917 - val_loss: 0.2935 - val_prc_auc: 0.4787 - val_precision: 0.6387 - val_recall: 0.2285 - val_subset_accuracy: 0.0722 - val_subset_f1: 0.3270 - val_subset_precision: 0.4472 - val_subset_recall: 0.2593\n","Epoch 17/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8570 - binary_accuracy: 0.8866 - label_wise_accuracy: 0.8865 - label_wise_f1_score: 0.2054 - label_wise_macro_f1: 0.2068 - loss: 0.2789 - prc_auc: 0.5157 - precision: 0.6708 - recall: 0.2481 - subset_accuracy: 0.0953 - subset_f1: 0.3495 - subset_precision: 0.4624 - subset_recall: 0.2835\n","Epoch 17: Validation Metrics:\n","loss: 0.2787858545780182\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.         0.         0.6666666\n"," 0.43478256 0.631579  ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.90625 0.78125 0.90625\n"," 0.59375 0.78125]\n","val_binary_accuracy: 0.8806176781654358\n","val_precision: 0.637269914150238\n","val_recall: 0.23296888172626495\n","val_label_wise_macro_f1: 0.19652478396892548\n","val_subset_accuracy: 0.0706845223903656\n","val_subset_precision: 0.4529390335083008\n","val_subset_recall: 0.26360514760017395\n","val_subset_f1: 0.33188506960868835\n","val_auc: 0.8426689505577087\n","val_prc_auc: 0.48098239302635193\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - auc: 0.8570 - binary_accuracy: 0.8866 - label_wise_accuracy: 0.8864 - label_wise_f1_score: 0.2056 - label_wise_macro_f1: 0.2067 - loss: 0.2789 - prc_auc: 0.5157 - precision: 0.6708 - recall: 0.2481 - subset_accuracy: 0.0953 - subset_f1: 0.3494 - subset_precision: 0.4624 - subset_recall: 0.2835 - val_auc: 0.8427 - val_binary_accuracy: 0.8806 - val_label_wise_accuracy: 0.8766 - val_label_wise_f1_score: 0.2517 - val_label_wise_macro_f1: 0.1965 - val_loss: 0.2928 - val_prc_auc: 0.4810 - val_precision: 0.6373 - val_recall: 0.2330 - val_subset_accuracy: 0.0707 - val_subset_f1: 0.3319 - val_subset_precision: 0.4529 - val_subset_recall: 0.2636\n","Epoch 18/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8584 - binary_accuracy: 0.8872 - label_wise_accuracy: 0.8870 - label_wise_f1_score: 0.2108 - label_wise_macro_f1: 0.2124 - loss: 0.2777 - prc_auc: 0.5194 - precision: 0.6734 - recall: 0.2550 - subset_accuracy: 0.0975 - subset_f1: 0.3591 - subset_precision: 0.4738 - subset_recall: 0.2919\n","Epoch 18: Validation Metrics:\n","loss: 0.2776413857936859\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.49999997 0.         0.6666666\n"," 0.49999994 0.6999999 ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.9375  0.78125 0.90625\n"," 0.625   0.8125 ]\n","val_binary_accuracy: 0.8807291388511658\n","val_precision: 0.6352059841156006\n","val_recall: 0.23773479461669922\n","val_label_wise_macro_f1: 0.20197054743766785\n","val_subset_accuracy: 0.0736607164144516\n","val_subset_precision: 0.4587673842906952\n","val_subset_recall: 0.27030155062675476\n","val_subset_f1: 0.3386678099632263\n","val_auc: 0.8435862064361572\n","val_prc_auc: 0.4830183684825897\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8584 - binary_accuracy: 0.8872 - label_wise_accuracy: 0.8869 - label_wise_f1_score: 0.2112 - label_wise_macro_f1: 0.2123 - loss: 0.2777 - prc_auc: 0.5194 - precision: 0.6734 - recall: 0.2550 - subset_accuracy: 0.0975 - subset_f1: 0.3591 - subset_precision: 0.4738 - subset_recall: 0.2919 - val_auc: 0.8436 - val_binary_accuracy: 0.8807 - val_label_wise_accuracy: 0.8813 - val_label_wise_f1_score: 0.2833 - val_label_wise_macro_f1: 0.2020 - val_loss: 0.2922 - val_prc_auc: 0.4830 - val_precision: 0.6352 - val_recall: 0.2377 - val_subset_accuracy: 0.0737 - val_subset_f1: 0.3387 - val_subset_precision: 0.4588 - val_subset_recall: 0.2703\n","Epoch 19/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8598 - binary_accuracy: 0.8875 - label_wise_accuracy: 0.8873 - label_wise_f1_score: 0.2143 - label_wise_macro_f1: 0.2156 - loss: 0.2766 - prc_auc: 0.5227 - precision: 0.6738 - recall: 0.2592 - subset_accuracy: 0.0987 - subset_f1: 0.3641 - subset_precision: 0.4795 - subset_recall: 0.2964\n","Epoch 19: Validation Metrics:\n","loss: 0.2765732705593109\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.49999997 0.         0.6666666\n"," 0.49999994 0.6999999 ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.9375  0.78125 0.90625\n"," 0.625   0.8125 ]\n","val_binary_accuracy: 0.8812498450279236\n","val_precision: 0.6379690766334534\n","val_recall: 0.2430613934993744\n","val_label_wise_macro_f1: 0.20715758204460144\n","val_subset_accuracy: 0.0744047611951828\n","val_subset_precision: 0.4638516902923584\n","val_subset_recall: 0.2751874625682831\n","val_subset_f1: 0.3440476953983307\n","val_auc: 0.844333291053772\n","val_prc_auc: 0.4849252998828888\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8598 - binary_accuracy: 0.8875 - label_wise_accuracy: 0.8872 - label_wise_f1_score: 0.2147 - label_wise_macro_f1: 0.2156 - loss: 0.2766 - prc_auc: 0.5227 - precision: 0.6738 - recall: 0.2591 - subset_accuracy: 0.0987 - subset_f1: 0.3641 - subset_precision: 0.4794 - subset_recall: 0.2963 - val_auc: 0.8443 - val_binary_accuracy: 0.8812 - val_label_wise_accuracy: 0.8813 - val_label_wise_f1_score: 0.2833 - val_label_wise_macro_f1: 0.2072 - val_loss: 0.2917 - val_prc_auc: 0.4849 - val_precision: 0.6380 - val_recall: 0.2431 - val_subset_accuracy: 0.0744 - val_subset_f1: 0.3440 - val_subset_precision: 0.4639 - val_subset_recall: 0.2752\n","Epoch 20/20\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.8612 - binary_accuracy: 0.8880 - label_wise_accuracy: 0.8878 - label_wise_f1_score: 0.2185 - label_wise_macro_f1: 0.2195 - loss: 0.2756 - prc_auc: 0.5260 - precision: 0.6766 - recall: 0.2627 - subset_accuracy: 0.0981 - subset_f1: 0.3691 - subset_precision: 0.4870 - subset_recall: 0.3000\n","Epoch 20: Validation Metrics:\n","loss: 0.2755753695964813\n","val_label_wise_f1_score: [0.         0.         0.         1.         0.         0.\n"," 1.         0.         0.         0.         0.         0.\n"," 0.29999995 1.         0.         0.49999997 0.         0.6666666\n"," 0.49999994 0.6999999 ]\n","val_label_wise_accuracy: [0.9375  0.65625 0.9375  1.      0.875   0.96875 1.      0.96875 0.96875\n"," 0.96875 0.90625 0.875   0.5625  1.      0.9375  0.9375  0.78125 0.90625\n"," 0.625   0.8125 ]\n","val_binary_accuracy: 0.8812870979309082\n","val_precision: 0.6366279125213623\n","val_recall: 0.24558451771736145\n","val_label_wise_macro_f1: 0.2105560004711151\n","val_subset_accuracy: 0.075148805975914\n","val_subset_precision: 0.465711772441864\n","val_subset_recall: 0.2798439562320709\n","val_subset_f1: 0.3483337163925171\n","val_auc: 0.8449172377586365\n","val_prc_auc: 0.4865277409553528\n","\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - auc: 0.8612 - binary_accuracy: 0.8880 - label_wise_accuracy: 0.8877 - label_wise_f1_score: 0.2189 - label_wise_macro_f1: 0.2195 - loss: 0.2756 - prc_auc: 0.5259 - precision: 0.6766 - recall: 0.2627 - subset_accuracy: 0.0981 - subset_f1: 0.3690 - subset_precision: 0.4869 - subset_recall: 0.3000 - val_auc: 0.8449 - val_binary_accuracy: 0.8813 - val_label_wise_accuracy: 0.8813 - val_label_wise_f1_score: 0.2833 - val_label_wise_macro_f1: 0.2106 - val_loss: 0.2912 - val_prc_auc: 0.4865 - val_precision: 0.6366 - val_recall: 0.2456 - val_subset_accuracy: 0.0751 - val_subset_f1: 0.3483 - val_subset_precision: 0.4657 - val_subset_recall: 0.2798\n","\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - auc: 0.7321 - binary_accuracy: 0.9055 - label_wise_accuracy: 0.9053 - label_wise_f1_score: 0.1882 - label_wise_macro_f1: 0.1986 - loss: 0.2770 - prc_auc: 0.2517 - precision: 0.3624 - recall: 0.2334 - subset_accuracy: 0.0559 - subset_f1: 0.2500 - subset_precision: 0.2495 - subset_recall: 0.2530\n","Evaluation Metrics:\n","Loss: 0.27720117568969727\n","Label F1 Scores: [0.         0.         0.         0.         0.39999995 0.\n"," 0.8571428  0.         0.         0.         0.         0.\n"," 0.2222222  0.39999995 0.         0.         0.         0.\n"," 0.         0.2222222 ]\n","Label Accuracies: [0.875   0.875   0.875   0.8125  0.90625 0.84375 0.96875 0.9375  0.875\n"," 0.9375  0.96875 0.8125  0.78125 0.90625 0.96875 0.90625 0.9375  0.9375\n"," 0.8125  0.78125]\n","Accuracy: 0.9060096144676208\n","Precision: 0.35826295614242554\n","Recall: 0.22347629070281982\n","F1 Score: 0.19144520163536072\n","Subset Accuracy: 0.06370192021131516\n","Subset Precision: 0.23756009340286255\n","Subset Recall: 0.23597757518291473\n","Subset F1: 0.23493793606758118\n","AUC: 0.7281604409217834\n","PRC AUC: 0.24436137080192566\n"]}]},{"cell_type":"markdown","source":["SINGLE MODEL CLASSIFIER - EVALUATE BASE MODELS"],"metadata":{"id":"ZpieTwlSJNoy"}},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS1 = 5\n","NUMBER_OF_TAGS2 = 10\n","NUMBER_OF_TAGS3 = 20\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","# # #####################################################################################################################################################\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS1,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS1}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS2,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS2}_TESTING_DATASET_PATH']\n","  )\n","\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS3,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS3}_TESTING_DATASET_PATH']\n","  )\n","\n","\n","from google.colab import runtime\n","runtime.unassign()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4afcb99348e4455eb657df6dc90b8d55","043ba573883243ed84eae5c122cadfc8","46637e391a644e95a31f6c4ffea482b4","1cece33f709f4968969431a001107471","6e03178874a14cacb69ee820cae9f7eb","6206f9354227400aaa338c949f5ed6d9","82252d37f88f4ce899efc4a66eb00ada","10831fd8172e4ca49906e38d22019ac0","7e4394007b424a1fa1ff42b0cdb9d2a3","eaaa7151dcf54e03b04bd540401c913a","245d0fa4859f4b9bbd2459741cd6b8fc","b6dcc5e1172e4b269320196b412f8dd2","bd811fc2fec045a5a7478b4944e76d47","423f990e1fa1454685046cb05f124582","5a07a63a06d541b796c685101a4d5bef","bf339a44ac38425f9f14368f08279c34","2976cda4e4ee4ac29c75f23672caefdc","9172b438e6e14022bd3a6baa963cf1c0","aeda576f6b3c47e7b50f42cf32e1cf44","f8555f5b6b8548ef80d4350b0ab75266","e957b33664fa427ba33dd7afb899c2b0","de1c78153912471e9435026330b7cf51","0dd0a7e565dd4faa96b4445e262961a9","1ca3a169545c46ff883273708acae34b","c4064cc20e0e4b7ab20b85feda332b93","98e7045b794c44be87d2ed6468e9fe37","00286c5b428d46cf9a9484049c403645","29752e29de414966896999ff803e247a","9b82c1298b5d47a480bf8326cd60dc52","f5dbb4bc659b4f6484edcb73ee6740c4","40c099ce79d14b3781ad2981081c30fe","c7181bd0612c44febc5879a9287dc36c","9e1f8babcc31473f8695169a9e428bb0","81462ae1f1e246d08e91a0c39903bab3","efba3005f7534a45b74cde73ed808866","b2a2a2675eb346fdb1d3493ac176f66c","9da7a9aadb414c0d91d5a5f8c699e4a4","e6ef7ca8cc3f4b36b60458604a8a8aa6","361fd45e55f444fd8c6f55a36a260226","df32a02e89564099a6c24032172c31cd","2866345a6c304fd18be9c81767a422a2","340951ee2ee84154881538efd6c2b25a","41d78e010b0048e9a231b1ac5ae29298","9b6766513f484dc39963f4ba5b10d968","496250acd5214604aaf5f1addf57af84","6397a36de43b43aa956aed411c458802","8ee51089fa224bacafbb333651cd9d2e","d9ca8ed4e0f642e5984793ff2ad38fe3","792784c6717847b392179ef5a4253ba0","0765d4ccc95b42dd8f325f6c4143d9af","ec02d3b7b91d461e8ca2a3d76f6c5eef","6b43ef958e104718ae3acb5e4f5438e2","cce8b056a5c24e5e864975047f43821e","9d132da83c364428a9aef93cfe521652","6b015832db32471098fb316fa3776a80","5f5092bedaa4449ba25e93e1ca84f499","209c5b062cb44907829c22d73c456662","64789556d8a74b759be291ba6d95b6c9","f289bc83dcc14017a2d619741e3f13f6","b27f549196654a44922b8a181bcb06d7","97228d11746c4fe181ccc9ca0aea07a5","ba41f1eddf5f4848b66a0aef6ceeaf1a","a3951336c50143a2b6196e0b53b017a4","1dc7310ce2fb40adbdab07580499e345","1b773383be994c59b31e5a5e0a7cf9e4","719a108a45d944daaa220a5b817e4a81"]},"id":"eTOBn8WWI9P3","executionInfo":{"status":"ok","timestamp":1740605881469,"user_tz":-120,"elapsed":120967,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"f7969800-308d-4790-9d9d-5d288d1dba0b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4afcb99348e4455eb657df6dc90b8d55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6dcc5e1172e4b269320196b412f8dd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd0a7e565dd4faa96b4445e262961a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81462ae1f1e246d08e91a0c39903bab3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496250acd5214604aaf5f1addf57af84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f5092bedaa4449ba25e93e1ca84f499"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 107ms/step - auc: 0.4986 - binary_accuracy: 0.4179 - label_wise_accuracy: 0.4192 - label_wise_f1_score: 0.4181 - label_wise_macro_f1: 0.4138 - loss: 0.7106 - prc_auc: 0.3305 - precision: 0.3145 - recall: 0.6721 - subset_accuracy: 0.0069 - subset_f1: 0.4192 - subset_precision: 0.3071 - subset_recall: 0.6649\n","Evaluation Metrics:\n","Loss: 0.7116167545318604\n","Label F1 Scores: [0.5333333  0.56410253 0.24999996 0.17647056 0.48648646]\n","Label Accuracies: [0.5625  0.46875 0.4375  0.125   0.40625]\n","Accuracy: 0.4197115898132324\n","Precision: 0.3167930245399475\n","Recall: 0.6806515455245972\n","F1 Score: 0.41853880882263184\n","Subset Accuracy: 0.008814102970063686\n","Subset Precision: 0.31264689564704895\n","Subset Recall: 0.6805021166801453\n","Subset F1: 0.42700380086898804\n","AUC: 0.4918302893638611\n","PRC AUC: 0.32151028513908386\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - auc: 0.4804 - binary_accuracy: 0.4321 - label_wise_accuracy: 0.4653 - label_wise_f1_score: 0.3525 - label_wise_macro_f1: 0.2924 - loss: 0.7063 - prc_auc: 0.2149 - precision: 0.2112 - recall: 0.5698 - subset_accuracy: 0.0000e+00 - subset_f1: 0.3071 - subset_precision: 0.2099 - subset_recall: 0.5770\n","Evaluation Metrics:\n","Loss: 0.7062082290649414\n","Label F1 Scores: [0.32258058 0.33333328 0.21052629 0.21428569 0.        ]\n","Label Accuracies: [0.34375 0.375   0.53125 0.3125  0.5    ]\n","Accuracy: 0.435101717710495\n","Precision: 0.2120807021856308\n","Recall: 0.5749588012695312\n","F1 Score: 0.29381313920021057\n","Subset Accuracy: 0.0\n","Subset Precision: 0.210720956325531\n","Subset Recall: 0.5807672142982483\n","Subset F1: 0.30845826864242554\n","AUC: 0.48439353704452515\n","PRC AUC: 0.2154168039560318\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - auc: 0.4886 - binary_accuracy: 0.4824 - label_wise_accuracy: 0.4751 - label_wise_f1_score: 0.3166 - label_wise_macro_f1: 0.1836 - loss: 0.6993 - prc_auc: 0.1364 - precision: 0.1341 - recall: 0.4979 - subset_accuracy: 0.0000e+00 - subset_f1: 0.2110 - subset_precision: 0.1338 - subset_recall: 0.5030\n","Evaluation Metrics:\n","Loss: 0.698846697807312\n","Label F1 Scores: [0.         0.3870967  0.4324324  0.41666663 0.4137931 ]\n","Label Accuracies: [0.59375 0.40625 0.34375 0.5625  0.46875]\n","Accuracy: 0.4830966293811798\n","Precision: 0.1368008852005005\n","Recall: 0.49974900484085083\n","F1 Score: 0.18629659712314606\n","Subset Accuracy: 0.0\n","Subset Precision: 0.13565194606781006\n","Subset Recall: 0.5058000683784485\n","Subset F1: 0.21354056894779205\n","AUC: 0.48941248655319214\n","PRC AUC: 0.1400294303894043\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - auc: 0.4975 - binary_accuracy: 0.4089 - label_wise_accuracy: 0.4156 - label_wise_f1_score: 0.2963 - label_wise_macro_f1: 0.2920 - loss: 0.7141 - prc_auc: 0.1996 - precision: 0.2011 - recall: 0.6581 - subset_accuracy: 0.0108 - subset_f1: 0.3074 - subset_precision: 0.2007 - subset_recall: 0.6581\n","Evaluation Metrics:\n","Loss: 0.7132693529129028\n","Label F1 Scores: [0.19047616 0.5142857  0.28571424 0.19354835 0.48484847]\n","Label Accuracies: [0.46875 0.46875 0.6875  0.21875 0.46875]\n","Accuracy: 0.41420453786849976\n","Precision: 0.20349344611167908\n","Recall: 0.6619318127632141\n","F1 Score: 0.29513561725616455\n","Subset Accuracy: 0.009469697251915932\n","Subset Precision: 0.20277780294418335\n","Subset Recall: 0.6619317531585693\n","Subset F1: 0.3102041482925415\n","AUC: 0.5045554637908936\n","PRC AUC: 0.2012413889169693\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - auc: 0.4886 - binary_accuracy: 0.4676 - label_wise_accuracy: 0.4897 - label_wise_f1_score: 0.1589 - label_wise_macro_f1: 0.1547 - loss: 0.6984 - prc_auc: 0.1039 - precision: 0.0993 - recall: 0.4993 - subset_accuracy: 0.0000e+00 - subset_f1: 0.1627 - subset_precision: 0.0976 - subset_recall: 0.4943\n","Evaluation Metrics:\n","Loss: 0.6987931728363037\n","Label F1 Scores: [0.14285713 0.22222221 0.         0.24       0.21428569]\n","Label Accuracies: [0.625   0.5625  0.6875  0.40625 0.3125 ]\n","Accuracy: 0.4684374928474426\n","Precision: 0.10027311742305756\n","Recall: 0.5114427804946899\n","F1 Score: 0.15718163549900055\n","Subset Accuracy: 0.0\n","Subset Precision: 0.09943203628063202\n","Subset Recall: 0.512499988079071\n","Subset F1: 0.16633957624435425\n","AUC: 0.493078351020813\n","PRC AUC: 0.10512066632509232\n","Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - auc: 0.5069 - binary_accuracy: 0.4949 - label_wise_accuracy: 0.4877 - label_wise_f1_score: 0.1298 - label_wise_macro_f1: 0.1294 - loss: 0.6947 - prc_auc: 0.0787 - precision: 0.0790 - recall: 0.5113 - subset_accuracy: 0.0000e+00 - subset_f1: 0.1345 - subset_precision: 0.0783 - subset_recall: 0.4795\n","Evaluation Metrics:\n","Loss: 0.6948614716529846\n","Label F1 Scores: [0.         0.         0.19999997 0.         0.08695649]\n","Label Accuracies: [0.78125 0.4375  0.25    0.5     0.34375]\n","Accuracy: 0.49717551469802856\n","Precision: 0.08134142309427261\n","Recall: 0.5158371329307556\n","F1 Score: 0.13439366221427917\n","Subset Accuracy: 0.0\n","Subset Precision: 0.08103073388338089\n","Subset Recall: 0.4889824092388153\n","Subset F1: 0.13890193402767181\n","AUC: 0.511749267578125\n","PRC AUC: 0.08091290295124054\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab75f67eb42b4a1ca21d6468049a3a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0b2bf7c41854086a868c6425482130a","IPY_MODEL_8316f4f113cc448bb3499124c39f211a","IPY_MODEL_035b31cd9a8d4ea6919b7b86f6d0b615"],"layout":"IPY_MODEL_7943ae8731234fa0836a59cf7e4244f3"}},"a0b2bf7c41854086a868c6425482130a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2240f0013694f07bed47fe75a5a1641","placeholder":"​","style":"IPY_MODEL_11589f1d66dd451d970c79ce42cb7171","value":"tokenizer_config.json: 100%"}},"8316f4f113cc448bb3499124c39f211a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdab0baa964e4b2fb906b35a20902ddc","max":352,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb3894688cd04c88bdf92501441b60e2","value":352}},"035b31cd9a8d4ea6919b7b86f6d0b615":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b178e852a15e46228594ced4cf8aa27e","placeholder":"​","style":"IPY_MODEL_cd5c5e3f4508453ea82ff0fc16e27296","value":" 352/352 [00:00&lt;00:00, 42.4kB/s]"}},"7943ae8731234fa0836a59cf7e4244f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2240f0013694f07bed47fe75a5a1641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11589f1d66dd451d970c79ce42cb7171":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdab0baa964e4b2fb906b35a20902ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3894688cd04c88bdf92501441b60e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b178e852a15e46228594ced4cf8aa27e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd5c5e3f4508453ea82ff0fc16e27296":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3055ea4e48cb4418b8f6504cc8c08467":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4183705c5384ce88d098138701ff430","IPY_MODEL_3ac81fc0f037454f85d5ba838e4af86f","IPY_MODEL_d48be92e49844ca28a2e8043cafdb115"],"layout":"IPY_MODEL_1545bbd1a8464908a0965b541726955e"}},"d4183705c5384ce88d098138701ff430":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9676e2ff41fb4b5c85b5c2d0c1456140","placeholder":"​","style":"IPY_MODEL_ea3aa6ac78be4c39b7f66a55c4e5428f","value":"vocab.txt: 100%"}},"3ac81fc0f037454f85d5ba838e4af86f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42ec6beaa68b438f9d4b61c149d49e2f","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_206b60fa24504fed99b79cc57951fe41","value":231508}},"d48be92e49844ca28a2e8043cafdb115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c168639624c64cc6a23227abf2815f5f","placeholder":"​","style":"IPY_MODEL_d769cfc2ebb4448cb81d84604ce35c00","value":" 232k/232k [00:00&lt;00:00, 544kB/s]"}},"1545bbd1a8464908a0965b541726955e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9676e2ff41fb4b5c85b5c2d0c1456140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea3aa6ac78be4c39b7f66a55c4e5428f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42ec6beaa68b438f9d4b61c149d49e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"206b60fa24504fed99b79cc57951fe41":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c168639624c64cc6a23227abf2815f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d769cfc2ebb4448cb81d84604ce35c00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fd716c8298246818220c3d03d4c85d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4de9a757f6e74d0195bf319c2e893c36","IPY_MODEL_f5d816e9a3834a7fadcea9e7aedacf93","IPY_MODEL_c738430dec2240eeb761b21b7540a45d"],"layout":"IPY_MODEL_df694098c89a49cd99732b52466278f3"}},"4de9a757f6e74d0195bf319c2e893c36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d66a179586f459bbb47a32de58f1a38","placeholder":"​","style":"IPY_MODEL_2af30a8b517c4171826296b82bf11db0","value":"tokenizer.json: 100%"}},"f5d816e9a3834a7fadcea9e7aedacf93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d8d7d944c644e81a74c4d2b5284855f","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_887b10734cf54c93a3a753e9cba86175","value":466247}},"c738430dec2240eeb761b21b7540a45d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6acba668429e440ebfeed86b1b991f68","placeholder":"​","style":"IPY_MODEL_07c9d7d2cf994ab09fe1985b3d611041","value":" 466k/466k [00:00&lt;00:00, 1.12MB/s]"}},"df694098c89a49cd99732b52466278f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d66a179586f459bbb47a32de58f1a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af30a8b517c4171826296b82bf11db0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d8d7d944c644e81a74c4d2b5284855f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"887b10734cf54c93a3a753e9cba86175":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6acba668429e440ebfeed86b1b991f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c9d7d2cf994ab09fe1985b3d611041":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c7ef7385dc642e28088fbc953bcc1a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_44c836770f0846c698f9a02023b2a7f1","IPY_MODEL_5b317a4e47554fd1a2e18bde011a140a","IPY_MODEL_f08e2bb04ca04bea92daee838df0c279"],"layout":"IPY_MODEL_b609d99de499468c89dba07fbe8d5fdb"}},"44c836770f0846c698f9a02023b2a7f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3385ae4046c74d02b71def42296972e2","placeholder":"​","style":"IPY_MODEL_6f26c09acb93419aa497867f971a6a13","value":"special_tokens_map.json: 100%"}},"5b317a4e47554fd1a2e18bde011a140a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdb80f290b664a3b84225de50ac57131","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e7751f1290c46a395562b059e337444","value":112}},"f08e2bb04ca04bea92daee838df0c279":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a104ffe21dfb4fc2863c6955e258337b","placeholder":"​","style":"IPY_MODEL_d50e75c126ee46f2af3197950fe4feb4","value":" 112/112 [00:00&lt;00:00, 15.1kB/s]"}},"b609d99de499468c89dba07fbe8d5fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3385ae4046c74d02b71def42296972e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f26c09acb93419aa497867f971a6a13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdb80f290b664a3b84225de50ac57131":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e7751f1290c46a395562b059e337444":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a104ffe21dfb4fc2863c6955e258337b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d50e75c126ee46f2af3197950fe4feb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b8871e38c44ee08f79919ecf2d4a59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25b01b07c03e4b1fb67f83f2572831bc","IPY_MODEL_47afe335d23542c8ba9d24f5511b95e3","IPY_MODEL_b185cc64f5814d8588c3d0c7e5973b9d"],"layout":"IPY_MODEL_b877e913bc2b4a878b65fc89f71f79bf"}},"25b01b07c03e4b1fb67f83f2572831bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0326e04166894e91b65de74a355bd6bb","placeholder":"​","style":"IPY_MODEL_2d28ebfb09be4445bd8876c386b4a08f","value":"tokenizer_config.json: 100%"}},"47afe335d23542c8ba9d24f5511b95e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_526cd94d7b6745338a677a35ec71267a","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce8c054496504d8cace349f2808f6177","value":363}},"b185cc64f5814d8588c3d0c7e5973b9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97727e59cc754dd9a0caa86724397204","placeholder":"​","style":"IPY_MODEL_7ab4b2019cec467c94c8345a5b0d483c","value":" 363/363 [00:00&lt;00:00, 42.2kB/s]"}},"b877e913bc2b4a878b65fc89f71f79bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0326e04166894e91b65de74a355bd6bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d28ebfb09be4445bd8876c386b4a08f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"526cd94d7b6745338a677a35ec71267a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce8c054496504d8cace349f2808f6177":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97727e59cc754dd9a0caa86724397204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab4b2019cec467c94c8345a5b0d483c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bdd1c45ba35483eb7ffc9be26bd2cbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6686d1800aa4c0eac2ce3119b03f9ad","IPY_MODEL_dad8bf8d257047eaad0a259a59cb8e65","IPY_MODEL_47ad0a3fe8b84694b315c96ff6ea7272"],"layout":"IPY_MODEL_61f3da3002e84c8eb47446cb32d8643d"}},"e6686d1800aa4c0eac2ce3119b03f9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0e77bd67bd4b318f49c5bfc2f2044c","placeholder":"​","style":"IPY_MODEL_e109930020a8413fac4029584f7645a7","value":"vocab.txt: 100%"}},"dad8bf8d257047eaad0a259a59cb8e65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8977af5eabc4fb5aca438b480224fd2","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc200d368bfd4485b05d28df01875927","value":231536}},"47ad0a3fe8b84694b315c96ff6ea7272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9208c58128cb4d65897b6f1f3b47f6f4","placeholder":"​","style":"IPY_MODEL_c0fe27c84eb6404f91cf62250364387d","value":" 232k/232k [00:00&lt;00:00, 2.44MB/s]"}},"61f3da3002e84c8eb47446cb32d8643d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef0e77bd67bd4b318f49c5bfc2f2044c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e109930020a8413fac4029584f7645a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8977af5eabc4fb5aca438b480224fd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc200d368bfd4485b05d28df01875927":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9208c58128cb4d65897b6f1f3b47f6f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0fe27c84eb6404f91cf62250364387d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff02d35d2044f798525c220a5da720e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74771f365e464c16939d72c95fb25092","IPY_MODEL_45481bd363f24744a8c4a99746144051","IPY_MODEL_a3599526d1fc44ebad1328dc9b06ccf7"],"layout":"IPY_MODEL_ec14629366fe4c5bb18cdd300df4ada0"}},"74771f365e464c16939d72c95fb25092":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94254415e22247d7b3abb092fcf8c3f3","placeholder":"​","style":"IPY_MODEL_3343db48619d469bbb23a355af1de335","value":"tokenizer.json: 100%"}},"45481bd363f24744a8c4a99746144051":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_268322c174bc4aa6bdbfe5dc99ee6f46","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54612f124d23411e86a053b4212b2b78","value":466021}},"a3599526d1fc44ebad1328dc9b06ccf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67bdf0d99eb5425c8825344b1371c06f","placeholder":"​","style":"IPY_MODEL_7b8a38f18cf74604bd4fe71a764e2fa7","value":" 466k/466k [00:00&lt;00:00, 11.9MB/s]"}},"ec14629366fe4c5bb18cdd300df4ada0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94254415e22247d7b3abb092fcf8c3f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3343db48619d469bbb23a355af1de335":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"268322c174bc4aa6bdbfe5dc99ee6f46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54612f124d23411e86a053b4212b2b78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67bdf0d99eb5425c8825344b1371c06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b8a38f18cf74604bd4fe71a764e2fa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98f4727015544075b51249ec17574341":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fbb0a51f33e4391b542e6dde45ce263","IPY_MODEL_79c8e244a34b4e438cfeaecb8ba06482","IPY_MODEL_4a8c51ad59ef4373bd4710e554adab6a"],"layout":"IPY_MODEL_9d0d770bfeec4f20abe88cc05f15cca4"}},"8fbb0a51f33e4391b542e6dde45ce263":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_540f2a8ea1c04c458240e87afe4eeab1","placeholder":"​","style":"IPY_MODEL_d6d9c7356f8143e2b927b5089a6d2a0e","value":"special_tokens_map.json: 100%"}},"79c8e244a34b4e438cfeaecb8ba06482":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2212afac6cdc4e35ae3a3c2de35b35de","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_391f10a76c1a4859a06f7541b85b5aea","value":239}},"4a8c51ad59ef4373bd4710e554adab6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8cf696f82f84c8abdb09a694016f5d5","placeholder":"​","style":"IPY_MODEL_bd4ede6526eb4392b10e6967dba2dbea","value":" 239/239 [00:00&lt;00:00, 30.3kB/s]"}},"9d0d770bfeec4f20abe88cc05f15cca4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"540f2a8ea1c04c458240e87afe4eeab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d9c7356f8143e2b927b5089a6d2a0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2212afac6cdc4e35ae3a3c2de35b35de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"391f10a76c1a4859a06f7541b85b5aea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8cf696f82f84c8abdb09a694016f5d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd4ede6526eb4392b10e6967dba2dbea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f48aa799028f45deac82474f037542c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e50b43d63bc84f199942409c2f379918","IPY_MODEL_1e4d76a58a694e648c1d11a0ffccff4e","IPY_MODEL_b75d6bfcb8674253ada5db33deae5cfc"],"layout":"IPY_MODEL_69f9649a66f943d584d713392bdf6987"}},"e50b43d63bc84f199942409c2f379918":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea595275a75843ea8673881c59f4be6f","placeholder":"​","style":"IPY_MODEL_ee42fa6cf7084a7aade563f562e3408c","value":"config.json: 100%"}},"1e4d76a58a694e648c1d11a0ffccff4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ec2ddf240bb423ebbd032613bf6ddce","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1380749860c2431e987d14be76d36765","value":571}},"b75d6bfcb8674253ada5db33deae5cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c382fcb3372249528d23772146672044","placeholder":"​","style":"IPY_MODEL_a5b57911e7834bc4967bb7eec9aadcf3","value":" 571/571 [00:00&lt;00:00, 66.9kB/s]"}},"69f9649a66f943d584d713392bdf6987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea595275a75843ea8673881c59f4be6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee42fa6cf7084a7aade563f562e3408c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ec2ddf240bb423ebbd032613bf6ddce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1380749860c2431e987d14be76d36765":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c382fcb3372249528d23772146672044":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5b57911e7834bc4967bb7eec9aadcf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a69a26a2c5bf42b29634fb52df795b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc6c522d33a24af28956ce964b1f4c39","IPY_MODEL_a910f41247834518986fc052aa950129","IPY_MODEL_7255e31b9f0c4d5d8e4c66f168ac4614"],"layout":"IPY_MODEL_86044863b4b6435d9e9dc7f0b631dbb6"}},"cc6c522d33a24af28956ce964b1f4c39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ad4eb12cf40492aa9f54ed8708080fd","placeholder":"​","style":"IPY_MODEL_f1e9944e249b4acd99dfd2c68da78c1d","value":"model.safetensors: 100%"}},"a910f41247834518986fc052aa950129":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_933990dbd74b45bba720bfd96009b772","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_febc9be8b02340ba9a74e7a1af347a83","value":437971872}},"7255e31b9f0c4d5d8e4c66f168ac4614":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e59669e37824834a1cceea83509eb1f","placeholder":"​","style":"IPY_MODEL_f18274d74cec49708999fe4d3043779a","value":" 438M/438M [00:01&lt;00:00, 236MB/s]"}},"86044863b4b6435d9e9dc7f0b631dbb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ad4eb12cf40492aa9f54ed8708080fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e9944e249b4acd99dfd2c68da78c1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"933990dbd74b45bba720bfd96009b772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"febc9be8b02340ba9a74e7a1af347a83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e59669e37824834a1cceea83509eb1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18274d74cec49708999fe4d3043779a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cd105141f3a4c92995f2748abda07e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_854f1811f5e8401aa668b123db75f502","IPY_MODEL_0a7cdb4546044deebd24ed57e5161dd5","IPY_MODEL_ff98d952924547dc984a6adf1ed86eac"],"layout":"IPY_MODEL_2305cdbccec84568aa4637acc011d4bb"}},"854f1811f5e8401aa668b123db75f502":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_998a6234106c43728f6260e6dba7bbb0","placeholder":"​","style":"IPY_MODEL_01931057bc2c49c18fe13e0056f154fd","value":"tokenizer_config.json: 100%"}},"0a7cdb4546044deebd24ed57e5161dd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80b8b549ea984dc9b8945d1346a39751","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8b6764ff11b4c49b414d2be8e1be055","value":363}},"ff98d952924547dc984a6adf1ed86eac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab2ca99f2334dc787c2d6a1980bdb5a","placeholder":"​","style":"IPY_MODEL_3339e8654acf40ff854295e6a1fb71c5","value":" 363/363 [00:00&lt;00:00, 42.5kB/s]"}},"2305cdbccec84568aa4637acc011d4bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998a6234106c43728f6260e6dba7bbb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01931057bc2c49c18fe13e0056f154fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80b8b549ea984dc9b8945d1346a39751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b6764ff11b4c49b414d2be8e1be055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ab2ca99f2334dc787c2d6a1980bdb5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3339e8654acf40ff854295e6a1fb71c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"798c6b5b49ec4db78d2a9e668b8dd43f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b4232f269534253ab0667e14705b4e8","IPY_MODEL_b724ee576f084dbfb176245c7e5e437c","IPY_MODEL_bc3035798d1341f4a96a689c0f9ae9df"],"layout":"IPY_MODEL_8d641cee244b4d9280b655887e9487f7"}},"7b4232f269534253ab0667e14705b4e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ed1c143f8944f0e8d466ac82b7cf105","placeholder":"​","style":"IPY_MODEL_d135cb720f4e49f19b6bc405b1a47b0f","value":"vocab.txt: 100%"}},"b724ee576f084dbfb176245c7e5e437c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1620f24b0854c8daadd0b17393034a5","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2044dac6d9e6424f9e7fe44fb30c8210","value":231536}},"bc3035798d1341f4a96a689c0f9ae9df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edbe0dd553ed47c3a058c11d643b6ca6","placeholder":"​","style":"IPY_MODEL_79f85022cf0043d584c253130bc74738","value":" 232k/232k [00:00&lt;00:00, 4.89MB/s]"}},"8d641cee244b4d9280b655887e9487f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed1c143f8944f0e8d466ac82b7cf105":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d135cb720f4e49f19b6bc405b1a47b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1620f24b0854c8daadd0b17393034a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2044dac6d9e6424f9e7fe44fb30c8210":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edbe0dd553ed47c3a058c11d643b6ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f85022cf0043d584c253130bc74738":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01712d5da64b4670aa00b4a2bf1ba1cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_287b2c996ad14a2cbbc9424ace66ed1a","IPY_MODEL_fc6b1578cd9a43c89aaef26cc1409d34","IPY_MODEL_d04ade88a3534b02b253b70a37d74fff"],"layout":"IPY_MODEL_ac3ca46ebaf143aaa859ef9aaa0b9e4a"}},"287b2c996ad14a2cbbc9424ace66ed1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e01e0ce35a0406b853d45821128f444","placeholder":"​","style":"IPY_MODEL_ddb34a307bbb48c8adda9af468aac073","value":"tokenizer.json: 100%"}},"fc6b1578cd9a43c89aaef26cc1409d34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_310357abc60649f0b2fdbe77d02b29c3","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed8373e0ad20462481c3285eceb7f871","value":466021}},"d04ade88a3534b02b253b70a37d74fff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bd71294ce8c47cfa09ad1cbc0d896e8","placeholder":"​","style":"IPY_MODEL_db90aecf04ce4f9484735601b59a52ea","value":" 466k/466k [00:00&lt;00:00, 24.0MB/s]"}},"ac3ca46ebaf143aaa859ef9aaa0b9e4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e01e0ce35a0406b853d45821128f444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddb34a307bbb48c8adda9af468aac073":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"310357abc60649f0b2fdbe77d02b29c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed8373e0ad20462481c3285eceb7f871":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bd71294ce8c47cfa09ad1cbc0d896e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db90aecf04ce4f9484735601b59a52ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59165906e52d403c91e53abe84c1d365":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fff31088d2f14627ae4263556082b1dd","IPY_MODEL_d746e14f65424ac09f0d692372f5dadf","IPY_MODEL_184f548b04fe4bb1b273e9e809280f5d"],"layout":"IPY_MODEL_54e4a35d2a0043f78653e4c67f6a76ee"}},"fff31088d2f14627ae4263556082b1dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b90916f3d604f5b83d69497eba9541d","placeholder":"​","style":"IPY_MODEL_1e1284ddc4ea40eab285856936a5cf7e","value":"special_tokens_map.json: 100%"}},"d746e14f65424ac09f0d692372f5dadf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf07e155ff88460587f3edc915e4675a","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f84b00b2de024bb9b1388d79067299e8","value":239}},"184f548b04fe4bb1b273e9e809280f5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faa2081e6efb49f88ae920a0b363d7b8","placeholder":"​","style":"IPY_MODEL_95ebcab5cb5841bd8dbb8411448982fc","value":" 239/239 [00:00&lt;00:00, 30.5kB/s]"}},"54e4a35d2a0043f78653e4c67f6a76ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b90916f3d604f5b83d69497eba9541d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e1284ddc4ea40eab285856936a5cf7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf07e155ff88460587f3edc915e4675a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f84b00b2de024bb9b1388d79067299e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faa2081e6efb49f88ae920a0b363d7b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ebcab5cb5841bd8dbb8411448982fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96f9aa37ca694fd9992cd1024de6f6b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6cd518dd4b44bf38a088b9c5b5a79ec","IPY_MODEL_6feb1997aca147bdb54e19676868da21","IPY_MODEL_5ff415eb2c68464b9956074f19405183"],"layout":"IPY_MODEL_a2b54a1ea2e64ea8b5eb5e3a74dc34fb"}},"b6cd518dd4b44bf38a088b9c5b5a79ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c42a4083736a4d86a160c4b909ab3fdd","placeholder":"​","style":"IPY_MODEL_0762eb75d257410bae92b06d762c5d7e","value":"config.json: 100%"}},"6feb1997aca147bdb54e19676868da21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4b4e0404ab416eadd9ef58a4e364b6","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55f7c63a59aa48adb88e2ad83463c57b","value":571}},"5ff415eb2c68464b9956074f19405183":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db4c98d48f8845e789257dc7236a9735","placeholder":"​","style":"IPY_MODEL_5af9b995fb3f4dc0a04e945aa1c58a46","value":" 571/571 [00:00&lt;00:00, 66.9kB/s]"}},"a2b54a1ea2e64ea8b5eb5e3a74dc34fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c42a4083736a4d86a160c4b909ab3fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0762eb75d257410bae92b06d762c5d7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d4b4e0404ab416eadd9ef58a4e364b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f7c63a59aa48adb88e2ad83463c57b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db4c98d48f8845e789257dc7236a9735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af9b995fb3f4dc0a04e945aa1c58a46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eac512bda6154776a8109fc232899da0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3609920b4b24812a19f02ad0321ab3d","IPY_MODEL_b4fe9376518245fabfc677bddb2d7b91","IPY_MODEL_8e7a013c3cd14d288c6d9535402237bb"],"layout":"IPY_MODEL_b5f4de06db9f4e3589ccd4e5bfeee133"}},"b3609920b4b24812a19f02ad0321ab3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49dfd6587845450b9b056cb964d52067","placeholder":"​","style":"IPY_MODEL_0bc32a7d8dc64117b481fe2913c5d9f8","value":"model.safetensors: 100%"}},"b4fe9376518245fabfc677bddb2d7b91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0264eea6db314003ba01170255ee011d","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7805bd5803d64537b9b71beaf4a3aa10","value":437971872}},"8e7a013c3cd14d288c6d9535402237bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07be0479b7f04da9b58c7feb3333b051","placeholder":"​","style":"IPY_MODEL_26c0852bdcf34941ae1952f362c827c8","value":" 438M/438M [00:02&lt;00:00, 231MB/s]"}},"b5f4de06db9f4e3589ccd4e5bfeee133":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49dfd6587845450b9b056cb964d52067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bc32a7d8dc64117b481fe2913c5d9f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0264eea6db314003ba01170255ee011d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7805bd5803d64537b9b71beaf4a3aa10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07be0479b7f04da9b58c7feb3333b051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c0852bdcf34941ae1952f362c827c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88fe10f7f4514619925f29c5f4bc0056":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc23d38bdc8c420b8133992cba025009","IPY_MODEL_e937614c182d4428abeb49181d6c106c","IPY_MODEL_1229dccd6ade4c318c09db8f8d6e788e"],"layout":"IPY_MODEL_cec11d9dde1241eebcefd15812fa47b7"}},"bc23d38bdc8c420b8133992cba025009":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea8d804ef87945be9572abd96cb41e7c","placeholder":"​","style":"IPY_MODEL_5f4fce1b1911448ea6307bd8dddad907","value":"tokenizer_config.json: 100%"}},"e937614c182d4428abeb49181d6c106c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bc92f40f0b0443f9360594412835a0f","max":333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643a25a747e34b7fab35e07d39303728","value":333}},"1229dccd6ade4c318c09db8f8d6e788e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bde52327dec4867824277d6bb6d6e75","placeholder":"​","style":"IPY_MODEL_57fbb0ab064d4d178cbb0692982b3304","value":" 333/333 [00:00&lt;00:00, 40.5kB/s]"}},"cec11d9dde1241eebcefd15812fa47b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8d804ef87945be9572abd96cb41e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f4fce1b1911448ea6307bd8dddad907":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bc92f40f0b0443f9360594412835a0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643a25a747e34b7fab35e07d39303728":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bde52327dec4867824277d6bb6d6e75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57fbb0ab064d4d178cbb0692982b3304":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a8f7d8508a429e88701579131fdd23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f7aca5dd6c04ffc87d4ea48347e92b5","IPY_MODEL_804cd4aa0bf74386bdea2a64d4f65c25","IPY_MODEL_7929e641f57b4270b5e446291c9c6e27"],"layout":"IPY_MODEL_6f8a7f6de2dd4567a0a84b5b68266262"}},"1f7aca5dd6c04ffc87d4ea48347e92b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d44814f03dbb4d359b3a89774a2fdc42","placeholder":"​","style":"IPY_MODEL_3d02e2de40464b079d6dac68a89a7bef","value":"vocab.txt: 100%"}},"804cd4aa0bf74386bdea2a64d4f65c25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9168191ee8d642c59046ca6ed9870785","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e599eb973fac4c0b976bcc412c37c25c","value":231508}},"7929e641f57b4270b5e446291c9c6e27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9acb1eae03ec4ed2a9182d6638bba073","placeholder":"​","style":"IPY_MODEL_31a6d5d7bbe8470b96bf65e1f42a0fd6","value":" 232k/232k [00:00&lt;00:00, 4.94MB/s]"}},"6f8a7f6de2dd4567a0a84b5b68266262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d44814f03dbb4d359b3a89774a2fdc42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d02e2de40464b079d6dac68a89a7bef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9168191ee8d642c59046ca6ed9870785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e599eb973fac4c0b976bcc412c37c25c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9acb1eae03ec4ed2a9182d6638bba073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a6d5d7bbe8470b96bf65e1f42a0fd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53b3ba65207745c58ab2eba361dc4b44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56e69be7468548389ce31294ce315852","IPY_MODEL_bdf0bb0eac1446fb97a04987b5166e3d","IPY_MODEL_86ddc002aba24c69b7de81503bee50d2"],"layout":"IPY_MODEL_963363422aa74f5a8c0cb44e42300f61"}},"56e69be7468548389ce31294ce315852":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4cb34edcd464a7aab02396229693941","placeholder":"​","style":"IPY_MODEL_2e2be76cd92a461895c245561d60f48b","value":"tokenizer.json: 100%"}},"bdf0bb0eac1446fb97a04987b5166e3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42dca08b3dea4bd0ba8a55c527c53a5b","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de1be903fb7b481eab5d7f71444122f2","value":466247}},"86ddc002aba24c69b7de81503bee50d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1422593cc954303afa5598b4ff732bd","placeholder":"​","style":"IPY_MODEL_00e35c0ffb0c4f72a6b91aa311684e06","value":" 466k/466k [00:00&lt;00:00, 11.4MB/s]"}},"963363422aa74f5a8c0cb44e42300f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4cb34edcd464a7aab02396229693941":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e2be76cd92a461895c245561d60f48b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42dca08b3dea4bd0ba8a55c527c53a5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1be903fb7b481eab5d7f71444122f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1422593cc954303afa5598b4ff732bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e35c0ffb0c4f72a6b91aa311684e06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1079a862500d441489b8cf140d252dff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b69f5c04ae0f40bcbfad917351ab0911","IPY_MODEL_6a912585fe584e2a9209c8f799b06993","IPY_MODEL_f91a8f9caee8488f8e27810c800ae16d"],"layout":"IPY_MODEL_fe1c4364b3804aa299649a55618fdc1f"}},"b69f5c04ae0f40bcbfad917351ab0911":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c60844e982d4f6e8cbe0cd43fc64521","placeholder":"​","style":"IPY_MODEL_d9ad7b02e1014c7aa321f0992bc7739a","value":"special_tokens_map.json: 100%"}},"6a912585fe584e2a9209c8f799b06993":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_475d93e9403e43d38fd2e61c4ff6a615","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99f5e06a4657402283734d69188b5705","value":112}},"f91a8f9caee8488f8e27810c800ae16d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccd11dffad9c439ea753b05ca65e6cff","placeholder":"​","style":"IPY_MODEL_cb1f430691b64773baec1e442174497e","value":" 112/112 [00:00&lt;00:00, 15.1kB/s]"}},"fe1c4364b3804aa299649a55618fdc1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c60844e982d4f6e8cbe0cd43fc64521":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ad7b02e1014c7aa321f0992bc7739a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"475d93e9403e43d38fd2e61c4ff6a615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f5e06a4657402283734d69188b5705":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccd11dffad9c439ea753b05ca65e6cff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb1f430691b64773baec1e442174497e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5088c41b183b420aa7f9f85013f307f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fd8df306b154448a03e4910ad251790","IPY_MODEL_226aefc7a6644defa11a23f820a57bd1","IPY_MODEL_1b3e48f019e74c79880c5b5c2dabee66"],"layout":"IPY_MODEL_098acf3459ea443ab370b8d712b32051"}},"5fd8df306b154448a03e4910ad251790":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ca313da1ee14994a1cf833f289bdab8","placeholder":"​","style":"IPY_MODEL_aa7eef12a821406995e928e5be1d021e","value":"config.json: 100%"}},"226aefc7a6644defa11a23f820a57bd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65784d78cf4f4355a0621017c41b9150","max":523,"min":0,"orientation":"horizontal","style":"IPY_MODEL_302c3e61c1c64835b9ee4ffeadb82b78","value":523}},"1b3e48f019e74c79880c5b5c2dabee66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4962e5f9ddd4486a703401fcf7a0011","placeholder":"​","style":"IPY_MODEL_d25300245563454f9da8421223121ae3","value":" 523/523 [00:00&lt;00:00, 61.1kB/s]"}},"098acf3459ea443ab370b8d712b32051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ca313da1ee14994a1cf833f289bdab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa7eef12a821406995e928e5be1d021e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65784d78cf4f4355a0621017c41b9150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"302c3e61c1c64835b9ee4ffeadb82b78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4962e5f9ddd4486a703401fcf7a0011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25300245563454f9da8421223121ae3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a776c4c9bfcf4035a226d4fa59ab84a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9c8ccd8645d4779ae6551f13c8dd91a","IPY_MODEL_77ecfde5ef8e4415991ee7c22c897a8d","IPY_MODEL_ccb654fa5c7a4b5597c97748465987d8"],"layout":"IPY_MODEL_7afe1e29a71742bcb0546734d43222a5"}},"d9c8ccd8645d4779ae6551f13c8dd91a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a59447422f21493187bd466fec1f7434","placeholder":"​","style":"IPY_MODEL_63ad1b8925ce426585a7be65afd0d181","value":"model.safetensors: 100%"}},"77ecfde5ef8e4415991ee7c22c897a8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47030b44a04e49ed9fd70f71708ddef1","max":265462608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5981410e444f42a4b329ead0103ee5ae","value":265462608}},"ccb654fa5c7a4b5597c97748465987d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee7ec2196804e619d9fe79eb31c9cfa","placeholder":"​","style":"IPY_MODEL_b35bf1dc125c441888c3fddc1bcfbc38","value":" 265M/265M [00:02&lt;00:00, 106MB/s]"}},"7afe1e29a71742bcb0546734d43222a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59447422f21493187bd466fec1f7434":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63ad1b8925ce426585a7be65afd0d181":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47030b44a04e49ed9fd70f71708ddef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5981410e444f42a4b329ead0103ee5ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bee7ec2196804e619d9fe79eb31c9cfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35bf1dc125c441888c3fddc1bcfbc38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98818d3839124f1ca94c9bcab601de27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35daa5097c884e14be6b54f804f7e694","IPY_MODEL_2679206ed8ed4e6b8b5386429eb94b35","IPY_MODEL_7a199b81decd4a3ca33915d38e30a736"],"layout":"IPY_MODEL_a0ab81481d05461c87e5197e6775e38d"}},"35daa5097c884e14be6b54f804f7e694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8f60699ecfd4f7fb1b3a5298ec6a0ce","placeholder":"​","style":"IPY_MODEL_a7de6e638d31463b977532111f8c97be","value":"tokenizer_config.json: 100%"}},"2679206ed8ed4e6b8b5386429eb94b35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6e666f8f2ea4070a273fa37f925a08b","max":333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01e71a0ff1664d5e8f889e2fbc799ca0","value":333}},"7a199b81decd4a3ca33915d38e30a736":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1a9b380891b43a0a498f6150033bd1d","placeholder":"​","style":"IPY_MODEL_76ba34fa5c0b48d8bbcc883dd24f394c","value":" 333/333 [00:00&lt;00:00, 42.5kB/s]"}},"a0ab81481d05461c87e5197e6775e38d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8f60699ecfd4f7fb1b3a5298ec6a0ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7de6e638d31463b977532111f8c97be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6e666f8f2ea4070a273fa37f925a08b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e71a0ff1664d5e8f889e2fbc799ca0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1a9b380891b43a0a498f6150033bd1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ba34fa5c0b48d8bbcc883dd24f394c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61892bf08f94477da0a0862661dfcdae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4adf4fc9c2554977bdddb4100a765711","IPY_MODEL_cf45015451fa4c309bb74608e474a56c","IPY_MODEL_01973213b96c45809112c0ae952f1bbe"],"layout":"IPY_MODEL_47f3fbbf834e41f2aae954d6df9213b2"}},"4adf4fc9c2554977bdddb4100a765711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f59b9cb8ee5480ab844777141de107c","placeholder":"​","style":"IPY_MODEL_1b0cff0f8ecd47a5bb7087300ff351c1","value":"vocab.json: 100%"}},"cf45015451fa4c309bb74608e474a56c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cc36989b9cf400ba2d721ee4a0b81a1","max":798293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a050577d4f544bd1ae3eed36b685589c","value":798293}},"01973213b96c45809112c0ae952f1bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d355646d13f442d83f93aaf3c375bc1","placeholder":"​","style":"IPY_MODEL_dc41424fe7824c2d8ae5aefc8aed27ee","value":" 798k/798k [00:00&lt;00:00, 9.34MB/s]"}},"47f3fbbf834e41f2aae954d6df9213b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f59b9cb8ee5480ab844777141de107c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b0cff0f8ecd47a5bb7087300ff351c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cc36989b9cf400ba2d721ee4a0b81a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a050577d4f544bd1ae3eed36b685589c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d355646d13f442d83f93aaf3c375bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc41424fe7824c2d8ae5aefc8aed27ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d626bf001024415bf4189a9fa9e6790":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6bf2ceb8aed54fb2a9a2892774d926d1","IPY_MODEL_e0400db9defb4ad185891c476292849a","IPY_MODEL_486f5df6ac2a40c1a21bf77aa411826a"],"layout":"IPY_MODEL_a91305fa2d9046cea835c43d0df072eb"}},"6bf2ceb8aed54fb2a9a2892774d926d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_221761596386442eaab1c9d09ef6b5b1","placeholder":"​","style":"IPY_MODEL_5a53856c33db411893d9abfbad1386c1","value":"merges.txt: 100%"}},"e0400db9defb4ad185891c476292849a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c510d0728532493d8916462c2e6c5fa1","max":456356,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a732e74cf5294d78bea1060aaea8156e","value":456356}},"486f5df6ac2a40c1a21bf77aa411826a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_069b1f4277b5474ca492e41efc897073","placeholder":"​","style":"IPY_MODEL_b2bafd52d6dd4c37a6139e2cae6c0c13","value":" 456k/456k [00:00&lt;00:00, 12.2MB/s]"}},"a91305fa2d9046cea835c43d0df072eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"221761596386442eaab1c9d09ef6b5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a53856c33db411893d9abfbad1386c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c510d0728532493d8916462c2e6c5fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a732e74cf5294d78bea1060aaea8156e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"069b1f4277b5474ca492e41efc897073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2bafd52d6dd4c37a6139e2cae6c0c13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec1768ff11484d66b7f02c0249ea3ca4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c05825335fc94912a240c179377c0cea","IPY_MODEL_2b36f1a3e17c42ecb746b47b4e239926","IPY_MODEL_4801ea97081949b28903007442a5ce10"],"layout":"IPY_MODEL_2bf381be28af42b9a9cda1b08019cf25"}},"c05825335fc94912a240c179377c0cea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fa8fbb6ca1e471c836692f47c9b71e0","placeholder":"​","style":"IPY_MODEL_9fcbb1fa9bec4aa78e0c5a6bdb461f04","value":"tokenizer.json: 100%"}},"2b36f1a3e17c42ecb746b47b4e239926":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2e217b77d4245f5b57e84d68b099413","max":1356047,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fc95ecf3244494ea9fe291de4eb7953","value":1356047}},"4801ea97081949b28903007442a5ce10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e745e4364a948cab227d0fb64e8af0c","placeholder":"​","style":"IPY_MODEL_b3041f0182034fbc9007a67635868d71","value":" 1.36M/1.36M [00:00&lt;00:00, 25.0MB/s]"}},"2bf381be28af42b9a9cda1b08019cf25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fa8fbb6ca1e471c836692f47c9b71e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fcbb1fa9bec4aa78e0c5a6bdb461f04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2e217b77d4245f5b57e84d68b099413":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fc95ecf3244494ea9fe291de4eb7953":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e745e4364a948cab227d0fb64e8af0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3041f0182034fbc9007a67635868d71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc7f0b12d75a422d9888bff6809c58f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4e61a59a8784f159af36d36fa20dbd1","IPY_MODEL_38392ae43f98448fbed95ca14f96a020","IPY_MODEL_6cdc2fb7087f47de9ca8a1c52f71e4c5"],"layout":"IPY_MODEL_fdb7cc93046a43e8911665b53295b6af"}},"e4e61a59a8784f159af36d36fa20dbd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83c6961cee4c4acea51bf19676be1592","placeholder":"​","style":"IPY_MODEL_28dfd04ab6234a8284cdfabecc89e158","value":"special_tokens_map.json: 100%"}},"38392ae43f98448fbed95ca14f96a020":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06b2e228d8144385b1bbe58b8e89c1c5","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f5ac612a7d84a4cb095623763e27565","value":239}},"6cdc2fb7087f47de9ca8a1c52f71e4c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a4f5921061d476499f4377be4cf5050","placeholder":"​","style":"IPY_MODEL_9d9ec7e67e1f40aeae1e34346b7df37c","value":" 239/239 [00:00&lt;00:00, 32.7kB/s]"}},"fdb7cc93046a43e8911665b53295b6af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83c6961cee4c4acea51bf19676be1592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28dfd04ab6234a8284cdfabecc89e158":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b2e228d8144385b1bbe58b8e89c1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f5ac612a7d84a4cb095623763e27565":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a4f5921061d476499f4377be4cf5050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d9ec7e67e1f40aeae1e34346b7df37c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f4af2ac4fe64a5bb2b98be2b7273099":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c02b98aa2d3e4abba60b90e9029b56f9","IPY_MODEL_b96cf3e807234ee7834f0a7ccc517f20","IPY_MODEL_0a207549c763442f861bec46972bd033"],"layout":"IPY_MODEL_b4eea5cdd66946209bf29b41ed8c20d9"}},"c02b98aa2d3e4abba60b90e9029b56f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d098f60c1964aa6925ac44348a50af1","placeholder":"​","style":"IPY_MODEL_324d00ae92e3448b85e59ab65ecf4dd0","value":"config.json: 100%"}},"b96cf3e807234ee7834f0a7ccc517f20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f55e18ac927c46b580f4497814bb976c","max":653,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3599d78ffe7b4e1aad1fc05e7178a453","value":653}},"0a207549c763442f861bec46972bd033":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd7bab52d2ff4e9ea0c3ee6d98bf425c","placeholder":"​","style":"IPY_MODEL_aafbdf937b134f10bdf4b554b70c7a2f","value":" 653/653 [00:00&lt;00:00, 84.8kB/s]"}},"b4eea5cdd66946209bf29b41ed8c20d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d098f60c1964aa6925ac44348a50af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324d00ae92e3448b85e59ab65ecf4dd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f55e18ac927c46b580f4497814bb976c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3599d78ffe7b4e1aad1fc05e7178a453":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd7bab52d2ff4e9ea0c3ee6d98bf425c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aafbdf937b134f10bdf4b554b70c7a2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f87337dd2f78448887eac6c6cf33a5ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_691ddef57c5848fd883c5d9012c94045","IPY_MODEL_7d8b16dd68664ce5879de4e5f6370f79","IPY_MODEL_d07052827bc643789dd44d98470f8515"],"layout":"IPY_MODEL_1195af52e396464f9925c37528b923ea"}},"691ddef57c5848fd883c5d9012c94045":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f697625c7eb446538788d0da12dda7eb","placeholder":"​","style":"IPY_MODEL_cfe71caf9ef34fffb338f8b912aaf86e","value":"model.safetensors: 100%"}},"7d8b16dd68664ce5879de4e5f6370f79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67962942e6a74c4aacf084c4a6b94e30","max":328489328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0015edfaae9b4b4a80dd8af43d23d826","value":328489328}},"d07052827bc643789dd44d98470f8515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3e757b96524f1b924562641594454d","placeholder":"​","style":"IPY_MODEL_f1975dc3ba7a4cfeab0f30e83879de20","value":" 328M/328M [00:03&lt;00:00, 95.8MB/s]"}},"1195af52e396464f9925c37528b923ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f697625c7eb446538788d0da12dda7eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe71caf9ef34fffb338f8b912aaf86e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67962942e6a74c4aacf084c4a6b94e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0015edfaae9b4b4a80dd8af43d23d826":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a3e757b96524f1b924562641594454d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1975dc3ba7a4cfeab0f30e83879de20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92a4f2c303d942b6819d095a9be59a49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a19035c4645491ba2455967081f0fb0","IPY_MODEL_8a3a36a54a9447989728d5565c6b83f8","IPY_MODEL_bf0bc230a5d145ad8583a0394c46d74a"],"layout":"IPY_MODEL_33202e426d50459bacdd863c19ddb436"}},"5a19035c4645491ba2455967081f0fb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b31f6154c2147fb9bd90345a9a086fa","placeholder":"​","style":"IPY_MODEL_a4ea297b38d5434baf34caff05f9b154","value":"tokenizer_config.json: 100%"}},"8a3a36a54a9447989728d5565c6b83f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3202bea3ff64c6f9732ef65e2e17762","max":352,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d098fc73ae14aa791bc37ca14118596","value":352}},"bf0bc230a5d145ad8583a0394c46d74a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_983f18692b2f44288555c879ca9453aa","placeholder":"​","style":"IPY_MODEL_fac935b2c8f54124ae476bebbe279d7b","value":" 352/352 [00:00&lt;00:00, 47.9kB/s]"}},"33202e426d50459bacdd863c19ddb436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b31f6154c2147fb9bd90345a9a086fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4ea297b38d5434baf34caff05f9b154":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3202bea3ff64c6f9732ef65e2e17762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d098fc73ae14aa791bc37ca14118596":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"983f18692b2f44288555c879ca9453aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fac935b2c8f54124ae476bebbe279d7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"426fc031ad2741779d60e3b01f49fbe4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1732faff578745bfafb5cd26e5ae54bd","IPY_MODEL_cdb4993f65c94f1d8d890488da593ecd","IPY_MODEL_eeb06d6ebb2f4fc48ba3e8ca37a15d37"],"layout":"IPY_MODEL_97547fe7b54a4470b2d5878ed92bbf16"}},"1732faff578745bfafb5cd26e5ae54bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ea6d2c66f64452a8a077a4e488f1c5e","placeholder":"​","style":"IPY_MODEL_02bc3344e8264c03a676f85387bc37c0","value":"vocab.txt: 100%"}},"cdb4993f65c94f1d8d890488da593ecd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82e9ed2db6ab45179831d3397a37ee75","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68456052447f456fa519c2d6a45f56e2","value":231508}},"eeb06d6ebb2f4fc48ba3e8ca37a15d37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61a248802124cbe9b80f4a9855b533a","placeholder":"​","style":"IPY_MODEL_66ec20af59b94dbb9b4cf76943230cdd","value":" 232k/232k [00:00&lt;00:00, 26.4MB/s]"}},"97547fe7b54a4470b2d5878ed92bbf16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea6d2c66f64452a8a077a4e488f1c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02bc3344e8264c03a676f85387bc37c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82e9ed2db6ab45179831d3397a37ee75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68456052447f456fa519c2d6a45f56e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b61a248802124cbe9b80f4a9855b533a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ec20af59b94dbb9b4cf76943230cdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f53188c89a304ab19cdddd98031c9325":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a715726a9133486fb9d3956667dc7b83","IPY_MODEL_ffa46ad9f0f240d9ac31f129134c3cc2","IPY_MODEL_0279ed93c980420786bd46ba2b62982c"],"layout":"IPY_MODEL_019a20cc526d44618f8364f97d39e56f"}},"a715726a9133486fb9d3956667dc7b83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27d05e2328a14edc9134b739e314ada8","placeholder":"​","style":"IPY_MODEL_a2c5c6b7daab481589759aefbce19082","value":"tokenizer.json: 100%"}},"ffa46ad9f0f240d9ac31f129134c3cc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f161165b6e54a4abf04a181e7e6cf50","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91a312ea81394f318907f0d0b584172d","value":466247}},"0279ed93c980420786bd46ba2b62982c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1549ecc63bf14c03bb37b9c170f4b796","placeholder":"​","style":"IPY_MODEL_fa8f5c63ffd14c50adfd833ebcfe3cfe","value":" 466k/466k [00:00&lt;00:00, 46.4MB/s]"}},"019a20cc526d44618f8364f97d39e56f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d05e2328a14edc9134b739e314ada8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2c5c6b7daab481589759aefbce19082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f161165b6e54a4abf04a181e7e6cf50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a312ea81394f318907f0d0b584172d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1549ecc63bf14c03bb37b9c170f4b796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa8f5c63ffd14c50adfd833ebcfe3cfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95a2e13b5b3b4bd283f82f91275588a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_059d7fb551484eb4a89c6cfb4a851541","IPY_MODEL_6267dbd8f6b0457380b0b0acf11709d0","IPY_MODEL_b5bcb7940d494bc6975cf65a8138b1ab"],"layout":"IPY_MODEL_dfd748f2131f4e7ba0e9e3309e1a339d"}},"059d7fb551484eb4a89c6cfb4a851541":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e57fd859a6340e397017f4aba4c67d9","placeholder":"​","style":"IPY_MODEL_593a612ab5c64f8bab67b1a279228a0b","value":"special_tokens_map.json: 100%"}},"6267dbd8f6b0457380b0b0acf11709d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1f8d64920a47fa99d0771f6f9e598c","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e01af936e794f029f8a0ebeb36e98b4","value":112}},"b5bcb7940d494bc6975cf65a8138b1ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e00f859c149840e09f0ee528f8af484b","placeholder":"​","style":"IPY_MODEL_8990c63160144a78831bde90f9ac5258","value":" 112/112 [00:00&lt;00:00, 14.2kB/s]"}},"dfd748f2131f4e7ba0e9e3309e1a339d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e57fd859a6340e397017f4aba4c67d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"593a612ab5c64f8bab67b1a279228a0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a1f8d64920a47fa99d0771f6f9e598c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e01af936e794f029f8a0ebeb36e98b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e00f859c149840e09f0ee528f8af484b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8990c63160144a78831bde90f9ac5258":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfb5ed39808342c5b41d340e19005093":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38c438c37fd640808d5a027ddbad0592","IPY_MODEL_62b40c42df3e407c9a3b9906bf0b6c0f","IPY_MODEL_097d11cbc613496190677afe4af3526c"],"layout":"IPY_MODEL_7daf1551f39d471284d69d234899f40b"}},"38c438c37fd640808d5a027ddbad0592":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ea6fbd1ab04a81a58f5b0fb818021c","placeholder":"​","style":"IPY_MODEL_c2690fa39b7b4abd8c99b2795a0c2965","value":"config.json: 100%"}},"62b40c42df3e407c9a3b9906bf0b6c0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dea5be60a56c4356a90111e91b3a2525","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c315a5dab8d94ea6b3462bf86e69e9dc","value":615}},"097d11cbc613496190677afe4af3526c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b1e414feec347fd810f2990bfdb5987","placeholder":"​","style":"IPY_MODEL_9e79a778ebf444d09ebbdcd8ed290361","value":" 615/615 [00:00&lt;00:00, 79.6kB/s]"}},"7daf1551f39d471284d69d234899f40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03ea6fbd1ab04a81a58f5b0fb818021c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2690fa39b7b4abd8c99b2795a0c2965":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dea5be60a56c4356a90111e91b3a2525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c315a5dab8d94ea6b3462bf86e69e9dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b1e414feec347fd810f2990bfdb5987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e79a778ebf444d09ebbdcd8ed290361":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c69cd9f647be4989af2e5e5e21dad780":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36be5d5e34e24fd8b7f6bfdf3f14dc76","IPY_MODEL_26f42fda6d9344a48933ea892cefb87c","IPY_MODEL_1500fd4e94114aa98454678e5baa9549"],"layout":"IPY_MODEL_77c9306848444db69dbf21da9370346f"}},"36be5d5e34e24fd8b7f6bfdf3f14dc76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0bc765d0a3442a2b162fa4d17d31445","placeholder":"​","style":"IPY_MODEL_356525a630dd4bfdae8586bc76851afe","value":"model.safetensors: 100%"}},"26f42fda6d9344a48933ea892cefb87c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e7e91a702624226a3d661f443ab6f17","max":133466304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c6b764048ea4fd8ad2e1f07a535e312","value":133466304}},"1500fd4e94114aa98454678e5baa9549":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6d73282cde34f99ae5f99945d6a088c","placeholder":"​","style":"IPY_MODEL_d2f8c8ef24ee4231a343100267982773","value":" 133M/133M [00:01&lt;00:00, 95.0MB/s]"}},"77c9306848444db69dbf21da9370346f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0bc765d0a3442a2b162fa4d17d31445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"356525a630dd4bfdae8586bc76851afe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e7e91a702624226a3d661f443ab6f17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6b764048ea4fd8ad2e1f07a535e312":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6d73282cde34f99ae5f99945d6a088c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f8c8ef24ee4231a343100267982773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39b55ca016714c03a60208cc49a6b396":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c55f7d403a9a4178a3a09c330f36073b","IPY_MODEL_40e590fcfacb44f184fb3cd0f491ea9e","IPY_MODEL_be99005858d04039a77226609ce02cef"],"layout":"IPY_MODEL_8476f4bb395a4d9291dfc960c0d25eff"}},"c55f7d403a9a4178a3a09c330f36073b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03381d7aaf704d87b77cb05a0245d38a","placeholder":"​","style":"IPY_MODEL_695ab68d6d4b468a9091c8951204fdbe","value":"tokenizer_config.json: 100%"}},"40e590fcfacb44f184fb3cd0f491ea9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf738f2a9bc94964a7f5df221799460a","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbeb7fad69b2491dbed805204ab99cb2","value":52}},"be99005858d04039a77226609ce02cef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a2a07225ea447c9961fccc7ddf2ee04","placeholder":"​","style":"IPY_MODEL_0fbcd8b716094fc695fed86b260bb31f","value":" 52.0/52.0 [00:00&lt;00:00, 6.97kB/s]"}},"8476f4bb395a4d9291dfc960c0d25eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03381d7aaf704d87b77cb05a0245d38a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695ab68d6d4b468a9091c8951204fdbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf738f2a9bc94964a7f5df221799460a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbeb7fad69b2491dbed805204ab99cb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a2a07225ea447c9961fccc7ddf2ee04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fbcd8b716094fc695fed86b260bb31f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50207a2fa0df4436aec3d7912d7df478":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daabbcfd808449a4bc475ac5f3be2073","IPY_MODEL_4a57292903334f428fb67d4e0a650762","IPY_MODEL_ed3aa274e0d04b78b9aaa7c36565ebca"],"layout":"IPY_MODEL_fe3bf2799e7048ec94b7249cd91b83a8"}},"daabbcfd808449a4bc475ac5f3be2073":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79686f4b88a6492bb814d97b50a1b320","placeholder":"​","style":"IPY_MODEL_cfe34636ffa944a38e779ffd67d70202","value":"config.json: 100%"}},"4a57292903334f428fb67d4e0a650762":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9eca35fdcf014c7caa0f63a6ff883a81","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55e9ede5c8bb40819b8419db4007d16a","value":579}},"ed3aa274e0d04b78b9aaa7c36565ebca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd8df956048e4434af88ac15707e29f4","placeholder":"​","style":"IPY_MODEL_3c8debd45b734adab462ede4906417ae","value":" 579/579 [00:00&lt;00:00, 76.7kB/s]"}},"fe3bf2799e7048ec94b7249cd91b83a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79686f4b88a6492bb814d97b50a1b320":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe34636ffa944a38e779ffd67d70202":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9eca35fdcf014c7caa0f63a6ff883a81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55e9ede5c8bb40819b8419db4007d16a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd8df956048e4434af88ac15707e29f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c8debd45b734adab462ede4906417ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b111be4b34d42f9801daba9c9f623da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2a76dff60d14298a421ce02442b1b33","IPY_MODEL_2acdc4ed71494aa089ec9a07338e6285","IPY_MODEL_644929d279554c2a96845f1889d641d5"],"layout":"IPY_MODEL_bd958e3fa9184817bef65705651e2dc8"}},"b2a76dff60d14298a421ce02442b1b33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eaf6bef3704419a9020bc509f87820d","placeholder":"​","style":"IPY_MODEL_7b3fbaf24a144488826a44065494f936","value":"spm.model: 100%"}},"2acdc4ed71494aa089ec9a07338e6285":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24f07f5dd3674985978748f8bf933f12","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebaf365a3d56441790253b466fab3248","value":2464616}},"644929d279554c2a96845f1889d641d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2044447e6c8e4168923b28397023707b","placeholder":"​","style":"IPY_MODEL_b65c4198c4764fe9bc7ebe63723ada15","value":" 2.46M/2.46M [00:00&lt;00:00, 82.4MB/s]"}},"bd958e3fa9184817bef65705651e2dc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eaf6bef3704419a9020bc509f87820d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b3fbaf24a144488826a44065494f936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24f07f5dd3674985978748f8bf933f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebaf365a3d56441790253b466fab3248":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2044447e6c8e4168923b28397023707b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65c4198c4764fe9bc7ebe63723ada15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04487fa1f01e4344b49b378b0ea1068b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7596a0c7b45490dad136b5e35b8022a","IPY_MODEL_a1fc78e8817344668c89951b468e28f1","IPY_MODEL_98482eb4d6bf42b99f043fed56d7ac37"],"layout":"IPY_MODEL_2b92b3226122412ab509330c3bb8a18f"}},"a7596a0c7b45490dad136b5e35b8022a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e72c7ff66c645de8efb7b53ec7aa728","placeholder":"​","style":"IPY_MODEL_d7fb298d23f24f3998ef5f51fcaf0108","value":"tf_model.h5: 100%"}},"a1fc78e8817344668c89951b468e28f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_695d8e0800854d05a608bc689c9a4c2e","max":735589384,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c9d4d83656241dab02b7d65d2dffdd8","value":735589384}},"98482eb4d6bf42b99f043fed56d7ac37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a080a4c972f64410bf624fbd6c9864d1","placeholder":"​","style":"IPY_MODEL_0da75f1e8afd447ea1b207307933d5fc","value":" 736M/736M [00:06&lt;00:00, 104MB/s]"}},"2b92b3226122412ab509330c3bb8a18f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e72c7ff66c645de8efb7b53ec7aa728":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7fb298d23f24f3998ef5f51fcaf0108":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"695d8e0800854d05a608bc689c9a4c2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c9d4d83656241dab02b7d65d2dffdd8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a080a4c972f64410bf624fbd6c9864d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0da75f1e8afd447ea1b207307933d5fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2447b53235034c03807e8bd43f20f1b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d48a1d744f7740fdaf15a8ac1c054463","IPY_MODEL_1f7d8a47612240508578cba9501b08cf","IPY_MODEL_0f41432ecb6040379f446a42113720e1"],"layout":"IPY_MODEL_19db576129eb4752a4601ba62ca5d601"}},"d48a1d744f7740fdaf15a8ac1c054463":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa1a6494f0fb4df3a8cce0736263a0bf","placeholder":"​","style":"IPY_MODEL_a10a4c55f07647eeb8f91eec5d4ef226","value":"tokenizer_config.json: 100%"}},"1f7d8a47612240508578cba9501b08cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f30e2f2c78e34d84b9f5da6d695667e0","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9f7ee718bab4a658e628f060f483bbd","value":25}},"0f41432ecb6040379f446a42113720e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5bdd392a6824ac0827c0dd0d0302232","placeholder":"​","style":"IPY_MODEL_688081eb31b243ab9bbe8a6880b68dff","value":" 25.0/25.0 [00:00&lt;00:00, 3.18kB/s]"}},"19db576129eb4752a4601ba62ca5d601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa1a6494f0fb4df3a8cce0736263a0bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a10a4c55f07647eeb8f91eec5d4ef226":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f30e2f2c78e34d84b9f5da6d695667e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9f7ee718bab4a658e628f060f483bbd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5bdd392a6824ac0827c0dd0d0302232":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"688081eb31b243ab9bbe8a6880b68dff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08cc6cfe7ef742649b32a9e566ba88df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bdd2dd51b02451c9aaf33a2d0a6e88e","IPY_MODEL_ec5c165a12e740f39d59c4fdf93f8d86","IPY_MODEL_ea02449d51984b71812661d0479f9f53"],"layout":"IPY_MODEL_4bd6f27cf90d4ffcaa47925e76e075bd"}},"3bdd2dd51b02451c9aaf33a2d0a6e88e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0000a6aca5c84282ad7b99671c6a1020","placeholder":"​","style":"IPY_MODEL_64dd84f91c0e4baa8fce6d28edd58b9c","value":"config.json: 100%"}},"ec5c165a12e740f39d59c4fdf93f8d86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8378a358a8494e5aa7efdf278db009b7","max":498,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eec8b201e41d4186b95bbfc99b0a4093","value":498}},"ea02449d51984b71812661d0479f9f53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b5121b6d2b48fdbcd78479008639a1","placeholder":"​","style":"IPY_MODEL_40060699111049008928788aa359047b","value":" 498/498 [00:00&lt;00:00, 62.0kB/s]"}},"4bd6f27cf90d4ffcaa47925e76e075bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0000a6aca5c84282ad7b99671c6a1020":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64dd84f91c0e4baa8fce6d28edd58b9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8378a358a8494e5aa7efdf278db009b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec8b201e41d4186b95bbfc99b0a4093":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4b5121b6d2b48fdbcd78479008639a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40060699111049008928788aa359047b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b637cf671654876a55ff106e9b5898b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0b52c6fc2af4588843ef512ff3aa58e","IPY_MODEL_3dcf5f8e0e6f4e859eac98fac47c040e","IPY_MODEL_3ca5cb8e536c469c9ea8b724bb763860"],"layout":"IPY_MODEL_7a4c56c79cde4763b96559ef295f0cb3"}},"e0b52c6fc2af4588843ef512ff3aa58e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d6644394e854f77a6d1895486ea98ff","placeholder":"​","style":"IPY_MODEL_783aba3f2a6341ddbd7cb553eb2a7d8f","value":"vocab.json: 100%"}},"3dcf5f8e0e6f4e859eac98fac47c040e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9cd81cce7fe4eaeab4ffdd48e7108c1","max":898822,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29b17ffe3df2470993eaba0a39185972","value":898822}},"3ca5cb8e536c469c9ea8b724bb763860":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_062836e2f98c40219a67e93418828e27","placeholder":"​","style":"IPY_MODEL_bee5cebc3cdd4504ac957d8407c935c8","value":" 899k/899k [00:00&lt;00:00, 5.19MB/s]"}},"7a4c56c79cde4763b96559ef295f0cb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d6644394e854f77a6d1895486ea98ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783aba3f2a6341ddbd7cb553eb2a7d8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9cd81cce7fe4eaeab4ffdd48e7108c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29b17ffe3df2470993eaba0a39185972":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"062836e2f98c40219a67e93418828e27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bee5cebc3cdd4504ac957d8407c935c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de9c7c9c64c44b11a9dacf9b3ed4c85d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f4a6dfc0ff3425786a6424e70118483","IPY_MODEL_3cf1d799731944519809bebe36a261d4","IPY_MODEL_e0b030a5f3264c6dac7ac1ebdf37ef0b"],"layout":"IPY_MODEL_bc3c4407af8a4c3c9012ca37e207e028"}},"9f4a6dfc0ff3425786a6424e70118483":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fda57c5c3f004243896a6e96e8e9e08b","placeholder":"​","style":"IPY_MODEL_ce252ed598a6400aa3adbce4bb510fa3","value":"merges.txt: 100%"}},"3cf1d799731944519809bebe36a261d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_631a7284a2f04db984c123dc22b8e1b8","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dce9516fefd44411ae2285cd4bf307f2","value":456318}},"e0b030a5f3264c6dac7ac1ebdf37ef0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_263ae3e60a50431493e3e76e542ded69","placeholder":"​","style":"IPY_MODEL_f374834a454049949030d74a9188d7a9","value":" 456k/456k [00:00&lt;00:00, 34.4MB/s]"}},"bc3c4407af8a4c3c9012ca37e207e028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fda57c5c3f004243896a6e96e8e9e08b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce252ed598a6400aa3adbce4bb510fa3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"631a7284a2f04db984c123dc22b8e1b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce9516fefd44411ae2285cd4bf307f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"263ae3e60a50431493e3e76e542ded69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f374834a454049949030d74a9188d7a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91d0c46761a04f9c8682e209cde8677d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0298515569d4f119c65d2792ef61d46","IPY_MODEL_e0b806a6fb8c438982db4bce42146c40","IPY_MODEL_e946433235d14eaeb95a0ff6e45b0b6f"],"layout":"IPY_MODEL_1e3db13b9e2e437ba0db3a9da668cb7f"}},"c0298515569d4f119c65d2792ef61d46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c38874fa9ff476e84ac5e476d4502e5","placeholder":"​","style":"IPY_MODEL_7d02c5d968d14b169e4f6250b990a8bd","value":"special_tokens_map.json: 100%"}},"e0b806a6fb8c438982db4bce42146c40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96293be43a7645f8b41e10157ce721e5","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62ce42d0db5c4d24a6598b534ce4b733","value":150}},"e946433235d14eaeb95a0ff6e45b0b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f35cd4b1be94269947394252eeac2cf","placeholder":"​","style":"IPY_MODEL_2cb73954dc8f4c03896727e6fda88b7d","value":" 150/150 [00:00&lt;00:00, 22.0kB/s]"}},"1e3db13b9e2e437ba0db3a9da668cb7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c38874fa9ff476e84ac5e476d4502e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d02c5d968d14b169e4f6250b990a8bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96293be43a7645f8b41e10157ce721e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62ce42d0db5c4d24a6598b534ce4b733":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f35cd4b1be94269947394252eeac2cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cb73954dc8f4c03896727e6fda88b7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a4786a9bb174c7f865503e7c6b3f230":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_123cabf26e574aa59d90751e274a3309","IPY_MODEL_f56cf122ee4d4ea09aa434307a3045fe","IPY_MODEL_7b05dfe01b974e81b6b7a12db849b496"],"layout":"IPY_MODEL_e2985ed87f5a4d8dbd7ac4486031468d"}},"123cabf26e574aa59d90751e274a3309":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_996e073194aa45439737189625a51f30","placeholder":"​","style":"IPY_MODEL_21bfda79719f4e618c3ea6e9c9dc4daf","value":"tf_model.h5: 100%"}},"f56cf122ee4d4ea09aa434307a3045fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f1dd1f9edb64c2083d55d3191e7bf77","max":498845224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9fc15d4836b4bed9cabe5d8a077cf8c","value":498845224}},"7b05dfe01b974e81b6b7a12db849b496":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de7f3e06c0a54953a66d2a98465b5b9e","placeholder":"​","style":"IPY_MODEL_3b7be91ae5a34caea33e9fd5f5a168dc","value":" 499M/499M [00:04&lt;00:00, 114MB/s]"}},"e2985ed87f5a4d8dbd7ac4486031468d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996e073194aa45439737189625a51f30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21bfda79719f4e618c3ea6e9c9dc4daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f1dd1f9edb64c2083d55d3191e7bf77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9fc15d4836b4bed9cabe5d8a077cf8c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de7f3e06c0a54953a66d2a98465b5b9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b7be91ae5a34caea33e9fd5f5a168dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"683bc661987a4a37948a02fd1fdd69f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2abb463e89de4a60b5956ab8b84d2001","IPY_MODEL_9273dad39ce0474ba0cf9305f6dfe2b5","IPY_MODEL_d10317949d584624a7c08d650f54910b"],"layout":"IPY_MODEL_71893c7fe5a747689d64a34f7d520399"}},"2abb463e89de4a60b5956ab8b84d2001":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2318a8a90855429ab8e64572208fc542","placeholder":"​","style":"IPY_MODEL_9a16a551d08247f9ac66c6858df119f6","value":"tokenizer_config.json: 100%"}},"9273dad39ce0474ba0cf9305f6dfe2b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a49593ef439418da70ab539b9c2cbce","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b58c4391b86f469fb40a6fb912ed5344","value":48}},"d10317949d584624a7c08d650f54910b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_677a5ce4d5a640b1865c35dc1b57bdbc","placeholder":"​","style":"IPY_MODEL_52a7b96979e64177a090a689b60382ee","value":" 48.0/48.0 [00:00&lt;00:00, 6.35kB/s]"}},"71893c7fe5a747689d64a34f7d520399":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2318a8a90855429ab8e64572208fc542":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a16a551d08247f9ac66c6858df119f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a49593ef439418da70ab539b9c2cbce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b58c4391b86f469fb40a6fb912ed5344":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"677a5ce4d5a640b1865c35dc1b57bdbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52a7b96979e64177a090a689b60382ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef8d492f1c4c4c6eb4c0e9f1f51e65eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d53c806655db481bae284b8ce3fdf66e","IPY_MODEL_7a78d831ea1d4507b998e64e704ce228","IPY_MODEL_a37b432669a44ce8abe78e558e88ac47"],"layout":"IPY_MODEL_eeb0feb7060342e3aaeba65003ba6701"}},"d53c806655db481bae284b8ce3fdf66e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0f313379c443afb683ba83dddcd090","placeholder":"​","style":"IPY_MODEL_a4a93869373540799ddbb423a8607132","value":"config.json: 100%"}},"7a78d831ea1d4507b998e64e704ce228":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31dd5f31c15b48bf8bf8fa803a9d8198","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7c5b29010334053ae97504c0ec2bea6","value":570}},"a37b432669a44ce8abe78e558e88ac47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_874dc4d016734036a185b38d0f90ea9c","placeholder":"​","style":"IPY_MODEL_4e324e5f4ab64bb88499f8dda37c6a13","value":" 570/570 [00:00&lt;00:00, 71.9kB/s]"}},"eeb0feb7060342e3aaeba65003ba6701":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb0f313379c443afb683ba83dddcd090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4a93869373540799ddbb423a8607132":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31dd5f31c15b48bf8bf8fa803a9d8198":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7c5b29010334053ae97504c0ec2bea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"874dc4d016734036a185b38d0f90ea9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e324e5f4ab64bb88499f8dda37c6a13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31fe981882744d24a5554ec5817c7ffd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_975c0a75bf6a4ba089c73588cd3ef2b3","IPY_MODEL_15546706885f4399b3747a44a06f7c9f","IPY_MODEL_29d1ca90bdbe424fb2d14df70cd9bcf4"],"layout":"IPY_MODEL_ff59f70f151341bca7daec7d1a312859"}},"975c0a75bf6a4ba089c73588cd3ef2b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a29b2105df848209878d3ebad476d94","placeholder":"​","style":"IPY_MODEL_dfc8e2dd74564dc4b61f30cac5fcb639","value":"vocab.txt: 100%"}},"15546706885f4399b3747a44a06f7c9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93c58088fbf4a478d5b4374c5c9ecc5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2056590dbf4a4889a4cf369549daf83c","value":231508}},"29d1ca90bdbe424fb2d14df70cd9bcf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0a70d23cfd043c2814b693de7be42f5","placeholder":"​","style":"IPY_MODEL_1b56873534e74de8975c244c086209b3","value":" 232k/232k [00:00&lt;00:00, 5.00MB/s]"}},"ff59f70f151341bca7daec7d1a312859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a29b2105df848209878d3ebad476d94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc8e2dd74564dc4b61f30cac5fcb639":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a93c58088fbf4a478d5b4374c5c9ecc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2056590dbf4a4889a4cf369549daf83c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0a70d23cfd043c2814b693de7be42f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b56873534e74de8975c244c086209b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"342eb4641c944d42831d398807f604cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbf0bc0e3688433e842fbff5d6e9a329","IPY_MODEL_0374eefd7beb46e9b0add7200a0e4548","IPY_MODEL_815df6123d0c45768774f29dfb76c088"],"layout":"IPY_MODEL_362b9f5e1bdd459ab8c912cc122b1329"}},"bbf0bc0e3688433e842fbff5d6e9a329":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c453b958cd04539b13c779296f35193","placeholder":"​","style":"IPY_MODEL_ae73f4d5939c47a789096103ae6924fc","value":"tokenizer.json: 100%"}},"0374eefd7beb46e9b0add7200a0e4548":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f7cce27c93d4ef5931c0211fcce37d4","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6af32093626c490eafa01d3760cead4e","value":466062}},"815df6123d0c45768774f29dfb76c088":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d472dff3249749ac8c276dd85b86bf6a","placeholder":"​","style":"IPY_MODEL_75815ed83a364ee1a3f4eb80c0b4eb93","value":" 466k/466k [00:00&lt;00:00, 24.9MB/s]"}},"362b9f5e1bdd459ab8c912cc122b1329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c453b958cd04539b13c779296f35193":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae73f4d5939c47a789096103ae6924fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f7cce27c93d4ef5931c0211fcce37d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af32093626c490eafa01d3760cead4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d472dff3249749ac8c276dd85b86bf6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75815ed83a364ee1a3f4eb80c0b4eb93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3335f3ee56314a9db856b6d090e7d9d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7266d11bdef146c8b88bc7c252f6ba04","IPY_MODEL_afaa2b9cce49479f90772adff9312a7a","IPY_MODEL_3773d466ecf7492289936bc498fce64c"],"layout":"IPY_MODEL_d134c8afb3384dd78b4872dd3313c2df"}},"7266d11bdef146c8b88bc7c252f6ba04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc8ca40596bf4957a98c2e9e5081306c","placeholder":"​","style":"IPY_MODEL_35eb1dbbce204108af528bfdc1bfd341","value":"model.safetensors: 100%"}},"afaa2b9cce49479f90772adff9312a7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_547ff1c3454846db89aa451eeac06da7","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ef0ff3fbbb7455a9fef85302e8a934a","value":440449768}},"3773d466ecf7492289936bc498fce64c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69c9894005fb4761a6e72bc07544fb44","placeholder":"​","style":"IPY_MODEL_8f18860c6ccb46b6b8e2afa3eb9722d4","value":" 440M/440M [00:01&lt;00:00, 238MB/s]"}},"d134c8afb3384dd78b4872dd3313c2df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc8ca40596bf4957a98c2e9e5081306c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35eb1dbbce204108af528bfdc1bfd341":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"547ff1c3454846db89aa451eeac06da7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ef0ff3fbbb7455a9fef85302e8a934a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69c9894005fb4761a6e72bc07544fb44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f18860c6ccb46b6b8e2afa3eb9722d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89d8676581c84452ac3dca8197bf8075":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b148f28a3fa941d585c58e217fd8be55","IPY_MODEL_cbbd9ea9340741cd8c75e56882c59c96","IPY_MODEL_8018582abd9e46028458e2f0bb49aa68"],"layout":"IPY_MODEL_2457de4035074edb8d0e0e896339e451"}},"b148f28a3fa941d585c58e217fd8be55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_334d7b554cc949b3ad8c278b612436c5","placeholder":"​","style":"IPY_MODEL_16709891f78d4330aa30f2c0d0f25e36","value":"tokenizer_config.json: 100%"}},"cbbd9ea9340741cd8c75e56882c59c96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e07a8840dd400ea300bbc47db1c2bb","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea48c26823364ca7ad93c7f9c6a7a9ab","value":363}},"8018582abd9e46028458e2f0bb49aa68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_145f74f8151244d8a9abe6f19702207e","placeholder":"​","style":"IPY_MODEL_e016f2983060497bbb8305d29030fd29","value":" 363/363 [00:00&lt;00:00, 44.7kB/s]"}},"2457de4035074edb8d0e0e896339e451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"334d7b554cc949b3ad8c278b612436c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16709891f78d4330aa30f2c0d0f25e36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e07a8840dd400ea300bbc47db1c2bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea48c26823364ca7ad93c7f9c6a7a9ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"145f74f8151244d8a9abe6f19702207e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e016f2983060497bbb8305d29030fd29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c453bca1feef4d7e995ed8927f0616d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85c394a305a746a48f34c9152bce8f8b","IPY_MODEL_97125525c4ad4f4195170b5473e6ce8e","IPY_MODEL_8f7f3e164fe54a028d6ef8cefadb5357"],"layout":"IPY_MODEL_f7b92639bc654a498a16cb1acf1f0eae"}},"85c394a305a746a48f34c9152bce8f8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6099387574d4a3db8199c2acca3773c","placeholder":"​","style":"IPY_MODEL_758fc2ead5914fc2811493979aa40485","value":"vocab.txt: 100%"}},"97125525c4ad4f4195170b5473e6ce8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e938feae4874204bf9e75f606345222","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eba78b635e594ebbacb48c503cd70f1a","value":231536}},"8f7f3e164fe54a028d6ef8cefadb5357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1834f02ecb774d68bf9a4a47024884f5","placeholder":"​","style":"IPY_MODEL_73f1e3bb31034f49a76974d29c9d6e5d","value":" 232k/232k [00:00&lt;00:00, 1.10MB/s]"}},"f7b92639bc654a498a16cb1acf1f0eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6099387574d4a3db8199c2acca3773c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"758fc2ead5914fc2811493979aa40485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e938feae4874204bf9e75f606345222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba78b635e594ebbacb48c503cd70f1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1834f02ecb774d68bf9a4a47024884f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f1e3bb31034f49a76974d29c9d6e5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b65940a5844185b6df13eda7833dad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90c4667efcaf4ec89289b230b4405b82","IPY_MODEL_3583ca230f714d7e96acb6d8c2adf855","IPY_MODEL_35f0425bd9254cff94ea80a3a87f424f"],"layout":"IPY_MODEL_6621eb88a44644149e243ed3d5119f77"}},"90c4667efcaf4ec89289b230b4405b82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2075f23cfe5040c7923c7cec1d5919e4","placeholder":"​","style":"IPY_MODEL_f399ac2dcd894eb4a597f41aa2c53d00","value":"tokenizer.json: 100%"}},"3583ca230f714d7e96acb6d8c2adf855":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3d202f9ab7546489f4c824659e5d4e2","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cefbe97b8a7b4aa3a1ca4ebf9f0848a4","value":466021}},"35f0425bd9254cff94ea80a3a87f424f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db16a08b51054e129f338cf28dc12860","placeholder":"​","style":"IPY_MODEL_2e59e220e1eb47f5b47f033e291f54a1","value":" 466k/466k [00:00&lt;00:00, 1.08MB/s]"}},"6621eb88a44644149e243ed3d5119f77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2075f23cfe5040c7923c7cec1d5919e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f399ac2dcd894eb4a597f41aa2c53d00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3d202f9ab7546489f4c824659e5d4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cefbe97b8a7b4aa3a1ca4ebf9f0848a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db16a08b51054e129f338cf28dc12860":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e59e220e1eb47f5b47f033e291f54a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c4b01afb14d430fa7c09a72937714ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98fe94ba97b242b0beb0a9ae5d9482d3","IPY_MODEL_b5f527456a9f4340825447e0160aba94","IPY_MODEL_b34d57acb8f44571990d23b4659fd955"],"layout":"IPY_MODEL_7e6f497b5d76441083d645d65bc11a28"}},"98fe94ba97b242b0beb0a9ae5d9482d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08cd1cb859794c818af4095d42c0aa2e","placeholder":"​","style":"IPY_MODEL_2d959ea2063540268ad377ed5cfcf156","value":"special_tokens_map.json: 100%"}},"b5f527456a9f4340825447e0160aba94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39f3a7d89dcd4b8db0d525d9140530fd","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_963eb1c547234cb5af99abe810857c48","value":239}},"b34d57acb8f44571990d23b4659fd955":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f63a81bba30944b58096c5c6365dd596","placeholder":"​","style":"IPY_MODEL_9fdabb13d6e544ff9debc66cdd3aae35","value":" 239/239 [00:00&lt;00:00, 29.7kB/s]"}},"7e6f497b5d76441083d645d65bc11a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08cd1cb859794c818af4095d42c0aa2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d959ea2063540268ad377ed5cfcf156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39f3a7d89dcd4b8db0d525d9140530fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963eb1c547234cb5af99abe810857c48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f63a81bba30944b58096c5c6365dd596":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fdabb13d6e544ff9debc66cdd3aae35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccf71ef69d6748cfb190d94c08b0e943":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed51bd66cf1b4546ba04628833d20a64","IPY_MODEL_2ac743e5e1974dedb31ec490576209db","IPY_MODEL_d407dd5647aa4f8fb39eb881c475a259"],"layout":"IPY_MODEL_903a2b8ec24a42b6be27113ec19b5258"}},"ed51bd66cf1b4546ba04628833d20a64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d63c34906561471f9092a63fd00b44db","placeholder":"​","style":"IPY_MODEL_6c204cb081be4ff4b0afee9dadb15818","value":"tokenizer_config.json: 100%"}},"2ac743e5e1974dedb31ec490576209db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d14833d4a6b4e21ae10112821442f06","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_409c40de138e4829a444c564d4ed9e95","value":363}},"d407dd5647aa4f8fb39eb881c475a259":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53e53d968510448ea13202bee35cf12d","placeholder":"​","style":"IPY_MODEL_d67df1b5f7694b748aacecc6e6855ed6","value":" 363/363 [00:00&lt;00:00, 38.9kB/s]"}},"903a2b8ec24a42b6be27113ec19b5258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63c34906561471f9092a63fd00b44db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c204cb081be4ff4b0afee9dadb15818":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d14833d4a6b4e21ae10112821442f06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"409c40de138e4829a444c564d4ed9e95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53e53d968510448ea13202bee35cf12d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d67df1b5f7694b748aacecc6e6855ed6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97998b89aeb5452d98b75564ce6b7119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc245f3ac9c64e2bba768bd76cb1091b","IPY_MODEL_e14d6036a56f4cc4b426f3e7a7a451ed","IPY_MODEL_6418210dfa9f4212b59a7871ce1ab128"],"layout":"IPY_MODEL_f1a71565f71548f0acf33a5f5a686440"}},"cc245f3ac9c64e2bba768bd76cb1091b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa24d582d8e845739837b2d709fdf152","placeholder":"​","style":"IPY_MODEL_902f3cd03acb4de78af96007e345bb4b","value":"vocab.txt: 100%"}},"e14d6036a56f4cc4b426f3e7a7a451ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d66d1aa8a4d4fefac3ec244a76871b0","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3b349dde8834c84919ce466f3f01f7c","value":231536}},"6418210dfa9f4212b59a7871ce1ab128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_124caf22a5d440f3891c7aba0ba02cff","placeholder":"​","style":"IPY_MODEL_0a8be40ed51d494280ad9705be8a7d3e","value":" 232k/232k [00:00&lt;00:00, 5.11MB/s]"}},"f1a71565f71548f0acf33a5f5a686440":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa24d582d8e845739837b2d709fdf152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"902f3cd03acb4de78af96007e345bb4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d66d1aa8a4d4fefac3ec244a76871b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b349dde8834c84919ce466f3f01f7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"124caf22a5d440f3891c7aba0ba02cff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a8be40ed51d494280ad9705be8a7d3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71e43115a5b5449ea4fe9e51fbdd7261":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19e53d74ff22468294af8c30543bc238","IPY_MODEL_f52fd95d126c4c599b13afa4d720704e","IPY_MODEL_08b2c94852834d208a2f8b4767ea09e1"],"layout":"IPY_MODEL_c4bf96e9504f4c0babb248d0ec527c13"}},"19e53d74ff22468294af8c30543bc238":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e12372dceb1a4046a0679b2a633f7f84","placeholder":"​","style":"IPY_MODEL_46d2a2a16e20488f90d5ee3734f464c5","value":"tokenizer.json: 100%"}},"f52fd95d126c4c599b13afa4d720704e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_215f094c3695467eb2824631dcd4f704","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce0422ffd4524fa7b9c17402835c16cb","value":466021}},"08b2c94852834d208a2f8b4767ea09e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85fab071adef433ca1a8449567456063","placeholder":"​","style":"IPY_MODEL_a020cc480ebb45988d9a3b1e94a6e8f1","value":" 466k/466k [00:00&lt;00:00, 25.0MB/s]"}},"c4bf96e9504f4c0babb248d0ec527c13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e12372dceb1a4046a0679b2a633f7f84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d2a2a16e20488f90d5ee3734f464c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"215f094c3695467eb2824631dcd4f704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce0422ffd4524fa7b9c17402835c16cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85fab071adef433ca1a8449567456063":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a020cc480ebb45988d9a3b1e94a6e8f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11e3df3c8e9d4b33b09db9348392b0ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf69768dd22d416d8b48742dc406029f","IPY_MODEL_0ac1b540e4a24c20a934b7cbdac7128e","IPY_MODEL_720f1a0b20bf490d8a1bc22f6ec95023"],"layout":"IPY_MODEL_b63d17107709412bbcc1d3c1f597e2e0"}},"cf69768dd22d416d8b48742dc406029f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675dad3b11254f38b78ca8bed50847eb","placeholder":"​","style":"IPY_MODEL_eb2aa37e56774c2e91056857373bc8af","value":"special_tokens_map.json: 100%"}},"0ac1b540e4a24c20a934b7cbdac7128e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36d793efae8f4943af934aaf6050315b","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a91e2e590e449658e0fb7b35edbab4d","value":239}},"720f1a0b20bf490d8a1bc22f6ec95023":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46ad870cc07c470da97a4bd84fedfe51","placeholder":"​","style":"IPY_MODEL_9285033d142a4593bc50f52e7ac387a2","value":" 239/239 [00:00&lt;00:00, 21.5kB/s]"}},"b63d17107709412bbcc1d3c1f597e2e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675dad3b11254f38b78ca8bed50847eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb2aa37e56774c2e91056857373bc8af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36d793efae8f4943af934aaf6050315b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a91e2e590e449658e0fb7b35edbab4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46ad870cc07c470da97a4bd84fedfe51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9285033d142a4593bc50f52e7ac387a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32f52b6a83ea4ba99c4f8d9c8590a726":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53c8cbdf1f1148d8b2971af121eb37cf","IPY_MODEL_878e698ab10d46bca44cced3b3b41c2c","IPY_MODEL_de99a826e5d0410cbb639ab46bc6abdc"],"layout":"IPY_MODEL_33a5eaa1d7e04b2c83f60df6031838bd"}},"53c8cbdf1f1148d8b2971af121eb37cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a46450e51004458b934330d5bd68e82d","placeholder":"​","style":"IPY_MODEL_a66bfe8c6d154a1c88ac707e66f5b66b","value":"tokenizer_config.json: 100%"}},"878e698ab10d46bca44cced3b3b41c2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b5130f7849a422db7fdfb53a0530011","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ed283d5d1944333a1615b7b1884c17b","value":363}},"de99a826e5d0410cbb639ab46bc6abdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccda8d4ff7ba47afa95091a1ba72284f","placeholder":"​","style":"IPY_MODEL_ccde2fe05af44e0aa1e8e2fd5d5da9ce","value":" 363/363 [00:00&lt;00:00, 43.5kB/s]"}},"33a5eaa1d7e04b2c83f60df6031838bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a46450e51004458b934330d5bd68e82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a66bfe8c6d154a1c88ac707e66f5b66b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b5130f7849a422db7fdfb53a0530011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ed283d5d1944333a1615b7b1884c17b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ccda8d4ff7ba47afa95091a1ba72284f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccde2fe05af44e0aa1e8e2fd5d5da9ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48d0b0faeaf64cdfae04f38beac5412e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4055beb83ba46e399c12f80feca7f81","IPY_MODEL_24a3abe28a114be386115806b189890c","IPY_MODEL_3f3d32c96ad4426180c47246f76a4769"],"layout":"IPY_MODEL_8808a7380cdb43c59ef7239304884796"}},"b4055beb83ba46e399c12f80feca7f81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3439462dd99f4312a625bae2a11f11bf","placeholder":"​","style":"IPY_MODEL_a5bf869229474863997b775dc94fef57","value":"vocab.txt: 100%"}},"24a3abe28a114be386115806b189890c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daa539eba5564410bfea46d706928b18","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d90729579c94168933eace4ad6cf720","value":231536}},"3f3d32c96ad4426180c47246f76a4769":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_990bf27b7b7d4843b6116ca03799e88c","placeholder":"​","style":"IPY_MODEL_e1531324da624a1fa307ee31574778a4","value":" 232k/232k [00:00&lt;00:00, 2.00MB/s]"}},"8808a7380cdb43c59ef7239304884796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3439462dd99f4312a625bae2a11f11bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5bf869229474863997b775dc94fef57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daa539eba5564410bfea46d706928b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d90729579c94168933eace4ad6cf720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"990bf27b7b7d4843b6116ca03799e88c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1531324da624a1fa307ee31574778a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b986cfb4af14955ad7343095b862e0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_045049a775bc491a9c362f1630660168","IPY_MODEL_a23af30131fe4878a4f5a7552c7ad0f5","IPY_MODEL_55d1e8c1600949489da8c6d99ea52bc3"],"layout":"IPY_MODEL_f2c9325977584b8aaa927cc4d34c9bfe"}},"045049a775bc491a9c362f1630660168":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8316ce21976342888667843df597bccf","placeholder":"​","style":"IPY_MODEL_41b4c6e096914ec0a2966b8b0e3db8fb","value":"tokenizer.json: 100%"}},"a23af30131fe4878a4f5a7552c7ad0f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0585c666e1d943ad85feffa59112b837","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d68f092c06247c58d7810b1e0a8bb97","value":466021}},"55d1e8c1600949489da8c6d99ea52bc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4a7c80c5c84c07842b1ef8eec334b4","placeholder":"​","style":"IPY_MODEL_f0267e009e7c472aba0abcb847be5382","value":" 466k/466k [00:00&lt;00:00, 9.24MB/s]"}},"f2c9325977584b8aaa927cc4d34c9bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8316ce21976342888667843df597bccf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b4c6e096914ec0a2966b8b0e3db8fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0585c666e1d943ad85feffa59112b837":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d68f092c06247c58d7810b1e0a8bb97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad4a7c80c5c84c07842b1ef8eec334b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0267e009e7c472aba0abcb847be5382":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23120690c8484281892bd7aeb2082cae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_309c3931c7bb4273a6c56e4245913c72","IPY_MODEL_529f5b6a0f6040aea6f8ed6644284be3","IPY_MODEL_5bd1d21486d24f38995defbd718d3fe8"],"layout":"IPY_MODEL_c44a36a04e7b4943a48f30c01d76dcbc"}},"309c3931c7bb4273a6c56e4245913c72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b901fecc98b4d0bb241b91ee5849bb2","placeholder":"​","style":"IPY_MODEL_3eaf364182ff46d9b04ca464ebc9f488","value":"special_tokens_map.json: 100%"}},"529f5b6a0f6040aea6f8ed6644284be3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eff3085396524665ae11da6d09df5b34","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5933a75716d54a80a8d22967c76004fc","value":239}},"5bd1d21486d24f38995defbd718d3fe8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d0081f0dea4cfbb1570ac5140a0149","placeholder":"​","style":"IPY_MODEL_5f75cdfb90204a858050c53e0f8820cb","value":" 239/239 [00:00&lt;00:00, 29.6kB/s]"}},"c44a36a04e7b4943a48f30c01d76dcbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b901fecc98b4d0bb241b91ee5849bb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eaf364182ff46d9b04ca464ebc9f488":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eff3085396524665ae11da6d09df5b34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5933a75716d54a80a8d22967c76004fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5d0081f0dea4cfbb1570ac5140a0149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f75cdfb90204a858050c53e0f8820cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d51a750a2afa44d49c89a582feefcf72":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31028bc5abfd4980baef9636fe0e32ad","IPY_MODEL_e7eb765a0fdf4903a72da7ddc28e495d","IPY_MODEL_6909eafd62f9423b8958f9ffbe692335"],"layout":"IPY_MODEL_ae3fbfd0d9c44687a416e417dab20381"}},"31028bc5abfd4980baef9636fe0e32ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40c247d4fa6941ccab3f9f47cf221c39","placeholder":"​","style":"IPY_MODEL_459c582527ba4780809a80b8d1f5c0de","value":"config.json: 100%"}},"e7eb765a0fdf4903a72da7ddc28e495d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19e6a80598214fd49843bc3144a94d9d","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_caa523233fbb4c3d9c4409e3f4d1d999","value":571}},"6909eafd62f9423b8958f9ffbe692335":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2951e5954b194544a9dfd69f8ec05b17","placeholder":"​","style":"IPY_MODEL_ed24eebedccf437d967141a162b3bb94","value":" 571/571 [00:00&lt;00:00, 77.6kB/s]"}},"ae3fbfd0d9c44687a416e417dab20381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40c247d4fa6941ccab3f9f47cf221c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"459c582527ba4780809a80b8d1f5c0de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19e6a80598214fd49843bc3144a94d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa523233fbb4c3d9c4409e3f4d1d999":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2951e5954b194544a9dfd69f8ec05b17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed24eebedccf437d967141a162b3bb94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfc85653913e47578a4f568afa91a607":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3193d84e1e424203ba5676ace433d780","IPY_MODEL_210fcaa9b4aa4f269bdbeb0b389da125","IPY_MODEL_20f646d4b3ee45fb93c58f8c01b4b892"],"layout":"IPY_MODEL_51880c0fd5044725b733749340b869e1"}},"3193d84e1e424203ba5676ace433d780":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e405b575c3341da9f60da8e30a4f20a","placeholder":"​","style":"IPY_MODEL_84b85b3357874ce9a60b11dd7df70ea4","value":"model.safetensors: 100%"}},"210fcaa9b4aa4f269bdbeb0b389da125":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c9a7d0a4d1d446e8a98f48a74562776","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e708d45825994489a2471743a896bc0a","value":437971872}},"20f646d4b3ee45fb93c58f8c01b4b892":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df19808adbc14a82ac974a48d129f159","placeholder":"​","style":"IPY_MODEL_7e1bea3b62aa4026a1f600c436c818b5","value":" 438M/438M [00:02&lt;00:00, 230MB/s]"}},"51880c0fd5044725b733749340b869e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e405b575c3341da9f60da8e30a4f20a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b85b3357874ce9a60b11dd7df70ea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c9a7d0a4d1d446e8a98f48a74562776":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e708d45825994489a2471743a896bc0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df19808adbc14a82ac974a48d129f159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e1bea3b62aa4026a1f600c436c818b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccf04eb279484992b3ab4444deffd9f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_836895a195614e8585c0c8315df9e203","IPY_MODEL_51dc24b26c5846bba54742c60fb1e449","IPY_MODEL_4a635675b4b048debccc0fb05b95e193"],"layout":"IPY_MODEL_de1d8a62e5c845c487226b5d3741a697"}},"836895a195614e8585c0c8315df9e203":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9034f266f79b45dc9c9723fc44b5687f","placeholder":"​","style":"IPY_MODEL_daf01074d3d14b3daa06e1d93a95526a","value":"tokenizer_config.json: 100%"}},"51dc24b26c5846bba54742c60fb1e449":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e6fa649ff634430a323f4261896847e","max":383,"min":0,"orientation":"horizontal","style":"IPY_MODEL_971bf3ff9bcc4d37b5b060be80847f46","value":383}},"4a635675b4b048debccc0fb05b95e193":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc3b9c3d8d74dc2a985396514794c3d","placeholder":"​","style":"IPY_MODEL_cbe9938fd3284759942233b8d5c00143","value":" 383/383 [00:00&lt;00:00, 49.9kB/s]"}},"de1d8a62e5c845c487226b5d3741a697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9034f266f79b45dc9c9723fc44b5687f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daf01074d3d14b3daa06e1d93a95526a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e6fa649ff634430a323f4261896847e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971bf3ff9bcc4d37b5b060be80847f46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcc3b9c3d8d74dc2a985396514794c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe9938fd3284759942233b8d5c00143":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf93bcacabdd4a1f9ad4d891f09260a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec281bf2782c4074a513917c2c36598a","IPY_MODEL_21c2fda734624ee084a2d98ae3112815","IPY_MODEL_52d8ce05f4c74f44bfb8dd743dc984cb"],"layout":"IPY_MODEL_a7d0932d36954aeb8b097e3a95219c86"}},"ec281bf2782c4074a513917c2c36598a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fe5a80af61341478805a294f2960765","placeholder":"​","style":"IPY_MODEL_e4f6244917ab4320b888fffeaf510204","value":"vocab.txt: 100%"}},"21c2fda734624ee084a2d98ae3112815":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cb8c61c5efe4f499822578421e28aaa","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73a148b3d03a43c683918016d08022bb","value":231508}},"52d8ce05f4c74f44bfb8dd743dc984cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb6b25945be6437ea606b0ee83e810ea","placeholder":"​","style":"IPY_MODEL_22602b2c18eb4f6f8211bc92bf364cf7","value":" 232k/232k [00:00&lt;00:00, 1.14MB/s]"}},"a7d0932d36954aeb8b097e3a95219c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe5a80af61341478805a294f2960765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f6244917ab4320b888fffeaf510204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cb8c61c5efe4f499822578421e28aaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a148b3d03a43c683918016d08022bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb6b25945be6437ea606b0ee83e810ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22602b2c18eb4f6f8211bc92bf364cf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"832b77df399142d8b9d723d6c959118a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad6c09136a154b5ab1e22bd625fcab8d","IPY_MODEL_eafc4af6bff9483e9af1a6e3264d2ee5","IPY_MODEL_fe3b00f874674dee97b2d9aacb813207"],"layout":"IPY_MODEL_343d8886b97f4b61905c85010696d913"}},"ad6c09136a154b5ab1e22bd625fcab8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_250521bb8d8a47f0a9c903b3118b4ed6","placeholder":"​","style":"IPY_MODEL_05af75900b3a4851a7d2e77f4d1ac888","value":"tokenizer.json: 100%"}},"eafc4af6bff9483e9af1a6e3264d2ee5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f39489081dfb465fa50ada5aaa4421d1","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aeb858e5c9a14456966f6d835805ddfb","value":466247}},"fe3b00f874674dee97b2d9aacb813207":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edc6e8e284274038bf43aa9c7842af4a","placeholder":"​","style":"IPY_MODEL_da043eb6203346e7b205146011a77ab9","value":" 466k/466k [00:00&lt;00:00, 2.38MB/s]"}},"343d8886b97f4b61905c85010696d913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250521bb8d8a47f0a9c903b3118b4ed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05af75900b3a4851a7d2e77f4d1ac888":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f39489081dfb465fa50ada5aaa4421d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeb858e5c9a14456966f6d835805ddfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edc6e8e284274038bf43aa9c7842af4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da043eb6203346e7b205146011a77ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"422cf6b8a8b641549989c163554764ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_537a8f7dd930428eba40fe3841cd2bf6","IPY_MODEL_d0885150fd0d487c800cbfaf5d9ddd63","IPY_MODEL_da0b9d44a2834e668c1cdbbd9aedf1b8"],"layout":"IPY_MODEL_7a4e916433e14febbaf17bd192ee82d8"}},"537a8f7dd930428eba40fe3841cd2bf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_613db4b7577240b8a7e10b92ab07df24","placeholder":"​","style":"IPY_MODEL_09d7493be2884f4eb0bf82af6b81a331","value":"special_tokens_map.json: 100%"}},"d0885150fd0d487c800cbfaf5d9ddd63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdc8d61906ad493199f3877d0ae6c2f6","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2be275799c1449af942628c9ddc2cb93","value":112}},"da0b9d44a2834e668c1cdbbd9aedf1b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e28561ff3434f55921db84a20564782","placeholder":"​","style":"IPY_MODEL_509b89f35c724b758de0a2333ae1977f","value":" 112/112 [00:00&lt;00:00, 15.0kB/s]"}},"7a4e916433e14febbaf17bd192ee82d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"613db4b7577240b8a7e10b92ab07df24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09d7493be2884f4eb0bf82af6b81a331":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdc8d61906ad493199f3877d0ae6c2f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be275799c1449af942628c9ddc2cb93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e28561ff3434f55921db84a20564782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509b89f35c724b758de0a2333ae1977f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caea72a479794d7aa90ba7a0e8ace7f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b58fe5004d0e4500901a663968fcade2","IPY_MODEL_8a23b889b58a460786833df1333ab872","IPY_MODEL_b2a9c07aaa874ec7a7e7d2428c6ff406"],"layout":"IPY_MODEL_65684ee8400b4db4b641a44da07ce6c4"}},"b58fe5004d0e4500901a663968fcade2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c518c43599bd43df821a816a42298b1c","placeholder":"​","style":"IPY_MODEL_24fc9d0919eb47adb8f6b99df3e2a0e9","value":"config.json: 100%"}},"8a23b889b58a460786833df1333ab872":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67d64a2ae82f4338a83de95fe26f3ba0","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8bf0aadbc37400f8c2deb94f3b14f76","value":612}},"b2a9c07aaa874ec7a7e7d2428c6ff406":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f85c497d3e6d4fea829937c8c654a1c2","placeholder":"​","style":"IPY_MODEL_feb6859745a743378ab162d46667d3b1","value":" 612/612 [00:00&lt;00:00, 63.4kB/s]"}},"65684ee8400b4db4b641a44da07ce6c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c518c43599bd43df821a816a42298b1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24fc9d0919eb47adb8f6b99df3e2a0e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67d64a2ae82f4338a83de95fe26f3ba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8bf0aadbc37400f8c2deb94f3b14f76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f85c497d3e6d4fea829937c8c654a1c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb6859745a743378ab162d46667d3b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49ec40c3c4f04e1d84f21994098b91b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28f370263b2149b7abfe54f845d8de14","IPY_MODEL_def0e8563b1b4f8cbe12b0b7067abec7","IPY_MODEL_c3e0be24e7b84e8497003c78540a03d9"],"layout":"IPY_MODEL_5e5355f4479949b69d531d578c3633c5"}},"28f370263b2149b7abfe54f845d8de14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e664bc40dd54d68a46a1b8d9abdbdb9","placeholder":"​","style":"IPY_MODEL_909a22ff6b6243f187c8579d274476ff","value":"model.safetensors: 100%"}},"def0e8563b1b4f8cbe12b0b7067abec7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f24cc12671504ea3ab78444b25bbf95f","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9271dc9c7f74230885f45b4c5f5b5c1","value":90868376}},"c3e0be24e7b84e8497003c78540a03d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fce988744caa45e2a683f84ec3efc8c7","placeholder":"​","style":"IPY_MODEL_7e0b6d1909fa409e9318b5b04f613f91","value":" 90.9M/90.9M [00:00&lt;00:00, 252MB/s]"}},"5e5355f4479949b69d531d578c3633c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e664bc40dd54d68a46a1b8d9abdbdb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"909a22ff6b6243f187c8579d274476ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f24cc12671504ea3ab78444b25bbf95f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9271dc9c7f74230885f45b4c5f5b5c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fce988744caa45e2a683f84ec3efc8c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e0b6d1909fa409e9318b5b04f613f91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53f0b3c79c784c11bfbbafef2928bc34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1e28497887b4eabb0b3af3078f7cfd7","IPY_MODEL_b318a93f98f24a84a7b51fadbd44dcd1","IPY_MODEL_1bd96184841b4ab9be30ea36cc1d356a"],"layout":"IPY_MODEL_5e7593d188b24b76825c84810885f75e"}},"b1e28497887b4eabb0b3af3078f7cfd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6efaa3f968e7404187b9aaedaa4d3ed6","placeholder":"​","style":"IPY_MODEL_1edef61bfa3641b387e32e3a42fd4657","value":"tokenizer_config.json: 100%"}},"b318a93f98f24a84a7b51fadbd44dcd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b352bbe409d45c9b33c8c6ed51d0b43","max":402,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8c4d5e5e1c2418da5f19d406a6d285f","value":402}},"1bd96184841b4ab9be30ea36cc1d356a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7789427c7c14126b735d65a9ca58778","placeholder":"​","style":"IPY_MODEL_f95ef765dd66491daf610e0ad3bdfe03","value":" 402/402 [00:00&lt;00:00, 52.3kB/s]"}},"5e7593d188b24b76825c84810885f75e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6efaa3f968e7404187b9aaedaa4d3ed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1edef61bfa3641b387e32e3a42fd4657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b352bbe409d45c9b33c8c6ed51d0b43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8c4d5e5e1c2418da5f19d406a6d285f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7789427c7c14126b735d65a9ca58778":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f95ef765dd66491daf610e0ad3bdfe03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1644eea704c4784a257654aae2ba7d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc6fee65997445f29ac87b6b0926a0f8","IPY_MODEL_40d33a173ef2462fb91251d0a163632d","IPY_MODEL_eb61704ce32c40df9db5ced7a236dbb9"],"layout":"IPY_MODEL_fcd9911466634f4aa1649d66f6353de1"}},"fc6fee65997445f29ac87b6b0926a0f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a216558fc8f047e7ae5c216d468386f3","placeholder":"​","style":"IPY_MODEL_707d7e3900ac430a9782be75bd0eae8c","value":"config.json: 100%"}},"40d33a173ef2462fb91251d0a163632d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce9b3cb41b0d4dc88226330b3be05565","max":723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_70f986ec02e54a078f022075995b93ae","value":723}},"eb61704ce32c40df9db5ced7a236dbb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1691ad62a7c24acab3def60323fea468","placeholder":"​","style":"IPY_MODEL_63a5b9f5f3204bed870a29f8c2f580ae","value":" 723/723 [00:00&lt;00:00, 88.8kB/s]"}},"fcd9911466634f4aa1649d66f6353de1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a216558fc8f047e7ae5c216d468386f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"707d7e3900ac430a9782be75bd0eae8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce9b3cb41b0d4dc88226330b3be05565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f986ec02e54a078f022075995b93ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1691ad62a7c24acab3def60323fea468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a5b9f5f3204bed870a29f8c2f580ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d302daad61d449d8d7fb10f731d13b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d7aa28196ec45c1bf1f55f5c943d616","IPY_MODEL_74dfbe15b6124f63994a1ce82c522b61","IPY_MODEL_50598175aec34cf0b04d9372edca3f00"],"layout":"IPY_MODEL_6383c05f294640d894ea60f5ca2b3b5c"}},"0d7aa28196ec45c1bf1f55f5c943d616":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12ce0b4287634be3a8b38cd921b79720","placeholder":"​","style":"IPY_MODEL_92486ca3383748a3a8acd39bb45a39d2","value":"sentencepiece.bpe.model: 100%"}},"74dfbe15b6124f63994a1ce82c522b61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41c58315af11486b8f68f84fd070ebbd","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bec838229faf4b60a5514cb5f67ccbc9","value":5069051}},"50598175aec34cf0b04d9372edca3f00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_792c9cad1b1e45d78a0dc93ad3b455b2","placeholder":"​","style":"IPY_MODEL_5685778154594b16836a94bb5275bdaa","value":" 5.07M/5.07M [00:00&lt;00:00, 188MB/s]"}},"6383c05f294640d894ea60f5ca2b3b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ce0b4287634be3a8b38cd921b79720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92486ca3383748a3a8acd39bb45a39d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41c58315af11486b8f68f84fd070ebbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec838229faf4b60a5514cb5f67ccbc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"792c9cad1b1e45d78a0dc93ad3b455b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685778154594b16836a94bb5275bdaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"677ed44b74604f4c8bfda6bc74310832":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bcbecfa0c1e4429e93250eee0e2da748","IPY_MODEL_cea196c97a734ae3911e63dac2ac5c65","IPY_MODEL_8bdc7154dbd0444e9a85a7553983960e"],"layout":"IPY_MODEL_a40c3a0f655c4e1893d3f4e692b76444"}},"bcbecfa0c1e4429e93250eee0e2da748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_571e702ed4bb47c1912bf0c3ae440fa3","placeholder":"​","style":"IPY_MODEL_f2ffb498e1874587a4192b8afba0b78b","value":"tokenizer.json: 100%"}},"cea196c97a734ae3911e63dac2ac5c65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1f01e020d2540f2b99e5dee6d84dd12","max":9081518,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb00f64df1b645dba309b988d0ec8a11","value":9081518}},"8bdc7154dbd0444e9a85a7553983960e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed5f5c1a46845d2a325967d1da4a86b","placeholder":"​","style":"IPY_MODEL_6924a13879d649dc8271c785c607a82f","value":" 9.08M/9.08M [00:00&lt;00:00, 10.9MB/s]"}},"a40c3a0f655c4e1893d3f4e692b76444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"571e702ed4bb47c1912bf0c3ae440fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2ffb498e1874587a4192b8afba0b78b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1f01e020d2540f2b99e5dee6d84dd12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb00f64df1b645dba309b988d0ec8a11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ed5f5c1a46845d2a325967d1da4a86b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6924a13879d649dc8271c785c607a82f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71642e6ce884417797c3718879cf6e2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a00e0cee92434c3fbb1674618896c985","IPY_MODEL_c1ae79a6f49b42069fff84605079a47d","IPY_MODEL_7ded4c8a54674148bf5854314eacd74b"],"layout":"IPY_MODEL_6b2c6e36344a499e9811a1bdd5b10859"}},"a00e0cee92434c3fbb1674618896c985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8aaf495d90744838fac8556d859b1a1","placeholder":"​","style":"IPY_MODEL_68c1a0b29ace4eb18ac62a9bc1e7bbab","value":"special_tokens_map.json: 100%"}},"c1ae79a6f49b42069fff84605079a47d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3077a6fec03c4c97a1fab3ae2b8c8485","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a24d71197d7a410f92291a055ff527dc","value":239}},"7ded4c8a54674148bf5854314eacd74b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70fb81a9395a492dbba8b83f246e362f","placeholder":"​","style":"IPY_MODEL_68ae6530d4ed4b1f9c5c475b04adf84a","value":" 239/239 [00:00&lt;00:00, 28.9kB/s]"}},"6b2c6e36344a499e9811a1bdd5b10859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8aaf495d90744838fac8556d859b1a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68c1a0b29ace4eb18ac62a9bc1e7bbab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3077a6fec03c4c97a1fab3ae2b8c8485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a24d71197d7a410f92291a055ff527dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70fb81a9395a492dbba8b83f246e362f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ae6530d4ed4b1f9c5c475b04adf84a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d65a8413ee84599901e66b322696215":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49b9a034959340058247e7130efd6691","IPY_MODEL_3111dec24bc5473ba268b9746574af67","IPY_MODEL_f229e64462c04f68a6cb88c3d1847e9b"],"layout":"IPY_MODEL_d78288a5a8994a998c5d2d96a0640cb9"}},"49b9a034959340058247e7130efd6691":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f14ed022d37408fae02d01851bb4b07","placeholder":"​","style":"IPY_MODEL_6d1c3083c6a643faada7a4931a117ce0","value":"model.safetensors: 100%"}},"3111dec24bc5473ba268b9746574af67":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_493999a8bbc64d5892e4cf9db3a0b58c","max":1112201288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_967b0e1247ed4fd6bd35175291a55c76","value":1112201288}},"f229e64462c04f68a6cb88c3d1847e9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ddd190ae2dd4c2a97ab503982711e60","placeholder":"​","style":"IPY_MODEL_cf5b6cdd17a445c784b6094a72dc1366","value":" 1.11G/1.11G [00:04&lt;00:00, 251MB/s]"}},"d78288a5a8994a998c5d2d96a0640cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f14ed022d37408fae02d01851bb4b07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d1c3083c6a643faada7a4931a117ce0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"493999a8bbc64d5892e4cf9db3a0b58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"967b0e1247ed4fd6bd35175291a55c76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ddd190ae2dd4c2a97ab503982711e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf5b6cdd17a445c784b6094a72dc1366":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e86cb7c9806c4feeb34a3d0dd2092ff3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74dd3a58f7d84b899918f3d17ed42ed8","IPY_MODEL_4064e90126904b59834089521634e812","IPY_MODEL_57e596e03ead43ec9a1ca7c6751c145d"],"layout":"IPY_MODEL_81e67cc6a8b54341ae714d0817a6efc0"}},"74dd3a58f7d84b899918f3d17ed42ed8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c84a5f9a6b460e94783cc156443210","placeholder":"​","style":"IPY_MODEL_42f4775c673342c59ceba157c1f8844f","value":"tokenizer_config.json: 100%"}},"4064e90126904b59834089521634e812":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ce741a4f9b240cc87867480d7230f33","max":465,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4239ded27f774dee87d080fb9787eea4","value":465}},"57e596e03ead43ec9a1ca7c6751c145d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a35d0357ac884d54aec072b206e7535c","placeholder":"​","style":"IPY_MODEL_b04d10e149ee4d7694dfca8ee5029f5c","value":" 465/465 [00:00&lt;00:00, 65.5kB/s]"}},"81e67cc6a8b54341ae714d0817a6efc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c84a5f9a6b460e94783cc156443210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f4775c673342c59ceba157c1f8844f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ce741a4f9b240cc87867480d7230f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4239ded27f774dee87d080fb9787eea4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a35d0357ac884d54aec072b206e7535c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b04d10e149ee4d7694dfca8ee5029f5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc64a146b8c4b938b522fc97510541a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ec9a6d2df174dc59b2718223e72e9da","IPY_MODEL_24e369e44af74a018c94e746f7acad48","IPY_MODEL_a17debfd92de44d9b23eeefb75225a28"],"layout":"IPY_MODEL_95f5784aea704f67ba10073af0222906"}},"4ec9a6d2df174dc59b2718223e72e9da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9e42f2cf8d443bfb1aa95d0862e2acc","placeholder":"​","style":"IPY_MODEL_d84c06b39d4e4daea721497db2998800","value":"config.json: 100%"}},"24e369e44af74a018c94e746f7acad48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1fa2ce5c8ec4abf99f7cce9134705a9","max":827,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9b790dd18854493bd80a68771b457bc","value":827}},"a17debfd92de44d9b23eeefb75225a28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca107895440a4c36af97b5db8de966f9","placeholder":"​","style":"IPY_MODEL_33b2a2280e604f80a35bf884957a0cce","value":" 827/827 [00:00&lt;00:00, 101kB/s]"}},"95f5784aea704f67ba10073af0222906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9e42f2cf8d443bfb1aa95d0862e2acc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84c06b39d4e4daea721497db2998800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1fa2ce5c8ec4abf99f7cce9134705a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b790dd18854493bd80a68771b457bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca107895440a4c36af97b5db8de966f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33b2a2280e604f80a35bf884957a0cce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e80575a87344138b346e5a6aa02c4e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2099194d95d480f9a5df7d1ea3fb610","IPY_MODEL_5ff38cb00f2540d096a9909a5b484796","IPY_MODEL_8d3471bf474941cfbace94ca8d0fbca6"],"layout":"IPY_MODEL_84f14ff84eba4d679a0408dc38a3fa2f"}},"d2099194d95d480f9a5df7d1ea3fb610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_963b5569231a46daa7fdee8ef84b8189","placeholder":"​","style":"IPY_MODEL_6cf3e3d516074575bf0d11dad1521485","value":"spiece.model: 100%"}},"5ff38cb00f2540d096a9909a5b484796":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23c010ad3b5b4ae389b7d46629f253a2","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe692b61a8e04f16b0d718bad4c2ea71","value":760289}},"8d3471bf474941cfbace94ca8d0fbca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9225bbd0fb1e4ab4868ee8792cd19d80","placeholder":"​","style":"IPY_MODEL_9aa6846c58cf4bdc9f39f689efaabd43","value":" 760k/760k [00:00&lt;00:00, 75.7MB/s]"}},"84f14ff84eba4d679a0408dc38a3fa2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963b5569231a46daa7fdee8ef84b8189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cf3e3d516074575bf0d11dad1521485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23c010ad3b5b4ae389b7d46629f253a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe692b61a8e04f16b0d718bad4c2ea71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9225bbd0fb1e4ab4868ee8792cd19d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa6846c58cf4bdc9f39f689efaabd43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d7ab395ea204de5be665a42cfa90f54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00791fef3d0c4d778041fd78349713d8","IPY_MODEL_b87fa2973ae44f51a9b366e54c7cd0da","IPY_MODEL_fd21113757cf42798b9ddc64e4c30317"],"layout":"IPY_MODEL_21f8458fb65a425bae8220b67e36250a"}},"00791fef3d0c4d778041fd78349713d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff6d3f8e1c934bc284c114988985ec2b","placeholder":"​","style":"IPY_MODEL_5fb8db3cb5f44fb38bb8368a3c4c14e6","value":"tokenizer.json: 100%"}},"b87fa2973ae44f51a9b366e54c7cd0da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5649c4d6ba3445afa44bd41295b43957","max":1311010,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3c50c8713ef4ac08e73465626048a78","value":1311010}},"fd21113757cf42798b9ddc64e4c30317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8c17a10a03a48069557f257f21d8459","placeholder":"​","style":"IPY_MODEL_06d0d2b4db2f4d66b50c8dfd53161493","value":" 1.31M/1.31M [00:00&lt;00:00, 18.1MB/s]"}},"21f8458fb65a425bae8220b67e36250a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6d3f8e1c934bc284c114988985ec2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb8db3cb5f44fb38bb8368a3c4c14e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5649c4d6ba3445afa44bd41295b43957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c50c8713ef4ac08e73465626048a78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8c17a10a03a48069557f257f21d8459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06d0d2b4db2f4d66b50c8dfd53161493":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9336a90fffe640ff81176b1213e7d5dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a8c195e925544a9ad51c7e81ee18384","IPY_MODEL_9cf3d1b386d242a8ba54a92eccc6a43b","IPY_MODEL_79f9a3c0025048dabbcf3253b4eb5c7a"],"layout":"IPY_MODEL_dda6ae87efc14bd98eeda352ceda26a3"}},"6a8c195e925544a9ad51c7e81ee18384":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_374fed6d5e2544e191ad1e08ab0fc565","placeholder":"​","style":"IPY_MODEL_7f1f1d094b7d4f8699853f183fee8c6a","value":"special_tokens_map.json: 100%"}},"9cf3d1b386d242a8ba54a92eccc6a43b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbf1a760145646b0b959bdca8b230df3","max":245,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3220883a6a074709bd35da9f2ca59d6d","value":245}},"79f9a3c0025048dabbcf3253b4eb5c7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d614cfca2441438f96a6d19e99abe375","placeholder":"​","style":"IPY_MODEL_1f1f72f6631c48e99c4192eb481743df","value":" 245/245 [00:00&lt;00:00, 30.2kB/s]"}},"dda6ae87efc14bd98eeda352ceda26a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"374fed6d5e2544e191ad1e08ab0fc565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f1f1d094b7d4f8699853f183fee8c6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbf1a760145646b0b959bdca8b230df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3220883a6a074709bd35da9f2ca59d6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d614cfca2441438f96a6d19e99abe375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f1f72f6631c48e99c4192eb481743df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad853de1c5a4de2ac40e03898f83b7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7822304c12d40978b33cd205d4ac1e9","IPY_MODEL_d7fdc1ef098744aa9d753b3216549b68","IPY_MODEL_9631324e1e5444928a39fe91f0347d0c"],"layout":"IPY_MODEL_c53a8fd59ff44c17bb00dbf0565f252a"}},"a7822304c12d40978b33cd205d4ac1e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe9cc3fe801349f89824a8bbbd859915","placeholder":"​","style":"IPY_MODEL_f1a0c9d8c5ae45dfb73c46fc957891d3","value":"model.safetensors: 100%"}},"d7fdc1ef098744aa9d753b3216549b68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e32ebb8aa5a24256b75a3ed4bd2161b6","max":46741600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0da362670eb440658e73bdfd7e13c8d9","value":46741600}},"9631324e1e5444928a39fe91f0347d0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de55984aa91e46dda25fb6cb806d79af","placeholder":"​","style":"IPY_MODEL_9b632f78b50d4a03a3f5efb0ea861329","value":" 46.7M/46.7M [00:00&lt;00:00, 187MB/s]"}},"c53a8fd59ff44c17bb00dbf0565f252a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe9cc3fe801349f89824a8bbbd859915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a0c9d8c5ae45dfb73c46fc957891d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e32ebb8aa5a24256b75a3ed4bd2161b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0da362670eb440658e73bdfd7e13c8d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de55984aa91e46dda25fb6cb806d79af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b632f78b50d4a03a3f5efb0ea861329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c993ee3dca74c7fabea6eaa6dba8941":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_222fc8937918437780ea04f4fe16e7ed","IPY_MODEL_760aaab16b544c1fa63bfe841f02eee8","IPY_MODEL_f59d0ade57054f25b52d393c0204a981"],"layout":"IPY_MODEL_56027c61842f4043a2677041d3ab88a9"}},"222fc8937918437780ea04f4fe16e7ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e762003ea694b87b2e48a6b9b223ab7","placeholder":"​","style":"IPY_MODEL_5864d12e8a5c40ddbc83f37edb0d26cb","value":"tokenizer_config.json: 100%"}},"760aaab16b544c1fa63bfe841f02eee8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_885187f76ce84a9280fd0e250e3b4b76","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1690ddabdf3d4ab491bb211c402be8ec","value":25}},"f59d0ade57054f25b52d393c0204a981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0215a5f131cd43db8f37a3f509fc1236","placeholder":"​","style":"IPY_MODEL_92d397a0ae6249229ff276c347635bb9","value":" 25.0/25.0 [00:00&lt;00:00, 3.08kB/s]"}},"56027c61842f4043a2677041d3ab88a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e762003ea694b87b2e48a6b9b223ab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5864d12e8a5c40ddbc83f37edb0d26cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"885187f76ce84a9280fd0e250e3b4b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1690ddabdf3d4ab491bb211c402be8ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0215a5f131cd43db8f37a3f509fc1236":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92d397a0ae6249229ff276c347635bb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32baae8c556e4249b2a27259dd41d07c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79f8df41bfbd4ca6a7a8b893c2679f0b","IPY_MODEL_4be694bd26c24b96812055f1072308d6","IPY_MODEL_360cdc5b28ae45b481a29698c9f123ea"],"layout":"IPY_MODEL_1cf5fa0962f542008b97942ac986832a"}},"79f8df41bfbd4ca6a7a8b893c2679f0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d788339bd0ae49da936e5f98dc4b97bd","placeholder":"​","style":"IPY_MODEL_bfe76fd999cb4b00b3fe71ae0350d41f","value":"config.json: 100%"}},"4be694bd26c24b96812055f1072308d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a86a1ec6ddd43c8a51b831a4ef295a7","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4aa2d0c5f924134b6bab6218601aaa9","value":481}},"360cdc5b28ae45b481a29698c9f123ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c48898c115584761a5bb379c2204a905","placeholder":"​","style":"IPY_MODEL_b6dce6643af34f0894eeb706027d9338","value":" 481/481 [00:00&lt;00:00, 61.9kB/s]"}},"1cf5fa0962f542008b97942ac986832a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d788339bd0ae49da936e5f98dc4b97bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfe76fd999cb4b00b3fe71ae0350d41f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a86a1ec6ddd43c8a51b831a4ef295a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4aa2d0c5f924134b6bab6218601aaa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c48898c115584761a5bb379c2204a905":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6dce6643af34f0894eeb706027d9338":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"076b0a045ef145d9b50fbfcc6e45def8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_535fa29e2352482eacfee35308893c78","IPY_MODEL_b03ab33e3eae4c42abedb76b03c7d1e8","IPY_MODEL_a460371e426b45ee81687188f44ab7c7"],"layout":"IPY_MODEL_a0b9124bbc6d410ba2ef6958a0092290"}},"535fa29e2352482eacfee35308893c78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d83ca7ff81734fe2b1dd9b7b1d23b9d8","placeholder":"​","style":"IPY_MODEL_574cee6b2deb42d794bf21d7ea7a63d2","value":"vocab.json: 100%"}},"b03ab33e3eae4c42abedb76b03c7d1e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb91f3c6cd44930a1f2bf0113424093","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_500d6b56b521466eb85f2ff63a2f00d9","value":898823}},"a460371e426b45ee81687188f44ab7c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ea9644a6620472298f0deba77ffefb2","placeholder":"​","style":"IPY_MODEL_2f30e50b6cc443cd8926fc5d42b0d56d","value":" 899k/899k [00:00&lt;00:00, 35.1MB/s]"}},"a0b9124bbc6d410ba2ef6958a0092290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d83ca7ff81734fe2b1dd9b7b1d23b9d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"574cee6b2deb42d794bf21d7ea7a63d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb91f3c6cd44930a1f2bf0113424093":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"500d6b56b521466eb85f2ff63a2f00d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ea9644a6620472298f0deba77ffefb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f30e50b6cc443cd8926fc5d42b0d56d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cdc09cbcda642b6b4c9cb46aad2ef7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02a1abff8e4d4453b48da02c4f89db72","IPY_MODEL_53084811783b44ababf1d1ee45cef78e","IPY_MODEL_1c55f2ba3efb4fecb50da5761a1aa644"],"layout":"IPY_MODEL_ba1bf99522e244f1a3321ad0a8986468"}},"02a1abff8e4d4453b48da02c4f89db72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16df382a6f724aa599751c3780646308","placeholder":"​","style":"IPY_MODEL_439aaff96c5c480a8a92b0ca8604e706","value":"merges.txt: 100%"}},"53084811783b44ababf1d1ee45cef78e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d151db52d5e493cbb775d7519453f85","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98c4b45d991b4ae3aabefb91a524f588","value":456318}},"1c55f2ba3efb4fecb50da5761a1aa644":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eee22eb65d44063bd58942226c66a53","placeholder":"​","style":"IPY_MODEL_23ee00d77956404bb5dcbcbae3ac7359","value":" 456k/456k [00:00&lt;00:00, 40.7MB/s]"}},"ba1bf99522e244f1a3321ad0a8986468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16df382a6f724aa599751c3780646308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"439aaff96c5c480a8a92b0ca8604e706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d151db52d5e493cbb775d7519453f85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98c4b45d991b4ae3aabefb91a524f588":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2eee22eb65d44063bd58942226c66a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23ee00d77956404bb5dcbcbae3ac7359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e625654715a645c598dbf3e8b3d82b29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b73ee7e7c964a029e5cfaf7577b0271","IPY_MODEL_6a4bb5349d334ba89a4ff598a58ec869","IPY_MODEL_c1b3b1fa8fbc454c8bb686b85e8cf2c6"],"layout":"IPY_MODEL_90eb93fbe8824653a242b1c5cf8ef58c"}},"1b73ee7e7c964a029e5cfaf7577b0271":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_434eac6ce2824698a10c35abfcf85f7b","placeholder":"​","style":"IPY_MODEL_53c257828eff4d76a7311582d54897c0","value":"tokenizer.json: 100%"}},"6a4bb5349d334ba89a4ff598a58ec869":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08a4a442f7684b83b2512f27674af64c","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_882397236b394fa2900f09dc4311b54c","value":1355863}},"c1b3b1fa8fbc454c8bb686b85e8cf2c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b99169cd5d13443caf1acd9a86df300e","placeholder":"​","style":"IPY_MODEL_cc598401f15e4a68a1f9c89947178fd8","value":" 1.36M/1.36M [00:00&lt;00:00, 6.50MB/s]"}},"90eb93fbe8824653a242b1c5cf8ef58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"434eac6ce2824698a10c35abfcf85f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c257828eff4d76a7311582d54897c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08a4a442f7684b83b2512f27674af64c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"882397236b394fa2900f09dc4311b54c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b99169cd5d13443caf1acd9a86df300e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc598401f15e4a68a1f9c89947178fd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf38e228e6f04f3eb3bb3b34e30d5b8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4a0be73470840df89dd39a385e147d0","IPY_MODEL_48e65eded86c4810b5b6836625c813e9","IPY_MODEL_99475dd37a6c400293f99771d82c728c"],"layout":"IPY_MODEL_f8b6ac486d014079a1231a3328cb952f"}},"c4a0be73470840df89dd39a385e147d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e67b02275ad4e81a8bd13498d34b36d","placeholder":"​","style":"IPY_MODEL_73d90ef2491a48df936ddb1a4e84aea5","value":"model.safetensors: 100%"}},"48e65eded86c4810b5b6836625c813e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98eee075a07d4ce79820a5547a938183","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05773aff8dd2434284468c20cae6ac69","value":498818054}},"99475dd37a6c400293f99771d82c728c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_601cd6589bf84dcfab179021242e51cf","placeholder":"​","style":"IPY_MODEL_05eb30b6c16c4f2abba71898d774497e","value":" 499M/499M [00:02&lt;00:00, 245MB/s]"}},"f8b6ac486d014079a1231a3328cb952f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e67b02275ad4e81a8bd13498d34b36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73d90ef2491a48df936ddb1a4e84aea5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98eee075a07d4ce79820a5547a938183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05773aff8dd2434284468c20cae6ac69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"601cd6589bf84dcfab179021242e51cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05eb30b6c16c4f2abba71898d774497e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c40551fd6a204496aab63746030dc133":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86e119d5fbc747c4a2f7d59f1522a520","IPY_MODEL_c5b3c566654b4744993d2c81a97eaece","IPY_MODEL_34341afe13524ef7b58c4c034f59b712"],"layout":"IPY_MODEL_7d759b781df44d619cccc2637fbabdfd"}},"86e119d5fbc747c4a2f7d59f1522a520":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b5e2b4c459849c9a84b9f76cb7d33a4","placeholder":"​","style":"IPY_MODEL_d34ab93ae1c241fd8df8c5ad3ab78f5b","value":"tokenizer_config.json: 100%"}},"c5b3c566654b4744993d2c81a97eaece":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ace896a7704f6a8ac6b0aea63fc040","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef5a943ccd764c1cbb33f22d4ae586e3","value":363}},"34341afe13524ef7b58c4c034f59b712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d32a13856244321805488f47acd5e30","placeholder":"​","style":"IPY_MODEL_6d681b94b74b4d1883dfa22210e6bce6","value":" 363/363 [00:00&lt;00:00, 40.5kB/s]"}},"7d759b781df44d619cccc2637fbabdfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5e2b4c459849c9a84b9f76cb7d33a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d34ab93ae1c241fd8df8c5ad3ab78f5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17ace896a7704f6a8ac6b0aea63fc040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5a943ccd764c1cbb33f22d4ae586e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d32a13856244321805488f47acd5e30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d681b94b74b4d1883dfa22210e6bce6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e22bbe20e7c40449a08f8ea798aa541":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_027b5fd9790c4119a4db1714c7803114","IPY_MODEL_8d2935eab487460db1980d1d3bc88d11","IPY_MODEL_9a07ef28e915401985ede6e114d23ac3"],"layout":"IPY_MODEL_a7020ce267484634b191980c8bb27cde"}},"027b5fd9790c4119a4db1714c7803114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_871ee480fc6b4f25b8d3202c7bbb2108","placeholder":"​","style":"IPY_MODEL_8cf608532abc445288921239fc584581","value":"vocab.txt: 100%"}},"8d2935eab487460db1980d1d3bc88d11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_691b378f0dac47589d0e083d36a55918","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9df2db4569194334abc01be470ba2cb8","value":231536}},"9a07ef28e915401985ede6e114d23ac3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10e43c6bab1346a582d417d5c0d4a12b","placeholder":"​","style":"IPY_MODEL_8b4f524b85154eb18d54b72698497f8d","value":" 232k/232k [00:00&lt;00:00, 353kB/s]"}},"a7020ce267484634b191980c8bb27cde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"871ee480fc6b4f25b8d3202c7bbb2108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cf608532abc445288921239fc584581":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"691b378f0dac47589d0e083d36a55918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9df2db4569194334abc01be470ba2cb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10e43c6bab1346a582d417d5c0d4a12b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4f524b85154eb18d54b72698497f8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f356e8df36c4a98a6d44c45d288ad59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80402d63b1fb475abd5d6a2f0aa2c01d","IPY_MODEL_d42d416adbf54582b1b83126c706a282","IPY_MODEL_3a34f246f2944fc5aed970fe56e503b8"],"layout":"IPY_MODEL_e40a241647734799ae4d1aa3d6f61cac"}},"80402d63b1fb475abd5d6a2f0aa2c01d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95dc6be54e324831831e6b5400840869","placeholder":"​","style":"IPY_MODEL_95ac6de2264a43ecab04912f2e5e0d0e","value":"tokenizer.json: 100%"}},"d42d416adbf54582b1b83126c706a282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05124c8c36ed45e09676865b96c352ee","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_974950d387554c92b2f5336ff0f72f0f","value":466021}},"3a34f246f2944fc5aed970fe56e503b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_011a1cfcbd37422bb330a1e443061f29","placeholder":"​","style":"IPY_MODEL_a1a57919da584dd9900b0b1157b57219","value":" 466k/466k [00:00&lt;00:00, 2.14MB/s]"}},"e40a241647734799ae4d1aa3d6f61cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95dc6be54e324831831e6b5400840869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ac6de2264a43ecab04912f2e5e0d0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05124c8c36ed45e09676865b96c352ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"974950d387554c92b2f5336ff0f72f0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"011a1cfcbd37422bb330a1e443061f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a57919da584dd9900b0b1157b57219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e09d175a5e2b4f899c0ce23f26177709":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ee658396d5c4fa5abe1ca349ee42c0a","IPY_MODEL_7f16de82fa3b496c9f9dde188b7243cc","IPY_MODEL_9acb0d31d3ed4c23803f5cf2d02d1028"],"layout":"IPY_MODEL_a150344daae14523a5d5ade8bd1ddad9"}},"2ee658396d5c4fa5abe1ca349ee42c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edf31995e80c4da69ac8fb3d38016191","placeholder":"​","style":"IPY_MODEL_8a59f4de8f67445798277f33237661c8","value":"special_tokens_map.json: 100%"}},"7f16de82fa3b496c9f9dde188b7243cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ef0bce0f70849299fdf61cd603389da","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf23cdc7fbc3415bb89e7a0a6a766745","value":239}},"9acb0d31d3ed4c23803f5cf2d02d1028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff9e189837474f3db7e4fcd40e807901","placeholder":"​","style":"IPY_MODEL_aa85b43b497e48808561dfd234e34d48","value":" 239/239 [00:00&lt;00:00, 29.7kB/s]"}},"a150344daae14523a5d5ade8bd1ddad9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edf31995e80c4da69ac8fb3d38016191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a59f4de8f67445798277f33237661c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ef0bce0f70849299fdf61cd603389da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf23cdc7fbc3415bb89e7a0a6a766745":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff9e189837474f3db7e4fcd40e807901":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa85b43b497e48808561dfd234e34d48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5204ebb5e3d54229a31a7e7c3d14f1dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebbc42abcdc642629b954ea41b8d7dda","IPY_MODEL_5030c9c0c7e94015bb50d2d830957d7e","IPY_MODEL_6e4351a9d7ba46509edacd81745a5651"],"layout":"IPY_MODEL_11a0c92e8aaf4292befa68d47fce9613"}},"ebbc42abcdc642629b954ea41b8d7dda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3982539096a04f738e6887c56590cf0f","placeholder":"​","style":"IPY_MODEL_ef6316aec90d4955bfe3eb412ef1f76b","value":"config.json: 100%"}},"5030c9c0c7e94015bb50d2d830957d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e68870ff030e41b4aad049f69e4b8601","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bf0776dfa69482a92a787667468eeed","value":571}},"6e4351a9d7ba46509edacd81745a5651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b095222e42f34fb9b3f7a99d65f3056c","placeholder":"​","style":"IPY_MODEL_7c3c3dc1b0384894865f38e1e00d9c2c","value":" 571/571 [00:00&lt;00:00, 71.4kB/s]"}},"11a0c92e8aaf4292befa68d47fce9613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3982539096a04f738e6887c56590cf0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef6316aec90d4955bfe3eb412ef1f76b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e68870ff030e41b4aad049f69e4b8601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf0776dfa69482a92a787667468eeed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b095222e42f34fb9b3f7a99d65f3056c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3c3dc1b0384894865f38e1e00d9c2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530960d0c3ba435cac9da593c9eed4f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48b9698da35a4f25b4269430ade864cf","IPY_MODEL_5992c320a8244327a29e8cacb09d2610","IPY_MODEL_21bf43765df046d3b88aa2adb9a13a38"],"layout":"IPY_MODEL_eec97ce4407c4fed9796aa533413bdcc"}},"48b9698da35a4f25b4269430ade864cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a854e24919c649d09e34218e71a8e81a","placeholder":"​","style":"IPY_MODEL_d5cc28f8fcc34aae9ee9f9c4ce99f727","value":"model.safetensors: 100%"}},"5992c320a8244327a29e8cacb09d2610":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72e04e288198402abb0a98f3000d829b","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4c71eabba65455790d9aa732d1eec4e","value":437971872}},"21bf43765df046d3b88aa2adb9a13a38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49891c85dba14f66869945fb5c333b86","placeholder":"​","style":"IPY_MODEL_82b56546da3f43f58ac5a710bd0e0b6d","value":" 438M/438M [00:01&lt;00:00, 243MB/s]"}},"eec97ce4407c4fed9796aa533413bdcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a854e24919c649d09e34218e71a8e81a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5cc28f8fcc34aae9ee9f9c4ce99f727":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72e04e288198402abb0a98f3000d829b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4c71eabba65455790d9aa732d1eec4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49891c85dba14f66869945fb5c333b86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b56546da3f43f58ac5a710bd0e0b6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4afcb99348e4455eb657df6dc90b8d55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_043ba573883243ed84eae5c122cadfc8","IPY_MODEL_46637e391a644e95a31f6c4ffea482b4","IPY_MODEL_1cece33f709f4968969431a001107471"],"layout":"IPY_MODEL_6e03178874a14cacb69ee820cae9f7eb"}},"043ba573883243ed84eae5c122cadfc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6206f9354227400aaa338c949f5ed6d9","placeholder":"​","style":"IPY_MODEL_82252d37f88f4ce899efc4a66eb00ada","value":"tokenizer_config.json: 100%"}},"46637e391a644e95a31f6c4ffea482b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10831fd8172e4ca49906e38d22019ac0","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e4394007b424a1fa1ff42b0cdb9d2a3","value":363}},"1cece33f709f4968969431a001107471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaaa7151dcf54e03b04bd540401c913a","placeholder":"​","style":"IPY_MODEL_245d0fa4859f4b9bbd2459741cd6b8fc","value":" 363/363 [00:00&lt;00:00, 40.3kB/s]"}},"6e03178874a14cacb69ee820cae9f7eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6206f9354227400aaa338c949f5ed6d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82252d37f88f4ce899efc4a66eb00ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10831fd8172e4ca49906e38d22019ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e4394007b424a1fa1ff42b0cdb9d2a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaaa7151dcf54e03b04bd540401c913a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"245d0fa4859f4b9bbd2459741cd6b8fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6dcc5e1172e4b269320196b412f8dd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd811fc2fec045a5a7478b4944e76d47","IPY_MODEL_423f990e1fa1454685046cb05f124582","IPY_MODEL_5a07a63a06d541b796c685101a4d5bef"],"layout":"IPY_MODEL_bf339a44ac38425f9f14368f08279c34"}},"bd811fc2fec045a5a7478b4944e76d47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2976cda4e4ee4ac29c75f23672caefdc","placeholder":"​","style":"IPY_MODEL_9172b438e6e14022bd3a6baa963cf1c0","value":"vocab.txt: 100%"}},"423f990e1fa1454685046cb05f124582":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeda576f6b3c47e7b50f42cf32e1cf44","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8555f5b6b8548ef80d4350b0ab75266","value":231536}},"5a07a63a06d541b796c685101a4d5bef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e957b33664fa427ba33dd7afb899c2b0","placeholder":"​","style":"IPY_MODEL_de1c78153912471e9435026330b7cf51","value":" 232k/232k [00:00&lt;00:00, 5.14MB/s]"}},"bf339a44ac38425f9f14368f08279c34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2976cda4e4ee4ac29c75f23672caefdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9172b438e6e14022bd3a6baa963cf1c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeda576f6b3c47e7b50f42cf32e1cf44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8555f5b6b8548ef80d4350b0ab75266":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e957b33664fa427ba33dd7afb899c2b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1c78153912471e9435026330b7cf51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dd0a7e565dd4faa96b4445e262961a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ca3a169545c46ff883273708acae34b","IPY_MODEL_c4064cc20e0e4b7ab20b85feda332b93","IPY_MODEL_98e7045b794c44be87d2ed6468e9fe37"],"layout":"IPY_MODEL_00286c5b428d46cf9a9484049c403645"}},"1ca3a169545c46ff883273708acae34b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29752e29de414966896999ff803e247a","placeholder":"​","style":"IPY_MODEL_9b82c1298b5d47a480bf8326cd60dc52","value":"tokenizer.json: 100%"}},"c4064cc20e0e4b7ab20b85feda332b93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5dbb4bc659b4f6484edcb73ee6740c4","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40c099ce79d14b3781ad2981081c30fe","value":466021}},"98e7045b794c44be87d2ed6468e9fe37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7181bd0612c44febc5879a9287dc36c","placeholder":"​","style":"IPY_MODEL_9e1f8babcc31473f8695169a9e428bb0","value":" 466k/466k [00:00&lt;00:00, 25.5MB/s]"}},"00286c5b428d46cf9a9484049c403645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29752e29de414966896999ff803e247a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b82c1298b5d47a480bf8326cd60dc52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5dbb4bc659b4f6484edcb73ee6740c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40c099ce79d14b3781ad2981081c30fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7181bd0612c44febc5879a9287dc36c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1f8babcc31473f8695169a9e428bb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81462ae1f1e246d08e91a0c39903bab3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efba3005f7534a45b74cde73ed808866","IPY_MODEL_b2a2a2675eb346fdb1d3493ac176f66c","IPY_MODEL_9da7a9aadb414c0d91d5a5f8c699e4a4"],"layout":"IPY_MODEL_e6ef7ca8cc3f4b36b60458604a8a8aa6"}},"efba3005f7534a45b74cde73ed808866":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_361fd45e55f444fd8c6f55a36a260226","placeholder":"​","style":"IPY_MODEL_df32a02e89564099a6c24032172c31cd","value":"special_tokens_map.json: 100%"}},"b2a2a2675eb346fdb1d3493ac176f66c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2866345a6c304fd18be9c81767a422a2","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_340951ee2ee84154881538efd6c2b25a","value":239}},"9da7a9aadb414c0d91d5a5f8c699e4a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d78e010b0048e9a231b1ac5ae29298","placeholder":"​","style":"IPY_MODEL_9b6766513f484dc39963f4ba5b10d968","value":" 239/239 [00:00&lt;00:00, 27.8kB/s]"}},"e6ef7ca8cc3f4b36b60458604a8a8aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"361fd45e55f444fd8c6f55a36a260226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df32a02e89564099a6c24032172c31cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2866345a6c304fd18be9c81767a422a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340951ee2ee84154881538efd6c2b25a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41d78e010b0048e9a231b1ac5ae29298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b6766513f484dc39963f4ba5b10d968":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"496250acd5214604aaf5f1addf57af84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6397a36de43b43aa956aed411c458802","IPY_MODEL_8ee51089fa224bacafbb333651cd9d2e","IPY_MODEL_d9ca8ed4e0f642e5984793ff2ad38fe3"],"layout":"IPY_MODEL_792784c6717847b392179ef5a4253ba0"}},"6397a36de43b43aa956aed411c458802":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0765d4ccc95b42dd8f325f6c4143d9af","placeholder":"​","style":"IPY_MODEL_ec02d3b7b91d461e8ca2a3d76f6c5eef","value":"config.json: 100%"}},"8ee51089fa224bacafbb333651cd9d2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b43ef958e104718ae3acb5e4f5438e2","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cce8b056a5c24e5e864975047f43821e","value":571}},"d9ca8ed4e0f642e5984793ff2ad38fe3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d132da83c364428a9aef93cfe521652","placeholder":"​","style":"IPY_MODEL_6b015832db32471098fb316fa3776a80","value":" 571/571 [00:00&lt;00:00, 69.9kB/s]"}},"792784c6717847b392179ef5a4253ba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0765d4ccc95b42dd8f325f6c4143d9af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec02d3b7b91d461e8ca2a3d76f6c5eef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b43ef958e104718ae3acb5e4f5438e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce8b056a5c24e5e864975047f43821e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d132da83c364428a9aef93cfe521652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b015832db32471098fb316fa3776a80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f5092bedaa4449ba25e93e1ca84f499":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_209c5b062cb44907829c22d73c456662","IPY_MODEL_64789556d8a74b759be291ba6d95b6c9","IPY_MODEL_f289bc83dcc14017a2d619741e3f13f6"],"layout":"IPY_MODEL_b27f549196654a44922b8a181bcb06d7"}},"209c5b062cb44907829c22d73c456662":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97228d11746c4fe181ccc9ca0aea07a5","placeholder":"​","style":"IPY_MODEL_ba41f1eddf5f4848b66a0aef6ceeaf1a","value":"model.safetensors: 100%"}},"64789556d8a74b759be291ba6d95b6c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3951336c50143a2b6196e0b53b017a4","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dc7310ce2fb40adbdab07580499e345","value":437971872}},"f289bc83dcc14017a2d619741e3f13f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b773383be994c59b31e5a5e0a7cf9e4","placeholder":"​","style":"IPY_MODEL_719a108a45d944daaa220a5b817e4a81","value":" 438M/438M [00:01&lt;00:00, 231MB/s]"}},"b27f549196654a44922b8a181bcb06d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97228d11746c4fe181ccc9ca0aea07a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba41f1eddf5f4848b66a0aef6ceeaf1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3951336c50143a2b6196e0b53b017a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dc7310ce2fb40adbdab07580499e345":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b773383be994c59b31e5a5e0a7cf9e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"719a108a45d944daaa220a5b817e4a81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}