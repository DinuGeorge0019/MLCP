{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14885,"status":"ok","timestamp":1739027426837,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"xe8Eih0hHc2-","outputId":"23a68e8b-4809-403f-d982-f3007d12747b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1739027427205,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"YmNUmwcdHc3B","outputId":"7dd9ceaa-dcf8-4a9d-dc24-938dd4f66625"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2519,"status":"ok","timestamp":1739027429726,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"qIIAqc0VIDm4","outputId":"1e604b44-9174-41b2-9827-0cdc8f4ba32a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n","Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}],"source":["# install dependencies\n","\n","# !pip install catboost\n","!pip install scikit-multilearn\n","# !pip install --upgrade tensorflow-addons\n","# !pip install sentence-transformers\n","# !pip install --upgrade tensorflow-addons\n","# !pip install dask[dataframe]\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1739027429742,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"T2lmJ49jGPJE","outputId":"30e3185c-deb6-46e3-ad21-6a38efe8ef16"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":920,"status":"ok","timestamp":1739027430662,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"7T7YDX_3GPJE","outputId":"d105b168-e124-4212-fafc-3f14c01f1a58"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"elapsed":2129,"status":"error","timestamp":1739027432803,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"vnQee3H_Hc3B","outputId":"93859f2d-fe9d-4e36-8869-ed550be4af9a"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-31747437e9e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapp_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"This is a test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is another test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is a third test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCustomEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomEncoder\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mClassifierChainWrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/CustomEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# related third-party\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackboneMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeHintParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_json_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m from .doc import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_jinja_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImmutableSandboxedEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jinja2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbccache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileSystemBytecodeCache\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFileSystemBytecodeCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbccache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemcachedBytecodeCache\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMemcachedBytecodeCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvironment\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplateAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTemplateAssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jinja2/environment.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmarkupsafe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from app_src import CustomEncoder\n","\n","encoder = CustomEncoder(\"bert-base-uncased\")\n","data = [\"This is a test\", \"This is another test\", \"This is a third test\"]\n","\n","encodded_sentence = encoder.encode_problem_statement(data)\n","print(encodded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":23706,"status":"error","timestamp":1738784679685,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"AL8NTNOKHc3C","outputId":"abb35947-c589-4a59-e7ac-fde63c1314b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"error","ename":"TypeError","evalue":"ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-97d0783496a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifierChainWrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given"]}],"source":["from app_src import ClassifierChainWrapper\n","from sklearn.ensemble import RandomForestClassifier\n","\n","classifierChainWrapper = ClassifierChainWrapper(RandomForestClassifier(), \"bert-base-uncased\", 5)\n","classifierChainWrapper.fit()\n","metrics_results = classifierChainWrapper.predict()\n","\n","for metric_name, metric_value in metrics_results.items():\n","    print(f\"{metric_name}: {metric_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":21,"status":"error","timestamp":1738784694006,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"2V2DZ5O5wpXk","outputId":"d20aeebd-4329-42fc-84ea-6727ce8dad68"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DecisionTreeEvaluator' object has no attribute 'benchmark_models'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f48c8ed72720>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecisionTreeEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecisionTreeEvaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeEvaluator' object has no attribute 'benchmark_models'"]}],"source":["from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=5)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4154,"status":"ok","timestamp":1738441980041,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"UMkaJZsOBid0","outputId":"607490d9-83ea-4484-8a63-e7bc11428d7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.18.0\n","CUDA version: 12.5.1\n","CUDNN version: 9\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","build_info = tf.sysconfig.get_build_info()\n","print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Unknown\"))\n","print(\"CUDNN version:\", build_info.get(\"cudnn_version\", \"Unknown\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729,"referenced_widgets":["7ee763e22b064a0fbcf9b42ccf97b9ca","40fb4eea828a47eebde3deffb34eccaf","6c28c29db2b54a68809be4927f2e6561","156e7b3dc5c74377abf997088f5d5039","143f3f72648947628be426536c54165a","d465a2294ac346fcaeb1e40f905431ed","e8217faab1a64813989a48f3bc71980e","31789b2281b447e9a533802256b73e32","ffa3a842b49943ba8fffe30c63b7e803","0e0b5259abee4a00b2aed377427faebc","b1298a3565b24588878eab99a2f778d2"]},"executionInfo":{"elapsed":222505,"status":"ok","timestamp":1738622095096,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"_DhP3q-Htoh9","outputId":"8783a6b1-64b3-4e8d-bf2b-f3990fc2ee04"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n","GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:  24%|##3       | 126M/532M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee763e22b064a0fbcf9b42ccf97b9ca"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFMPNetModel were not initialized from the PyTorch model and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962ms/step - auc: 0.5180 - binary_accuracy: 0.4868 - label_wise_accuracy: 0.5003 - label_wise_f1_score: 0.4110 - label_wise_macro_f1: 0.4369 - loss: 0.7062 - prc_auc: 0.3934 - precision: 0.3981 - recall: 0.6753 - subset_accuracy: 0.0170 - subset_f1: 0.4971 - subset_precision: 0.3978 - subset_recall: 0.6687\n","Epoch 1: Validation Metrics:\n","loss: 0.7000761032104492\n","val_label_wise_f1_score: [0.6046511  0.31999996 0.         0.6666666  0.        ]\n","val_label_wise_accuracy: [0.46875 0.46875 0.6875  0.53125 0.71875]\n","val_binary_accuracy: 0.5161765217781067\n","val_precision: 0.40509089827537537\n","val_recall: 0.5279620885848999\n","val_label_wise_macro_f1: 0.35385945439338684\n","val_subset_accuracy: 0.03492647036910057\n","val_subset_precision: 0.4010416865348816\n","val_subset_recall: 0.5241115093231201\n","val_subset_f1: 0.45356810092926025\n","val_auc: 0.5249963998794556\n","val_prc_auc: 0.40708646178245544\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - auc: 0.5181 - binary_accuracy: 0.4868 - label_wise_accuracy: 0.5008 - label_wise_f1_score: 0.4104 - label_wise_macro_f1: 0.4367 - loss: 0.7061 - prc_auc: 0.3935 - precision: 0.3981 - recall: 0.6750 - subset_accuracy: 0.0171 - subset_f1: 0.4970 - subset_precision: 0.3979 - subset_recall: 0.6683 - val_auc: 0.5250 - val_binary_accuracy: 0.5162 - val_label_wise_accuracy: 0.5750 - val_label_wise_f1_score: 0.3183 - val_label_wise_macro_f1: 0.3539 - val_loss: 0.6918 - val_prc_auc: 0.4071 - val_precision: 0.4051 - val_recall: 0.5280 - val_subset_accuracy: 0.0349 - val_subset_f1: 0.4536 - val_subset_precision: 0.4010 - val_subset_recall: 0.5241\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_223120\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250203_223120.weights.h5\n"]}],"source":["import os\n","import tensorflow as tf\n","\n","# Check if GPU is available and print details\n","if tf.config.experimental.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","    print(\"GPU details:\", tf.config.list_physical_devices('GPU'))\n","else:\n","    print(\"GPU not available, using CPU\")\n","\n","# # If GPU is available, try setting memory growth\n","# gpus = tf.config.list_physical_devices('GPU')\n","# if gpus:\n","#     try:\n","#         # Currently, memory growth needs to be the same across GPUs\n","#         for gpu in gpus:\n","#             tf.config.experimental.set_memory_growth(gpu, True)\n","#         logical_gpus = tf.config.list_logical_devices('GPU')\n","#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#     except RuntimeError as e:\n","#         # Memory growth must be set before GPUs have been initialized\n","#         print('Error')\n","#         print(e)\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"microsoft/mpnet-base\", NUMBER_OF_TAGS)\n","sentenceTransformerWrapper.train_model(\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=32,\n","    train_model=True\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59070,"status":"ok","timestamp":1738622242973,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"Pd4K7EOOtoh9","outputId":"d6499eee-9aa8-4b77-fa81-b902b942e2ee"},"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_223120.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded from /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250203_223120.weights.h5\n","\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 990ms/step - auc: 0.5208 - binary_accuracy: 0.5071 - label_wise_accuracy: 0.5067 - label_wise_f1_score: 0.3501 - label_wise_macro_f1: 0.3516 - loss: 0.6924 - prc_auc: 0.4088 - precision: 0.3994 - recall: 0.5128 - subset_accuracy: 0.0333 - subset_f1: 0.4498 - subset_precision: 0.4007 - subset_recall: 0.5159\n","Evaluation Metrics:\n","Loss: 0.6929304599761963\n","Label F1 Scores: [0.56410253 0.4705882  0.09999999 0.43243238 0.        ]\n","Label Accuracies: [0.46875 0.4375  0.4375  0.34375 0.75   ]\n","Accuracy: 0.5071220993995667\n","Precision: 0.3944847583770752\n","Recall: 0.5101351141929626\n","F1 Score: 0.3509281873703003\n","Subset Accuracy: 0.028343023732304573\n","Subset Precision: 0.3935804069042206\n","Subset Recall: 0.5103682279586792\n","Subset F1: 0.44326552748680115\n","AUC: 0.5183724164962769\n","PRC AUC: 0.4017588496208191\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Loss': 0.6929304599761963,\n"," 'Label F1 Scores': array([0.56410253, 0.4705882 , 0.09999999, 0.43243238, 0.        ],\n","       dtype=float32),\n"," 'Label Accuracies': array([0.46875, 0.4375 , 0.4375 , 0.34375, 0.75   ], dtype=float32),\n"," 'Accuracy': 0.5071220993995667,\n"," 'Precision': 0.3944847583770752,\n"," 'Recall': 0.5101351141929626,\n"," 'F1 Score': 0.3509281873703003,\n"," 'Subset Accuracy': 0.028343023732304573,\n"," 'Subset Precision': 0.3935804069042206,\n"," 'Subset Recall': 0.5103682279586792,\n"," 'Subset F1': 0.44326552748680115,\n"," 'AUC': 0.5183724164962769,\n"," 'PRC AUC': 0.4017588496208191}"]},"metadata":{},"execution_count":12}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"microsoft/mpnet-base\", NUMBER_OF_TAGS)\n","\n","sentenceTransformerWrapper.benchmark_model(\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH'],\n","    batch_size=32,\n","    model_path= os.path.join(CONFIG[\"MODEL_SAVE_PATH_ROOT\"], 'custom_model_20250203_223120.weights.h5'),\n","    transformer_model_path= os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250203_223120')\n","    )"]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=1,\n","    batch_size=32,\n","    number_of_tags=5,\n","    train_model=True,\n","    threshold=0.5\n","  )\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCcdWL_XfxIG","executionInfo":{"status":"ok","timestamp":1738962760192,"user_tz":-120,"elapsed":55355,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"a41735a1-0e6e-4cd6-a14a-ee43e3b8c7b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.4902 - binary_accuracy: 0.4628 - label_wise_accuracy: 0.4950 - label_wise_f1_score: 0.3594 - label_wise_macro_f1: 0.3763 - loss: 0.7013 - prc_auc: 0.3108 - precision: 0.3101 - recall: 0.5722 - subset_accuracy: 0.0220 - subset_f1: 0.3961 - subset_precision: 0.3053 - subset_recall: 0.5734\n","Epoch 1: Validation Metrics:\n","loss: 0.6955702900886536\n","val_label_wise_f1_score: [0.2222222  0.39999995 0.19999996 0.24999996 0.1428571 ]\n","val_label_wise_accuracy: [0.78125 0.53125 0.5     0.4375  0.625  ]\n","val_binary_accuracy: 0.5491666793823242\n","val_precision: 0.32087913155555725\n","val_recall: 0.38624337315559387\n","val_label_wise_macro_f1: 0.31174829602241516\n","val_subset_accuracy: 0.0625\n","val_subset_precision: 0.2865277826786041\n","val_subset_recall: 0.3822569251060486\n","val_subset_f1: 0.32612332701683044\n","val_auc: 0.5089168548583984\n","val_prc_auc: 0.32180047035217285\n","\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 105ms/step - auc: 0.4902 - binary_accuracy: 0.4629 - label_wise_accuracy: 0.4953 - label_wise_f1_score: 0.3590 - label_wise_macro_f1: 0.3762 - loss: 0.7013 - prc_auc: 0.3108 - precision: 0.3101 - recall: 0.5720 - subset_accuracy: 0.0220 - subset_f1: 0.3961 - subset_precision: 0.3053 - subset_recall: 0.5731 - val_auc: 0.5089 - val_binary_accuracy: 0.5492 - val_label_wise_accuracy: 0.5750 - val_label_wise_f1_score: 0.2430 - val_label_wise_macro_f1: 0.3117 - val_loss: 0.6863 - val_prc_auc: 0.3218 - val_precision: 0.3209 - val_recall: 0.3862 - val_subset_accuracy: 0.0625 - val_subset_f1: 0.3261 - val_subset_precision: 0.2865 - val_subset_recall: 0.3823\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250207_210225\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250207_210225.weights.h5\n","Using the trained model\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - auc: 0.4993 - binary_accuracy: 0.5539 - label_wise_accuracy: 0.5617 - label_wise_f1_score: 0.3158 - label_wise_macro_f1: 0.3119 - loss: 0.6873 - prc_auc: 0.3324 - precision: 0.3296 - recall: 0.3664 - subset_accuracy: 0.0578 - subset_f1: 0.3298 - subset_precision: 0.3002 - subset_recall: 0.3701\n","Evaluation Metrics:\n","Loss: 0.6860524415969849\n","Label F1 Scores: [0.26666662 0.48275852 0.4615384  0.27586204 0.28571424]\n","Label Accuracies: [0.65625 0.53125 0.78125 0.34375 0.6875 ]\n","Accuracy: 0.5606907606124878\n","Precision: 0.33256879448890686\n","Recall: 0.37351879477500916\n","F1 Score: 0.31481698155403137\n","Subset Accuracy: 0.06003289297223091\n","Subset Precision: 0.3043448328971863\n","Subset Recall: 0.3727933466434479\n","Subset F1: 0.3330017626285553\n","AUC: 0.5105616450309753\n","PRC AUC: 0.3324340581893921\n"]}]},{"cell_type":"code","source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='microsoft/mpnet-base',\n","    model_path= os.path.join(CONFIG[\"MODEL_SAVE_PATH_ROOT\"], 'custom_model_20250203_225321.weights.h5'),\n","    transformer_model_path= os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250203_225321')\n","    )"],"metadata":{"id":"QNraNQLMG2Ga","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738627541119,"user_tz":-120,"elapsed":495627,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"5c208d8d-1b71-4a42-84e8-676813dfe553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_225321.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model from: /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_225321\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 158/158 [03:28<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 44/44 [00:57<00:00,  1.32s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 2241, number of negative: 2784\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025515 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445970 -> initscore=-0.216967\n","[LightGBM] [Info] Start training from score -0.216967\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1979, number of negative: 3046\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015391 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195842\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 769\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393831 -> initscore=-0.431238\n","[LightGBM] [Info] Start training from score -0.431238\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1883, number of negative: 3142\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014327 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195844\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 770\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.374726 -> initscore=-0.511993\n","[LightGBM] [Info] Start training from score -0.511993\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1849, number of negative: 3176\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014668 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195846\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 771\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.367960 -> initscore=-0.540978\n","[LightGBM] [Info] Start training from score -0.540978\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1677, number of negative: 3348\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022198 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195848\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 772\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333731 -> initscore=-0.691357\n","[LightGBM] [Info] Start training from score -0.691357\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: SVC\n"]}]},{"cell_type":"code","source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2'\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a76d43f7e247423d8bd0267409172ae1","8ef25127aea24b65aed075efbf782bd9","4905559eaa5b40779fa2d579308ddeb3","ec09a2d650af46328f1be4ad121ed09f","42f3658a4ec241fc93c783ee84caa9cf","aa274429fd264ada9935779eaa1ca354","faaa9d56430f4cd1854b1775bc3172ba","baa06b0ec2d34d02b113f8503fddc216","d441459d1c884b52b9772285b2fd17f0","9c4cd35bd3c64007a9744c871f60f686","b1ae715e675d45c2957a160069ac7d08","76c7ede6ff5e462a8312821bad1a8202","4dc6ae2f526f4653a54c0c07381768db","c42874edb92e43cca983af83dc96420b","4bdb5352724c40eb9d493cb1efd743d1","d4da583e676f4d08a7e4356e6c19f394","6812d035d701491cb605814f86bcbb3e","4549d9c099ab48e88afcbb1d8f4c789d","224fb6448d974adc8c89a7e5d92893f2","ca45baf4c67c4a679a7300e9fb6e18d3","ae478ac2bfec4d3694f2550a6e7d28e8","1969c0b6db9c4f47b22607038a7b1a79","37822c1dea7c4066891fe9dc2bfad9de","0607fc3d5ee2416ea523bd5cce0e8c80","4b42397cb6fa4f13a52fcdfc4e7d7095","115fb8c0adf84e5687cdfecaddc7fc88","b469b0c304d84cbe9467cc76204428c5","15ff464abd8f4c98bcacb672569a8dc6","824bdcb736db49b0b01e101f3d4bbe32","dbca1f857e064aeeabac2f8eac9c9ba7","ae0bdf64c6fe474ba4b361a10d3406ab","5a2a9545b11644b6a7c683c3baa92760","54739fd4f13d4b128a24de6e70c503f3","cd6805a6b4bc490bb3dabb61504ab8e6","fed591da0d304c0f8b320ff464c5666c","2c6bd7e97ea2414aac33c456b046e873","6dd438058253463ab15a65ad8f33192f","1872502f5bbf42d1827f773b9bcd37f6","eee4ebb41d904ad7a3084540c6b2f33a","229551aa84fd4c7787adcc867eabba53","a75a543c4a414a9e98646af48b6bbe80","c77a74539b4a4ca7a56aae18c674362e","67b0ded56d4342698ab40156896dbef3","da87376fe355463386e1bcae2d6146d4","f394cc47b76c424ea50f39894d33a95e","ae139a3cd6614bdb8b13997dfa0926c7","e3067982ccdd4f4b9e25d084782b196b","b2026bb57acb43ccabb5254e5a74b4d6","5c535e651f1c4adcbaa60791742af937","25c1221c444c4c6e81dc25e8ab06143f","359a25604e64401bba227185ae1c76c6","e2efb55c88a44d24941853097ec4a60d","bcb1e5270d0b4d76ad75e7f33f15895a","18c24b0b760a4b5e8dfcbace68fd7469","f9642ec2fd524b17a5a1ce5f4f5c1ee1","64e547717c224c02981da5a4ff0462a4","810f6376fd9e4b4589f1d76bdbbba698","65b9b5ea95334da8a0519f61e9dd4c8b","3a0217664365498e81c1375d11696089","a763decf210b4bb19269b66251f8ff6f","36965743912a4bbc83a05b3c55b9e544","fcb2b70818dd4586bc146ccf99f08869","b654486cb19443ec88cba4f74f18da7b","ece2b16bff0d42e1a080df7ff743a59d","42f47dbea5d44dff9749627569b344e3","afd7b77b1b5e41b9aa344ef3d4af6eee"]},"id":"P780gFGDJfn_","executionInfo":{"status":"ok","timestamp":1738962694527,"user_tz":-120,"elapsed":570286,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"d4957257-75fd-4827-f2ea-e6d532f9d1be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a76d43f7e247423d8bd0267409172ae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c7ede6ff5e462a8312821bad1a8202"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37822c1dea7c4066891fe9dc2bfad9de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd6805a6b4bc490bb3dabb61504ab8e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f394cc47b76c424ea50f39894d33a95e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64e547717c224c02981da5a4ff0462a4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 279/279 [01:04<00:00,  4.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 39/39 [00:08<00:00,  4.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 3400, number of negative: 5516\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048537 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381337 -> initscore=-0.483878\n","[LightGBM] [Info] Start training from score -0.483878\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 3334, number of negative: 5582\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024986 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195842\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 769\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373934 -> initscore=-0.515374\n","[LightGBM] [Info] Start training from score -0.515374\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 2998, number of negative: 5918\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022292 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195844\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 770\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336249 -> initscore=-0.680053\n","[LightGBM] [Info] Start training from score -0.680053\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 2390, number of negative: 6526\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022028 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195846\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 771\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268057 -> initscore=-1.004501\n","[LightGBM] [Info] Start training from score -1.004501\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 2024, number of negative: 6892\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020946 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195848\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 772\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227008 -> initscore=-1.225286\n","[LightGBM] [Info] Start training from score -1.225286\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: SVC\n"]}]},{"cell_type":"code","source":["import os\n","\n","# local application/library specific imports\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import OneVsAllDecisionTreeEvaluator\n","\n","decisionTreeEvaluator = OneVsAllDecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2'\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNyOaKubFYPY","executionInfo":{"status":"ok","timestamp":1738956382290,"user_tz":-120,"elapsed":230748,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"8b8ad66c-8d94-4bca-cf4c-ba4905b43071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 39/39 [00:08<00:00,  4.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1700, number of negative: 2758\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014652 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381337 -> initscore=-0.483878\n","[LightGBM] [Info] Start training from score -0.483878\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1667, number of negative: 2791\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373934 -> initscore=-0.515374\n","[LightGBM] [Info] Start training from score -0.515374\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1499, number of negative: 2959\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021165 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336249 -> initscore=-0.680053\n","[LightGBM] [Info] Start training from score -0.680053\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1195, number of negative: 3263\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012665 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268057 -> initscore=-1.004501\n","[LightGBM] [Info] Start training from score -1.004501\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1012, number of negative: 3446\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012527 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227008 -> initscore=-1.225286\n","[LightGBM] [Info] Start training from score -1.225286\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: SVC\n"]}]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=1,\n","    batch_size=32,\n","    number_of_tags=5,\n","    train_model=True,\n","    threshold=0.5\n","  )\n","\n"],"metadata":{"id":"PHgqiOcBdQh_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738956594129,"user_tz":-120,"elapsed":211836,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"e2435a46-4a1b-4fc4-b144-318752f8cbf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4729 - binary_accuracy: 0.5651 - f1: 0.2521 - loss: 0.6864 - prc_auc: 0.3631 - precision: 0.3538 - recall: 0.1969\n","Epoch 1: Validation Metrics:\n","loss: 0.686181902885437\n","val_binary_accuracy: 0.5854166746139526\n","val_precision: 0.40625\n","val_recall: 0.13903743028640747\n","val_auc: 0.46750378608703613\n","val_prc_auc: 0.38557296991348267\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - auc: 0.4729 - binary_accuracy: 0.5651 - f1: 0.2519 - loss: 0.6864 - prc_auc: 0.3631 - precision: 0.3538 - recall: 0.1966 - val_auc: 0.4675 - val_binary_accuracy: 0.5854 - val_f1: 0.2072 - val_loss: 0.6849 - val_prc_auc: 0.3856 - val_precision: 0.4062 - val_recall: 0.1390\n","Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.5482 - binary_accuracy: 0.4909 - f1: 0.4986 - loss: 0.6955 - prc_auc: 0.4098 - precision: 0.3935 - recall: 0.6811\n","Epoch 1: Validation Metrics:\n","loss: 0.6955739855766296\n","val_binary_accuracy: 0.5395833253860474\n","val_precision: 0.4117647111415863\n","val_recall: 0.5474860072135925\n","val_auc: 0.5642551183700562\n","val_prc_auc: 0.4129665791988373\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - auc: 0.5481 - binary_accuracy: 0.4909 - f1: 0.4985 - loss: 0.6955 - prc_auc: 0.4097 - precision: 0.3935 - recall: 0.6807 - val_auc: 0.5643 - val_binary_accuracy: 0.5396 - val_f1: 0.4700 - val_loss: 0.6895 - val_prc_auc: 0.4130 - val_precision: 0.4118 - val_recall: 0.5475\n","Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5426 - binary_accuracy: 0.5497 - f1: 0.4158 - loss: 0.6886 - prc_auc: 0.3782 - precision: 0.3669 - recall: 0.4815\n","Epoch 1: Validation Metrics:\n","loss: 0.6873651742935181\n","val_binary_accuracy: 0.5791666507720947\n","val_precision: 0.39436620473861694\n","val_recall: 0.3255814015865326\n","val_auc: 0.5228216648101807\n","val_prc_auc: 0.38145366311073303\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 113ms/step - auc: 0.5425 - binary_accuracy: 0.5498 - f1: 0.4157 - loss: 0.6886 - prc_auc: 0.3782 - precision: 0.3669 - recall: 0.4811 - val_auc: 0.5228 - val_binary_accuracy: 0.5792 - val_f1: 0.3567 - val_loss: 0.6860 - val_prc_auc: 0.3815 - val_precision: 0.3944 - val_recall: 0.3256\n","Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4647 - binary_accuracy: 0.4365 - f1: 0.3634 - loss: 0.7060 - prc_auc: 0.2438 - precision: 0.2610 - recall: 0.6001\n","Epoch 1: Validation Metrics:\n","loss: 0.7018375992774963\n","val_binary_accuracy: 0.48750001192092896\n","val_precision: 0.22466960549354553\n","val_recall: 0.42148759961128235\n","val_auc: 0.4521167576313019\n","val_prc_auc: 0.21609055995941162\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 113ms/step - auc: 0.4647 - binary_accuracy: 0.4367 - f1: 0.3632 - loss: 0.7060 - prc_auc: 0.2438 - precision: 0.2609 - recall: 0.5996 - val_auc: 0.4521 - val_binary_accuracy: 0.4875 - val_f1: 0.2931 - val_loss: 0.6973 - val_prc_auc: 0.2161 - val_precision: 0.2247 - val_recall: 0.4215\n","Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4654 - binary_accuracy: 0.6132 - f1: 0.2177 - loss: 0.6776 - prc_auc: 0.2102 - precision: 0.2005 - recall: 0.2400\n","Epoch 1: Validation Metrics:\n","loss: 0.6737685799598694\n","val_binary_accuracy: 0.6833333373069763\n","val_precision: 0.11267605423927307\n","val_recall: 0.0824742242693901\n","val_auc: 0.46710723638534546\n","val_prc_auc: 0.177982896566391\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - auc: 0.4654 - binary_accuracy: 0.6133 - f1: 0.2176 - loss: 0.6775 - prc_auc: 0.2101 - precision: 0.2005 - recall: 0.2397 - val_auc: 0.4671 - val_binary_accuracy: 0.6833 - val_f1: 0.0952 - val_loss: 0.6616 - val_prc_auc: 0.1780 - val_precision: 0.1127 - val_recall: 0.0825\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 249ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 204ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step\n","[[0 1 1 0 0]\n"," [0 0 1 0 0]\n"," [0 0 1 0 0]\n"," ...\n"," [0 1 0 1 0]\n"," [0 1 0 0 0]\n"," [0 1 0 1 0]]\n","[[0 0 1 0 0]\n"," [0 1 1 0 0]\n"," [0 1 1 0 0]\n"," ...\n"," [0 0 0 1 1]\n"," [0 0 1 0 0]\n"," [1 1 1 0 0]]\n","test_tags_np shape: (1239, 5)\n","predictions shape: (1239, 5)\n"]}]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path=CONFIG[f'NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=8,\n","  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":854,"referenced_widgets":["2f635272bf644c7b9ad6bb16fa33c37a","70a7cbdb50c143cfa4298bd259f6aef5","3eea70bc6c1342adbbcd5908cc6daca4","c5e87a540e0f4b0f9b5709b8a6563a43","d6bbffac4b6f4009b0b8af1a62bc5fac","5dd19023684c456291509a08ac6ce5a3","e3569a6c63ca45d2ae9e9137b338873b","6f738b7c382b44359466ee6413363af9","f69617c85c524ca78322b4dc8ef42577","6aaa16ad43c64fb1ab63982c03d86c12","d84611313b97485480ec523d41109278","7244c912ef1045a2b2fd29bcb9b2e727","5385c6191ac04ead91602e56def2a1d1","8369bf148dc743b9a3581ffa70498a20","65b142e468454bb1b12b00a62949f344","254581d36a57430692197f27fbc5c9d0","c5f9fc059e324b24b3a8ed8c632b4227","0310de90a49742a38e0aae681cab3236","7874e24a3cf34985abcc6633189531d1","46ebb0ff5b4d4c2e8b4910697fbbc5e9","e485b2f7cb9b426fb2e9b7c5a4df5abc","3be9abd9636b4e80848a69567d13d344","f8b668d3617045afb5dc263e8e0acf35","32cdff0727ff46738c1b6a77907ec3a9","481afab291534683a24f4c8bd8dcacd1","5827a19677064259ad6f909991f31ad1","5dceb45faa7a45bab4b5d380777ba621","b4be74ce7a624bd7b1b6b59691e9b767","7d62c1d00ad4441c928ff95d584835eb","cd6cc25d55614c459829e65197b20ed1","0cc995370b2347218eec81a7367dc9d2","f5581b7550204b2982c8e08d30944749","6115617d8bd2468faff655aedef74cef","4e45292352ba4f729912d16caa0d0d1a","43471673350b4096b57ca8e503aabbe1","21ceb60898f94344b0462c0cf94e1625","63eff360459f46238399e1d9c5038886","0d77f5bc65534aacb18d9eb78beef3ed","1dd061280566468b9255c11eaafda880","5d119d5643bf4f9189f97d1338cda896","7c5329bf246a47debe5ae72f2419e10a","4a1afe5219e24214a0147b091ae36c96","1ccbb352e2f04b11acaed253ba6d9738","9e30d00f850047d89280b7e56e375d04","4d4538e8168441808e258ddd29c9e98e","715e93329555452990ca8549dde6f8d9","50dcfa7e2e22498da8dc120e50efa767","bf126456a2b74b0799435e57459cdf6e","91ca12c35db643539157d51ebfe53bac","fdc1a38c8d904768a08a59c8c6531cb8","eed22357e9384e8986840e63d2d11e6f","73590bcef718430b919f46548ae75cf0","5d9bc9204d7340a393ef606ab2549233","6fc271d97cde4c5f9858dd84812913f2","ffe4262f0f1a4aae947d7acca344bac8","e36737a9f49a46629cf36f5bed2d44fa","6f6edf95187949a5bcaf0492e6b63089","c94f23b6c29f4bbb9058c91cfa11a02f","96b8cbcc262f4b058dc8017730071509","ceafc16644d34862a1b84e54c30065f1","885f20db0074495ca472122a4bd9d558","99a70d83198d465c9fd3a9f33bd76afb","5775a8b785f44e13aa35780b1dae258e","9b19bdeabf3342bc8eaa2ab2842ff03b","5512813ca5194a6895b087b7c3001929","0a34c8456b3f469ab0398e06ef4b1030"]},"id":"JRO_Vzk2MtcV","executionInfo":{"status":"ok","timestamp":1739027743941,"user_tz":-120,"elapsed":308699,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"43dbfbfe-0f51-4859-8b5e-68851329f768"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f635272bf644c7b9ad6bb16fa33c37a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7244c912ef1045a2b2fd29bcb9b2e727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b668d3617045afb5dc263e8e0acf35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e45292352ba4f729912d16caa0d0d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4538e8168441808e258ddd29c9e98e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e36737a9f49a46629cf36f5bed2d44fa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (8, 768)\n","Positive Embeddings Shape: (8, 768)\n","Negative Embeddings Shape: (8, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a373df38150>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a370ffceb10>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a373d3a11d0>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tfmp_net_model/mpnet/pooler/dense/kernel:0', 'tfmp_net_model/mpnet/pooler/dense/bias:0'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (8, 768)\n","Positive Embeddings Shape: (8, 768)\n","Negative Embeddings Shape: (8, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a36004b8150>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a36983f4ed0>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7a35bb869fd0>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 274ms/step - loss: 0.5038\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250208_151058\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7ee763e22b064a0fbcf9b42ccf97b9ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40fb4eea828a47eebde3deffb34eccaf","IPY_MODEL_6c28c29db2b54a68809be4927f2e6561","IPY_MODEL_156e7b3dc5c74377abf997088f5d5039"],"layout":"IPY_MODEL_143f3f72648947628be426536c54165a"}},"40fb4eea828a47eebde3deffb34eccaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d465a2294ac346fcaeb1e40f905431ed","placeholder":"​","style":"IPY_MODEL_e8217faab1a64813989a48f3bc71980e","value":"model.safetensors: 100%"}},"6c28c29db2b54a68809be4927f2e6561":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31789b2281b447e9a533802256b73e32","max":531998632,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffa3a842b49943ba8fffe30c63b7e803","value":531998632}},"156e7b3dc5c74377abf997088f5d5039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0b5259abee4a00b2aed377427faebc","placeholder":"​","style":"IPY_MODEL_b1298a3565b24588878eab99a2f778d2","value":" 532M/532M [00:11&lt;00:00, 34.3MB/s]"}},"143f3f72648947628be426536c54165a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d465a2294ac346fcaeb1e40f905431ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8217faab1a64813989a48f3bc71980e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31789b2281b447e9a533802256b73e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffa3a842b49943ba8fffe30c63b7e803":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e0b5259abee4a00b2aed377427faebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1298a3565b24588878eab99a2f778d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a76d43f7e247423d8bd0267409172ae1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ef25127aea24b65aed075efbf782bd9","IPY_MODEL_4905559eaa5b40779fa2d579308ddeb3","IPY_MODEL_ec09a2d650af46328f1be4ad121ed09f"],"layout":"IPY_MODEL_42f3658a4ec241fc93c783ee84caa9cf"}},"8ef25127aea24b65aed075efbf782bd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa274429fd264ada9935779eaa1ca354","placeholder":"​","style":"IPY_MODEL_faaa9d56430f4cd1854b1775bc3172ba","value":"tokenizer_config.json: 100%"}},"4905559eaa5b40779fa2d579308ddeb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa06b0ec2d34d02b113f8503fddc216","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d441459d1c884b52b9772285b2fd17f0","value":363}},"ec09a2d650af46328f1be4ad121ed09f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c4cd35bd3c64007a9744c871f60f686","placeholder":"​","style":"IPY_MODEL_b1ae715e675d45c2957a160069ac7d08","value":" 363/363 [00:00&lt;00:00, 31.3kB/s]"}},"42f3658a4ec241fc93c783ee84caa9cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa274429fd264ada9935779eaa1ca354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faaa9d56430f4cd1854b1775bc3172ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baa06b0ec2d34d02b113f8503fddc216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d441459d1c884b52b9772285b2fd17f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c4cd35bd3c64007a9744c871f60f686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ae715e675d45c2957a160069ac7d08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76c7ede6ff5e462a8312821bad1a8202":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dc6ae2f526f4653a54c0c07381768db","IPY_MODEL_c42874edb92e43cca983af83dc96420b","IPY_MODEL_4bdb5352724c40eb9d493cb1efd743d1"],"layout":"IPY_MODEL_d4da583e676f4d08a7e4356e6c19f394"}},"4dc6ae2f526f4653a54c0c07381768db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6812d035d701491cb605814f86bcbb3e","placeholder":"​","style":"IPY_MODEL_4549d9c099ab48e88afcbb1d8f4c789d","value":"vocab.txt: 100%"}},"c42874edb92e43cca983af83dc96420b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_224fb6448d974adc8c89a7e5d92893f2","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca45baf4c67c4a679a7300e9fb6e18d3","value":231536}},"4bdb5352724c40eb9d493cb1efd743d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae478ac2bfec4d3694f2550a6e7d28e8","placeholder":"​","style":"IPY_MODEL_1969c0b6db9c4f47b22607038a7b1a79","value":" 232k/232k [00:00&lt;00:00, 4.81MB/s]"}},"d4da583e676f4d08a7e4356e6c19f394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6812d035d701491cb605814f86bcbb3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4549d9c099ab48e88afcbb1d8f4c789d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224fb6448d974adc8c89a7e5d92893f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca45baf4c67c4a679a7300e9fb6e18d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae478ac2bfec4d3694f2550a6e7d28e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1969c0b6db9c4f47b22607038a7b1a79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37822c1dea7c4066891fe9dc2bfad9de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0607fc3d5ee2416ea523bd5cce0e8c80","IPY_MODEL_4b42397cb6fa4f13a52fcdfc4e7d7095","IPY_MODEL_115fb8c0adf84e5687cdfecaddc7fc88"],"layout":"IPY_MODEL_b469b0c304d84cbe9467cc76204428c5"}},"0607fc3d5ee2416ea523bd5cce0e8c80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ff464abd8f4c98bcacb672569a8dc6","placeholder":"​","style":"IPY_MODEL_824bdcb736db49b0b01e101f3d4bbe32","value":"tokenizer.json: 100%"}},"4b42397cb6fa4f13a52fcdfc4e7d7095":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbca1f857e064aeeabac2f8eac9c9ba7","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae0bdf64c6fe474ba4b361a10d3406ab","value":466021}},"115fb8c0adf84e5687cdfecaddc7fc88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a2a9545b11644b6a7c683c3baa92760","placeholder":"​","style":"IPY_MODEL_54739fd4f13d4b128a24de6e70c503f3","value":" 466k/466k [00:00&lt;00:00, 10.7MB/s]"}},"b469b0c304d84cbe9467cc76204428c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ff464abd8f4c98bcacb672569a8dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"824bdcb736db49b0b01e101f3d4bbe32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbca1f857e064aeeabac2f8eac9c9ba7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0bdf64c6fe474ba4b361a10d3406ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a2a9545b11644b6a7c683c3baa92760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54739fd4f13d4b128a24de6e70c503f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd6805a6b4bc490bb3dabb61504ab8e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fed591da0d304c0f8b320ff464c5666c","IPY_MODEL_2c6bd7e97ea2414aac33c456b046e873","IPY_MODEL_6dd438058253463ab15a65ad8f33192f"],"layout":"IPY_MODEL_1872502f5bbf42d1827f773b9bcd37f6"}},"fed591da0d304c0f8b320ff464c5666c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eee4ebb41d904ad7a3084540c6b2f33a","placeholder":"​","style":"IPY_MODEL_229551aa84fd4c7787adcc867eabba53","value":"special_tokens_map.json: 100%"}},"2c6bd7e97ea2414aac33c456b046e873":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a75a543c4a414a9e98646af48b6bbe80","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c77a74539b4a4ca7a56aae18c674362e","value":239}},"6dd438058253463ab15a65ad8f33192f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b0ded56d4342698ab40156896dbef3","placeholder":"​","style":"IPY_MODEL_da87376fe355463386e1bcae2d6146d4","value":" 239/239 [00:00&lt;00:00, 21.9kB/s]"}},"1872502f5bbf42d1827f773b9bcd37f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee4ebb41d904ad7a3084540c6b2f33a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"229551aa84fd4c7787adcc867eabba53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a75a543c4a414a9e98646af48b6bbe80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77a74539b4a4ca7a56aae18c674362e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67b0ded56d4342698ab40156896dbef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da87376fe355463386e1bcae2d6146d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f394cc47b76c424ea50f39894d33a95e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae139a3cd6614bdb8b13997dfa0926c7","IPY_MODEL_e3067982ccdd4f4b9e25d084782b196b","IPY_MODEL_b2026bb57acb43ccabb5254e5a74b4d6"],"layout":"IPY_MODEL_5c535e651f1c4adcbaa60791742af937"}},"ae139a3cd6614bdb8b13997dfa0926c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c1221c444c4c6e81dc25e8ab06143f","placeholder":"​","style":"IPY_MODEL_359a25604e64401bba227185ae1c76c6","value":"config.json: 100%"}},"e3067982ccdd4f4b9e25d084782b196b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2efb55c88a44d24941853097ec4a60d","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcb1e5270d0b4d76ad75e7f33f15895a","value":571}},"b2026bb57acb43ccabb5254e5a74b4d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c24b0b760a4b5e8dfcbace68fd7469","placeholder":"​","style":"IPY_MODEL_f9642ec2fd524b17a5a1ce5f4f5c1ee1","value":" 571/571 [00:00&lt;00:00, 52.1kB/s]"}},"5c535e651f1c4adcbaa60791742af937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25c1221c444c4c6e81dc25e8ab06143f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"359a25604e64401bba227185ae1c76c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2efb55c88a44d24941853097ec4a60d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb1e5270d0b4d76ad75e7f33f15895a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18c24b0b760a4b5e8dfcbace68fd7469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9642ec2fd524b17a5a1ce5f4f5c1ee1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64e547717c224c02981da5a4ff0462a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810f6376fd9e4b4589f1d76bdbbba698","IPY_MODEL_65b9b5ea95334da8a0519f61e9dd4c8b","IPY_MODEL_3a0217664365498e81c1375d11696089"],"layout":"IPY_MODEL_a763decf210b4bb19269b66251f8ff6f"}},"810f6376fd9e4b4589f1d76bdbbba698":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36965743912a4bbc83a05b3c55b9e544","placeholder":"​","style":"IPY_MODEL_fcb2b70818dd4586bc146ccf99f08869","value":"model.safetensors: 100%"}},"65b9b5ea95334da8a0519f61e9dd4c8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b654486cb19443ec88cba4f74f18da7b","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ece2b16bff0d42e1a080df7ff743a59d","value":437971872}},"3a0217664365498e81c1375d11696089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f47dbea5d44dff9749627569b344e3","placeholder":"​","style":"IPY_MODEL_afd7b77b1b5e41b9aa344ef3d4af6eee","value":" 438M/438M [00:01&lt;00:00, 238MB/s]"}},"a763decf210b4bb19269b66251f8ff6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36965743912a4bbc83a05b3c55b9e544":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb2b70818dd4586bc146ccf99f08869":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b654486cb19443ec88cba4f74f18da7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece2b16bff0d42e1a080df7ff743a59d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42f47dbea5d44dff9749627569b344e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd7b77b1b5e41b9aa344ef3d4af6eee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f635272bf644c7b9ad6bb16fa33c37a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70a7cbdb50c143cfa4298bd259f6aef5","IPY_MODEL_3eea70bc6c1342adbbcd5908cc6daca4","IPY_MODEL_c5e87a540e0f4b0f9b5709b8a6563a43"],"layout":"IPY_MODEL_d6bbffac4b6f4009b0b8af1a62bc5fac"}},"70a7cbdb50c143cfa4298bd259f6aef5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dd19023684c456291509a08ac6ce5a3","placeholder":"​","style":"IPY_MODEL_e3569a6c63ca45d2ae9e9137b338873b","value":"tokenizer_config.json: 100%"}},"3eea70bc6c1342adbbcd5908cc6daca4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f738b7c382b44359466ee6413363af9","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f69617c85c524ca78322b4dc8ef42577","value":363}},"c5e87a540e0f4b0f9b5709b8a6563a43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aaa16ad43c64fb1ab63982c03d86c12","placeholder":"​","style":"IPY_MODEL_d84611313b97485480ec523d41109278","value":" 363/363 [00:00&lt;00:00, 26.1kB/s]"}},"d6bbffac4b6f4009b0b8af1a62bc5fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dd19023684c456291509a08ac6ce5a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3569a6c63ca45d2ae9e9137b338873b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f738b7c382b44359466ee6413363af9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f69617c85c524ca78322b4dc8ef42577":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6aaa16ad43c64fb1ab63982c03d86c12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84611313b97485480ec523d41109278":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7244c912ef1045a2b2fd29bcb9b2e727":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5385c6191ac04ead91602e56def2a1d1","IPY_MODEL_8369bf148dc743b9a3581ffa70498a20","IPY_MODEL_65b142e468454bb1b12b00a62949f344"],"layout":"IPY_MODEL_254581d36a57430692197f27fbc5c9d0"}},"5385c6191ac04ead91602e56def2a1d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f9fc059e324b24b3a8ed8c632b4227","placeholder":"​","style":"IPY_MODEL_0310de90a49742a38e0aae681cab3236","value":"vocab.txt: 100%"}},"8369bf148dc743b9a3581ffa70498a20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7874e24a3cf34985abcc6633189531d1","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46ebb0ff5b4d4c2e8b4910697fbbc5e9","value":231536}},"65b142e468454bb1b12b00a62949f344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e485b2f7cb9b426fb2e9b7c5a4df5abc","placeholder":"​","style":"IPY_MODEL_3be9abd9636b4e80848a69567d13d344","value":" 232k/232k [00:00&lt;00:00, 5.15MB/s]"}},"254581d36a57430692197f27fbc5c9d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5f9fc059e324b24b3a8ed8c632b4227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0310de90a49742a38e0aae681cab3236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7874e24a3cf34985abcc6633189531d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ebb0ff5b4d4c2e8b4910697fbbc5e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e485b2f7cb9b426fb2e9b7c5a4df5abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be9abd9636b4e80848a69567d13d344":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8b668d3617045afb5dc263e8e0acf35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32cdff0727ff46738c1b6a77907ec3a9","IPY_MODEL_481afab291534683a24f4c8bd8dcacd1","IPY_MODEL_5827a19677064259ad6f909991f31ad1"],"layout":"IPY_MODEL_5dceb45faa7a45bab4b5d380777ba621"}},"32cdff0727ff46738c1b6a77907ec3a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4be74ce7a624bd7b1b6b59691e9b767","placeholder":"​","style":"IPY_MODEL_7d62c1d00ad4441c928ff95d584835eb","value":"tokenizer.json: 100%"}},"481afab291534683a24f4c8bd8dcacd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd6cc25d55614c459829e65197b20ed1","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cc995370b2347218eec81a7367dc9d2","value":466021}},"5827a19677064259ad6f909991f31ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5581b7550204b2982c8e08d30944749","placeholder":"​","style":"IPY_MODEL_6115617d8bd2468faff655aedef74cef","value":" 466k/466k [00:00&lt;00:00, 21.4MB/s]"}},"5dceb45faa7a45bab4b5d380777ba621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4be74ce7a624bd7b1b6b59691e9b767":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d62c1d00ad4441c928ff95d584835eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd6cc25d55614c459829e65197b20ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc995370b2347218eec81a7367dc9d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5581b7550204b2982c8e08d30944749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6115617d8bd2468faff655aedef74cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e45292352ba4f729912d16caa0d0d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43471673350b4096b57ca8e503aabbe1","IPY_MODEL_21ceb60898f94344b0462c0cf94e1625","IPY_MODEL_63eff360459f46238399e1d9c5038886"],"layout":"IPY_MODEL_0d77f5bc65534aacb18d9eb78beef3ed"}},"43471673350b4096b57ca8e503aabbe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dd061280566468b9255c11eaafda880","placeholder":"​","style":"IPY_MODEL_5d119d5643bf4f9189f97d1338cda896","value":"special_tokens_map.json: 100%"}},"21ceb60898f94344b0462c0cf94e1625":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c5329bf246a47debe5ae72f2419e10a","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a1afe5219e24214a0147b091ae36c96","value":239}},"63eff360459f46238399e1d9c5038886":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ccbb352e2f04b11acaed253ba6d9738","placeholder":"​","style":"IPY_MODEL_9e30d00f850047d89280b7e56e375d04","value":" 239/239 [00:00&lt;00:00, 19.3kB/s]"}},"0d77f5bc65534aacb18d9eb78beef3ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd061280566468b9255c11eaafda880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d119d5643bf4f9189f97d1338cda896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c5329bf246a47debe5ae72f2419e10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a1afe5219e24214a0147b091ae36c96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ccbb352e2f04b11acaed253ba6d9738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e30d00f850047d89280b7e56e375d04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d4538e8168441808e258ddd29c9e98e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_715e93329555452990ca8549dde6f8d9","IPY_MODEL_50dcfa7e2e22498da8dc120e50efa767","IPY_MODEL_bf126456a2b74b0799435e57459cdf6e"],"layout":"IPY_MODEL_91ca12c35db643539157d51ebfe53bac"}},"715e93329555452990ca8549dde6f8d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc1a38c8d904768a08a59c8c6531cb8","placeholder":"​","style":"IPY_MODEL_eed22357e9384e8986840e63d2d11e6f","value":"config.json: 100%"}},"50dcfa7e2e22498da8dc120e50efa767":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73590bcef718430b919f46548ae75cf0","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d9bc9204d7340a393ef606ab2549233","value":571}},"bf126456a2b74b0799435e57459cdf6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fc271d97cde4c5f9858dd84812913f2","placeholder":"​","style":"IPY_MODEL_ffe4262f0f1a4aae947d7acca344bac8","value":" 571/571 [00:00&lt;00:00, 47.8kB/s]"}},"91ca12c35db643539157d51ebfe53bac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdc1a38c8d904768a08a59c8c6531cb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed22357e9384e8986840e63d2d11e6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73590bcef718430b919f46548ae75cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9bc9204d7340a393ef606ab2549233":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fc271d97cde4c5f9858dd84812913f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe4262f0f1a4aae947d7acca344bac8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e36737a9f49a46629cf36f5bed2d44fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f6edf95187949a5bcaf0492e6b63089","IPY_MODEL_c94f23b6c29f4bbb9058c91cfa11a02f","IPY_MODEL_96b8cbcc262f4b058dc8017730071509"],"layout":"IPY_MODEL_ceafc16644d34862a1b84e54c30065f1"}},"6f6edf95187949a5bcaf0492e6b63089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_885f20db0074495ca472122a4bd9d558","placeholder":"​","style":"IPY_MODEL_99a70d83198d465c9fd3a9f33bd76afb","value":"model.safetensors: 100%"}},"c94f23b6c29f4bbb9058c91cfa11a02f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5775a8b785f44e13aa35780b1dae258e","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b19bdeabf3342bc8eaa2ab2842ff03b","value":437971872}},"96b8cbcc262f4b058dc8017730071509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5512813ca5194a6895b087b7c3001929","placeholder":"​","style":"IPY_MODEL_0a34c8456b3f469ab0398e06ef4b1030","value":" 438M/438M [00:01&lt;00:00, 199MB/s]"}},"ceafc16644d34862a1b84e54c30065f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"885f20db0074495ca472122a4bd9d558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99a70d83198d465c9fd3a9f33bd76afb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5775a8b785f44e13aa35780b1dae258e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b19bdeabf3342bc8eaa2ab2842ff03b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5512813ca5194a6895b087b7c3001929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a34c8456b3f469ab0398e06ef4b1030":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}