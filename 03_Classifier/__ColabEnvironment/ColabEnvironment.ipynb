{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13985,"status":"ok","timestamp":1750659713976,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-180},"id":"xe8Eih0hHc2-","outputId":"edf9f449-05ae-4ff7-9b48-b4a963408099"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1750659714597,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-180},"id":"YmNUmwcdHc3B","outputId":"7b5c6d59-3d4a-4cdc-dcda-6f45f916b9b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6026,"status":"ok","timestamp":1750659720625,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-180},"id":"qIIAqc0VIDm4","outputId":"ee2b03e0-3ae8-4bb1-dce8-8cf712b90111"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n","Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}],"source":["# install dependencies\n","\n","!pip install scikit-multilearn"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1750659720644,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-180},"id":"T2lmJ49jGPJE","outputId":"16b97d94-d913-42ae-e5b3-3efb520aaf78"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1346,"status":"ok","timestamp":1750659721994,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-180},"id":"7T7YDX_3GPJE","outputId":"8c3981ab-6968-4b0d-d8d0-17521152a3eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"markdown","metadata":{"id":"xRHELeWOU15Q"},"source":["1. START DOMAIN ADAPTATION"]},{"cell_type":"markdown","metadata":{"id":"y311Be0zZ711"},"source":["1.1. DOMAIN ADAPTATION ON OUR DATASET"]},{"cell_type":"markdown","metadata":{"id":"rrBcOUD6VIs5"},"source":["1.1.1 Domain adaptation for top N subset on our dataset using augumentation (DA models dataset from paper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRO_Vzk2MtcV"},"outputs":[],"source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 10\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'TOP_{NUMBER_OF_TAGS}_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"ZWRTRsxoVNgH"},"source":["1.1.2. Domain adaptation for top N subset on our dataset without using augumentation (Basic DA models dataset from paper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qRh79wVV1qA"},"outputs":[],"source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'TOP_{NUMBER_OF_TAGS}_BASIC_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"_ZTkqCnUaPFY"},"source":["1.1. DOMAIN ADAPTATION ON KIM ET AL. DATASET"]},{"cell_type":"markdown","metadata":{"id":"2OmINYWPWyFn"},"source":["1.2.1. Domain adaptation for top N subset on Kim et al. dataset using augumentation (DA models dataset from paper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6h0hoXRQVFe8"},"outputs":[],"source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"vHlNmBEUVEMn"},"source":["1.2.2. Domain adaptation for top N subset on Kim et al. dataset without using augumentation (Basic DA models dataset from paper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaaZnQw6W5YZ"},"outputs":[],"source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_BASIC_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"iplTslnBXEjH"},"source":["2. START CHAIN CLASSIFIER EXPERIEMNTS"]},{"cell_type":"markdown","metadata":{"id":"OQmyezRIabba"},"source":["2.1. Start Chain Classifier experiments using Gausinan Naive Bayes (paper presented experiements)"]},{"cell_type":"markdown","metadata":{"id":"vhcpt0a9as3L"},"source":["2.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxccKR9-LaVM"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_base_top_5')\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"tseRnIGRbQqE"},"source":["2.1.2 Our Dataset without domain adapted model (Base / Basic train models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnlbaWoMbhUH"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"Fnc4tPXLcmUk"},"source":["2.1.3 Kim et al. dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYXOTZL_cqD3"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    outside_dataset=True\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"DVngfrjic4fH"},"source":["2.1.4 Kim et al. dataset without domain adapted model (Base / Basic train models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xYjmgLh8c-u7"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    outside_dataset=True\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"Kz3iVYHsdQfW"},"source":["2.2. Run all Chain Classifier Experients (not present in the paper)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf539_VjeDLI"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    outside_dataset=False  # Comment to change to True to change to Kim. et all dataset\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"PTJXyT36eZvq"},"source":["3. START ONE VS ALL model EXPERIEMNTS"]},{"cell_type":"markdown","metadata":{"id":"ooWvGWrNjvLw"},"source":["3.1. Experiemnts on Our Dataset"]},{"cell_type":"markdown","metadata":{"id":"Qn_1hWp0fbKI"},"source":["3.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E67PUmrfEy0H"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 10\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_base_top_10'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"InniuOcdiw7Q"},"source":["3.1.2. Our Dataset training without domain adaptation (Basic Train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWK7yUbui-7h"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"Ff-jfLrsgNwM"},"source":["3.1.3. Our Dataset without any training OnveVsAll (Base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NV-8lk7Q1b0"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"IdIqbYQFjaeQ"},"source":["3.2. Experiemnts on Kim et al. Dataset"]},{"cell_type":"markdown","metadata":{"id":"c7BxWIB_k-xi"},"source":["3.2.1 Kim et al. Dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"azBnzDcwlFBV"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"CF7LEQwWmPig"},"source":["3.2.2. Kim et al. Dataset training without domain adaptation (Basic Train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fV0oihUamY14"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"YyTSB97Omgpq"},"source":["3.2.3. Kim et al. Dataset without without any training OnveVsAll (Base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIPLL9QVm0Y3"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"_Kfum1lam51i"},"source":["3.2.4 Kim et al. Dataset - All base experiments from Table 5."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhOjjloZnBHq"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"N6PeLmKrnZU3"},"source":["4. SINGLE MODEL CLASSIFIER EXPERIEMNTS"]},{"cell_type":"markdown","metadata":{"id":"Z9gHGmI0nhFB"},"source":["4.1. Experiemnts on Our Dataset"]},{"cell_type":"markdown","metadata":{"id":"ff6394xgo722"},"source":["4.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6na0mMFnhUq"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"4x4ibT_tp6Tj"},"source":["4.1.2. Our Dataset training without domain adaptation (Basic Train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5P7W9KgqgTh"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"oJ3IZ1qsqDlp"},"source":["4.1.3. Our Dataset without without any training OnveVsAll (Base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuZq6aorqwXP"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"Jc6i4ThcqKs4"},"source":["4.2. Experiemnts on Kim et al. Dataset"]},{"cell_type":"markdown","metadata":{"id":"f64q3HnDqNdm"},"source":["4.2.1 Kim et al. Dataset with domain adapted model (DA / Basic DA models)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbvU_DmEq6zC"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"HHw_BGmwqQeS"},"source":["4.2.2. Kim et al. Dataset training without domain adaptation (Basic Train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfGARVY5rAYF"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"cUP3hlh9qTv2"},"source":["4.2.3. Kim et al. Dataset without without any training OnveVsAll (Base)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_0r97Yfp6aG"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","metadata":{"id":"VJzjpUJqdbbw"},"source":["4. MULTI-HEAD EXPERIEMNTS"]},{"cell_type":"markdown","source":["4.1 Multi-Head with difficulty on Kim et al. and Our Dataset"],"metadata":{"id":"qeI6JrnBaZ9z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXw5F7VRdbbw"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import MultiHeadTransformerEvaluator\n","from app_config import AppConfig\n","import pandas as pd\n","import numpy as np\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","training_df = pd.read_csv(CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 10\n","training_df = pd.read_csv(CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 20\n","training_df = pd.read_csv(CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 5\n","training_df = pd.read_csv(CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 10\n","training_df = pd.read_csv(CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 20\n","training_df = pd.read_csv(CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'])\n","NUMBER_OF_DIFFICULTY_TAGS = training_df['problem_dificulty'].nunique()\n","\n","transformer_evaluator = MultiHeadTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    number_of_difficulty_tags=NUMBER_OF_DIFFICULTY_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )"]},{"cell_type":"markdown","source":["4.2 SingleModelClassifier Multi-Head with Editorial on Our Dataset"],"metadata":{"id":"ddZT2GETapmo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPN10IyX1IQp"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import MultiHeadEditorialTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = MultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 10\n","\n","transformer_evaluator = MultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 20\n","\n","transformer_evaluator = MultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","source":["4.3 OneVsAll Multi-Head with Editorial on Our Dataset"],"metadata":{"id":"QAsNCYgWa2sU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fN6nxHu_f8Rb"},"outputs":[],"source":["\n","\n","##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllMultiHeadEditorialTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllMultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_062327_base_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 10\n","\n","transformer_evaluator = OneVsAllMultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_020325_base_top_10'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n","\n","NUMBER_OF_TAGS = 20\n","\n","transformer_evaluator = OneVsAllMultiHeadEditorialTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250219_145342_base_top_20'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_ENHANCED_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_ENHANCED_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_ENHANCED_DATASET_PATH']\n","  )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzxeL39tV69N"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"py310_venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":0}