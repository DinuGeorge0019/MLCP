{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29417,"status":"ok","timestamp":1739452510647,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"xe8Eih0hHc2-","outputId":"8aa843e5-0a06-4a2a-b054-5c60592a2e72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2070,"status":"ok","timestamp":1739452512716,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"YmNUmwcdHc3B","outputId":"12443bd1-1072-47fd-eaef-fa5b576fff4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2690,"status":"ok","timestamp":1739452515404,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"qIIAqc0VIDm4","outputId":"91825ad9-7077-493f-f274-6ac417b82af9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n","Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}],"source":["# install dependencies\n","\n","# !pip install catboost\n","!pip install scikit-multilearn\n","# !pip install --upgrade tensorflow-addons\n","# !pip install sentence-transformers\n","# !pip install --upgrade tensorflow-addons\n","# !pip install dask[dataframe]\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739452515404,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"T2lmJ49jGPJE","outputId":"b7689cdc-915d-45d1-8f26-d71123e46753"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1928,"status":"ok","timestamp":1739452517330,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"7T7YDX_3GPJE","outputId":"0a2ea0c8-7a80-49a4-8794-1a6aa63ebaf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"elapsed":2129,"status":"error","timestamp":1739027432803,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"vnQee3H_Hc3B","outputId":"93859f2d-fe9d-4e36-8869-ed550be4af9a"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-31747437e9e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapp_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"This is a test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is another test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is a third test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCustomEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomEncoder\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mCustomEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mClassifierChainWrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/CustomEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# related third-party\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackboneMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeHintParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_json_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m from .doc import (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_jinja_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImmutableSandboxedEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jinja2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbccache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileSystemBytecodeCache\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mFileSystemBytecodeCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbccache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemcachedBytecodeCache\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMemcachedBytecodeCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnvironment\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0menvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplateAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTemplateAssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jinja2/environment.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmarkupsafe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from app_src import CustomEncoder\n","\n","encoder = CustomEncoder(\"bert-base-uncased\")\n","data = [\"This is a test\", \"This is another test\", \"This is a third test\"]\n","\n","encodded_sentence = encoder.encode_problem_statement(data)\n","print(encodded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":23706,"status":"error","timestamp":1738784679685,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"AL8NTNOKHc3C","outputId":"abb35947-c589-4a59-e7ac-fde63c1314b8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"ename":"TypeError","evalue":"ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-97d0783496a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifierChainWrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given"]}],"source":["from app_src import ClassifierChainWrapper\n","from sklearn.ensemble import RandomForestClassifier\n","\n","classifierChainWrapper = ClassifierChainWrapper(RandomForestClassifier(), \"bert-base-uncased\", 5)\n","classifierChainWrapper.fit()\n","metrics_results = classifierChainWrapper.predict()\n","\n","for metric_name, metric_value in metrics_results.items():\n","    print(f\"{metric_name}: {metric_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":21,"status":"error","timestamp":1738784694006,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"2V2DZ5O5wpXk","outputId":"d20aeebd-4329-42fc-84ea-6727ce8dad68"},"outputs":[{"ename":"AttributeError","evalue":"'DecisionTreeEvaluator' object has no attribute 'benchmark_models'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f48c8ed72720>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecisionTreeEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecisionTreeEvaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeEvaluator' object has no attribute 'benchmark_models'"]}],"source":["from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=5)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4154,"status":"ok","timestamp":1738441980041,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"UMkaJZsOBid0","outputId":"607490d9-83ea-4484-8a63-e7bc11428d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.18.0\n","CUDA version: 12.5.1\n","CUDNN version: 9\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","build_info = tf.sysconfig.get_build_info()\n","print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Unknown\"))\n","print(\"CUDNN version:\", build_info.get(\"cudnn_version\", \"Unknown\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729,"referenced_widgets":["7ee763e22b064a0fbcf9b42ccf97b9ca","40fb4eea828a47eebde3deffb34eccaf","6c28c29db2b54a68809be4927f2e6561","156e7b3dc5c74377abf997088f5d5039","143f3f72648947628be426536c54165a","d465a2294ac346fcaeb1e40f905431ed","e8217faab1a64813989a48f3bc71980e","31789b2281b447e9a533802256b73e32","ffa3a842b49943ba8fffe30c63b7e803","0e0b5259abee4a00b2aed377427faebc","b1298a3565b24588878eab99a2f778d2"]},"executionInfo":{"elapsed":222505,"status":"ok","timestamp":1738622095096,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"_DhP3q-Htoh9","outputId":"8783a6b1-64b3-4e8d-bf2b-f3990fc2ee04"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available\n","GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ee763e22b064a0fbcf9b42ccf97b9ca","version_major":2,"version_minor":0},"text/plain":["model.safetensors:  24%|##3       | 126M/532M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFMPNetModel were not initialized from the PyTorch model and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962ms/step - auc: 0.5180 - binary_accuracy: 0.4868 - label_wise_accuracy: 0.5003 - label_wise_f1_score: 0.4110 - label_wise_macro_f1: 0.4369 - loss: 0.7062 - prc_auc: 0.3934 - precision: 0.3981 - recall: 0.6753 - subset_accuracy: 0.0170 - subset_f1: 0.4971 - subset_precision: 0.3978 - subset_recall: 0.6687\n","Epoch 1: Validation Metrics:\n","loss: 0.7000761032104492\n","val_label_wise_f1_score: [0.6046511  0.31999996 0.         0.6666666  0.        ]\n","val_label_wise_accuracy: [0.46875 0.46875 0.6875  0.53125 0.71875]\n","val_binary_accuracy: 0.5161765217781067\n","val_precision: 0.40509089827537537\n","val_recall: 0.5279620885848999\n","val_label_wise_macro_f1: 0.35385945439338684\n","val_subset_accuracy: 0.03492647036910057\n","val_subset_precision: 0.4010416865348816\n","val_subset_recall: 0.5241115093231201\n","val_subset_f1: 0.45356810092926025\n","val_auc: 0.5249963998794556\n","val_prc_auc: 0.40708646178245544\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - auc: 0.5181 - binary_accuracy: 0.4868 - label_wise_accuracy: 0.5008 - label_wise_f1_score: 0.4104 - label_wise_macro_f1: 0.4367 - loss: 0.7061 - prc_auc: 0.3935 - precision: 0.3981 - recall: 0.6750 - subset_accuracy: 0.0171 - subset_f1: 0.4970 - subset_precision: 0.3979 - subset_recall: 0.6683 - val_auc: 0.5250 - val_binary_accuracy: 0.5162 - val_label_wise_accuracy: 0.5750 - val_label_wise_f1_score: 0.3183 - val_label_wise_macro_f1: 0.3539 - val_loss: 0.6918 - val_prc_auc: 0.4071 - val_precision: 0.4051 - val_recall: 0.5280 - val_subset_accuracy: 0.0349 - val_subset_f1: 0.4536 - val_subset_precision: 0.4010 - val_subset_recall: 0.5241\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_223120\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250203_223120.weights.h5\n"]}],"source":["import os\n","import tensorflow as tf\n","\n","# Check if GPU is available and print details\n","if tf.config.experimental.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","    print(\"GPU details:\", tf.config.list_physical_devices('GPU'))\n","else:\n","    print(\"GPU not available, using CPU\")\n","\n","# # If GPU is available, try setting memory growth\n","# gpus = tf.config.list_physical_devices('GPU')\n","# if gpus:\n","#     try:\n","#         # Currently, memory growth needs to be the same across GPUs\n","#         for gpu in gpus:\n","#             tf.config.experimental.set_memory_growth(gpu, True)\n","#         logical_gpus = tf.config.list_logical_devices('GPU')\n","#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#     except RuntimeError as e:\n","#         # Memory growth must be set before GPUs have been initialized\n","#         print('Error')\n","#         print(e)\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"microsoft/mpnet-base\", NUMBER_OF_TAGS)\n","sentenceTransformerWrapper.train_model(\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=32,\n","    train_model=True\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59070,"status":"ok","timestamp":1738622242973,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"Pd4K7EOOtoh9","outputId":"d6499eee-9aa8-4b77-fa81-b902b942e2ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_223120.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded from /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250203_223120.weights.h5\n","\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 990ms/step - auc: 0.5208 - binary_accuracy: 0.5071 - label_wise_accuracy: 0.5067 - label_wise_f1_score: 0.3501 - label_wise_macro_f1: 0.3516 - loss: 0.6924 - prc_auc: 0.4088 - precision: 0.3994 - recall: 0.5128 - subset_accuracy: 0.0333 - subset_f1: 0.4498 - subset_precision: 0.4007 - subset_recall: 0.5159\n","Evaluation Metrics:\n","Loss: 0.6929304599761963\n","Label F1 Scores: [0.56410253 0.4705882  0.09999999 0.43243238 0.        ]\n","Label Accuracies: [0.46875 0.4375  0.4375  0.34375 0.75   ]\n","Accuracy: 0.5071220993995667\n","Precision: 0.3944847583770752\n","Recall: 0.5101351141929626\n","F1 Score: 0.3509281873703003\n","Subset Accuracy: 0.028343023732304573\n","Subset Precision: 0.3935804069042206\n","Subset Recall: 0.5103682279586792\n","Subset F1: 0.44326552748680115\n","AUC: 0.5183724164962769\n","PRC AUC: 0.4017588496208191\n"]},{"data":{"text/plain":["{'Loss': 0.6929304599761963,\n"," 'Label F1 Scores': array([0.56410253, 0.4705882 , 0.09999999, 0.43243238, 0.        ],\n","       dtype=float32),\n"," 'Label Accuracies': array([0.46875, 0.4375 , 0.4375 , 0.34375, 0.75   ], dtype=float32),\n"," 'Accuracy': 0.5071220993995667,\n"," 'Precision': 0.3944847583770752,\n"," 'Recall': 0.5101351141929626,\n"," 'F1 Score': 0.3509281873703003,\n"," 'Subset Accuracy': 0.028343023732304573,\n"," 'Subset Precision': 0.3935804069042206,\n"," 'Subset Recall': 0.5103682279586792,\n"," 'Subset F1': 0.44326552748680115,\n"," 'AUC': 0.5183724164962769,\n"," 'PRC AUC': 0.4017588496208191}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"microsoft/mpnet-base\", NUMBER_OF_TAGS)\n","\n","sentenceTransformerWrapper.benchmark_model(\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH'],\n","    batch_size=32,\n","    model_path= os.path.join(CONFIG[\"MODEL_SAVE_PATH_ROOT\"], 'custom_model_20250203_223120.weights.h5'),\n","    transformer_model_path= os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250203_223120')\n","    )"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b361cf0ce9374064aa7938cc9b15e4e3","b67268cfe5294e178e7be8458255eb62","7e6858d2eadf40d7aa6d6c842f2afd8c","256d9fcf09da45788be85c3c25348db8","4ddcca862b9c48ae82197f7cdfb7099c","5f42fcf20762492491d69e415321a306","cdabfde45a224cb9adb3b993173f0a3f","3e90e780dda3463ab27f64320bb226ff","f79b7d8cb52d4ff1be035420abdb7196","d85bf9d77cc4419aa0606b14db8a32ea","4bbd2452df8d41759de0c6bfeccbfe93","5e563e9ec02840feb90612f39de4b7d6","f4c63e2d86be4549b464172ecc2e004e","991583a89eee442180772986547417cb","df11c069a37e41c7b98355044dd8109f","691b471245dc43308eac46dbd52ca334","a6d81c66eea2492eb7177b94adf09672","aba4939b96bd4c718f6b71b123c6f03e","157ea918b15a4a30bf6249c6b1970533","19c5a7db7dfe45b984bfae1b3c1ee27c","7618d494162146ddb99ff2dae9a4d687","478b91e0bbb8497b9b8b0b2cc4d6f995","83aa0bcfb54b4bc38ce253300cbea3d6","70aa03d216854021805e201ceb94d60c","26cbe4f973944b8c98b9f338e0d71367","e0472d0757b64c389181e3334d010d21","0ee7d537d2ca4d309f80c421191a58b4","c5a3a383ba534407aa55b5941c02dcfd","2a696e45e9014ed487a374615d84dde2","433a0c4eaaab4a59884aa823e8d2ac8a","d1945cea97c34c348f301eba555ff20b","baf02c37119b44e98e816bf94785ef15","7200f30d527b47cab255bc71c2c81d3a","7a6b9b9721d8470a9661512cfd9ae8f9","74704115a3c1452cbb85ac80a3d302aa","cac0e8396c814053a5041253392a8920","4649bd4895344e9eb5f2b65872abcbb2","a0500a7dd92c44a6b5b56351c3f179ef","93f35ca5c74142f9a180694289dbbf26","794213dc30e94259846ffa89cc8d23dc","c2d735dcd7d5494ba19f102383261fda","3a7dcc8f57034486ba0bcfef999943ff","6a1a47bfd54f4cea8c0b3fa9871c0d47","3c518b50a2294c269d0f2f305e3128b8"]},"executionInfo":{"elapsed":180203,"status":"ok","timestamp":1739398084264,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"mCcdWL_XfxIG","outputId":"afe158c2-5588-4c33-8b8f-5df56666e8ce"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b361cf0ce9374064aa7938cc9b15e4e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e563e9ec02840feb90612f39de4b7d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83aa0bcfb54b4bc38ce253300cbea3d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6b9b9721d8470a9661512cfd9ae8f9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_001142_5_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.6075 - binary_accuracy: 0.5459 - label_wise_accuracy: 0.5802 - label_wise_f1_score: 0.4937 - label_wise_macro_f1: 0.4734 - loss: 0.6891 - prc_auc: 0.4110 - precision: 0.3761 - recall: 0.6790 - subset_accuracy: 0.0347 - subset_f1: 0.4870 - subset_precision: 0.3757 - subset_recall: 0.6994\n","Epoch 1: Validation Metrics:\n","loss: 0.6823056936264038\n","val_label_wise_f1_score: [0.7058823  0.58823526 0.5833333  0.27272722 0.36363634]\n","val_label_wise_accuracy: [0.6875 0.5625 0.6875 0.5    0.5625]\n","val_binary_accuracy: 0.6112499833106995\n","val_precision: 0.4375531077384949\n","val_recall: 0.6552162766456604\n","val_label_wise_macro_f1: 0.4987398684024811\n","val_subset_accuracy: 0.07500000298023224\n","val_subset_precision: 0.4547222852706909\n","val_subset_recall: 0.6723611354827881\n","val_subset_f1: 0.5413468480110168\n","val_auc: 0.658005952835083\n","val_prc_auc: 0.49701130390167236\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 139ms/step - auc: 0.6078 - binary_accuracy: 0.5462 - label_wise_accuracy: 0.5803 - label_wise_f1_score: 0.4937 - label_wise_macro_f1: 0.4735 - loss: 0.6890 - prc_auc: 0.4115 - precision: 0.3763 - recall: 0.6791 - subset_accuracy: 0.0348 - subset_f1: 0.4872 - subset_precision: 0.3760 - subset_recall: 0.6995 - val_auc: 0.6580 - val_binary_accuracy: 0.6112 - val_label_wise_accuracy: 0.6000 - val_label_wise_f1_score: 0.5028 - val_label_wise_macro_f1: 0.4987 - val_loss: 0.6770 - val_prc_auc: 0.4970 - val_precision: 0.4376 - val_recall: 0.6552 - val_subset_accuracy: 0.0750 - val_subset_f1: 0.5413 - val_subset_precision: 0.4547 - val_subset_recall: 0.6724\n","Epoch 2/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.7475 - binary_accuracy: 0.6782 - label_wise_accuracy: 0.6999 - label_wise_f1_score: 0.5684 - label_wise_macro_f1: 0.5538 - loss: 0.6624 - prc_auc: 0.6007 - precision: 0.4913 - recall: 0.7193 - subset_accuracy: 0.1434 - subset_f1: 0.6171 - subset_precision: 0.5266 - subset_recall: 0.7522\n","Epoch 2: Validation Metrics:\n","loss: 0.6564358472824097\n","val_label_wise_f1_score: [0.66666657 0.58064514 0.5217391  0.24999994 0.54545444]\n","val_label_wise_accuracy: [0.65625 0.59375 0.65625 0.625   0.84375]\n","val_binary_accuracy: 0.6804167628288269\n","val_precision: 0.5102260708808899\n","val_recall: 0.6030534505844116\n","val_label_wise_macro_f1: 0.5162662267684937\n","val_subset_accuracy: 0.16458334028720856\n","val_subset_precision: 0.5324653387069702\n","val_subset_recall: 0.6304513216018677\n","val_subset_f1: 0.5761339068412781\n","val_auc: 0.7049733400344849\n","val_prc_auc: 0.537283182144165\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - auc: 0.7477 - binary_accuracy: 0.6784 - label_wise_accuracy: 0.6997 - label_wise_f1_score: 0.5680 - label_wise_macro_f1: 0.5539 - loss: 0.6624 - prc_auc: 0.6008 - precision: 0.4915 - recall: 0.7193 - subset_accuracy: 0.1436 - subset_f1: 0.6172 - subset_precision: 0.5269 - subset_recall: 0.7522 - val_auc: 0.7050 - val_binary_accuracy: 0.6804 - val_label_wise_accuracy: 0.6750 - val_label_wise_f1_score: 0.5129 - val_label_wise_macro_f1: 0.5163 - val_loss: 0.6594 - val_prc_auc: 0.5373 - val_precision: 0.5102 - val_recall: 0.6031 - val_subset_accuracy: 0.1646 - val_subset_f1: 0.5761 - val_subset_precision: 0.5325 - val_subset_recall: 0.6305\n","Epoch 3/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.7952 - binary_accuracy: 0.7460 - label_wise_accuracy: 0.7531 - label_wise_f1_score: 0.6082 - label_wise_macro_f1: 0.5997 - loss: 0.6393 - prc_auc: 0.6520 - precision: 0.5770 - recall: 0.7107 - subset_accuracy: 0.2440 - subset_f1: 0.6819 - subset_precision: 0.6252 - subset_recall: 0.7534\n","Epoch 3: Validation Metrics:\n","loss: 0.6340661644935608\n","val_label_wise_f1_score: [0.66666657 0.59999996 0.5833333  0.28571424 0.54545444]\n","val_label_wise_accuracy: [0.65625 0.625   0.6875  0.6875  0.84375]\n","val_binary_accuracy: 0.6949999332427979\n","val_precision: 0.530474066734314\n","val_recall: 0.5979644060134888\n","val_label_wise_macro_f1: 0.522541344165802\n","val_subset_accuracy: 0.19374999403953552\n","val_subset_precision: 0.5598958134651184\n","val_subset_recall: 0.6278471350669861\n","val_subset_f1: 0.5906723141670227\n","val_auc: 0.7171059250831604\n","val_prc_auc: 0.5458858013153076\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - auc: 0.7952 - binary_accuracy: 0.7460 - label_wise_accuracy: 0.7527 - label_wise_f1_score: 0.6077 - label_wise_macro_f1: 0.5998 - loss: 0.6393 - prc_auc: 0.6521 - precision: 0.5771 - recall: 0.7107 - subset_accuracy: 0.2441 - subset_f1: 0.6819 - subset_precision: 0.6253 - subset_recall: 0.7533 - val_auc: 0.7171 - val_binary_accuracy: 0.6950 - val_label_wise_accuracy: 0.7000 - val_label_wise_f1_score: 0.5362 - val_label_wise_macro_f1: 0.5225 - val_loss: 0.6447 - val_prc_auc: 0.5459 - val_precision: 0.5305 - val_recall: 0.5980 - val_subset_accuracy: 0.1937 - val_subset_f1: 0.5907 - val_subset_precision: 0.5599 - val_subset_recall: 0.6278\n","Epoch 4/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8093 - binary_accuracy: 0.7620 - label_wise_accuracy: 0.7635 - label_wise_f1_score: 0.6215 - label_wise_macro_f1: 0.6192 - loss: 0.6193 - prc_auc: 0.6665 - precision: 0.6015 - recall: 0.7133 - subset_accuracy: 0.2679 - subset_f1: 0.7021 - subset_precision: 0.6553 - subset_recall: 0.7596\n","Epoch 4: Validation Metrics:\n","loss: 0.6147504448890686\n","val_label_wise_f1_score: [0.66666657 0.6923076  0.5833333  0.3076923  0.39999998]\n","val_label_wise_accuracy: [0.65625 0.75    0.6875  0.71875 0.8125 ]\n","val_binary_accuracy: 0.7016667127609253\n","val_precision: 0.5407925248146057\n","val_recall: 0.5903307795524597\n","val_label_wise_macro_f1: 0.5228137969970703\n","val_subset_accuracy: 0.19583334028720856\n","val_subset_precision: 0.571180522441864\n","val_subset_recall: 0.6176040768623352\n","val_subset_f1: 0.5921846032142639\n","val_auc: 0.721508800983429\n","val_prc_auc: 0.5469774603843689\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - auc: 0.8093 - binary_accuracy: 0.7620 - label_wise_accuracy: 0.7632 - label_wise_f1_score: 0.6208 - label_wise_macro_f1: 0.6192 - loss: 0.6193 - prc_auc: 0.6665 - precision: 0.6015 - recall: 0.7133 - subset_accuracy: 0.2680 - subset_f1: 0.7021 - subset_precision: 0.6553 - subset_recall: 0.7596 - val_auc: 0.7215 - val_binary_accuracy: 0.7017 - val_label_wise_accuracy: 0.7250 - val_label_wise_f1_score: 0.5300 - val_label_wise_macro_f1: 0.5228 - val_loss: 0.6324 - val_prc_auc: 0.5470 - val_precision: 0.5408 - val_recall: 0.5903 - val_subset_accuracy: 0.1958 - val_subset_f1: 0.5922 - val_subset_precision: 0.5712 - val_subset_recall: 0.6176\n","Epoch 5/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8146 - binary_accuracy: 0.7665 - label_wise_accuracy: 0.7675 - label_wise_f1_score: 0.6266 - label_wise_macro_f1: 0.6260 - loss: 0.6021 - prc_auc: 0.6722 - precision: 0.6083 - recall: 0.7167 - subset_accuracy: 0.2831 - subset_f1: 0.7089 - subset_precision: 0.6646 - subset_recall: 0.7631\n","Epoch 5: Validation Metrics:\n","loss: 0.5980959534645081\n","val_label_wise_f1_score: [0.625      0.6923076  0.5833333  0.3076923  0.39999998]\n","val_label_wise_accuracy: [0.625   0.75    0.6875  0.71875 0.8125 ]\n","val_binary_accuracy: 0.7016666531562805\n","val_precision: 0.5408878326416016\n","val_recall: 0.589058518409729\n","val_label_wise_macro_f1: 0.524401843547821\n","val_subset_accuracy: 0.20000000298023224\n","val_subset_precision: 0.5734374523162842\n","val_subset_recall: 0.6196874380111694\n","val_subset_f1: 0.5941277146339417\n","val_auc: 0.7230345606803894\n","val_prc_auc: 0.5468120574951172\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - auc: 0.8146 - binary_accuracy: 0.7665 - label_wise_accuracy: 0.7671 - label_wise_f1_score: 0.6259 - label_wise_macro_f1: 0.6260 - loss: 0.6021 - prc_auc: 0.6722 - precision: 0.6083 - recall: 0.7167 - subset_accuracy: 0.2831 - subset_f1: 0.7089 - subset_precision: 0.6646 - subset_recall: 0.7630 - val_auc: 0.7230 - val_binary_accuracy: 0.7017 - val_label_wise_accuracy: 0.7188 - val_label_wise_f1_score: 0.5217 - val_label_wise_macro_f1: 0.5244 - val_loss: 0.6224 - val_prc_auc: 0.5468 - val_precision: 0.5409 - val_recall: 0.5891 - val_subset_accuracy: 0.2000 - val_subset_f1: 0.5941 - val_subset_precision: 0.5734 - val_subset_recall: 0.6197\n","Epoch 6/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8171 - binary_accuracy: 0.7688 - label_wise_accuracy: 0.7691 - label_wise_f1_score: 0.6277 - label_wise_macro_f1: 0.6280 - loss: 0.5873 - prc_auc: 0.6747 - precision: 0.6119 - recall: 0.7173 - subset_accuracy: 0.2865 - subset_f1: 0.7125 - subset_precision: 0.6689 - subset_recall: 0.7656\n","Epoch 6: Validation Metrics:\n","loss: 0.5837475657463074\n","val_label_wise_f1_score: [0.625      0.6923076  0.6086956  0.39999995 0.39999998]\n","val_label_wise_accuracy: [0.625   0.75    0.71875 0.71875 0.8125 ]\n","val_binary_accuracy: 0.7037500143051147\n","val_precision: 0.5439624786376953\n","val_recall: 0.5903307795524597\n","val_label_wise_macro_f1: 0.528306782245636\n","val_subset_accuracy: 0.2083333283662796\n","val_subset_precision: 0.5795138478279114\n","val_subset_recall: 0.6217707991600037\n","val_subset_f1: 0.5981783270835876\n","val_auc: 0.7242669463157654\n","val_prc_auc: 0.5460836887359619\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - auc: 0.8171 - binary_accuracy: 0.7688 - label_wise_accuracy: 0.7688 - label_wise_f1_score: 0.6271 - label_wise_macro_f1: 0.6280 - loss: 0.5872 - prc_auc: 0.6747 - precision: 0.6119 - recall: 0.7173 - subset_accuracy: 0.2866 - subset_f1: 0.7125 - subset_precision: 0.6689 - subset_recall: 0.7656 - val_auc: 0.7243 - val_binary_accuracy: 0.7038 - val_label_wise_accuracy: 0.7250 - val_label_wise_f1_score: 0.5452 - val_label_wise_macro_f1: 0.5283 - val_loss: 0.6141 - val_prc_auc: 0.5461 - val_precision: 0.5440 - val_recall: 0.5903 - val_subset_accuracy: 0.2083 - val_subset_f1: 0.5982 - val_subset_precision: 0.5795 - val_subset_recall: 0.6218\n","Epoch 7/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8186 - binary_accuracy: 0.7693 - label_wise_accuracy: 0.7696 - label_wise_f1_score: 0.6279 - label_wise_macro_f1: 0.6274 - loss: 0.5745 - prc_auc: 0.6766 - precision: 0.6130 - recall: 0.7158 - subset_accuracy: 0.2837 - subset_f1: 0.7122 - subset_precision: 0.6699 - subset_recall: 0.7635\n","Epoch 7: Validation Metrics:\n","loss: 0.571387529373169\n","val_label_wise_f1_score: [0.625      0.6923076  0.6086956  0.39999995 0.44444442]\n","val_label_wise_accuracy: [0.625   0.75    0.71875 0.71875 0.84375]\n","val_binary_accuracy: 0.7054166793823242\n","val_precision: 0.5465252995491028\n","val_recall: 0.5903307795524597\n","val_label_wise_macro_f1: 0.5302387475967407\n","val_subset_accuracy: 0.21041665971279144\n","val_subset_precision: 0.5847222805023193\n","val_subset_recall: 0.6217707991600037\n","val_subset_f1: 0.6008695363998413\n","val_auc: 0.7254360318183899\n","val_prc_auc: 0.5469954013824463\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - auc: 0.8186 - binary_accuracy: 0.7693 - label_wise_accuracy: 0.7694 - label_wise_f1_score: 0.6274 - label_wise_macro_f1: 0.6274 - loss: 0.5744 - prc_auc: 0.6766 - precision: 0.6130 - recall: 0.7158 - subset_accuracy: 0.2837 - subset_f1: 0.7122 - subset_precision: 0.6700 - subset_recall: 0.7635 - val_auc: 0.7254 - val_binary_accuracy: 0.7054 - val_label_wise_accuracy: 0.7312 - val_label_wise_f1_score: 0.5541 - val_label_wise_macro_f1: 0.5302 - val_loss: 0.6074 - val_prc_auc: 0.5470 - val_precision: 0.5465 - val_recall: 0.5903 - val_subset_accuracy: 0.2104 - val_subset_f1: 0.6009 - val_subset_precision: 0.5847 - val_subset_recall: 0.6218\n","Epoch 8/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8198 - binary_accuracy: 0.7695 - label_wise_accuracy: 0.7707 - label_wise_f1_score: 0.6292 - label_wise_macro_f1: 0.6283 - loss: 0.5634 - prc_auc: 0.6783 - precision: 0.6133 - recall: 0.7159 - subset_accuracy: 0.2869 - subset_f1: 0.7129 - subset_precision: 0.6711 - subset_recall: 0.7636\n","Epoch 8: Validation Metrics:\n","loss: 0.560735821723938\n","val_label_wise_f1_score: [0.625      0.6923076  0.6086956  0.39999995 0.44444442]\n","val_label_wise_accuracy: [0.625   0.75    0.71875 0.71875 0.84375]\n","val_binary_accuracy: 0.7054166197776794\n","val_precision: 0.5466352105140686\n","val_recall: 0.589058518409729\n","val_label_wise_macro_f1: 0.5296533107757568\n","val_subset_accuracy: 0.21041665971279144\n","val_subset_precision: 0.5852431058883667\n","val_subset_recall: 0.6196874380111694\n","val_subset_f1: 0.6000707745552063\n","val_auc: 0.7257004380226135\n","val_prc_auc: 0.546190619468689\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - auc: 0.8198 - binary_accuracy: 0.7695 - label_wise_accuracy: 0.7704 - label_wise_f1_score: 0.6287 - label_wise_macro_f1: 0.6283 - loss: 0.5634 - prc_auc: 0.6783 - precision: 0.6133 - recall: 0.7159 - subset_accuracy: 0.2869 - subset_f1: 0.7129 - subset_precision: 0.6712 - subset_recall: 0.7636 - val_auc: 0.7257 - val_binary_accuracy: 0.7054 - val_label_wise_accuracy: 0.7312 - val_label_wise_f1_score: 0.5541 - val_label_wise_macro_f1: 0.5297 - val_loss: 0.6020 - val_prc_auc: 0.5462 - val_precision: 0.5466 - val_recall: 0.5891 - val_subset_accuracy: 0.2104 - val_subset_f1: 0.6001 - val_subset_precision: 0.5852 - val_subset_recall: 0.6197\n","Epoch 9/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8206 - binary_accuracy: 0.7709 - label_wise_accuracy: 0.7722 - label_wise_f1_score: 0.6312 - label_wise_macro_f1: 0.6317 - loss: 0.5539 - prc_auc: 0.6794 - precision: 0.6155 - recall: 0.7172 - subset_accuracy: 0.2887 - subset_f1: 0.7152 - subset_precision: 0.6734 - subset_recall: 0.7658\n","Epoch 9: Validation Metrics:\n","loss: 0.5515496134757996\n","val_label_wise_f1_score: [0.625      0.6923076  0.6086956  0.39999995 0.44444442]\n","val_label_wise_accuracy: [0.625   0.75    0.71875 0.71875 0.84375]\n","val_binary_accuracy: 0.7045833468437195\n","val_precision: 0.5453474521636963\n","val_recall: 0.589058518409729\n","val_label_wise_macro_f1: 0.5288391709327698\n","val_subset_accuracy: 0.21041665971279144\n","val_subset_precision: 0.5821180939674377\n","val_subset_recall: 0.6186457872390747\n","val_subset_f1: 0.5980105996131897\n","val_auc: 0.7265021204948425\n","val_prc_auc: 0.546044647693634\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - auc: 0.8206 - binary_accuracy: 0.7709 - label_wise_accuracy: 0.7719 - label_wise_f1_score: 0.6307 - label_wise_macro_f1: 0.6317 - loss: 0.5539 - prc_auc: 0.6794 - precision: 0.6155 - recall: 0.7172 - subset_accuracy: 0.2887 - subset_f1: 0.7152 - subset_precision: 0.6735 - subset_recall: 0.7658 - val_auc: 0.7265 - val_binary_accuracy: 0.7046 - val_label_wise_accuracy: 0.7312 - val_label_wise_f1_score: 0.5541 - val_label_wise_macro_f1: 0.5288 - val_loss: 0.5977 - val_prc_auc: 0.5460 - val_precision: 0.5453 - val_recall: 0.5891 - val_subset_accuracy: 0.2104 - val_subset_f1: 0.5980 - val_subset_precision: 0.5821 - val_subset_recall: 0.6186\n","Epoch 10/15\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - auc: 0.8213 - binary_accuracy: 0.7717 - label_wise_accuracy: 0.7731 - label_wise_f1_score: 0.6327 - label_wise_macro_f1: 0.6336 - loss: 0.5457 - prc_auc: 0.6807 - precision: 0.6166 - recall: 0.7186 - subset_accuracy: 0.2910 - subset_f1: 0.7166 - subset_precision: 0.6745 - subset_recall: 0.7673\n","Epoch 10: Validation Metrics:\n","loss: 0.5436158180236816\n","val_label_wise_f1_score: [0.625      0.71999997 0.6086956  0.39999995 0.44444442]\n","val_label_wise_accuracy: [0.625   0.78125 0.71875 0.71875 0.84375]\n","val_binary_accuracy: 0.7058334350585938\n","val_precision: 0.5473933815956116\n","val_recall: 0.5877862572669983\n","val_label_wise_macro_f1: 0.529304563999176\n","val_subset_accuracy: 0.21041665971279144\n","val_subset_precision: 0.5843750238418579\n","val_subset_recall: 0.6181249618530273\n","val_subset_f1: 0.5988104939460754\n","val_auc: 0.7266585826873779\n","val_prc_auc: 0.5466270446777344\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - auc: 0.8213 - binary_accuracy: 0.7717 - label_wise_accuracy: 0.7728 - label_wise_f1_score: 0.6322 - label_wise_macro_f1: 0.6336 - loss: 0.5457 - prc_auc: 0.6808 - precision: 0.6166 - recall: 0.7186 - subset_accuracy: 0.2910 - subset_f1: 0.7166 - subset_precision: 0.6745 - subset_recall: 0.7673 - val_auc: 0.7267 - val_binary_accuracy: 0.7058 - val_label_wise_accuracy: 0.7375 - val_label_wise_f1_score: 0.5596 - val_label_wise_macro_f1: 0.5293 - val_loss: 0.5943 - val_prc_auc: 0.5466 - val_precision: 0.5474 - val_recall: 0.5878 - val_subset_accuracy: 0.2104 - val_subset_f1: 0.5988 - val_subset_precision: 0.5844 - val_subset_recall: 0.6181\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Custom_Models/custom_model_20250212_220524.weights.h5\n","Using the trained model\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - auc: 0.7391 - binary_accuracy: 0.7075 - label_wise_accuracy: 0.7036 - label_wise_f1_score: 0.5269 - label_wise_macro_f1: 0.5423 - loss: 0.6024 - prc_auc: 0.5747 - precision: 0.5532 - recall: 0.6088 - subset_accuracy: 0.2005 - subset_f1: 0.6187 - subset_precision: 0.5902 - subset_recall: 0.6524\n","Evaluation Metrics:\n","Loss: 0.6034016013145447\n","Label F1 Scores: [0.42857137 0.55999994 0.5714285  0.33333328 0.24999994]\n","Label Accuracies: [0.5     0.65625 0.71875 0.625   0.625  ]\n","Accuracy: 0.7056090235710144\n","Precision: 0.541887104511261\n","Recall: 0.6063147783279419\n","F1 Score: 0.5293945670127869\n","Subset Accuracy: 0.1979166716337204\n","Subset Precision: 0.5787127017974854\n","Subset Recall: 0.6493188142776489\n","Subset F1: 0.6110230684280396\n","AUC: 0.733629584312439\n","PRC AUC: 0.5662963390350342\n"]}],"source":["# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=15,\n","    batch_size=32,\n","    number_of_tags=5,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250212_001142_5_tags_1_epoch')\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495627,"status":"ok","timestamp":1738627541119,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"QNraNQLMG2Ga","outputId":"5c208d8d-1b71-4a42-84e8-676813dfe553"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_225321.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"name":"stdout","output_type":"stream","text":["Loaded transformer model from: /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250203_225321\n","Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 158/158 [03:28<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 44/44 [00:57<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2241, number of negative: 2784\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025515 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.445970 -> initscore=-0.216967\n","[LightGBM] [Info] Start training from score -0.216967\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1979, number of negative: 3046\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015391 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195842\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 769\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393831 -> initscore=-0.431238\n","[LightGBM] [Info] Start training from score -0.431238\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1883, number of negative: 3142\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014327 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195844\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 770\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.374726 -> initscore=-0.511993\n","[LightGBM] [Info] Start training from score -0.511993\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1849, number of negative: 3176\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014668 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195846\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 771\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.367960 -> initscore=-0.540978\n","[LightGBM] [Info] Start training from score -0.540978\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1677, number of negative: 3348\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022198 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195848\n","[LightGBM] [Info] Number of data points in the train set: 5025, number of used features: 772\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333731 -> initscore=-0.691357\n","[LightGBM] [Info] Start training from score -0.691357\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: SVC\n"]}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='microsoft/mpnet-base',\n","    model_path= os.path.join(CONFIG[\"MODEL_SAVE_PATH_ROOT\"], 'custom_model_20250203_225321.weights.h5'),\n","    transformer_model_path= os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250203_225321')\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a76d43f7e247423d8bd0267409172ae1","8ef25127aea24b65aed075efbf782bd9","4905559eaa5b40779fa2d579308ddeb3","ec09a2d650af46328f1be4ad121ed09f","42f3658a4ec241fc93c783ee84caa9cf","aa274429fd264ada9935779eaa1ca354","faaa9d56430f4cd1854b1775bc3172ba","baa06b0ec2d34d02b113f8503fddc216","d441459d1c884b52b9772285b2fd17f0","9c4cd35bd3c64007a9744c871f60f686","b1ae715e675d45c2957a160069ac7d08","76c7ede6ff5e462a8312821bad1a8202","4dc6ae2f526f4653a54c0c07381768db","c42874edb92e43cca983af83dc96420b","4bdb5352724c40eb9d493cb1efd743d1","d4da583e676f4d08a7e4356e6c19f394","6812d035d701491cb605814f86bcbb3e","4549d9c099ab48e88afcbb1d8f4c789d","224fb6448d974adc8c89a7e5d92893f2","ca45baf4c67c4a679a7300e9fb6e18d3","ae478ac2bfec4d3694f2550a6e7d28e8","1969c0b6db9c4f47b22607038a7b1a79","37822c1dea7c4066891fe9dc2bfad9de","0607fc3d5ee2416ea523bd5cce0e8c80","4b42397cb6fa4f13a52fcdfc4e7d7095","115fb8c0adf84e5687cdfecaddc7fc88","b469b0c304d84cbe9467cc76204428c5","15ff464abd8f4c98bcacb672569a8dc6","824bdcb736db49b0b01e101f3d4bbe32","dbca1f857e064aeeabac2f8eac9c9ba7","ae0bdf64c6fe474ba4b361a10d3406ab","5a2a9545b11644b6a7c683c3baa92760","54739fd4f13d4b128a24de6e70c503f3","cd6805a6b4bc490bb3dabb61504ab8e6","fed591da0d304c0f8b320ff464c5666c","2c6bd7e97ea2414aac33c456b046e873","6dd438058253463ab15a65ad8f33192f","1872502f5bbf42d1827f773b9bcd37f6","eee4ebb41d904ad7a3084540c6b2f33a","229551aa84fd4c7787adcc867eabba53","a75a543c4a414a9e98646af48b6bbe80","c77a74539b4a4ca7a56aae18c674362e","67b0ded56d4342698ab40156896dbef3","da87376fe355463386e1bcae2d6146d4","f394cc47b76c424ea50f39894d33a95e","ae139a3cd6614bdb8b13997dfa0926c7","e3067982ccdd4f4b9e25d084782b196b","b2026bb57acb43ccabb5254e5a74b4d6","5c535e651f1c4adcbaa60791742af937","25c1221c444c4c6e81dc25e8ab06143f","359a25604e64401bba227185ae1c76c6","e2efb55c88a44d24941853097ec4a60d","bcb1e5270d0b4d76ad75e7f33f15895a","18c24b0b760a4b5e8dfcbace68fd7469","f9642ec2fd524b17a5a1ce5f4f5c1ee1","64e547717c224c02981da5a4ff0462a4","810f6376fd9e4b4589f1d76bdbbba698","65b9b5ea95334da8a0519f61e9dd4c8b","3a0217664365498e81c1375d11696089","a763decf210b4bb19269b66251f8ff6f","36965743912a4bbc83a05b3c55b9e544","fcb2b70818dd4586bc146ccf99f08869","b654486cb19443ec88cba4f74f18da7b","ece2b16bff0d42e1a080df7ff743a59d","42f47dbea5d44dff9749627569b344e3","afd7b77b1b5e41b9aa344ef3d4af6eee"]},"executionInfo":{"elapsed":570286,"status":"ok","timestamp":1738962694527,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"P780gFGDJfn_","outputId":"d4957257-75fd-4827-f2ea-e6d532f9d1be"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a76d43f7e247423d8bd0267409172ae1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76c7ede6ff5e462a8312821bad1a8202","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37822c1dea7c4066891fe9dc2bfad9de","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd6805a6b4bc490bb3dabb61504ab8e6","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f394cc47b76c424ea50f39894d33a95e","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64e547717c224c02981da5a4ff0462a4","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 279/279 [01:04<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 39/39 [00:08<00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 3400, number of negative: 5516\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048537 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381337 -> initscore=-0.483878\n","[LightGBM] [Info] Start training from score -0.483878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 3334, number of negative: 5582\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024986 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195842\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 769\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373934 -> initscore=-0.515374\n","[LightGBM] [Info] Start training from score -0.515374\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2998, number of negative: 5918\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022292 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195844\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 770\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336249 -> initscore=-0.680053\n","[LightGBM] [Info] Start training from score -0.680053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2390, number of negative: 6526\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022028 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195846\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 771\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268057 -> initscore=-1.004501\n","[LightGBM] [Info] Start training from score -1.004501\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2024, number of negative: 6892\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020946 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195848\n","[LightGBM] [Info] Number of data points in the train set: 8916, number of used features: 772\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227008 -> initscore=-1.225286\n","[LightGBM] [Info] Start training from score -1.225286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: SVC\n"]}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2'\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230748,"status":"ok","timestamp":1738956382290,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"MNyOaKubFYPY","outputId":"8b8ad66c-8d94-4bca-cf4c-ba4905b43071"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 140/140 [00:30<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 39/39 [00:08<00:00,  4.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1700, number of negative: 2758\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014652 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.381337 -> initscore=-0.483878\n","[LightGBM] [Info] Start training from score -0.483878\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1667, number of negative: 2791\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.373934 -> initscore=-0.515374\n","[LightGBM] [Info] Start training from score -0.515374\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1499, number of negative: 2959\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021165 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336249 -> initscore=-0.680053\n","[LightGBM] [Info] Start training from score -0.680053\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1195, number of negative: 3263\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012665 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.268057 -> initscore=-1.004501\n","[LightGBM] [Info] Start training from score -1.004501\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 1012, number of negative: 3446\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012527 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4458, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.227008 -> initscore=-1.225286\n","[LightGBM] [Info] Start training from score -1.225286\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: SVC\n"]}],"source":["import os\n","\n","# local application/library specific imports\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import OneVsAllDecisionTreeEvaluator\n","\n","decisionTreeEvaluator = OneVsAllDecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2'\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211836,"status":"ok","timestamp":1738956594129,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"PHgqiOcBdQh_","outputId":"e2435a46-4a1b-4fc4-b144-318752f8cbf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4729 - binary_accuracy: 0.5651 - f1: 0.2521 - loss: 0.6864 - prc_auc: 0.3631 - precision: 0.3538 - recall: 0.1969\n","Epoch 1: Validation Metrics:\n","loss: 0.686181902885437\n","val_binary_accuracy: 0.5854166746139526\n","val_precision: 0.40625\n","val_recall: 0.13903743028640747\n","val_auc: 0.46750378608703613\n","val_prc_auc: 0.38557296991348267\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - auc: 0.4729 - binary_accuracy: 0.5651 - f1: 0.2519 - loss: 0.6864 - prc_auc: 0.3631 - precision: 0.3538 - recall: 0.1966 - val_auc: 0.4675 - val_binary_accuracy: 0.5854 - val_f1: 0.2072 - val_loss: 0.6849 - val_prc_auc: 0.3856 - val_precision: 0.4062 - val_recall: 0.1390\n","Starting training for label: 1\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.5482 - binary_accuracy: 0.4909 - f1: 0.4986 - loss: 0.6955 - prc_auc: 0.4098 - precision: 0.3935 - recall: 0.6811\n","Epoch 1: Validation Metrics:\n","loss: 0.6955739855766296\n","val_binary_accuracy: 0.5395833253860474\n","val_precision: 0.4117647111415863\n","val_recall: 0.5474860072135925\n","val_auc: 0.5642551183700562\n","val_prc_auc: 0.4129665791988373\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - auc: 0.5481 - binary_accuracy: 0.4909 - f1: 0.4985 - loss: 0.6955 - prc_auc: 0.4097 - precision: 0.3935 - recall: 0.6807 - val_auc: 0.5643 - val_binary_accuracy: 0.5396 - val_f1: 0.4700 - val_loss: 0.6895 - val_prc_auc: 0.4130 - val_precision: 0.4118 - val_recall: 0.5475\n","Starting training for label: 2\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5426 - binary_accuracy: 0.5497 - f1: 0.4158 - loss: 0.6886 - prc_auc: 0.3782 - precision: 0.3669 - recall: 0.4815\n","Epoch 1: Validation Metrics:\n","loss: 0.6873651742935181\n","val_binary_accuracy: 0.5791666507720947\n","val_precision: 0.39436620473861694\n","val_recall: 0.3255814015865326\n","val_auc: 0.5228216648101807\n","val_prc_auc: 0.38145366311073303\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 113ms/step - auc: 0.5425 - binary_accuracy: 0.5498 - f1: 0.4157 - loss: 0.6886 - prc_auc: 0.3782 - precision: 0.3669 - recall: 0.4811 - val_auc: 0.5228 - val_binary_accuracy: 0.5792 - val_f1: 0.3567 - val_loss: 0.6860 - val_prc_auc: 0.3815 - val_precision: 0.3944 - val_recall: 0.3256\n","Starting training for label: 3\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4647 - binary_accuracy: 0.4365 - f1: 0.3634 - loss: 0.7060 - prc_auc: 0.2438 - precision: 0.2610 - recall: 0.6001\n","Epoch 1: Validation Metrics:\n","loss: 0.7018375992774963\n","val_binary_accuracy: 0.48750001192092896\n","val_precision: 0.22466960549354553\n","val_recall: 0.42148759961128235\n","val_auc: 0.4521167576313019\n","val_prc_auc: 0.21609055995941162\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 113ms/step - auc: 0.4647 - binary_accuracy: 0.4367 - f1: 0.3632 - loss: 0.7060 - prc_auc: 0.2438 - precision: 0.2609 - recall: 0.5996 - val_auc: 0.4521 - val_binary_accuracy: 0.4875 - val_f1: 0.2931 - val_loss: 0.6973 - val_prc_auc: 0.2161 - val_precision: 0.2247 - val_recall: 0.4215\n","Starting training for label: 4\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4654 - binary_accuracy: 0.6132 - f1: 0.2177 - loss: 0.6776 - prc_auc: 0.2102 - precision: 0.2005 - recall: 0.2400\n","Epoch 1: Validation Metrics:\n","loss: 0.6737685799598694\n","val_binary_accuracy: 0.6833333373069763\n","val_precision: 0.11267605423927307\n","val_recall: 0.0824742242693901\n","val_auc: 0.46710723638534546\n","val_prc_auc: 0.177982896566391\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - auc: 0.4654 - binary_accuracy: 0.6133 - f1: 0.2176 - loss: 0.6775 - prc_auc: 0.2101 - precision: 0.2005 - recall: 0.2397 - val_auc: 0.4671 - val_binary_accuracy: 0.6833 - val_f1: 0.0952 - val_loss: 0.6616 - val_prc_auc: 0.1780 - val_precision: 0.1127 - val_recall: 0.0825\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 249ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 203ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 204ms/step\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step\n","[[0 1 1 0 0]\n"," [0 0 1 0 0]\n"," [0 0 1 0 0]\n"," ...\n"," [0 1 0 1 0]\n"," [0 1 0 0 0]\n"," [0 1 0 1 0]]\n","[[0 0 1 0 0]\n"," [0 1 1 0 0]\n"," [0 1 1 0 0]\n"," ...\n"," [0 0 0 1 1]\n"," [0 0 1 0 0]\n"," [1 1 1 0 0]]\n","test_tags_np shape: (1239, 5)\n","predictions shape: (1239, 5)\n"]}],"source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=1,\n","    batch_size=32,\n","    number_of_tags=5,\n","    train_model=True,\n","    threshold=0.5\n","  )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":854,"referenced_widgets":["ff00d044eee7455ea055d41eecd46ab6","e4623dc4774e45e99eb5d906536f882b","243b4f0208734ba6be91003e326fc874","4dcae359e96247749b629688fc6065cf","6c0aa329098a4233b3d6822c2792c75a","5e90fa6acfeb4b20832f109feb3a137b","b98fa389be82430189b91a2d50a3bc6b","038bfdc607c44422996247e0a7c80c7f","3c2572a8315c477e930ab36657fbdc6c","d21ebc03335849e4a623c2f70f33c436","4d61888ae34040d2970cae8992193349","7310631e936e4d30905352dddeaaf3a7","f2f3918e10ad48dbb18b1414bb6a763d","77ffd8c6b54b4b94a751e3c029a47929","a138ab49a06b46a3b08d2a8de4e356f9","8802fedd0dcc45de9fa4bf229ee13e57","acee79ded0d048e7a4a7e61d8d5fcbb9","9f9ff5ef33e64dc294553b2a45401527","e55e058e23ca45e082bcd554ede43d07","3130d2ce8b1140aea1118882ad271c52","b8b72c52050b4ca79810c9db1428d6f4","9cb87ef2725b486c866e52817ad87a70","17f1416261a6443ebc9ed153b23aed98","4e067ebc1f9040aba9ee4f8c99bcf8bd","5dea9b4c9d7c496e86572882bbe10964","234238bbba354162ac750bbbce732618","0a3f83ff78d147f098b02924c1e0c091","d1f8d84742be4a8697093f49cad6bae8","f81a6633681448e1ac84321a66bbb6b5","7219e14cf440458db316c07e379851b9","b6f664f6320c4118976538aa49194248","c84f86f60e954463861dd9d42d3cdf22","2af7ae8034a14f97a6803d663b06e52a","47152a9d9de34707bbc4a68b68cf7166","a11be7fdedec40aeb32091d9c2c713be","6df8d4fd5c074ce09445cff6ad686673","f31c72a72de04a069831b6c02625ca06","d6126bb4b55f49afb2f94cbcb556cc0b","371dbed25d214ff0b3417747d1aa4e81","3886fa525b2644289609e3747d63a4c1","c25daf2859aa460a917a10ce3f34853c","3907f247e98e442ab9e2a2a46e395eb0","36524922e0b64f84b71f2781e2c6f53e","a9a647e054d8445cad1f2a69ea095578","b1b5444741424aa1bd4cf73d2e1bca2a","09444536f2e045c1b8b390b46ff6d36e","08c43396b31e4d728eecb18166a1f66e","7f71604621644558a5fa465fbdff813f","bdaf413f40584191ae09dc49ef208636","f97f8a1179694d1fbd138eb2dcceb9d5","a8d7395ad5714703a6dd62b1f4d1bfad","5bc9ec3005e74495b44cb0840bf5d1b6","0e5995b871784c78ad5b439719f3c6a4","ed26481f215848ffa1e82c536081d689","8c62f13468194098a4572e0c6390aeef","562910b86fa74e20af9b21cf2f09e7f3","5611117a53fe4ffaa67849d0379f508f","65d11ecfca704cbab78369971eb08c80","a2c1afbf99804724a5f91bced120db0e","13776de58fd84ca095568a9ae79eaa26","a405c677ddc749cf898d2acd2c70b99a","e757bcb54f1a4aeda214a66c201e748d","4f3fa9a374c34fab9237b3eafab125bc","92176040c4a8454ba5e067d0d37d3d99","2059f92c2260492a86e28c8e3a0e09e2","9859bbf180be43708e8c1c71be103e29"]},"id":"JRO_Vzk2MtcV","outputId":"db4c5f4d-5951-4374-f351-af963f6bc27f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff00d044eee7455ea055d41eecd46ab6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7310631e936e4d30905352dddeaaf3a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f1416261a6443ebc9ed153b23aed98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47152a9d9de34707bbc4a68b68cf7166"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b5444741424aa1bd4cf73d2e1bca2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"562910b86fa74e20af9b21cf2f09e7f3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (16, 768)\n","Positive Embeddings Shape: (16, 768)\n","Negative Embeddings Shape: (16, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8c4130e290>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8c41111ed0>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8c4160d290>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tfmp_net_model/mpnet/pooler/dense/kernel:0', 'tfmp_net_model/mpnet/pooler/dense/bias:0'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Anchor Embeddings Shape: (16, 768)\n","Positive Embeddings Shape: (16, 768)\n","Negative Embeddings Shape: (16, 768)\n","Loss Value: Tensor(\"Mean:0\", shape=(), dtype=float32)\n","[<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","Gradients: [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8c41232e50>, <tf.Tensor 'AddN_268:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_269:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_270:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_271:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_272:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_273:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_274:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_275:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_276:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_277:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_278:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_279:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_280:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_281:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_282:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_283:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_284:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_285:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_286:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_287:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_288:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_289:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_290:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_291:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_292:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_293:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_294:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_295:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_296:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_297:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_298:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_299:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_300:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_301:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_302:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_303:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_304:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_305:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_306:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_307:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_308:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_309:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_310:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_311:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_312:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_313:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_314:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_315:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_316:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_317:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_318:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_319:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_320:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_321:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_322:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_323:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_324:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_325:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_326:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_327:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_328:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_329:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_330:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_331:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_332:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_333:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_334:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_335:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_336:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_337:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_338:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_339:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_340:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_341:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_342:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_343:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_344:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_345:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_346:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_347:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_348:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_349:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_350:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_351:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_352:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_353:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_354:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_355:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_356:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_357:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_358:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_359:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_360:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_361:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_362:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_363:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_364:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_365:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_366:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_367:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_368:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_369:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_370:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_371:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_372:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_373:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_374:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_375:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_376:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_377:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_378:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_379:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_380:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_382:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_384:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_386:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_387:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_388:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_389:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_390:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_391:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_392:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_393:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_394:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_395:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_396:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_397:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_398:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_399:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_400:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_401:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_402:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_403:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_404:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_405:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_406:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_407:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_408:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_409:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_410:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_411:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_412:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_413:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_414:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_415:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_416:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_417:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_418:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_419:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_420:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_421:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_422:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_423:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_424:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_425:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_426:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_427:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_428:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_429:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_430:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_431:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_432:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_433:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_434:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_435:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_436:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_437:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_438:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_439:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_440:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_441:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_442:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_443:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_444:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_445:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_446:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_447:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_448:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_449:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_450:0' shape=(768, 768) dtype=float32>, <tf.Tensor 'AddN_451:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_452:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_453:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_454:0' shape=(768, 3072) dtype=float32>, <tf.Tensor 'AddN_455:0' shape=(3072,) dtype=float32>, <tf.Tensor 'AddN_456:0' shape=(3072, 768) dtype=float32>, <tf.Tensor 'AddN_457:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_458:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_459:0' shape=(768,) dtype=float32>, None, None, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8c3e003410>, <tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7e8ca8184b10>, <tf.Tensor 'AddN_460:0' shape=(768,) dtype=float32>, <tf.Tensor 'AddN_461:0' shape=(768,) dtype=float32>]\n","Trainable Variables: [<tf.Variable 'tfmp_net_model/mpnet/encoder/relative_attention_bias/embeddings:0' shape=(32, 12) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/q/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/k/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/v/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/attn/o/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/attention/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/word_embeddings/weight:0' shape=(30527, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/position_embeddings/embeddings:0' shape=(514, 768) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tfmp_net_model/mpnet/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>]\n","\u001b[1m1395/1395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 491ms/step - loss: 0.5983\n","Transformer model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009\n"]}],"source":["# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_5_NLI_TRAINING_DATASET_PATH'], # CONFIG[f'TOP_10_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250211_002605')\n","  )\n","\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e2a54679043643f68269b2d8ad325c3f","bc9364505b6c443494b603c7e27f2d19","abe186e84b6140488498f0940e250db9","b0552d257afb4692a3f84de4c967370e","133a16070bb7494287c0792cd67250ce","484926a3e41543898f72e0c016a4a513","8444187c6dae4aaaafcfb9e53edb1d25","6c5592426e394682b4e9aec25403fc38","deb44b2aa2294007b257810c5c997b80","2eb658645d45477ebc4ee20df2c43b67","c9650c8176d843a2ad281acc4b180fc0","f701f39595b043868f6e52e3f6d5e760","e1ab64b6ff584b7aa5af520862882e4e","e16204a6c2e4435fb5286996b488c2e8","4b8c43d558fe46248bde5eadd416d232","0be3a124385a4ed2b90810911ebf173b","19b22bdae129416fa79f01ef9f8bc964","4a7216014d524fd8aa62afbea6b6fe74","b5f59559e88648f4a877a7e05e161293","2478ce03d7d4489f98cd4d18275dd1d4","1d2e2f2f051c426e8dfb29ad618e834f","08169399262b4a0a93bd3930045d3431","3baf556aa20d418d95267dc1f1551c65","95926958240e4d7fbef3cc6153cf0906","39d64098196745a7b00c30bf274b065e","48c137ff745844b384bedb2d4c4f2fa4","7c2ec8cd9006466b8a9c70b98427bd88","900da647c45342ec81dac0b16ea40066","e4af78b8a56a46dca2be92e0da07e545","909e47768399479391bc2f6575cfdece","48b1051c6e294ffd9c7fb70c0a8d1a30","2d6d81bab9c243efa0707d4d28885e62","5bbf6b096a5241439d9d6bd1be9e8946","45d4fb2451224b9499451f2b81296627","d712c9016a0a40198c3d9b73deaa4cd8","680275bf22ba4f90980e26f623b9a82a","55e28e6c13174d87920164e39d2d73ed","07524f7dfac24d2083f3a20f7d55c2d6","dbedd28d8652417e8f30f0a2b3befe95","d35efd465346414c97055d8c41186809","ed889d9041f0435e9648011de965de4d","cbf7e3396ade4aa88c4d95d22a6ccea1","f2a3036e2e854b5d80f410e4b8e1e5ea","497f26fa4c7b48bcb7339ebf73e6691f","73fda70a2019495a888606f5955d1fb5","c710696ffce64366bef6fb606954ad94","f582f748a0fe4538b32af77b2e465553","43dcddd37ff44da59b105377129ced86","449e9bf86c974947b03a0e0a3b9e6999","b13b8188e25345b29c202cb4715d53f9","8687342b4c39418c80bd7bf9e28d1e3d","a4c71aae1552409a94bb0b007cf483d1","61fd6f7faa6f4b26af2c7335feb6ddae","78366280fac94821ad51b9a3eade571a","dfd7605f59524501a571c1aace81c9ca","5458308ec6d444499c89e58027ae115c","d6a6d47516f24a8e9d2c629599cbe303","fe5d54d3861f4fbcb5e35a4b2c8c85de","9a5906ffca4b4b81a93f84d51b36bfec","9983ffde2c0a49b585a69beeaa39d370","3d61cb10c43f434b8eba3b8ed0fe3524","c168a00564d74d62a6e3de42d022b943","479c53b24aeb43a6b85e2992a607cee8","cfbbdcc5a8924669a24075ddc33e274d","5d345ba95e024f16815f539189db4a0e","a45f9a7fd9904aa3bb659e7b4e63300d"]},"executionInfo":{"elapsed":286198,"status":"error","timestamp":1739397469782,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"ZxccKR9-LaVM","outputId":"15454f2d-b0d2-4a1d-c0d8-ff10f22b1763"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2a54679043643f68269b2d8ad325c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f701f39595b043868f6e52e3f6d5e760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3baf556aa20d418d95267dc1f1551c65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d4fb2451224b9499451f2b81296627"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73fda70a2019495a888606f5955d1fb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5458308ec6d444499c89e58027ae115c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 140/140 [00:33<00:00,  4.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 40/40 [00:08<00:00,  4.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n","Benchmarking estimator model: XGBClassifier\n","Benchmarking estimator model: LGBMClassifier\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1677, number of negative: 2782\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013820 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 4459, number of used features: 768\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376093 -> initscore=-0.506164\n","[LightGBM] [Info] Start training from score -0.506164\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1631, number of negative: 2828\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195842\n","[LightGBM] [Info] Number of data points in the train set: 4459, number of used features: 769\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.365777 -> initscore=-0.550376\n","[LightGBM] [Info] Start training from score -0.550376\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1496, number of negative: 2963\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018459 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195844\n","[LightGBM] [Info] Number of data points in the train set: 4459, number of used features: 770\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.335501 -> initscore=-0.683407\n","[LightGBM] [Info] Start training from score -0.683407\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1182, number of negative: 3277\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012887 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195846\n","[LightGBM] [Info] Number of data points in the train set: 4459, number of used features: 771\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265082 -> initscore=-1.019720\n","[LightGBM] [Info] Start training from score -1.019720\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 1008, number of negative: 3451\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013101 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 195848\n","[LightGBM] [Info] Number of data points in the train set: 4459, number of used features: 772\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226060 -> initscore=-1.230696\n","[LightGBM] [Info] Start training from score -1.230696\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: SVC\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-26254a891985>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdecisionTreeEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m decisionTreeEvaluator.benchmark_model(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mencoder_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/DecisionTreeEvaluator.py\u001b[0m in \u001b[0;36mbenchmark_model\u001b[0;34m(self, encoder_batch_size, number_of_tags, validation, transformer_name, transformer_model_path)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/ClassifierChainWrapper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_problem_statements, train_tags, validation_problem_statements, validation_tags)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_problem_statements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_problem_statements_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, order)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[0m\u001b[1;32m    155\u001b[0m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[1;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_model(\n","    encoder_batch_size=32,\n","    number_of_tags=5,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    # transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250212_001142_5_tags_1_epoch')\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d1ef7465bdad4aa99e46b17336eb08bd","ec374b14f56e46e0a12d176b661b7986","1fbfb85eaf35478e8876053ea46861ef","fd2972deaf514423a63ea6e455612f42","1c3c89caa70341958d09fb76c9a02d25","49b483d2bdb24ba8b75f8c4ddb29eb96","13e239216c1f4ed9b9e29f3062cafd23","d70004a06f3f44d4880a2401202605a7","cf6107f827f148f7b88f7580eeb76331","b5227f1d168c4a9fa524fe9690186985","64c9a91ff67540578251537b14ea0c42","528852e7c28c4539ae814ee12bec9a5f","7b4fe054152843d3b5bf40890a69b0e8","38f5bfa80dff411283a14e914eb4c212","e72957fb8b1c4c1ba5c557149476ffba","ba6b5689165b4ee68cdf5f747ee7bfc6","41cdddf3ec1c44d295665064e03f9c82","dae4dc5507834152b503b21a7294793d","28767b17f89b41ccab96269746c5a949","d410bbf89d97443c846bbb5e29fa5920","c5f9bc5968394f2f969c36228a8ae094","4eb9985bac2048188b8aecbb7befbcca","4fbc7def9aaf4662b0eb6c52805e27ec","9de72624690c418c99d2fe2954d13d3e","f0463927ebb5462094c1b48308884630","5304ffe53dc540a6986de63e64a5218c","6de7169200ff45b1b44745f91c1cdace","783892bb23614a64abae935239a54e55","730d3341411f4068b2258229d107a765","9e0c347fda0241cdac38388706d7ffb5","12f673dce58c4f56bd4c2536bcfbb933","f03273e0d985492398b877e3b72151cb","f84624339e094415af1dd2c649cab8a8","2321b55a4bdf4166bdd7f7f788e4e4fa","5334023429d041b28ff6b914e1ac495c","746dbc44be264efa8af352ab9ea58b52","bc6626908ad64eddb830291dc8a6a938","3298a9c5ebef44f4a8b7c26d1b8dd674","0b11c034c25c4441afe80ec2bdc815ca","b4f21e89d648425a89cb71552aa8c03f","68bac3bc6a2e4fdc8d6fba3d6ba01623","b2f42d2f245e4af5a8ae87119af57704","7d773a0c9d864fe6a635573983decf2f","790249b25d794f458612532abde61263"]},"id":"E67PUmrfEy0H","executionInfo":{"status":"ok","timestamp":1739400960967,"user_tz":-120,"elapsed":1482388,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"e89bdbae-fedd-44af-b2f0-cc9a8c5426c6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ef7465bdad4aa99e46b17336eb08bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"528852e7c28c4539ae814ee12bec9a5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fbc7def9aaf4662b0eb6c52805e27ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2321b55a4bdf4166bdd7f7f788e4e4fa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - auc: 0.1916 - binary_accuracy: 0.3049 - f1: 0.1616 - loss: 0.7370 - prc_auc: 0.3576 - precision: 0.2166 - recall: 0.1291\n","Epoch 1: Validation Metrics:\n","loss: 0.7334312200546265\n","val_binary_accuracy: 0.44727271795272827\n","val_precision: 0.20108695328235626\n","val_recall: 0.19072164595127106\n","val_auc: 0.3182844817638397\n","val_prc_auc: 0.25779181718826294\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 300ms/step - auc: 0.1917 - binary_accuracy: 0.3050 - f1: 0.1616 - loss: 0.7370 - prc_auc: 0.3575 - precision: 0.2165 - recall: 0.1292 - val_auc: 0.3183 - val_binary_accuracy: 0.4473 - val_f1: 0.1958 - val_loss: 0.7084 - val_prc_auc: 0.2578 - val_precision: 0.2011 - val_recall: 0.1907\n","Epoch 2/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.1992 - binary_accuracy: 0.3100 - f1: 0.1713 - loss: 0.7317 - prc_auc: 0.3601 - precision: 0.2280 - recall: 0.1375\n","Epoch 2: Validation Metrics:\n","loss: 0.7266674041748047\n","val_binary_accuracy: 0.46000000834465027\n","val_precision: 0.2185792326927185\n","val_recall: 0.20618556439876556\n","val_auc: 0.3390478193759918\n","val_prc_auc: 0.2644438147544861\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.1994 - binary_accuracy: 0.3101 - f1: 0.1714 - loss: 0.7317 - prc_auc: 0.3600 - precision: 0.2280 - recall: 0.1376 - val_auc: 0.3390 - val_binary_accuracy: 0.4600 - val_f1: 0.2122 - val_loss: 0.7042 - val_prc_auc: 0.2644 - val_precision: 0.2186 - val_recall: 0.2062\n","Epoch 3/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.2334 - binary_accuracy: 0.3265 - f1: 0.2079 - loss: 0.7195 - prc_auc: 0.3722 - precision: 0.2671 - recall: 0.1706\n","Epoch 3: Validation Metrics:\n","loss: 0.7136560082435608\n","val_binary_accuracy: 0.48181816935539246\n","val_precision: 0.2713567912578583\n","val_recall: 0.27835050225257874\n","val_auc: 0.408295214176178\n","val_prc_auc: 0.29010725021362305\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.2338 - binary_accuracy: 0.3268 - f1: 0.2082 - loss: 0.7195 - prc_auc: 0.3721 - precision: 0.2673 - recall: 0.1709 - val_auc: 0.4083 - val_binary_accuracy: 0.4818 - val_f1: 0.2748 - val_loss: 0.6979 - val_prc_auc: 0.2901 - val_precision: 0.2714 - val_recall: 0.2784\n","Epoch 4/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.3756 - binary_accuracy: 0.4031 - f1: 0.3355 - loss: 0.7019 - prc_auc: 0.4341 - precision: 0.3954 - recall: 0.2924\n","Epoch 4: Validation Metrics:\n","loss: 0.6965610384941101\n","val_binary_accuracy: 0.5418182015419006\n","val_precision: 0.39788731932640076\n","val_recall: 0.5824742317199707\n","val_auc: 0.5680093765258789\n","val_prc_auc: 0.39320701360702515\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.3765 - binary_accuracy: 0.4037 - f1: 0.3363 - loss: 0.7019 - prc_auc: 0.4343 - precision: 0.3960 - recall: 0.2932 - val_auc: 0.5680 - val_binary_accuracy: 0.5418 - val_f1: 0.4728 - val_loss: 0.6911 - val_prc_auc: 0.3932 - val_precision: 0.3979 - val_recall: 0.5825\n","Epoch 5/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6580 - binary_accuracy: 0.6398 - f1: 0.6798 - loss: 0.6840 - prc_auc: 0.6217 - precision: 0.6312 - recall: 0.7392\n","Epoch 5: Validation Metrics:\n","loss: 0.6800782680511475\n","val_binary_accuracy: 0.5672727227210999\n","val_precision: 0.4395604431629181\n","val_recall: 0.8247422575950623\n","val_auc: 0.679934561252594\n","val_prc_auc: 0.4992557466030121\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.6584 - binary_accuracy: 0.6400 - f1: 0.6801 - loss: 0.6840 - prc_auc: 0.6220 - precision: 0.6312 - recall: 0.7397 - val_auc: 0.6799 - val_binary_accuracy: 0.5673 - val_f1: 0.5735 - val_loss: 0.6851 - val_prc_auc: 0.4993 - val_precision: 0.4396 - val_recall: 0.8247\n","Epoch 6/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8035 - binary_accuracy: 0.7204 - f1: 0.7688 - loss: 0.6677 - prc_auc: 0.7803 - precision: 0.6730 - recall: 0.8972\n","Epoch 6: Validation Metrics:\n","loss: 0.6650383472442627\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.4615384638309479\n","val_recall: 0.8659793734550476\n","val_auc: 0.7235245704650879\n","val_prc_auc: 0.5436632633209229\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8036 - binary_accuracy: 0.7204 - f1: 0.7687 - loss: 0.6677 - prc_auc: 0.7803 - precision: 0.6729 - recall: 0.8972 - val_auc: 0.7235 - val_binary_accuracy: 0.5964 - val_f1: 0.6022 - val_loss: 0.6798 - val_prc_auc: 0.5437 - val_precision: 0.4615 - val_recall: 0.8660\n","Epoch 7/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8449 - binary_accuracy: 0.7480 - f1: 0.7913 - loss: 0.6528 - prc_auc: 0.8312 - precision: 0.6940 - recall: 0.9213\n","Epoch 7: Validation Metrics:\n","loss: 0.6512749791145325\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.4617486298084259\n","val_recall: 0.8711340427398682\n","val_auc: 0.7333632707595825\n","val_prc_auc: 0.5477904081344604\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8449 - binary_accuracy: 0.7479 - f1: 0.7912 - loss: 0.6528 - prc_auc: 0.8311 - precision: 0.6938 - recall: 0.9213 - val_auc: 0.7334 - val_binary_accuracy: 0.5964 - val_f1: 0.6036 - val_loss: 0.6751 - val_prc_auc: 0.5478 - val_precision: 0.4617 - val_recall: 0.8711\n","Epoch 8/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8577 - binary_accuracy: 0.7610 - f1: 0.8004 - loss: 0.6391 - prc_auc: 0.8468 - precision: 0.7067 - recall: 0.9234\n","Epoch 8: Validation Metrics:\n","loss: 0.6386505365371704\n","val_binary_accuracy: 0.6200000047683716\n","val_precision: 0.47875353693962097\n","val_recall: 0.8711340427398682\n","val_auc: 0.7367803454399109\n","val_prc_auc: 0.5536983609199524\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8577 - binary_accuracy: 0.7609 - f1: 0.8002 - loss: 0.6391 - prc_auc: 0.8466 - precision: 0.7065 - recall: 0.9233 - val_auc: 0.7368 - val_binary_accuracy: 0.6200 - val_f1: 0.6179 - val_loss: 0.6708 - val_prc_auc: 0.5537 - val_precision: 0.4788 - val_recall: 0.8711\n","Epoch 9/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8625 - binary_accuracy: 0.7674 - f1: 0.8048 - loss: 0.6266 - prc_auc: 0.8533 - precision: 0.7119 - recall: 0.9262\n","Epoch 9: Validation Metrics:\n","loss: 0.6270471215248108\n","val_binary_accuracy: 0.6200000047683716\n","val_precision: 0.47875353693962097\n","val_recall: 0.8711340427398682\n","val_auc: 0.7397559285163879\n","val_prc_auc: 0.5582531690597534\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8625 - binary_accuracy: 0.7673 - f1: 0.8047 - loss: 0.6266 - prc_auc: 0.8532 - precision: 0.7117 - recall: 0.9261 - val_auc: 0.7398 - val_binary_accuracy: 0.6200 - val_f1: 0.6179 - val_loss: 0.6671 - val_prc_auc: 0.5583 - val_precision: 0.4788 - val_recall: 0.8711\n","Epoch 10/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8642 - binary_accuracy: 0.7745 - f1: 0.8097 - loss: 0.6150 - prc_auc: 0.8550 - precision: 0.7194 - recall: 0.9263\n","Epoch 10: Validation Metrics:\n","loss: 0.616363525390625\n","val_binary_accuracy: 0.6236363649368286\n","val_precision: 0.48158639669418335\n","val_recall: 0.876288652420044\n","val_auc: 0.7400237321853638\n","val_prc_auc: 0.5568366050720215\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8642 - binary_accuracy: 0.7743 - f1: 0.8095 - loss: 0.6150 - prc_auc: 0.8549 - precision: 0.7192 - recall: 0.9262 - val_auc: 0.7400 - val_binary_accuracy: 0.6236 - val_f1: 0.6216 - val_loss: 0.6637 - val_prc_auc: 0.5568 - val_precision: 0.4816 - val_recall: 0.8763\n","Epoch 11/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8659 - binary_accuracy: 0.7763 - f1: 0.8105 - loss: 0.6044 - prc_auc: 0.8572 - precision: 0.7220 - recall: 0.9240\n","Epoch 11: Validation Metrics:\n","loss: 0.6065097451210022\n","val_binary_accuracy: 0.6254545450210571\n","val_precision: 0.4828571379184723\n","val_recall: 0.8711340427398682\n","val_auc: 0.739350438117981\n","val_prc_auc: 0.5561922192573547\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8659 - binary_accuracy: 0.7762 - f1: 0.8104 - loss: 0.6044 - prc_auc: 0.8571 - precision: 0.7219 - recall: 0.9239 - val_auc: 0.7394 - val_binary_accuracy: 0.6255 - val_f1: 0.6213 - val_loss: 0.6606 - val_prc_auc: 0.5562 - val_precision: 0.4829 - val_recall: 0.8711\n","Epoch 12/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8665 - binary_accuracy: 0.7787 - f1: 0.8115 - loss: 0.5946 - prc_auc: 0.8585 - precision: 0.7262 - recall: 0.9197\n","Epoch 12: Validation Metrics:\n","loss: 0.5974082350730896\n","val_binary_accuracy: 0.6218181848526001\n","val_precision: 0.479885071516037\n","val_recall: 0.8608247637748718\n","val_auc: 0.7408490777015686\n","val_prc_auc: 0.5572720170021057\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8664 - binary_accuracy: 0.7786 - f1: 0.8113 - loss: 0.5946 - prc_auc: 0.8584 - precision: 0.7261 - recall: 0.9196 - val_auc: 0.7408 - val_binary_accuracy: 0.6218 - val_f1: 0.6162 - val_loss: 0.6579 - val_prc_auc: 0.5573 - val_precision: 0.4799 - val_recall: 0.8608\n","Epoch 13/20\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8668 - binary_accuracy: 0.7770 - f1: 0.8092 - loss: 0.5855 - prc_auc: 0.8589 - precision: 0.7267 - recall: 0.9132\n","Epoch 13: Validation Metrics:\n","loss: 0.5889904499053955\n","val_binary_accuracy: 0.6254545450210571\n","val_precision: 0.48255813121795654\n","val_recall: 0.8556700944900513\n","val_auc: 0.7398717403411865\n","val_prc_auc: 0.5544666051864624\n","\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8667 - binary_accuracy: 0.7769 - f1: 0.8091 - loss: 0.5856 - prc_auc: 0.8587 - precision: 0.7266 - recall: 0.9131 - val_auc: 0.7399 - val_binary_accuracy: 0.6255 - val_f1: 0.6171 - val_loss: 0.6554 - val_prc_auc: 0.5545 - val_precision: 0.4826 - val_recall: 0.8557\n","Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - auc: 0.7044 - binary_accuracy: 0.5870 - f1: 0.7037 - loss: 0.6762 - prc_auc: 0.6462 - precision: 0.5515 - recall: 0.9723\n","Epoch 1: Validation Metrics:\n","loss: 0.6758056282997131\n","val_binary_accuracy: 0.41999998688697815\n","val_precision: 0.3586065471172333\n","val_recall: 0.9668508172035217\n","val_auc: 0.6545314192771912\n","val_prc_auc: 0.4297007918357849\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 253ms/step - auc: 0.7045 - binary_accuracy: 0.5870 - f1: 0.7037 - loss: 0.6762 - prc_auc: 0.6462 - precision: 0.5515 - recall: 0.9723 - val_auc: 0.6545 - val_binary_accuracy: 0.4200 - val_f1: 0.5232 - val_loss: 0.7105 - val_prc_auc: 0.4297 - val_precision: 0.3586 - val_recall: 0.9669\n","Epoch 2/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7335 - binary_accuracy: 0.5928 - f1: 0.7065 - loss: 0.6726 - prc_auc: 0.6835 - precision: 0.5551 - recall: 0.9716\n","Epoch 2: Validation Metrics:\n","loss: 0.6707082390785217\n","val_binary_accuracy: 0.43454545736312866\n","val_precision: 0.3645833432674408\n","val_recall: 0.9668508172035217\n","val_auc: 0.6929734349250793\n","val_prc_auc: 0.49421456456184387\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.7337 - binary_accuracy: 0.5928 - f1: 0.7064 - loss: 0.6725 - prc_auc: 0.6837 - precision: 0.5551 - recall: 0.9716 - val_auc: 0.6930 - val_binary_accuracy: 0.4345 - val_f1: 0.5295 - val_loss: 0.7089 - val_prc_auc: 0.4942 - val_precision: 0.3646 - val_recall: 0.9669\n","Epoch 3/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7838 - binary_accuracy: 0.6069 - f1: 0.7141 - loss: 0.6644 - prc_auc: 0.7472 - precision: 0.5641 - recall: 0.9733\n","Epoch 3: Validation Metrics:\n","loss: 0.6611447334289551\n","val_binary_accuracy: 0.4509090781211853\n","val_precision: 0.3704496920108795\n","val_recall: 0.9558011293411255\n","val_auc: 0.7272529602050781\n","val_prc_auc: 0.5371103286743164\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.7840 - binary_accuracy: 0.6070 - f1: 0.7141 - loss: 0.6644 - prc_auc: 0.7474 - precision: 0.5641 - recall: 0.9732 - val_auc: 0.7273 - val_binary_accuracy: 0.4509 - val_f1: 0.5340 - val_loss: 0.7064 - val_prc_auc: 0.5371 - val_precision: 0.3704 - val_recall: 0.9558\n","Epoch 4/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8235 - binary_accuracy: 0.6275 - f1: 0.7234 - loss: 0.6528 - prc_auc: 0.7987 - precision: 0.5785 - recall: 0.9656\n","Epoch 4: Validation Metrics:\n","loss: 0.6486726403236389\n","val_binary_accuracy: 0.4545454680919647\n","val_precision: 0.3698030710220337\n","val_recall: 0.9337016344070435\n","val_auc: 0.7403464317321777\n","val_prc_auc: 0.5689029097557068\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8237 - binary_accuracy: 0.6276 - f1: 0.7234 - loss: 0.6528 - prc_auc: 0.7988 - precision: 0.5785 - recall: 0.9656 - val_auc: 0.7403 - val_binary_accuracy: 0.4545 - val_f1: 0.5298 - val_loss: 0.7033 - val_prc_auc: 0.5689 - val_precision: 0.3698 - val_recall: 0.9337\n","Epoch 5/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8414 - binary_accuracy: 0.6497 - f1: 0.7337 - loss: 0.6410 - prc_auc: 0.8205 - precision: 0.5950 - recall: 0.9571\n","Epoch 5: Validation Metrics:\n","loss: 0.6366649866104126\n","val_binary_accuracy: 0.4745454490184784\n","val_precision: 0.37727272510528564\n","val_recall: 0.9171270728111267\n","val_auc: 0.7442542910575867\n","val_prc_auc: 0.5845207571983337\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8415 - binary_accuracy: 0.6498 - f1: 0.7338 - loss: 0.6410 - prc_auc: 0.8206 - precision: 0.5951 - recall: 0.9572 - val_auc: 0.7443 - val_binary_accuracy: 0.4745 - val_f1: 0.5346 - val_loss: 0.7002 - val_prc_auc: 0.5845 - val_precision: 0.3773 - val_recall: 0.9171\n","Epoch 6/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8488 - binary_accuracy: 0.6710 - f1: 0.7450 - loss: 0.6304 - prc_auc: 0.8295 - precision: 0.6116 - recall: 0.9531\n","Epoch 6: Validation Metrics:\n","loss: 0.6258060932159424\n","val_binary_accuracy: 0.4909090995788574\n","val_precision: 0.3835294246673584\n","val_recall: 0.90055251121521\n","val_auc: 0.7459686994552612\n","val_prc_auc: 0.5898861289024353\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8489 - binary_accuracy: 0.6710 - f1: 0.7450 - loss: 0.6303 - prc_auc: 0.8296 - precision: 0.6116 - recall: 0.9531 - val_auc: 0.7460 - val_binary_accuracy: 0.4909 - val_f1: 0.5380 - val_loss: 0.6972 - val_prc_auc: 0.5899 - val_precision: 0.3835 - val_recall: 0.9006\n","Epoch 7/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8529 - binary_accuracy: 0.6843 - f1: 0.7524 - loss: 0.6207 - prc_auc: 0.8360 - precision: 0.6224 - recall: 0.9511\n","Epoch 7: Validation Metrics:\n","loss: 0.6159082055091858\n","val_binary_accuracy: 0.5072727203369141\n","val_precision: 0.39077669382095337\n","val_recall: 0.889502763748169\n","val_auc: 0.7461408376693726\n","val_prc_auc: 0.5880746841430664\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8530 - binary_accuracy: 0.6843 - f1: 0.7524 - loss: 0.6206 - prc_auc: 0.8361 - precision: 0.6224 - recall: 0.9511 - val_auc: 0.7461 - val_binary_accuracy: 0.5073 - val_f1: 0.5430 - val_loss: 0.6942 - val_prc_auc: 0.5881 - val_precision: 0.3908 - val_recall: 0.8895\n","Epoch 8/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8564 - binary_accuracy: 0.6963 - f1: 0.7585 - loss: 0.6117 - prc_auc: 0.8408 - precision: 0.6331 - recall: 0.9460\n","Epoch 8: Validation Metrics:\n","loss: 0.6068280935287476\n","val_binary_accuracy: 0.5254545211791992\n","val_precision: 0.40049752593040466\n","val_recall: 0.889502763748169\n","val_auc: 0.7464252710342407\n","val_prc_auc: 0.594239354133606\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8564 - binary_accuracy: 0.6963 - f1: 0.7585 - loss: 0.6117 - prc_auc: 0.8408 - precision: 0.6332 - recall: 0.9460 - val_auc: 0.7464 - val_binary_accuracy: 0.5255 - val_f1: 0.5523 - val_loss: 0.6911 - val_prc_auc: 0.5942 - val_precision: 0.4005 - val_recall: 0.8895\n","Epoch 9/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8584 - binary_accuracy: 0.7044 - f1: 0.7622 - loss: 0.6035 - prc_auc: 0.8432 - precision: 0.6412 - recall: 0.9395\n","Epoch 9: Validation Metrics:\n","loss: 0.5984529852867126\n","val_binary_accuracy: 0.5363636612892151\n","val_precision: 0.4056122303009033\n","val_recall: 0.8784530162811279\n","val_auc: 0.7474359273910522\n","val_prc_auc: 0.5940411686897278\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - auc: 0.8584 - binary_accuracy: 0.7044 - f1: 0.7622 - loss: 0.6034 - prc_auc: 0.8433 - precision: 0.6413 - recall: 0.9394 - val_auc: 0.7474 - val_binary_accuracy: 0.5364 - val_f1: 0.5550 - val_loss: 0.6881 - val_prc_auc: 0.5940 - val_precision: 0.4056 - val_recall: 0.8785\n","Epoch 10/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8597 - binary_accuracy: 0.7192 - f1: 0.7712 - loss: 0.5959 - prc_auc: 0.8451 - precision: 0.6544 - recall: 0.9389\n","Epoch 10: Validation Metrics:\n","loss: 0.5906933546066284\n","val_binary_accuracy: 0.5490909218788147\n","val_precision: 0.41253262758255005\n","val_recall: 0.8729282021522522\n","val_auc: 0.7476231455802917\n","val_prc_auc: 0.5962222814559937\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8598 - binary_accuracy: 0.7192 - f1: 0.7712 - loss: 0.5958 - prc_auc: 0.8452 - precision: 0.6544 - recall: 0.9389 - val_auc: 0.7476 - val_binary_accuracy: 0.5491 - val_f1: 0.5603 - val_loss: 0.6851 - val_prc_auc: 0.5962 - val_precision: 0.4125 - val_recall: 0.8729\n","Epoch 11/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8606 - binary_accuracy: 0.7233 - f1: 0.7736 - loss: 0.5887 - prc_auc: 0.8459 - precision: 0.6584 - recall: 0.9377\n","Epoch 11: Validation Metrics:\n","loss: 0.5834763050079346\n","val_binary_accuracy: 0.5600000023841858\n","val_precision: 0.4177897572517395\n","val_recall: 0.8563535809516907\n","val_auc: 0.748049795627594\n","val_prc_auc: 0.5957832932472229\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8607 - binary_accuracy: 0.7233 - f1: 0.7736 - loss: 0.5887 - prc_auc: 0.8459 - precision: 0.6584 - recall: 0.9376 - val_auc: 0.7480 - val_binary_accuracy: 0.5600 - val_f1: 0.5616 - val_loss: 0.6821 - val_prc_auc: 0.5958 - val_precision: 0.4178 - val_recall: 0.8564\n","Epoch 12/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8615 - binary_accuracy: 0.7293 - f1: 0.7765 - loss: 0.5821 - prc_auc: 0.8466 - precision: 0.6650 - recall: 0.9329\n","Epoch 12: Validation Metrics:\n","loss: 0.5767418742179871\n","val_binary_accuracy: 0.5690909028053284\n","val_precision: 0.42307692766189575\n","val_recall: 0.8508287072181702\n","val_auc: 0.747840166091919\n","val_prc_auc: 0.5952010750770569\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - auc: 0.8615 - binary_accuracy: 0.7293 - f1: 0.7765 - loss: 0.5821 - prc_auc: 0.8466 - precision: 0.6650 - recall: 0.9329 - val_auc: 0.7478 - val_binary_accuracy: 0.5691 - val_f1: 0.5651 - val_loss: 0.6791 - val_prc_auc: 0.5952 - val_precision: 0.4231 - val_recall: 0.8508\n","Epoch 13/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8617 - binary_accuracy: 0.7311 - f1: 0.7763 - loss: 0.5759 - prc_auc: 0.8475 - precision: 0.6687 - recall: 0.9252\n","Epoch 13: Validation Metrics:\n","loss: 0.5704407691955566\n","val_binary_accuracy: 0.578181803226471\n","val_precision: 0.4285714328289032\n","val_recall: 0.8453038930892944\n","val_auc: 0.7473536133766174\n","val_prc_auc: 0.5927622318267822\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - auc: 0.8618 - binary_accuracy: 0.7311 - f1: 0.7763 - loss: 0.5758 - prc_auc: 0.8476 - precision: 0.6688 - recall: 0.9252 - val_auc: 0.7474 - val_binary_accuracy: 0.5782 - val_f1: 0.5688 - val_loss: 0.6762 - val_prc_auc: 0.5928 - val_precision: 0.4286 - val_recall: 0.8453\n","Epoch 14/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8625 - binary_accuracy: 0.7381 - f1: 0.7805 - loss: 0.5700 - prc_auc: 0.8487 - precision: 0.6760 - recall: 0.9235\n","Epoch 14: Validation Metrics:\n","loss: 0.5645312666893005\n","val_binary_accuracy: 0.5872727036476135\n","val_precision: 0.43390804529190063\n","val_recall: 0.8342541456222534\n","val_auc: 0.746979296207428\n","val_prc_auc: 0.5920802354812622\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - auc: 0.8625 - binary_accuracy: 0.7381 - f1: 0.7805 - loss: 0.5700 - prc_auc: 0.8487 - precision: 0.6760 - recall: 0.9235 - val_auc: 0.7470 - val_binary_accuracy: 0.5873 - val_f1: 0.5709 - val_loss: 0.6734 - val_prc_auc: 0.5921 - val_precision: 0.4339 - val_recall: 0.8343\n","Epoch 15/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8627 - binary_accuracy: 0.7435 - f1: 0.7838 - loss: 0.5646 - prc_auc: 0.8487 - precision: 0.6818 - recall: 0.9219\n","Epoch 15: Validation Metrics:\n","loss: 0.5589780807495117\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.4402332305908203\n","val_recall: 0.8342541456222534\n","val_auc: 0.7470616102218628\n","val_prc_auc: 0.5930596590042114\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8628 - binary_accuracy: 0.7435 - f1: 0.7838 - loss: 0.5645 - prc_auc: 0.8487 - precision: 0.6818 - recall: 0.9219 - val_auc: 0.7471 - val_binary_accuracy: 0.5964 - val_f1: 0.5763 - val_loss: 0.6706 - val_prc_auc: 0.5931 - val_precision: 0.4402 - val_recall: 0.8343\n","Epoch 16/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8630 - binary_accuracy: 0.7443 - f1: 0.7837 - loss: 0.5594 - prc_auc: 0.8492 - precision: 0.6834 - recall: 0.9187\n","Epoch 16: Validation Metrics:\n","loss: 0.5537512898445129\n","val_binary_accuracy: 0.6000000238418579\n","val_precision: 0.4421364963054657\n","val_recall: 0.8232043981552124\n","val_auc: 0.7472487688064575\n","val_prc_auc: 0.5938433408737183\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8631 - binary_accuracy: 0.7443 - f1: 0.7838 - loss: 0.5593 - prc_auc: 0.8493 - precision: 0.6835 - recall: 0.9187 - val_auc: 0.7472 - val_binary_accuracy: 0.6000 - val_f1: 0.5753 - val_loss: 0.6680 - val_prc_auc: 0.5938 - val_precision: 0.4421 - val_recall: 0.8232\n","Epoch 17/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8632 - binary_accuracy: 0.7479 - f1: 0.7859 - loss: 0.5545 - prc_auc: 0.8489 - precision: 0.6874 - recall: 0.9174\n","Epoch 17: Validation Metrics:\n","loss: 0.5488245487213135\n","val_binary_accuracy: 0.6054545640945435\n","val_precision: 0.44610777497291565\n","val_recall: 0.8232043981552124\n","val_auc: 0.7467846870422363\n","val_prc_auc: 0.5946177840232849\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - auc: 0.8632 - binary_accuracy: 0.7479 - f1: 0.7859 - loss: 0.5545 - prc_auc: 0.8489 - precision: 0.6875 - recall: 0.9173 - val_auc: 0.7468 - val_binary_accuracy: 0.6055 - val_f1: 0.5786 - val_loss: 0.6654 - val_prc_auc: 0.5946 - val_precision: 0.4461 - val_recall: 0.8232\n","Epoch 18/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8633 - binary_accuracy: 0.7523 - f1: 0.7886 - loss: 0.5499 - prc_auc: 0.8498 - precision: 0.6922 - recall: 0.9166\n","Epoch 18: Validation Metrics:\n","loss: 0.54417484998703\n","val_binary_accuracy: 0.614545464515686\n","val_precision: 0.4525993764400482\n","val_recall: 0.8176795840263367\n","val_auc: 0.746552586555481\n","val_prc_auc: 0.5909428596496582\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8633 - binary_accuracy: 0.7523 - f1: 0.7886 - loss: 0.5498 - prc_auc: 0.8498 - precision: 0.6922 - recall: 0.9165 - val_auc: 0.7466 - val_binary_accuracy: 0.6145 - val_f1: 0.5827 - val_loss: 0.6629 - val_prc_auc: 0.5909 - val_precision: 0.4526 - val_recall: 0.8177\n","Epoch 19/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8637 - binary_accuracy: 0.7537 - f1: 0.7888 - loss: 0.5455 - prc_auc: 0.8492 - precision: 0.6950 - recall: 0.9121\n","Epoch 19: Validation Metrics:\n","loss: 0.5397822856903076\n","val_binary_accuracy: 0.6181818246841431\n","val_precision: 0.45538461208343506\n","val_recall: 0.8176795840263367\n","val_auc: 0.7466424107551575\n","val_prc_auc: 0.5937562584877014\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8637 - binary_accuracy: 0.7537 - f1: 0.7889 - loss: 0.5455 - prc_auc: 0.8492 - precision: 0.6951 - recall: 0.9121 - val_auc: 0.7466 - val_binary_accuracy: 0.6182 - val_f1: 0.5850 - val_loss: 0.6605 - val_prc_auc: 0.5938 - val_precision: 0.4554 - val_recall: 0.8177\n","Epoch 20/20\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8633 - binary_accuracy: 0.7550 - f1: 0.7896 - loss: 0.5414 - prc_auc: 0.8495 - precision: 0.6966 - recall: 0.9115\n","Epoch 20: Validation Metrics:\n","loss: 0.5356287956237793\n","val_binary_accuracy: 0.6236363649368286\n","val_precision: 0.4591194987297058\n","val_recall: 0.8066298365592957\n","val_auc: 0.746058464050293\n","val_prc_auc: 0.5919177532196045\n","\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - auc: 0.8634 - binary_accuracy: 0.7550 - f1: 0.7896 - loss: 0.5414 - prc_auc: 0.8495 - precision: 0.6967 - recall: 0.9115 - val_auc: 0.7461 - val_binary_accuracy: 0.6236 - val_f1: 0.5852 - val_loss: 0.6583 - val_prc_auc: 0.5919 - val_precision: 0.4591 - val_recall: 0.8066\n","Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - auc: 0.6844 - binary_accuracy: 0.6167 - f1: 0.5649 - loss: 0.6664 - prc_auc: 0.6274 - precision: 0.6257 - recall: 0.5152\n","Epoch 1: Validation Metrics:\n","loss: 0.668780505657196\n","val_binary_accuracy: 0.6327272653579712\n","val_precision: 0.3837837874889374\n","val_recall: 0.446540892124176\n","val_auc: 0.6124756932258606\n","val_prc_auc: 0.3888552188873291\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 263ms/step - auc: 0.6843 - binary_accuracy: 0.6166 - f1: 0.5650 - loss: 0.6664 - prc_auc: 0.6274 - precision: 0.6258 - recall: 0.5153 - val_auc: 0.6125 - val_binary_accuracy: 0.6327 - val_f1: 0.4128 - val_loss: 0.6621 - val_prc_auc: 0.3889 - val_precision: 0.3838 - val_recall: 0.4465\n","Epoch 2/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6996 - binary_accuracy: 0.6346 - f1: 0.5976 - loss: 0.6631 - prc_auc: 0.6482 - precision: 0.6384 - recall: 0.5620\n","Epoch 2: Validation Metrics:\n","loss: 0.6643258929252625\n","val_binary_accuracy: 0.6327272653579712\n","val_precision: 0.3951219618320465\n","val_recall: 0.5094339847564697\n","val_auc: 0.6268960237503052\n","val_prc_auc: 0.3964933156967163\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - auc: 0.6996 - binary_accuracy: 0.6347 - f1: 0.5981 - loss: 0.6632 - prc_auc: 0.6485 - precision: 0.6387 - recall: 0.5625 - val_auc: 0.6269 - val_binary_accuracy: 0.6327 - val_f1: 0.4451 - val_loss: 0.6628 - val_prc_auc: 0.3965 - val_precision: 0.3951 - val_recall: 0.5094\n","Epoch 3/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7273 - binary_accuracy: 0.6685 - f1: 0.6566 - loss: 0.6562 - prc_auc: 0.6890 - precision: 0.6574 - recall: 0.6561\n","Epoch 3: Validation Metrics:\n","loss: 0.6560603380203247\n","val_binary_accuracy: 0.6181818246841431\n","val_precision: 0.3933054506778717\n","val_recall: 0.5911949872970581\n","val_auc: 0.6428203582763672\n","val_prc_auc: 0.4088941514492035\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - auc: 0.7275 - binary_accuracy: 0.6685 - f1: 0.6569 - loss: 0.6562 - prc_auc: 0.6895 - precision: 0.6576 - recall: 0.6567 - val_auc: 0.6428 - val_binary_accuracy: 0.6182 - val_f1: 0.4724 - val_loss: 0.6642 - val_prc_auc: 0.4089 - val_precision: 0.3933 - val_recall: 0.5912\n","Epoch 4/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7581 - binary_accuracy: 0.6935 - f1: 0.7024 - loss: 0.6464 - prc_auc: 0.7366 - precision: 0.6615 - recall: 0.7488\n","Epoch 4: Validation Metrics:\n","loss: 0.6452140808105469\n","val_binary_accuracy: 0.589090883731842\n","val_precision: 0.379928320646286\n","val_recall: 0.6666666865348816\n","val_auc: 0.6552944183349609\n","val_prc_auc: 0.41473454236984253\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - auc: 0.7583 - binary_accuracy: 0.6935 - f1: 0.7026 - loss: 0.6464 - prc_auc: 0.7372 - precision: 0.6616 - recall: 0.7492 - val_auc: 0.6553 - val_binary_accuracy: 0.5891 - val_f1: 0.4840 - val_loss: 0.6663 - val_prc_auc: 0.4147 - val_precision: 0.3799 - val_recall: 0.6667\n","Epoch 5/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7803 - binary_accuracy: 0.6953 - f1: 0.7182 - loss: 0.6362 - prc_auc: 0.7726 - precision: 0.6491 - recall: 0.8041\n","Epoch 5: Validation Metrics:\n","loss: 0.6346244812011719\n","val_binary_accuracy: 0.589090883731842\n","val_precision: 0.3864406645298004\n","val_recall: 0.7169811129570007\n","val_auc: 0.6622995138168335\n","val_prc_auc: 0.41758841276168823\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - auc: 0.7804 - binary_accuracy: 0.6952 - f1: 0.7183 - loss: 0.6361 - prc_auc: 0.7730 - precision: 0.6491 - recall: 0.8043 - val_auc: 0.6623 - val_binary_accuracy: 0.5891 - val_f1: 0.5022 - val_loss: 0.6686 - val_prc_auc: 0.4176 - val_precision: 0.3864 - val_recall: 0.7170\n","Epoch 6/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7931 - binary_accuracy: 0.6968 - f1: 0.7259 - loss: 0.6273 - prc_auc: 0.7937 - precision: 0.6444 - recall: 0.8312\n","Epoch 6: Validation Metrics:\n","loss: 0.6254833936691284\n","val_binary_accuracy: 0.5672727227210999\n","val_precision: 0.37380191683769226\n","val_recall: 0.7358490824699402\n","val_auc: 0.6649294495582581\n","val_prc_auc: 0.4219568371772766\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - auc: 0.7932 - binary_accuracy: 0.6968 - f1: 0.7261 - loss: 0.6273 - prc_auc: 0.7940 - precision: 0.6445 - recall: 0.8315 - val_auc: 0.6649 - val_binary_accuracy: 0.5673 - val_f1: 0.4958 - val_loss: 0.6711 - val_prc_auc: 0.4220 - val_precision: 0.3738 - val_recall: 0.7358\n","Epoch 7/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8012 - binary_accuracy: 0.6954 - f1: 0.7287 - loss: 0.6196 - prc_auc: 0.8069 - precision: 0.6396 - recall: 0.8469\n","Epoch 7: Validation Metrics:\n","loss: 0.6175592541694641\n","val_binary_accuracy: 0.5600000023841858\n","val_precision: 0.3690851628780365\n","val_recall: 0.7358490824699402\n","val_auc: 0.6650742292404175\n","val_prc_auc: 0.4189794361591339\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - auc: 0.8013 - binary_accuracy: 0.6954 - f1: 0.7288 - loss: 0.6196 - prc_auc: 0.8072 - precision: 0.6397 - recall: 0.8471 - val_auc: 0.6651 - val_binary_accuracy: 0.5600 - val_f1: 0.4916 - val_loss: 0.6737 - val_prc_auc: 0.4190 - val_precision: 0.3691 - val_recall: 0.7358\n","Epoch 8/20\n","\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8064 - binary_accuracy: 0.6938 - f1: 0.7304 - loss: 0.6129 - prc_auc: 0.8141 - precision: 0.6356 - recall: 0.8589\n","Epoch 8: Validation Metrics:\n","loss: 0.6106544137001038\n","val_binary_accuracy: 0.5545454621315002\n","val_precision: 0.3664596378803253\n","val_recall: 0.7421383857727051\n","val_auc: 0.6666907668113708\n","val_prc_auc: 0.42003974318504333\n","\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - auc: 0.8065 - binary_accuracy: 0.6937 - f1: 0.7305 - loss: 0.6129 - prc_auc: 0.8143 - precision: 0.6357 - recall: 0.8590 - val_auc: 0.6667 - val_binary_accuracy: 0.5545 - val_f1: 0.4906 - val_loss: 0.6762 - val_prc_auc: 0.4200 - val_precision: 0.3665 - val_recall: 0.7421\n","Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - auc: 0.3022 - binary_accuracy: 0.3321 - f1: 0.3272 - loss: 0.7223 - prc_auc: 0.3728 - precision: 0.3230 - recall: 0.3317\n","Epoch 1: Validation Metrics:\n","loss: 0.7207790613174438\n","val_binary_accuracy: 0.37272727489471436\n","val_precision: 0.23055554926395416\n","val_recall: 0.5496688485145569\n","val_auc: 0.41467076539993286\n","val_prc_auc: 0.23124375939369202\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 315ms/step - auc: 0.3023 - binary_accuracy: 0.3321 - f1: 0.3273 - loss: 0.7223 - prc_auc: 0.3729 - precision: 0.3232 - recall: 0.3318 - val_auc: 0.4147 - val_binary_accuracy: 0.3727 - val_f1: 0.3249 - val_loss: 0.7158 - val_prc_auc: 0.2312 - val_precision: 0.2306 - val_recall: 0.5497\n","Epoch 2/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3213 - binary_accuracy: 0.3538 - f1: 0.3543 - loss: 0.7184 - prc_auc: 0.3818 - precision: 0.3470 - recall: 0.3620\n","Epoch 2: Validation Metrics:\n","loss: 0.7156782746315002\n","val_binary_accuracy: 0.3909091055393219\n","val_precision: 0.24444444477558136\n","val_recall: 0.5827814340591431\n","val_auc: 0.44231441617012024\n","val_prc_auc: 0.24441298842430115\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - auc: 0.3216 - binary_accuracy: 0.3539 - f1: 0.3544 - loss: 0.7184 - prc_auc: 0.3820 - precision: 0.3472 - recall: 0.3621 - val_auc: 0.4423 - val_binary_accuracy: 0.3909 - val_f1: 0.3444 - val_loss: 0.7112 - val_prc_auc: 0.2444 - val_precision: 0.2444 - val_recall: 0.5828\n","Epoch 3/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3811 - binary_accuracy: 0.3902 - f1: 0.3949 - loss: 0.7095 - prc_auc: 0.4079 - precision: 0.3841 - recall: 0.4066\n","Epoch 3: Validation Metrics:\n","loss: 0.705664873123169\n","val_binary_accuracy: 0.43272727727890015\n","val_precision: 0.26530611515045166\n","val_recall: 0.6026490330696106\n","val_auc: 0.5007966756820679\n","val_prc_auc: 0.2797999382019043\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.3814 - binary_accuracy: 0.3906 - f1: 0.3953 - loss: 0.7095 - prc_auc: 0.4082 - precision: 0.3846 - recall: 0.4069 - val_auc: 0.5008 - val_binary_accuracy: 0.4327 - val_f1: 0.3684 - val_loss: 0.7039 - val_prc_auc: 0.2798 - val_precision: 0.2653 - val_recall: 0.6026\n","Epoch 4/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4901 - binary_accuracy: 0.4951 - f1: 0.5273 - loss: 0.6961 - prc_auc: 0.4729 - precision: 0.4870 - recall: 0.5750\n","Epoch 4: Validation Metrics:\n","loss: 0.6912827491760254\n","val_binary_accuracy: 0.5127272605895996\n","val_precision: 0.3211009204387665\n","val_recall: 0.695364236831665\n","val_auc: 0.5814619064331055\n","val_prc_auc: 0.34063470363616943\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - auc: 0.4907 - binary_accuracy: 0.4956 - f1: 0.5279 - loss: 0.6960 - prc_auc: 0.4734 - precision: 0.4876 - recall: 0.5756 - val_auc: 0.5815 - val_binary_accuracy: 0.5127 - val_f1: 0.4393 - val_loss: 0.6944 - val_prc_auc: 0.3406 - val_precision: 0.3211 - val_recall: 0.6954\n","Epoch 5/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6502 - binary_accuracy: 0.6237 - f1: 0.6621 - loss: 0.6788 - prc_auc: 0.6127 - precision: 0.5913 - recall: 0.7526\n","Epoch 5: Validation Metrics:\n","loss: 0.673620879650116\n","val_binary_accuracy: 0.5927272439002991\n","val_precision: 0.3728223145008087\n","val_recall: 0.7086092829704285\n","val_auc: 0.6559113264083862\n","val_prc_auc: 0.4306946098804474\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.6507 - binary_accuracy: 0.6241 - f1: 0.6625 - loss: 0.6787 - prc_auc: 0.6133 - precision: 0.5918 - recall: 0.7527 - val_auc: 0.6559 - val_binary_accuracy: 0.5927 - val_f1: 0.4886 - val_loss: 0.6839 - val_prc_auc: 0.4307 - val_precision: 0.3728 - val_recall: 0.7086\n","Epoch 6/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7783 - binary_accuracy: 0.6964 - f1: 0.7267 - loss: 0.6607 - prc_auc: 0.7547 - precision: 0.6502 - recall: 0.8246\n","Epoch 6: Validation Metrics:\n","loss: 0.6559834480285645\n","val_binary_accuracy: 0.6309090852737427\n","val_precision: 0.4007633626461029\n","val_recall: 0.695364236831665\n","val_auc: 0.6924430131912231\n","val_prc_auc: 0.455980509519577\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.7785 - binary_accuracy: 0.6966 - f1: 0.7269 - loss: 0.6606 - prc_auc: 0.7549 - precision: 0.6506 - recall: 0.8245 - val_auc: 0.6924 - val_binary_accuracy: 0.6309 - val_f1: 0.5085 - val_loss: 0.6744 - val_prc_auc: 0.4560 - val_precision: 0.4008 - val_recall: 0.6954\n","Epoch 7/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8368 - binary_accuracy: 0.7478 - f1: 0.7682 - loss: 0.6438 - prc_auc: 0.8220 - precision: 0.6989 - recall: 0.8537\n","Epoch 7: Validation Metrics:\n","loss: 0.6397011876106262\n","val_binary_accuracy: 0.6545454263687134\n","val_precision: 0.4204081594944\n","val_recall: 0.6821191906929016\n","val_auc: 0.7051403522491455\n","val_prc_auc: 0.4706050753593445\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8368 - binary_accuracy: 0.7479 - f1: 0.7683 - loss: 0.6438 - prc_auc: 0.8220 - precision: 0.6992 - recall: 0.8535 - val_auc: 0.7051 - val_binary_accuracy: 0.6545 - val_f1: 0.5202 - val_loss: 0.6659 - val_prc_auc: 0.4706 - val_precision: 0.4204 - val_recall: 0.6821\n","Epoch 8/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8604 - binary_accuracy: 0.7734 - f1: 0.7880 - loss: 0.6283 - prc_auc: 0.8510 - precision: 0.7271 - recall: 0.8609\n","Epoch 8: Validation Metrics:\n","loss: 0.624671220779419\n","val_binary_accuracy: 0.6727272868156433\n","val_precision: 0.4388185739517212\n","val_recall: 0.6887417435646057\n","val_auc: 0.7132898569107056\n","val_prc_auc: 0.475496768951416\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8604 - binary_accuracy: 0.7734 - f1: 0.7881 - loss: 0.6283 - prc_auc: 0.8509 - precision: 0.7273 - recall: 0.8607 - val_auc: 0.7133 - val_binary_accuracy: 0.6727 - val_f1: 0.5361 - val_loss: 0.6582 - val_prc_auc: 0.4755 - val_precision: 0.4388 - val_recall: 0.6887\n","Epoch 9/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8711 - binary_accuracy: 0.7825 - f1: 0.7945 - loss: 0.6139 - prc_auc: 0.8617 - precision: 0.7394 - recall: 0.8594\n","Epoch 9: Validation Metrics:\n","loss: 0.6107956171035767\n","val_binary_accuracy: 0.6800000071525574\n","val_precision: 0.4458874464035034\n","val_recall: 0.6821191906929016\n","val_auc: 0.7156135439872742\n","val_prc_auc: 0.47575655579566956\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8710 - binary_accuracy: 0.7825 - f1: 0.7946 - loss: 0.6139 - prc_auc: 0.8616 - precision: 0.7396 - recall: 0.8591 - val_auc: 0.7156 - val_binary_accuracy: 0.6800 - val_f1: 0.5393 - val_loss: 0.6513 - val_prc_auc: 0.4758 - val_precision: 0.4459 - val_recall: 0.6821\n","Epoch 10/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8767 - binary_accuracy: 0.7879 - f1: 0.7987 - loss: 0.6006 - prc_auc: 0.8684 - precision: 0.7464 - recall: 0.8597\n","Epoch 10: Validation Metrics:\n","loss: 0.5979865193367004\n","val_binary_accuracy: 0.6727272868156433\n","val_precision: 0.43668121099472046\n","val_recall: 0.6622516512870789\n","val_auc: 0.717812716960907\n","val_prc_auc: 0.4751160144805908\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8766 - binary_accuracy: 0.7879 - f1: 0.7987 - loss: 0.6006 - prc_auc: 0.8683 - precision: 0.7465 - recall: 0.8595 - val_auc: 0.7178 - val_binary_accuracy: 0.6727 - val_f1: 0.5263 - val_loss: 0.6452 - val_prc_auc: 0.4751 - val_precision: 0.4367 - val_recall: 0.6623\n","Epoch 11/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8798 - binary_accuracy: 0.7898 - f1: 0.7992 - loss: 0.5883 - prc_auc: 0.8709 - precision: 0.7512 - recall: 0.8547\n","Epoch 11: Validation Metrics:\n","loss: 0.586163341999054\n","val_binary_accuracy: 0.6818181872367859\n","val_precision: 0.44594594836235046\n","val_recall: 0.6556291580200195\n","val_auc: 0.7193562388420105\n","val_prc_auc: 0.472747266292572\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8797 - binary_accuracy: 0.7898 - f1: 0.7992 - loss: 0.5883 - prc_auc: 0.8708 - precision: 0.7514 - recall: 0.8546 - val_auc: 0.7194 - val_binary_accuracy: 0.6818 - val_f1: 0.5308 - val_loss: 0.6397 - val_prc_auc: 0.4727 - val_precision: 0.4459 - val_recall: 0.6556\n","Epoch 12/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8813 - binary_accuracy: 0.7967 - f1: 0.8047 - loss: 0.5770 - prc_auc: 0.8729 - precision: 0.7597 - recall: 0.8559\n","Epoch 12: Validation Metrics:\n","loss: 0.5752513408660889\n","val_binary_accuracy: 0.692727267742157\n","val_precision: 0.4587155878543854\n","val_recall: 0.6622516512870789\n","val_auc: 0.7201032042503357\n","val_prc_auc: 0.47132137417793274\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - auc: 0.8812 - binary_accuracy: 0.7966 - f1: 0.8047 - loss: 0.5769 - prc_auc: 0.8729 - precision: 0.7597 - recall: 0.8558 - val_auc: 0.7201 - val_binary_accuracy: 0.6927 - val_f1: 0.5420 - val_loss: 0.6349 - val_prc_auc: 0.4713 - val_precision: 0.4587 - val_recall: 0.6623\n","Epoch 13/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8820 - binary_accuracy: 0.7983 - f1: 0.8054 - loss: 0.5664 - prc_auc: 0.8724 - precision: 0.7632 - recall: 0.8531\n","Epoch 13: Validation Metrics:\n","loss: 0.5651816129684448\n","val_binary_accuracy: 0.6909090876579285\n","val_precision: 0.45622119307518005\n","val_recall: 0.6556291580200195\n","val_auc: 0.7213563919067383\n","val_prc_auc: 0.4742107391357422\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8819 - binary_accuracy: 0.7982 - f1: 0.8054 - loss: 0.5664 - prc_auc: 0.8723 - precision: 0.7633 - recall: 0.8529 - val_auc: 0.7214 - val_binary_accuracy: 0.6909 - val_f1: 0.5380 - val_loss: 0.6306 - val_prc_auc: 0.4742 - val_precision: 0.4562 - val_recall: 0.6556\n","Epoch 14/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8830 - binary_accuracy: 0.7979 - f1: 0.8047 - loss: 0.5567 - prc_auc: 0.8743 - precision: 0.7636 - recall: 0.8508\n","Epoch 14: Validation Metrics:\n","loss: 0.5558890104293823\n","val_binary_accuracy: 0.6909090876579285\n","val_precision: 0.4558139443397522\n","val_recall: 0.6490066051483154\n","val_auc: 0.7219372391700745\n","val_prc_auc: 0.4717607796192169\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8828 - binary_accuracy: 0.7979 - f1: 0.8047 - loss: 0.5567 - prc_auc: 0.8743 - precision: 0.7637 - recall: 0.8507 - val_auc: 0.7219 - val_binary_accuracy: 0.6909 - val_f1: 0.5355 - val_loss: 0.6269 - val_prc_auc: 0.4718 - val_precision: 0.4558 - val_recall: 0.6490\n","Epoch 15/20\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8838 - binary_accuracy: 0.8004 - f1: 0.8072 - loss: 0.5477 - prc_auc: 0.8744 - precision: 0.7657 - recall: 0.8536\n","Epoch 15: Validation Metrics:\n","loss: 0.547313928604126\n","val_binary_accuracy: 0.6945454478263855\n","val_precision: 0.4597156345844269\n","val_recall: 0.6423841118812561\n","val_auc: 0.7218128442764282\n","val_prc_auc: 0.46926289796829224\n","\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - auc: 0.8836 - binary_accuracy: 0.8003 - f1: 0.8071 - loss: 0.5477 - prc_auc: 0.8743 - precision: 0.7658 - recall: 0.8535 - val_auc: 0.7218 - val_binary_accuracy: 0.6945 - val_f1: 0.5359 - val_loss: 0.6236 - val_prc_auc: 0.4693 - val_precision: 0.4597 - val_recall: 0.6424\n","Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.2714 - binary_accuracy: 0.3459 - f1: 0.3399 - loss: 0.7170 - prc_auc: 0.3556 - precision: 0.3362 - recall: 0.3443\n","Epoch 1: Validation Metrics:\n","loss: 0.7171112298965454\n","val_binary_accuracy: 0.41090908646583557\n","val_precision: 0.14886730909347534\n","val_recall: 0.42990654706954956\n","val_auc: 0.37578320503234863\n","val_prc_auc: 0.1460934281349182\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 257ms/step - auc: 0.2713 - binary_accuracy: 0.3457 - f1: 0.3400 - loss: 0.7170 - prc_auc: 0.3557 - precision: 0.3362 - recall: 0.3443 - val_auc: 0.3758 - val_binary_accuracy: 0.4109 - val_f1: 0.2212 - val_loss: 0.7049 - val_prc_auc: 0.1461 - val_precision: 0.1489 - val_recall: 0.4299\n","Epoch 2/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.2927 - binary_accuracy: 0.3638 - f1: 0.3610 - loss: 0.7142 - prc_auc: 0.3631 - precision: 0.3554 - recall: 0.3674\n","Epoch 2: Validation Metrics:\n","loss: 0.7132539749145508\n","val_binary_accuracy: 0.44545453786849976\n","val_precision: 0.1743421107530594\n","val_recall: 0.4953271150588989\n","val_auc: 0.40709054470062256\n","val_prc_auc: 0.1548943668603897\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.2927 - binary_accuracy: 0.3637 - f1: 0.3611 - loss: 0.7142 - prc_auc: 0.3633 - precision: 0.3555 - recall: 0.3675 - val_auc: 0.4071 - val_binary_accuracy: 0.4455 - val_f1: 0.2579 - val_loss: 0.7004 - val_prc_auc: 0.1549 - val_precision: 0.1743 - val_recall: 0.4953\n","Epoch 3/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3509 - binary_accuracy: 0.4088 - f1: 0.4087 - loss: 0.7078 - prc_auc: 0.3890 - precision: 0.4006 - recall: 0.4176\n","Epoch 3: Validation Metrics:\n","loss: 0.7056742906570435\n","val_binary_accuracy: 0.503636360168457\n","val_precision: 0.19927535951137543\n","val_recall: 0.514018714427948\n","val_auc: 0.4702959656715393\n","val_prc_auc: 0.18302664160728455\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.3512 - binary_accuracy: 0.4089 - f1: 0.4090 - loss: 0.7078 - prc_auc: 0.3893 - precision: 0.4009 - recall: 0.4179 - val_auc: 0.4703 - val_binary_accuracy: 0.5036 - val_f1: 0.2872 - val_loss: 0.6931 - val_prc_auc: 0.1830 - val_precision: 0.1993 - val_recall: 0.5140\n","Epoch 4/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4666 - binary_accuracy: 0.4753 - f1: 0.4758 - loss: 0.6981 - prc_auc: 0.4790 - precision: 0.4657 - recall: 0.4868\n","Epoch 4: Validation Metrics:\n","loss: 0.6946840882301331\n","val_binary_accuracy: 0.610909104347229\n","val_precision: 0.23902438580989838\n","val_recall: 0.4579439163208008\n","val_auc: 0.5410118103027344\n","val_prc_auc: 0.2846033573150635\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.4672 - binary_accuracy: 0.4757 - f1: 0.4763 - loss: 0.6980 - prc_auc: 0.4799 - precision: 0.4663 - recall: 0.4872 - val_auc: 0.5410 - val_binary_accuracy: 0.6109 - val_f1: 0.3141 - val_loss: 0.6834 - val_prc_auc: 0.2846 - val_precision: 0.2390 - val_recall: 0.4579\n","Epoch 5/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6017 - binary_accuracy: 0.5772 - f1: 0.5535 - loss: 0.6854 - prc_auc: 0.6552 - precision: 0.5710 - recall: 0.5375\n","Epoch 5: Validation Metrics:\n","loss: 0.6807344555854797\n","val_binary_accuracy: 0.696363627910614\n","val_precision: 0.30263158679008484\n","val_recall: 0.42990654706954956\n","val_auc: 0.5823400616645813\n","val_prc_auc: 0.3777120113372803\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.6024 - binary_accuracy: 0.5778 - f1: 0.5543 - loss: 0.6854 - prc_auc: 0.6560 - precision: 0.5719 - recall: 0.5382 - val_auc: 0.5823 - val_binary_accuracy: 0.6964 - val_f1: 0.3552 - val_loss: 0.6717 - val_prc_auc: 0.3777 - val_precision: 0.3026 - val_recall: 0.4299\n","Epoch 6/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7117 - binary_accuracy: 0.6728 - f1: 0.6272 - loss: 0.6706 - prc_auc: 0.7520 - precision: 0.7061 - recall: 0.5646\n","Epoch 6: Validation Metrics:\n","loss: 0.6649637818336487\n","val_binary_accuracy: 0.7472727298736572\n","val_precision: 0.3730158805847168\n","val_recall: 0.4392523467540741\n","val_auc: 0.615989089012146\n","val_prc_auc: 0.4031021296977997\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.7123 - binary_accuracy: 0.6732 - f1: 0.6279 - loss: 0.6705 - prc_auc: 0.7526 - precision: 0.7067 - recall: 0.5653 - val_auc: 0.6160 - val_binary_accuracy: 0.7473 - val_f1: 0.4034 - val_loss: 0.6599 - val_prc_auc: 0.4031 - val_precision: 0.3730 - val_recall: 0.4393\n","Epoch 7/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7736 - binary_accuracy: 0.7243 - f1: 0.6791 - loss: 0.6560 - prc_auc: 0.7984 - precision: 0.7836 - recall: 0.6001\n","Epoch 7: Validation Metrics:\n","loss: 0.6498169898986816\n","val_binary_accuracy: 0.7581818103790283\n","val_precision: 0.39344263076782227\n","val_recall: 0.44859811663627625\n","val_auc: 0.634469747543335\n","val_prc_auc: 0.4215911030769348\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.7740 - binary_accuracy: 0.7247 - f1: 0.6797 - loss: 0.6559 - prc_auc: 0.7989 - precision: 0.7839 - recall: 0.6010 - val_auc: 0.6345 - val_binary_accuracy: 0.7582 - val_f1: 0.4192 - val_loss: 0.6489 - val_prc_auc: 0.4216 - val_precision: 0.3934 - val_recall: 0.4486\n","Epoch 8/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8055 - binary_accuracy: 0.7382 - f1: 0.7022 - loss: 0.6424 - prc_auc: 0.8203 - precision: 0.7884 - recall: 0.6332\n","Epoch 8: Validation Metrics:\n","loss: 0.6357168555259705\n","val_binary_accuracy: 0.7581818103790283\n","val_precision: 0.39516130089759827\n","val_recall: 0.4579439163208008\n","val_auc: 0.6534672379493713\n","val_prc_auc: 0.42928439378738403\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8058 - binary_accuracy: 0.7385 - f1: 0.7027 - loss: 0.6423 - prc_auc: 0.8207 - precision: 0.7888 - recall: 0.6338 - val_auc: 0.6535 - val_binary_accuracy: 0.7582 - val_f1: 0.4242 - val_loss: 0.6389 - val_prc_auc: 0.4293 - val_precision: 0.3952 - val_recall: 0.4579\n","Epoch 9/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8214 - binary_accuracy: 0.7523 - f1: 0.7184 - loss: 0.6298 - prc_auc: 0.8300 - precision: 0.8055 - recall: 0.6486\n","Epoch 9: Validation Metrics:\n","loss: 0.6225834488868713\n","val_binary_accuracy: 0.7581818103790283\n","val_precision: 0.3968254029750824\n","val_recall: 0.4672897160053253\n","val_auc: 0.6614523530006409\n","val_prc_auc: 0.43391889333724976\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8217 - binary_accuracy: 0.7526 - f1: 0.7189 - loss: 0.6297 - prc_auc: 0.8303 - precision: 0.8058 - recall: 0.6493 - val_auc: 0.6615 - val_binary_accuracy: 0.7582 - val_f1: 0.4292 - val_loss: 0.6297 - val_prc_auc: 0.4339 - val_precision: 0.3968 - val_recall: 0.4673\n","Epoch 10/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8316 - binary_accuracy: 0.7571 - f1: 0.7260 - loss: 0.6181 - prc_auc: 0.8385 - precision: 0.8064 - recall: 0.6604\n","Epoch 10: Validation Metrics:\n","loss: 0.6103467345237732\n","val_binary_accuracy: 0.7581818103790283\n","val_precision: 0.3984375\n","val_recall: 0.47663551568984985\n","val_auc: 0.6713149547576904\n","val_prc_auc: 0.44065046310424805\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8318 - binary_accuracy: 0.7574 - f1: 0.7265 - loss: 0.6180 - prc_auc: 0.8388 - precision: 0.8067 - recall: 0.6610 - val_auc: 0.6713 - val_binary_accuracy: 0.7582 - val_f1: 0.4340 - val_loss: 0.6212 - val_prc_auc: 0.4407 - val_precision: 0.3984 - val_recall: 0.4766\n","Epoch 11/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8378 - binary_accuracy: 0.7599 - f1: 0.7299 - loss: 0.6072 - prc_auc: 0.8392 - precision: 0.8076 - recall: 0.6660\n","Epoch 11: Validation Metrics:\n","loss: 0.5989442467689514\n","val_binary_accuracy: 0.7563636302947998\n","val_precision: 0.39694657921791077\n","val_recall: 0.4859813153743744\n","val_auc: 0.678867518901825\n","val_prc_auc: 0.4431249797344208\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8380 - binary_accuracy: 0.7602 - f1: 0.7304 - loss: 0.6071 - prc_auc: 0.8396 - precision: 0.8079 - recall: 0.6667 - val_auc: 0.6789 - val_binary_accuracy: 0.7564 - val_f1: 0.4370 - val_loss: 0.6134 - val_prc_auc: 0.4431 - val_precision: 0.3969 - val_recall: 0.4860\n","Epoch 12/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8412 - binary_accuracy: 0.7636 - f1: 0.7331 - loss: 0.5970 - prc_auc: 0.8429 - precision: 0.8125 - recall: 0.6684\n","Epoch 12: Validation Metrics:\n","loss: 0.58831787109375\n","val_binary_accuracy: 0.7563636302947998\n","val_precision: 0.39694657921791077\n","val_recall: 0.4859813153743744\n","val_auc: 0.6842894554138184\n","val_prc_auc: 0.44723761081695557\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8414 - binary_accuracy: 0.7639 - f1: 0.7337 - loss: 0.5969 - prc_auc: 0.8433 - precision: 0.8128 - recall: 0.6691 - val_auc: 0.6843 - val_binary_accuracy: 0.7564 - val_f1: 0.4370 - val_loss: 0.6063 - val_prc_auc: 0.4472 - val_precision: 0.3969 - val_recall: 0.4860\n","Epoch 13/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8440 - binary_accuracy: 0.7651 - f1: 0.7368 - loss: 0.5876 - prc_auc: 0.8443 - precision: 0.8095 - recall: 0.6765\n","Epoch 13: Validation Metrics:\n","loss: 0.578413724899292\n","val_binary_accuracy: 0.7581818103790283\n","val_precision: 0.4015151560306549\n","val_recall: 0.4953271150588989\n","val_auc: 0.6850489377975464\n","val_prc_auc: 0.44747909903526306\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8442 - binary_accuracy: 0.7655 - f1: 0.7373 - loss: 0.5874 - prc_auc: 0.8447 - precision: 0.8099 - recall: 0.6771 - val_auc: 0.6850 - val_binary_accuracy: 0.7582 - val_f1: 0.4435 - val_loss: 0.5997 - val_prc_auc: 0.4475 - val_precision: 0.4015 - val_recall: 0.4953\n","Epoch 14/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8459 - binary_accuracy: 0.7704 - f1: 0.7447 - loss: 0.5788 - prc_auc: 0.8451 - precision: 0.8112 - recall: 0.6887\n","Epoch 14: Validation Metrics:\n","loss: 0.5691822171211243\n","val_binary_accuracy: 0.7545454502105713\n","val_precision: 0.39393940567970276\n","val_recall: 0.4859813153743744\n","val_auc: 0.6877597570419312\n","val_prc_auc: 0.4473694860935211\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8461 - binary_accuracy: 0.7707 - f1: 0.7452 - loss: 0.5787 - prc_auc: 0.8455 - precision: 0.8115 - recall: 0.6893 - val_auc: 0.6878 - val_binary_accuracy: 0.7545 - val_f1: 0.4351 - val_loss: 0.5937 - val_prc_auc: 0.4474 - val_precision: 0.3939 - val_recall: 0.4860\n","Epoch 15/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8472 - binary_accuracy: 0.7715 - f1: 0.7464 - loss: 0.5706 - prc_auc: 0.8456 - precision: 0.8110 - recall: 0.6918\n","Epoch 15: Validation Metrics:\n","loss: 0.5605763792991638\n","val_binary_accuracy: 0.7490909099578857\n","val_precision: 0.385185182094574\n","val_recall: 0.4859813153743744\n","val_auc: 0.6904074549674988\n","val_prc_auc: 0.45142295956611633\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8475 - binary_accuracy: 0.7718 - f1: 0.7469 - loss: 0.5705 - prc_auc: 0.8460 - precision: 0.8113 - recall: 0.6924 - val_auc: 0.6904 - val_binary_accuracy: 0.7491 - val_f1: 0.4298 - val_loss: 0.5883 - val_prc_auc: 0.4514 - val_precision: 0.3852 - val_recall: 0.4860\n","Epoch 16/20\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8489 - binary_accuracy: 0.7727 - f1: 0.7480 - loss: 0.5630 - prc_auc: 0.8490 - precision: 0.8118 - recall: 0.6939\n","Epoch 16: Validation Metrics:\n","loss: 0.5525524020195007\n","val_binary_accuracy: 0.7490909099578857\n","val_precision: 0.38686132431030273\n","val_recall: 0.4953271150588989\n","val_auc: 0.6917575001716614\n","val_prc_auc: 0.448337197303772\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.8491 - binary_accuracy: 0.7730 - f1: 0.7485 - loss: 0.5629 - prc_auc: 0.8494 - precision: 0.8122 - recall: 0.6945 - val_auc: 0.6918 - val_binary_accuracy: 0.7491 - val_f1: 0.4344 - val_loss: 0.5833 - val_prc_auc: 0.4483 - val_precision: 0.3869 - val_recall: 0.4953\n","Starting training for label: 5\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3858 - binary_accuracy: 0.4128 - f1: 0.3634 - loss: 0.7112 - prc_auc: 0.4227 - precision: 0.3998 - recall: 0.3334\n","Epoch 1: Validation Metrics:\n","loss: 0.7124367356300354\n","val_binary_accuracy: 0.5109090805053711\n","val_precision: 0.24452555179595947\n","val_recall: 0.5193798542022705\n","val_auc: 0.51876300573349\n","val_prc_auc: 0.2531287670135498\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 262ms/step - auc: 0.3856 - binary_accuracy: 0.4127 - f1: 0.3631 - loss: 0.7112 - prc_auc: 0.4225 - precision: 0.3996 - recall: 0.3332 - val_auc: 0.5188 - val_binary_accuracy: 0.5109 - val_f1: 0.3325 - val_loss: 0.6962 - val_prc_auc: 0.2531 - val_precision: 0.2445 - val_recall: 0.5194\n","Epoch 2/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3912 - binary_accuracy: 0.4169 - f1: 0.3725 - loss: 0.7101 - prc_auc: 0.4244 - precision: 0.4064 - recall: 0.3443\n","Epoch 2: Validation Metrics:\n","loss: 0.7110295295715332\n","val_binary_accuracy: 0.5018181800842285\n","val_precision: 0.24381625652313232\n","val_recall: 0.5348837375640869\n","val_auc: 0.5194443464279175\n","val_prc_auc: 0.2546840310096741\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.3911 - binary_accuracy: 0.4168 - f1: 0.3723 - loss: 0.7101 - prc_auc: 0.4242 - precision: 0.4063 - recall: 0.3441 - val_auc: 0.5194 - val_binary_accuracy: 0.5018 - val_f1: 0.3350 - val_loss: 0.6970 - val_prc_auc: 0.2547 - val_precision: 0.2438 - val_recall: 0.5349\n","Epoch 3/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4059 - binary_accuracy: 0.4282 - f1: 0.3933 - loss: 0.7076 - prc_auc: 0.4323 - precision: 0.4219 - recall: 0.3687\n","Epoch 3: Validation Metrics:\n","loss: 0.7082347869873047\n","val_binary_accuracy: 0.48363634943962097\n","val_precision: 0.24080267548561096\n","val_recall: 0.5581395626068115\n","val_auc: 0.5211751461029053\n","val_prc_auc: 0.25574415922164917\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.4058 - binary_accuracy: 0.4282 - f1: 0.3933 - loss: 0.7076 - prc_auc: 0.4321 - precision: 0.4218 - recall: 0.3686 - val_auc: 0.5212 - val_binary_accuracy: 0.4836 - val_f1: 0.3364 - val_loss: 0.6983 - val_prc_auc: 0.2557 - val_precision: 0.2408 - val_recall: 0.5581\n","Epoch 4/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4298 - binary_accuracy: 0.4364 - f1: 0.4200 - loss: 0.7037 - prc_auc: 0.4431 - precision: 0.4354 - recall: 0.4059\n","Epoch 4: Validation Metrics:\n","loss: 0.7041923999786377\n","val_binary_accuracy: 0.4381818175315857\n","val_precision: 0.22560974955558777\n","val_recall: 0.5736433863639832\n","val_auc: 0.5188459157943726\n","val_prc_auc: 0.25361019372940063\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.4298 - binary_accuracy: 0.4366 - f1: 0.4202 - loss: 0.7037 - prc_auc: 0.4429 - precision: 0.4355 - recall: 0.4061 - val_auc: 0.5188 - val_binary_accuracy: 0.4382 - val_f1: 0.3239 - val_loss: 0.7000 - val_prc_auc: 0.2536 - val_precision: 0.2256 - val_recall: 0.5736\n","Epoch 5/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4677 - binary_accuracy: 0.4774 - f1: 0.4981 - loss: 0.6987 - prc_auc: 0.4653 - precision: 0.4816 - recall: 0.5163\n","Epoch 5: Validation Metrics:\n","loss: 0.6990997791290283\n","val_binary_accuracy: 0.43090909719467163\n","val_precision: 0.23563218116760254\n","val_recall: 0.6356589198112488\n","val_auc: 0.5219576954841614\n","val_prc_auc: 0.25597214698791504\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.4677 - binary_accuracy: 0.4775 - f1: 0.4984 - loss: 0.6987 - prc_auc: 0.4651 - precision: 0.4816 - recall: 0.5168 - val_auc: 0.5220 - val_binary_accuracy: 0.4309 - val_f1: 0.3438 - val_loss: 0.7022 - val_prc_auc: 0.2560 - val_precision: 0.2356 - val_recall: 0.6357\n","Epoch 6/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5119 - binary_accuracy: 0.5424 - f1: 0.6068 - loss: 0.6929 - prc_auc: 0.4918 - precision: 0.5340 - recall: 0.7031\n","Epoch 6: Validation Metrics:\n","loss: 0.6933439373970032\n","val_binary_accuracy: 0.389090895652771\n","val_precision: 0.22691293060779572\n","val_recall: 0.6666666865348816\n","val_auc: 0.5249682664871216\n","val_prc_auc: 0.2566542625427246\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.5119 - binary_accuracy: 0.5425 - f1: 0.6070 - loss: 0.6929 - prc_auc: 0.4916 - precision: 0.5339 - recall: 0.7035 - val_auc: 0.5250 - val_binary_accuracy: 0.3891 - val_f1: 0.3386 - val_loss: 0.7045 - val_prc_auc: 0.2567 - val_precision: 0.2269 - val_recall: 0.6667\n","Epoch 7/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5604 - binary_accuracy: 0.5693 - f1: 0.6419 - loss: 0.6871 - prc_auc: 0.5286 - precision: 0.5514 - recall: 0.7682\n","Epoch 7: Validation Metrics:\n","loss: 0.6878138184547424\n","val_binary_accuracy: 0.3781818151473999\n","val_precision: 0.22622108459472656\n","val_recall: 0.682170569896698\n","val_auc: 0.5200795531272888\n","val_prc_auc: 0.2599259912967682\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.5604 - binary_accuracy: 0.5692 - f1: 0.6419 - loss: 0.6871 - prc_auc: 0.5284 - precision: 0.5513 - recall: 0.7682 - val_auc: 0.5201 - val_binary_accuracy: 0.3782 - val_f1: 0.3398 - val_loss: 0.7067 - val_prc_auc: 0.2599 - val_precision: 0.2262 - val_recall: 0.6822\n","Epoch 8/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6120 - binary_accuracy: 0.5862 - f1: 0.6604 - loss: 0.6818 - prc_auc: 0.5800 - precision: 0.5620 - recall: 0.8007\n","Epoch 8: Validation Metrics:\n","loss: 0.6827166676521301\n","val_binary_accuracy: 0.38181817531585693\n","val_precision: 0.23017902672290802\n","val_recall: 0.6976743936538696\n","val_auc: 0.5209173560142517\n","val_prc_auc: 0.26945680379867554\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.6119 - binary_accuracy: 0.5861 - f1: 0.6603 - loss: 0.6818 - prc_auc: 0.5798 - precision: 0.5619 - recall: 0.8007 - val_auc: 0.5209 - val_binary_accuracy: 0.3818 - val_f1: 0.3462 - val_loss: 0.7086 - val_prc_auc: 0.2695 - val_precision: 0.2302 - val_recall: 0.6977\n","Epoch 9/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6552 - binary_accuracy: 0.5964 - f1: 0.6707 - loss: 0.6768 - prc_auc: 0.6317 - precision: 0.5686 - recall: 0.8179\n","Epoch 9: Validation Metrics:\n","loss: 0.6780062913894653\n","val_binary_accuracy: 0.3799999952316284\n","val_precision: 0.22680412232875824\n","val_recall: 0.682170569896698\n","val_auc: 0.520199179649353\n","val_prc_auc: 0.2694947123527527\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.6551 - binary_accuracy: 0.5962 - f1: 0.6706 - loss: 0.6769 - prc_auc: 0.6314 - precision: 0.5685 - recall: 0.8178 - val_auc: 0.5202 - val_binary_accuracy: 0.3800 - val_f1: 0.3404 - val_loss: 0.7104 - val_prc_auc: 0.2695 - val_precision: 0.2268 - val_recall: 0.6822\n","Epoch 10/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6870 - binary_accuracy: 0.6073 - f1: 0.6794 - loss: 0.6723 - prc_auc: 0.6753 - precision: 0.5764 - recall: 0.8278\n","Epoch 10: Validation Metrics:\n","loss: 0.673643171787262\n","val_binary_accuracy: 0.3799999952316284\n","val_precision: 0.2210526317358017\n","val_recall: 0.6511628031730652\n","val_auc: 0.5192049145698547\n","val_prc_auc: 0.2757664620876312\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.6868 - binary_accuracy: 0.6071 - f1: 0.6792 - loss: 0.6723 - prc_auc: 0.6749 - precision: 0.5762 - recall: 0.8277 - val_auc: 0.5192 - val_binary_accuracy: 0.3800 - val_f1: 0.3301 - val_loss: 0.7121 - val_prc_auc: 0.2758 - val_precision: 0.2211 - val_recall: 0.6512\n","Epoch 11/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7071 - binary_accuracy: 0.6069 - f1: 0.6791 - loss: 0.6680 - prc_auc: 0.7012 - precision: 0.5761 - recall: 0.8275\n","Epoch 11: Validation Metrics:\n","loss: 0.6695943474769592\n","val_binary_accuracy: 0.38545453548431396\n","val_precision: 0.2213333398103714\n","val_recall: 0.643410861492157\n","val_auc: 0.515881359577179\n","val_prc_auc: 0.2668623924255371\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - auc: 0.7069 - binary_accuracy: 0.6067 - f1: 0.6789 - loss: 0.6680 - prc_auc: 0.7008 - precision: 0.5760 - recall: 0.8274 - val_auc: 0.5159 - val_binary_accuracy: 0.3855 - val_f1: 0.3294 - val_loss: 0.7136 - val_prc_auc: 0.2669 - val_precision: 0.2213 - val_recall: 0.6434\n","Starting training for label: 6\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - auc: 0.3783 - binary_accuracy: 0.3890 - f1: 0.1712 - loss: 0.7310 - prc_auc: 0.3918 - precision: 0.2533 - recall: 0.1295  \n","Epoch 1: Validation Metrics:\n","loss: 0.7350295186042786\n","val_binary_accuracy: 0.5799999833106995\n","val_precision: 0.11612903326749802\n","val_recall: 0.1607142835855484\n","val_auc: 0.40111303329467773\n","val_prc_auc: 0.15844975411891937\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - auc: 0.3781 - binary_accuracy: 0.3888 - f1: 0.1712 - loss: 0.7310 - prc_auc: 0.3918 - precision: 0.2533 - recall: 0.1294 - val_auc: 0.4011 - val_binary_accuracy: 0.5800 - val_f1: 0.1348 - val_loss: 0.6771 - val_prc_auc: 0.1584 - val_precision: 0.1161 - val_recall: 0.1607\n","Epoch 2/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3883 - binary_accuracy: 0.3914 - f1: 0.1728 - loss: 0.7283 - prc_auc: 0.3955 - precision: 0.2564 - recall: 0.1304\n","Epoch 2: Validation Metrics:\n","loss: 0.7315020561218262\n","val_binary_accuracy: 0.5836363434791565\n","val_precision: 0.11258278042078018\n","val_recall: 0.1517857164144516\n","val_auc: 0.4146893322467804\n","val_prc_auc: 0.1617891788482666\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.3879 - binary_accuracy: 0.3911 - f1: 0.1728 - loss: 0.7284 - prc_auc: 0.3957 - precision: 0.2566 - recall: 0.1303 - val_auc: 0.4147 - val_binary_accuracy: 0.5836 - val_f1: 0.1293 - val_loss: 0.6756 - val_prc_auc: 0.1618 - val_precision: 0.1126 - val_recall: 0.1518\n","Epoch 3/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4106 - binary_accuracy: 0.3976 - f1: 0.1820 - loss: 0.7221 - prc_auc: 0.4051 - precision: 0.2696 - recall: 0.1375\n","Epoch 3: Validation Metrics:\n","loss: 0.7245033383369446\n","val_binary_accuracy: 0.589090883731842\n","val_precision: 0.11486486345529556\n","val_recall: 0.1517857164144516\n","val_auc: 0.43967097997665405\n","val_prc_auc: 0.16852600872516632\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.4104 - binary_accuracy: 0.3973 - f1: 0.1819 - loss: 0.7222 - prc_auc: 0.4053 - precision: 0.2697 - recall: 0.1374 - val_auc: 0.4397 - val_binary_accuracy: 0.5891 - val_f1: 0.1308 - val_loss: 0.6732 - val_prc_auc: 0.1685 - val_precision: 0.1149 - val_recall: 0.1518\n","Epoch 4/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4515 - binary_accuracy: 0.4115 - f1: 0.1958 - loss: 0.7127 - prc_auc: 0.4250 - precision: 0.2939 - recall: 0.1469\n","Epoch 4: Validation Metrics:\n","loss: 0.7143097519874573\n","val_binary_accuracy: 0.5963636636734009\n","val_precision: 0.12328767031431198\n","val_recall: 0.1607142835855484\n","val_auc: 0.47526296973228455\n","val_prc_auc: 0.17988111078739166\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.4514 - binary_accuracy: 0.4112 - f1: 0.1960 - loss: 0.7127 - prc_auc: 0.4253 - precision: 0.2942 - recall: 0.1470 - val_auc: 0.4753 - val_binary_accuracy: 0.5964 - val_f1: 0.1395 - val_loss: 0.6701 - val_prc_auc: 0.1799 - val_precision: 0.1233 - val_recall: 0.1607\n","Epoch 5/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5167 - binary_accuracy: 0.4378 - f1: 0.2446 - loss: 0.7003 - prc_auc: 0.4615 - precision: 0.3544 - recall: 0.1869\n","Epoch 5: Validation Metrics:\n","loss: 0.701322615146637\n","val_binary_accuracy: 0.614545464515686\n","val_precision: 0.1621621549129486\n","val_recall: 0.2142857164144516\n","val_auc: 0.5256645679473877\n","val_prc_auc: 0.20075750350952148\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.5166 - binary_accuracy: 0.4377 - f1: 0.2449 - loss: 0.7004 - prc_auc: 0.4618 - precision: 0.3549 - recall: 0.1871 - val_auc: 0.5257 - val_binary_accuracy: 0.6145 - val_f1: 0.1846 - val_loss: 0.6662 - val_prc_auc: 0.2008 - val_precision: 0.1622 - val_recall: 0.2143\n","Epoch 6/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5957 - binary_accuracy: 0.5061 - f1: 0.3809 - loss: 0.6857 - prc_auc: 0.5178 - precision: 0.4895 - recall: 0.3119\n","Epoch 6: Validation Metrics:\n","loss: 0.6864436268806458\n","val_binary_accuracy: 0.6363636255264282\n","val_precision: 0.23170731961727142\n","val_recall: 0.3392857015132904\n","val_auc: 0.5747513175010681\n","val_prc_auc: 0.2301623821258545\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.5956 - binary_accuracy: 0.5061 - f1: 0.3813 - loss: 0.6857 - prc_auc: 0.5181 - precision: 0.4902 - recall: 0.3122 - val_auc: 0.5748 - val_binary_accuracy: 0.6364 - val_f1: 0.2754 - val_loss: 0.6621 - val_prc_auc: 0.2302 - val_precision: 0.2317 - val_recall: 0.3393\n","Epoch 7/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6702 - binary_accuracy: 0.5982 - f1: 0.5404 - loss: 0.6711 - prc_auc: 0.5820 - precision: 0.6114 - recall: 0.4843\n","Epoch 7: Validation Metrics:\n","loss: 0.671964168548584\n","val_binary_accuracy: 0.6654545664787292\n","val_precision: 0.28823530673980713\n","val_recall: 0.4375\n","val_auc: 0.6183851361274719\n","val_prc_auc: 0.26959556341171265\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.6701 - binary_accuracy: 0.5982 - f1: 0.5407 - loss: 0.6711 - prc_auc: 0.5825 - precision: 0.6118 - recall: 0.4846 - val_auc: 0.6184 - val_binary_accuracy: 0.6655 - val_f1: 0.3475 - val_loss: 0.6582 - val_prc_auc: 0.2696 - val_precision: 0.2882 - val_recall: 0.4375\n","Epoch 8/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7410 - binary_accuracy: 0.6806 - f1: 0.6617 - loss: 0.6574 - prc_auc: 0.6596 - precision: 0.6845 - recall: 0.6406\n","Epoch 8: Validation Metrics:\n","loss: 0.6584312915802002\n","val_binary_accuracy: 0.6745454668998718\n","val_precision: 0.31491711735725403\n","val_recall: 0.5089285969734192\n","val_auc: 0.6598682999610901\n","val_prc_auc: 0.3340728282928467\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.7409 - binary_accuracy: 0.6806 - f1: 0.6619 - loss: 0.6574 - prc_auc: 0.6601 - precision: 0.6848 - recall: 0.6407 - val_auc: 0.6599 - val_binary_accuracy: 0.6745 - val_f1: 0.3891 - val_loss: 0.6545 - val_prc_auc: 0.3341 - val_precision: 0.3149 - val_recall: 0.5089\n","Epoch 9/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7998 - binary_accuracy: 0.7408 - f1: 0.7372 - loss: 0.6445 - prc_auc: 0.7299 - precision: 0.7292 - recall: 0.7457\n","Epoch 9: Validation Metrics:\n","loss: 0.6457650065422058\n","val_binary_accuracy: 0.6690909266471863\n","val_precision: 0.3232323229312897\n","val_recall: 0.5714285969734192\n","val_auc: 0.687724232673645\n","val_prc_auc: 0.3911081552505493\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.7996 - binary_accuracy: 0.7406 - f1: 0.7371 - loss: 0.6446 - prc_auc: 0.7303 - precision: 0.7294 - recall: 0.7454 - val_auc: 0.6877 - val_binary_accuracy: 0.6691 - val_f1: 0.4129 - val_loss: 0.6510 - val_prc_auc: 0.3911 - val_precision: 0.3232 - val_recall: 0.5714\n","Epoch 10/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8401 - binary_accuracy: 0.7798 - f1: 0.7813 - loss: 0.6325 - prc_auc: 0.7825 - precision: 0.7571 - recall: 0.8075\n","Epoch 10: Validation Metrics:\n","loss: 0.6338950395584106\n","val_binary_accuracy: 0.6727272868156433\n","val_precision: 0.3349514603614807\n","val_recall: 0.6160714030265808\n","val_auc: 0.7091895341873169\n","val_prc_auc: 0.430761456489563\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8399 - binary_accuracy: 0.7793 - f1: 0.7810 - loss: 0.6326 - prc_auc: 0.7828 - precision: 0.7568 - recall: 0.8071 - val_auc: 0.7092 - val_binary_accuracy: 0.6727 - val_f1: 0.4340 - val_loss: 0.6476 - val_prc_auc: 0.4308 - val_precision: 0.3350 - val_recall: 0.6161\n","Epoch 11/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8646 - binary_accuracy: 0.7991 - f1: 0.8042 - loss: 0.6212 - prc_auc: 0.8108 - precision: 0.7659 - recall: 0.8469\n","Epoch 11: Validation Metrics:\n","loss: 0.6227594017982483\n","val_binary_accuracy: 0.6709091067314148\n","val_precision: 0.3349282443523407\n","val_recall: 0.625\n","val_auc: 0.7239481806755066\n","val_prc_auc: 0.47328391671180725\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8644 - binary_accuracy: 0.7988 - f1: 0.8040 - loss: 0.6213 - prc_auc: 0.8111 - precision: 0.7657 - recall: 0.8466 - val_auc: 0.7239 - val_binary_accuracy: 0.6709 - val_f1: 0.4361 - val_loss: 0.6443 - val_prc_auc: 0.4733 - val_precision: 0.3349 - val_recall: 0.6250\n","Epoch 12/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8799 - binary_accuracy: 0.8103 - f1: 0.8147 - loss: 0.6107 - prc_auc: 0.8311 - precision: 0.7781 - recall: 0.8553\n","Epoch 12: Validation Metrics:\n","loss: 0.6123015880584717\n","val_binary_accuracy: 0.6800000071525574\n","val_precision: 0.3461538553237915\n","val_recall: 0.6428571343421936\n","val_auc: 0.7329174876213074\n","val_prc_auc: 0.49784088134765625\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8797 - binary_accuracy: 0.8099 - f1: 0.8144 - loss: 0.6107 - prc_auc: 0.8314 - precision: 0.7778 - recall: 0.8551 - val_auc: 0.7329 - val_binary_accuracy: 0.6800 - val_f1: 0.4500 - val_loss: 0.6411 - val_prc_auc: 0.4978 - val_precision: 0.3462 - val_recall: 0.6429\n","Epoch 13/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8895 - binary_accuracy: 0.8258 - f1: 0.8299 - loss: 0.6007 - prc_auc: 0.8400 - precision: 0.7921 - recall: 0.8722\n","Epoch 13: Validation Metrics:\n","loss: 0.6024702191352844\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.34433960914611816\n","val_recall: 0.6517857313156128\n","val_auc: 0.7426512241363525\n","val_prc_auc: 0.5164486765861511\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8892 - binary_accuracy: 0.8254 - f1: 0.8297 - loss: 0.6008 - prc_auc: 0.8403 - precision: 0.7917 - recall: 0.8720 - val_auc: 0.7427 - val_binary_accuracy: 0.6764 - val_f1: 0.4506 - val_loss: 0.6380 - val_prc_auc: 0.5164 - val_precision: 0.3443 - val_recall: 0.6518\n","Epoch 14/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8950 - binary_accuracy: 0.8318 - f1: 0.8363 - loss: 0.5913 - prc_auc: 0.8476 - precision: 0.7959 - recall: 0.8816\n","Epoch 14: Validation Metrics:\n","loss: 0.5932177901268005\n","val_binary_accuracy: 0.6818181872367859\n","val_precision: 0.35211268067359924\n","val_recall: 0.6696428656578064\n","val_auc: 0.7493476867675781\n","val_prc_auc: 0.5294176340103149\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8948 - binary_accuracy: 0.8315 - f1: 0.8361 - loss: 0.5914 - prc_auc: 0.8480 - precision: 0.7956 - recall: 0.8816 - val_auc: 0.7493 - val_binary_accuracy: 0.6818 - val_f1: 0.4615 - val_loss: 0.6349 - val_prc_auc: 0.5294 - val_precision: 0.3521 - val_recall: 0.6696\n","Epoch 15/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8988 - binary_accuracy: 0.8334 - f1: 0.8392 - loss: 0.5825 - prc_auc: 0.8556 - precision: 0.7934 - recall: 0.8910\n","Epoch 15: Validation Metrics:\n","loss: 0.5845008492469788\n","val_binary_accuracy: 0.6872727274894714\n","val_precision: 0.3571428656578064\n","val_recall: 0.6696428656578064\n","val_auc: 0.7543725371360779\n","val_prc_auc: 0.5388177633285522\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.8986 - binary_accuracy: 0.8331 - f1: 0.8390 - loss: 0.5826 - prc_auc: 0.8559 - precision: 0.7932 - recall: 0.8909 - val_auc: 0.7544 - val_binary_accuracy: 0.6873 - val_f1: 0.4658 - val_loss: 0.6319 - val_prc_auc: 0.5388 - val_precision: 0.3571 - val_recall: 0.6696\n","Epoch 16/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.9016 - binary_accuracy: 0.8355 - f1: 0.8427 - loss: 0.5742 - prc_auc: 0.8580 - precision: 0.7906 - recall: 0.9023\n","Epoch 16: Validation Metrics:\n","loss: 0.5762795209884644\n","val_binary_accuracy: 0.6836363673210144\n","val_precision: 0.3537735939025879\n","val_recall: 0.6696428656578064\n","val_auc: 0.7583374381065369\n","val_prc_auc: 0.5517321228981018\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.9014 - binary_accuracy: 0.8352 - f1: 0.8425 - loss: 0.5743 - prc_auc: 0.8583 - precision: 0.7905 - recall: 0.9021 - val_auc: 0.7583 - val_binary_accuracy: 0.6836 - val_f1: 0.4630 - val_loss: 0.6290 - val_prc_auc: 0.5517 - val_precision: 0.3538 - val_recall: 0.6696\n","Epoch 17/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.9035 - binary_accuracy: 0.8372 - f1: 0.8445 - loss: 0.5663 - prc_auc: 0.8604 - precision: 0.7918 - recall: 0.9047\n","Epoch 17: Validation Metrics:\n","loss: 0.5685176849365234\n","val_binary_accuracy: 0.6890909075737\n","val_precision: 0.35885167121887207\n","val_recall: 0.6696428656578064\n","val_auc: 0.7614155411720276\n","val_prc_auc: 0.5568075776100159\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.9033 - binary_accuracy: 0.8369 - f1: 0.8443 - loss: 0.5664 - prc_auc: 0.8608 - precision: 0.7917 - recall: 0.9045 - val_auc: 0.7614 - val_binary_accuracy: 0.6891 - val_f1: 0.4673 - val_loss: 0.6261 - val_prc_auc: 0.5568 - val_precision: 0.3589 - val_recall: 0.6696\n","Epoch 18/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.9050 - binary_accuracy: 0.8371 - f1: 0.8449 - loss: 0.5589 - prc_auc: 0.8629 - precision: 0.7898 - recall: 0.9085\n","Epoch 18: Validation Metrics:\n","loss: 0.5611813068389893\n","val_binary_accuracy: 0.6909090876579285\n","val_precision: 0.36320754885673523\n","val_recall: 0.6875\n","val_auc: 0.7639941573143005\n","val_prc_auc: 0.5642255544662476\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.9048 - binary_accuracy: 0.8368 - f1: 0.8447 - loss: 0.5590 - prc_auc: 0.8632 - precision: 0.7897 - recall: 0.9082 - val_auc: 0.7640 - val_binary_accuracy: 0.6909 - val_f1: 0.4753 - val_loss: 0.6233 - val_prc_auc: 0.5642 - val_precision: 0.3632 - val_recall: 0.6875\n","Epoch 19/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.9061 - binary_accuracy: 0.8372 - f1: 0.8455 - loss: 0.5519 - prc_auc: 0.8656 - precision: 0.7877 - recall: 0.9125\n","Epoch 19: Validation Metrics:\n","loss: 0.5542400479316711\n","val_binary_accuracy: 0.6890909075737\n","val_precision: 0.36150234937667847\n","val_recall: 0.6875\n","val_auc: 0.7667666077613831\n","val_prc_auc: 0.5702356696128845\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.9058 - binary_accuracy: 0.8368 - f1: 0.8452 - loss: 0.5520 - prc_auc: 0.8659 - precision: 0.7876 - recall: 0.9120 - val_auc: 0.7668 - val_binary_accuracy: 0.6891 - val_f1: 0.4738 - val_loss: 0.6205 - val_prc_auc: 0.5702 - val_precision: 0.3615 - val_recall: 0.6875\n","Epoch 20/20\n","\u001b[1m61/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.9071 - binary_accuracy: 0.8358 - f1: 0.8442 - loss: 0.5452 - prc_auc: 0.8679 - precision: 0.7860 - recall: 0.9120\n","Epoch 20: Validation Metrics:\n","loss: 0.5476657748222351\n","val_binary_accuracy: 0.6909090876579285\n","val_precision: 0.36320754885673523\n","val_recall: 0.6875\n","val_auc: 0.7677450180053711\n","val_prc_auc: 0.5761123299598694\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - auc: 0.9069 - binary_accuracy: 0.8354 - f1: 0.8440 - loss: 0.5453 - prc_auc: 0.8682 - precision: 0.7859 - recall: 0.9115 - val_auc: 0.7677 - val_binary_accuracy: 0.6909 - val_f1: 0.4753 - val_loss: 0.6177 - val_prc_auc: 0.5761 - val_precision: 0.3632 - val_recall: 0.6875\n","Starting training for label: 7\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - auc: 0.6840 - binary_accuracy: 0.6410 - f1: 0.6100 - loss: 0.6666 - prc_auc: 0.6678 - precision: 0.6510 - recall: 0.5745\n","Epoch 1: Validation Metrics:\n","loss: 0.666486918926239\n","val_binary_accuracy: 0.6527272462844849\n","val_precision: 0.1731843501329422\n","val_recall: 0.4189189076423645\n","val_auc: 0.5582841038703918\n","val_prc_auc: 0.1757175326347351\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 592ms/step - auc: 0.6841 - binary_accuracy: 0.6409 - f1: 0.6103 - loss: 0.6666 - prc_auc: 0.6681 - precision: 0.6511 - recall: 0.5751 - val_auc: 0.5583 - val_binary_accuracy: 0.6527 - val_f1: 0.2451 - val_loss: 0.6643 - val_prc_auc: 0.1757 - val_precision: 0.1732 - val_recall: 0.4189\n","Epoch 2/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6838 - binary_accuracy: 0.6405 - f1: 0.6093 - loss: 0.6663 - prc_auc: 0.6689 - precision: 0.6503 - recall: 0.5740\n","Epoch 2: Validation Metrics:\n","loss: 0.6660536527633667\n","val_binary_accuracy: 0.6527272462844849\n","val_precision: 0.1731843501329422\n","val_recall: 0.4189189076423645\n","val_auc: 0.55694979429245\n","val_prc_auc: 0.17492038011550903\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6841 - binary_accuracy: 0.6405 - f1: 0.6101 - loss: 0.6663 - prc_auc: 0.6695 - precision: 0.6504 - recall: 0.5753 - val_auc: 0.5569 - val_binary_accuracy: 0.6527 - val_f1: 0.2451 - val_loss: 0.6635 - val_prc_auc: 0.1749 - val_precision: 0.1732 - val_recall: 0.4189\n","Epoch 3/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6838 - binary_accuracy: 0.6414 - f1: 0.6099 - loss: 0.6655 - prc_auc: 0.6625 - precision: 0.6515 - recall: 0.5740\n","Epoch 3: Validation Metrics:\n","loss: 0.6651812791824341\n","val_binary_accuracy: 0.6618182063102722\n","val_precision: 0.1781609207391739\n","val_recall: 0.4189189076423645\n","val_auc: 0.5626419186592102\n","val_prc_auc: 0.17333471775054932\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6841 - binary_accuracy: 0.6414 - f1: 0.6107 - loss: 0.6655 - prc_auc: 0.6633 - precision: 0.6517 - recall: 0.5753 - val_auc: 0.5626 - val_binary_accuracy: 0.6618 - val_f1: 0.2500 - val_loss: 0.6621 - val_prc_auc: 0.1733 - val_precision: 0.1782 - val_recall: 0.4189\n","Epoch 4/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6873 - binary_accuracy: 0.6416 - f1: 0.6099 - loss: 0.6643 - prc_auc: 0.6726 - precision: 0.6519 - recall: 0.5738\n","Epoch 4: Validation Metrics:\n","loss: 0.6638899445533752\n","val_binary_accuracy: 0.6745454668998718\n","val_precision: 0.185628741979599\n","val_recall: 0.4189189076423645\n","val_auc: 0.5611089468002319\n","val_prc_auc: 0.1753319650888443\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6876 - binary_accuracy: 0.6417 - f1: 0.6108 - loss: 0.6643 - prc_auc: 0.6731 - precision: 0.6523 - recall: 0.5750 - val_auc: 0.5611 - val_binary_accuracy: 0.6745 - val_f1: 0.2573 - val_loss: 0.6601 - val_prc_auc: 0.1753 - val_precision: 0.1856 - val_recall: 0.4189\n","Epoch 5/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6905 - binary_accuracy: 0.6465 - f1: 0.6147 - loss: 0.6626 - prc_auc: 0.6753 - precision: 0.6580 - recall: 0.5775\n","Epoch 5: Validation Metrics:\n","loss: 0.6622104644775391\n","val_binary_accuracy: 0.6763636469841003\n","val_precision: 0.18292683362960815\n","val_recall: 0.4054054021835327\n","val_auc: 0.5634084939956665\n","val_prc_auc: 0.17373588681221008\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6909 - binary_accuracy: 0.6467 - f1: 0.6156 - loss: 0.6626 - prc_auc: 0.6759 - precision: 0.6584 - recall: 0.5787 - val_auc: 0.5634 - val_binary_accuracy: 0.6764 - val_f1: 0.2521 - val_loss: 0.6577 - val_prc_auc: 0.1737 - val_precision: 0.1829 - val_recall: 0.4054\n","Epoch 6/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6946 - binary_accuracy: 0.6524 - f1: 0.6188 - loss: 0.6606 - prc_auc: 0.6811 - precision: 0.6664 - recall: 0.5781\n","Epoch 6: Validation Metrics:\n","loss: 0.6601820588111877\n","val_binary_accuracy: 0.6890909075737\n","val_precision: 0.19108280539512634\n","val_recall: 0.4054054021835327\n","val_auc: 0.5650266408920288\n","val_prc_auc: 0.17514453828334808\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6948 - binary_accuracy: 0.6525 - f1: 0.6197 - loss: 0.6606 - prc_auc: 0.6815 - precision: 0.6668 - recall: 0.5794 - val_auc: 0.5650 - val_binary_accuracy: 0.6891 - val_f1: 0.2597 - val_loss: 0.6549 - val_prc_auc: 0.1751 - val_precision: 0.1911 - val_recall: 0.4054\n","Epoch 7/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6977 - binary_accuracy: 0.6509 - f1: 0.6122 - loss: 0.6582 - prc_auc: 0.6798 - precision: 0.6689 - recall: 0.5650\n","Epoch 7: Validation Metrics:\n","loss: 0.657849907875061\n","val_binary_accuracy: 0.699999988079071\n","val_precision: 0.1986754983663559\n","val_recall: 0.4054054021835327\n","val_auc: 0.5653673410415649\n","val_prc_auc: 0.17433303594589233\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.6979 - binary_accuracy: 0.6512 - f1: 0.6133 - loss: 0.6582 - prc_auc: 0.6804 - precision: 0.6694 - recall: 0.5665 - val_auc: 0.5654 - val_binary_accuracy: 0.7000 - val_f1: 0.2667 - val_loss: 0.6517 - val_prc_auc: 0.1743 - val_precision: 0.1987 - val_recall: 0.4054\n","Epoch 8/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7028 - binary_accuracy: 0.6508 - f1: 0.6116 - loss: 0.6556 - prc_auc: 0.6861 - precision: 0.6692 - recall: 0.5638\n","Epoch 8: Validation Metrics:\n","loss: 0.6552646160125732\n","val_binary_accuracy: 0.696363627910614\n","val_precision: 0.1879194676876068\n","val_recall: 0.37837839126586914\n","val_auc: 0.5698103308677673\n","val_prc_auc: 0.1750241219997406\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.7030 - binary_accuracy: 0.6512 - f1: 0.6128 - loss: 0.6556 - prc_auc: 0.6866 - precision: 0.6698 - recall: 0.5653 - val_auc: 0.5698 - val_binary_accuracy: 0.6964 - val_f1: 0.2511 - val_loss: 0.6482 - val_prc_auc: 0.1750 - val_precision: 0.1879 - val_recall: 0.3784\n","Epoch 9/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7059 - binary_accuracy: 0.6525 - f1: 0.6137 - loss: 0.6527 - prc_auc: 0.6836 - precision: 0.6709 - recall: 0.5662\n","Epoch 9: Validation Metrics:\n","loss: 0.6525266766548157\n","val_binary_accuracy: 0.696363627910614\n","val_precision: 0.18367347121238708\n","val_recall: 0.36486485600471497\n","val_auc: 0.5710594654083252\n","val_prc_auc: 0.17635709047317505\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.7061 - binary_accuracy: 0.6530 - f1: 0.6149 - loss: 0.6527 - prc_auc: 0.6842 - precision: 0.6715 - recall: 0.5678 - val_auc: 0.5711 - val_binary_accuracy: 0.6964 - val_f1: 0.2443 - val_loss: 0.6447 - val_prc_auc: 0.1764 - val_precision: 0.1837 - val_recall: 0.3649\n","Epoch 10/20\n","\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7094 - binary_accuracy: 0.6547 - f1: 0.6159 - loss: 0.6500 - prc_auc: 0.6909 - precision: 0.6733 - recall: 0.5680\n","Epoch 10: Validation Metrics:\n","loss: 0.6498939990997314\n","val_binary_accuracy: 0.7036363482475281\n","val_precision: 0.18881118297576904\n","val_recall: 0.36486485600471497\n","val_auc: 0.5741682052612305\n","val_prc_auc: 0.17484182119369507\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.7096 - binary_accuracy: 0.6552 - f1: 0.6171 - loss: 0.6500 - prc_auc: 0.6913 - precision: 0.6741 - recall: 0.5695 - val_auc: 0.5742 - val_binary_accuracy: 0.7036 - val_f1: 0.2488 - val_loss: 0.6414 - val_prc_auc: 0.1748 - val_precision: 0.1888 - val_recall: 0.3649\n","Starting training for label: 8\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - auc: 0.4665 - binary_accuracy: 0.4713 - f1: 0.2806 - loss: 0.7078 - prc_auc: 0.4688 - precision: 0.4361 - recall: 0.2075\n","Epoch 1: Validation Metrics:\n","loss: 0.7119972705841064\n","val_binary_accuracy: 0.6654545664787292\n","val_precision: 0.0746268630027771\n","val_recall: 0.1428571492433548\n","val_auc: 0.4025892913341522\n","val_prc_auc: 0.10161291062831879\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 505ms/step - auc: 0.4657 - binary_accuracy: 0.4710 - f1: 0.2806 - loss: 0.7079 - prc_auc: 0.4685 - precision: 0.4358 - recall: 0.2076 - val_auc: 0.4026 - val_binary_accuracy: 0.6655 - val_f1: 0.0980 - val_loss: 0.6558 - val_prc_auc: 0.1016 - val_precision: 0.0746 - val_recall: 0.1429\n","Epoch 2/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4715 - binary_accuracy: 0.4720 - f1: 0.2801 - loss: 0.7072 - prc_auc: 0.4709 - precision: 0.4371 - recall: 0.2067\n","Epoch 2: Validation Metrics:\n","loss: 0.7111775279045105\n","val_binary_accuracy: 0.6654545664787292\n","val_precision: 0.0746268630027771\n","val_recall: 0.1428571492433548\n","val_auc: 0.409657746553421\n","val_prc_auc: 0.10300606489181519\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.4708 - binary_accuracy: 0.4718 - f1: 0.2801 - loss: 0.7073 - prc_auc: 0.4707 - precision: 0.4368 - recall: 0.2068 - val_auc: 0.4097 - val_binary_accuracy: 0.6655 - val_f1: 0.0980 - val_loss: 0.6554 - val_prc_auc: 0.1030 - val_precision: 0.0746 - val_recall: 0.1429\n","Epoch 3/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4804 - binary_accuracy: 0.4747 - f1: 0.2850 - loss: 0.7057 - prc_auc: 0.4759 - precision: 0.4432 - recall: 0.2108\n","Epoch 3: Validation Metrics:\n","loss: 0.7095301151275635\n","val_binary_accuracy: 0.6709091067314148\n","val_precision: 0.07633587718009949\n","val_recall: 0.1428571492433548\n","val_auc: 0.4184226095676422\n","val_prc_auc: 0.10411547124385834\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.4797 - binary_accuracy: 0.4745 - f1: 0.2851 - loss: 0.7058 - prc_auc: 0.4757 - precision: 0.4428 - recall: 0.2109 - val_auc: 0.4184 - val_binary_accuracy: 0.6709 - val_f1: 0.0995 - val_loss: 0.6546 - val_prc_auc: 0.1041 - val_precision: 0.0763 - val_recall: 0.1429\n","Epoch 4/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.4944 - binary_accuracy: 0.4751 - f1: 0.2852 - loss: 0.7035 - prc_auc: 0.4839 - precision: 0.4437 - recall: 0.2108\n","Epoch 4: Validation Metrics:\n","loss: 0.7070751190185547\n","val_binary_accuracy: 0.6800000071525574\n","val_precision: 0.07258064299821854\n","val_recall: 0.12857143580913544\n","val_auc: 0.4300149083137512\n","val_prc_auc: 0.10631495714187622\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.4938 - binary_accuracy: 0.4749 - f1: 0.2852 - loss: 0.7036 - prc_auc: 0.4836 - precision: 0.4435 - recall: 0.2109 - val_auc: 0.4300 - val_binary_accuracy: 0.6800 - val_f1: 0.0928 - val_loss: 0.6536 - val_prc_auc: 0.1063 - val_precision: 0.0726 - val_recall: 0.1286\n","Epoch 5/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5186 - binary_accuracy: 0.4823 - f1: 0.2928 - loss: 0.7004 - prc_auc: 0.4959 - precision: 0.4580 - recall: 0.2157\n","Epoch 5: Validation Metrics:\n","loss: 0.7038438320159912\n","val_binary_accuracy: 0.6836363673210144\n","val_precision: 0.07377049326896667\n","val_recall: 0.12857143580913544\n","val_auc: 0.44418153166770935\n","val_prc_auc: 0.10907973349094391\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.5179 - binary_accuracy: 0.4822 - f1: 0.2928 - loss: 0.7005 - prc_auc: 0.4956 - precision: 0.4578 - recall: 0.2158 - val_auc: 0.4442 - val_binary_accuracy: 0.6836 - val_f1: 0.0937 - val_loss: 0.6523 - val_prc_auc: 0.1091 - val_precision: 0.0738 - val_recall: 0.1286\n","Epoch 6/20\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.5419 - binary_accuracy: 0.4866 - f1: 0.3007 - loss: 0.6967 - prc_auc: 0.5129 - precision: 0.4672 - recall: 0.2223\n","Epoch 6: Validation Metrics:\n","loss: 0.6998779773712158\n","val_binary_accuracy: 0.692727267742157\n","val_precision: 0.07692307978868484\n","val_recall: 0.12857143580913544\n","val_auc: 0.46264880895614624\n","val_prc_auc: 0.11224998533725739\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - auc: 0.5413 - binary_accuracy: 0.4864 - f1: 0.3008 - loss: 0.6967 - prc_auc: 0.5126 - precision: 0.4671 - recall: 0.2224 - val_auc: 0.4626 - val_binary_accuracy: 0.6927 - val_f1: 0.0963 - val_loss: 0.6507 - val_prc_auc: 0.1122 - val_precision: 0.0769 - val_recall: 0.1286\n","Starting training for label: 9\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250212_004816_10_tags_1_epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - auc: 0.2627 - binary_accuracy: 0.3583 - f1: 0.4788 - loss: 0.7358 - prc_auc: 0.3610 - precision: 0.3992 - recall: 0.5987\n","Epoch 1: Validation Metrics:\n","loss: 0.7325578331947327\n","val_binary_accuracy: 0.1599999964237213\n","val_precision: 0.08523908257484436\n","val_recall: 0.6507936716079712\n","val_auc: 0.2973664402961731\n","val_prc_auc: 0.07681522518396378\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 519ms/step - auc: 0.2631 - binary_accuracy: 0.3584 - f1: 0.4790 - loss: 0.7357 - prc_auc: 0.3613 - precision: 0.3994 - recall: 0.5988 - val_auc: 0.2974 - val_binary_accuracy: 0.1600 - val_f1: 0.1507 - val_loss: 0.7951 - val_prc_auc: 0.0768 - val_precision: 0.0852 - val_recall: 0.6508\n","Epoch 2/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.2674 - binary_accuracy: 0.3616 - f1: 0.4836 - loss: 0.7350 - prc_auc: 0.3628 - precision: 0.4021 - recall: 0.6070\n","Epoch 2: Validation Metrics:\n","loss: 0.7313487529754639\n","val_binary_accuracy: 0.16363635659217834\n","val_precision: 0.08559498935937881\n","val_recall: 0.6507936716079712\n","val_auc: 0.30401548743247986\n","val_prc_auc: 0.07766176760196686\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.2682 - binary_accuracy: 0.3617 - f1: 0.4838 - loss: 0.7348 - prc_auc: 0.3636 - precision: 0.4024 - recall: 0.6070 - val_auc: 0.3040 - val_binary_accuracy: 0.1636 - val_f1: 0.1513 - val_loss: 0.7930 - val_prc_auc: 0.0777 - val_precision: 0.0856 - val_recall: 0.6508\n","Epoch 3/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.2767 - binary_accuracy: 0.3626 - f1: 0.4849 - loss: 0.7328 - prc_auc: 0.3663 - precision: 0.4029 - recall: 0.6091\n","Epoch 3: Validation Metrics:\n","loss: 0.7288965582847595\n","val_binary_accuracy: 0.16545455157756805\n","val_precision: 0.08577405661344528\n","val_recall: 0.6507936716079712\n","val_auc: 0.31201720237731934\n","val_prc_auc: 0.078290656208992\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.2776 - binary_accuracy: 0.3627 - f1: 0.4851 - loss: 0.7326 - prc_auc: 0.3672 - precision: 0.4033 - recall: 0.6090 - val_auc: 0.3120 - val_binary_accuracy: 0.1655 - val_f1: 0.1516 - val_loss: 0.7894 - val_prc_auc: 0.0783 - val_precision: 0.0858 - val_recall: 0.6508\n","Epoch 4/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.2916 - binary_accuracy: 0.3705 - f1: 0.4908 - loss: 0.7295 - prc_auc: 0.3722 - precision: 0.4081 - recall: 0.6162\n","Epoch 4: Validation Metrics:\n","loss: 0.7252308130264282\n","val_binary_accuracy: 0.1709090918302536\n","val_precision: 0.0897703543305397\n","val_recall: 0.682539701461792\n","val_auc: 0.3270101845264435\n","val_prc_auc: 0.07981985807418823\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.2926 - binary_accuracy: 0.3707 - f1: 0.4912 - loss: 0.7292 - prc_auc: 0.3732 - precision: 0.4085 - recall: 0.6163 - val_auc: 0.3270 - val_binary_accuracy: 0.1709 - val_f1: 0.1587 - val_loss: 0.7844 - val_prc_auc: 0.0798 - val_precision: 0.0898 - val_recall: 0.6825\n","Epoch 5/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3137 - binary_accuracy: 0.3846 - f1: 0.5070 - loss: 0.7249 - prc_auc: 0.3819 - precision: 0.4188 - recall: 0.6427\n","Epoch 5: Validation Metrics:\n","loss: 0.7203978300094604\n","val_binary_accuracy: 0.17454545199871063\n","val_precision: 0.0901467502117157\n","val_recall: 0.682539701461792\n","val_auc: 0.34728333353996277\n","val_prc_auc: 0.08210102468729019\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.3149 - binary_accuracy: 0.3849 - f1: 0.5074 - loss: 0.7247 - prc_auc: 0.3830 - precision: 0.4192 - recall: 0.6429 - val_auc: 0.3473 - val_binary_accuracy: 0.1745 - val_f1: 0.1593 - val_loss: 0.7781 - val_prc_auc: 0.0821 - val_precision: 0.0901 - val_recall: 0.6825\n","Epoch 6/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.3479 - binary_accuracy: 0.4115 - f1: 0.5355 - loss: 0.7192 - prc_auc: 0.3984 - precision: 0.4382 - recall: 0.6892\n","Epoch 6: Validation Metrics:\n","loss: 0.7144591808319092\n","val_binary_accuracy: 0.18909090757369995\n","val_precision: 0.09513741731643677\n","val_recall: 0.7142857313156128\n","val_auc: 0.37847527861595154\n","val_prc_auc: 0.08618989586830139\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.3492 - binary_accuracy: 0.4116 - f1: 0.5355 - loss: 0.7190 - prc_auc: 0.3996 - precision: 0.4385 - recall: 0.6886 - val_auc: 0.3785 - val_binary_accuracy: 0.1891 - val_f1: 0.1679 - val_loss: 0.7705 - val_prc_auc: 0.0862 - val_precision: 0.0951 - val_recall: 0.7143\n","Epoch 7/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - auc: 0.3918 - binary_accuracy: 0.4414 - f1: 0.5615 - loss: 0.7125 - prc_auc: 0.4211 - precision: 0.4577 - recall: 0.7269\n","Epoch 7: Validation Metrics:\n","loss: 0.7074899673461914\n","val_binary_accuracy: 0.20181818306446075\n","val_precision: 0.10169491171836853\n","val_recall: 0.761904776096344\n","val_auc: 0.41540369391441345\n","val_prc_auc: 0.09235872328281403\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.3932 - binary_accuracy: 0.4415 - f1: 0.5616 - loss: 0.7122 - prc_auc: 0.4224 - precision: 0.4581 - recall: 0.7264 - val_auc: 0.4154 - val_binary_accuracy: 0.2018 - val_f1: 0.1794 - val_loss: 0.7618 - val_prc_auc: 0.0924 - val_precision: 0.1017 - val_recall: 0.7619\n","Epoch 8/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.4499 - binary_accuracy: 0.4801 - f1: 0.5959 - loss: 0.7047 - prc_auc: 0.4520 - precision: 0.4826 - recall: 0.7794\n","Epoch 8: Validation Metrics:\n","loss: 0.699577808380127\n","val_binary_accuracy: 0.25090909004211426\n","val_precision: 0.11308203637599945\n","val_recall: 0.8095238208770752\n","val_auc: 0.46147453784942627\n","val_prc_auc: 0.10136080533266068\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.4515 - binary_accuracy: 0.4808 - f1: 0.5965 - loss: 0.7045 - prc_auc: 0.4535 - precision: 0.4833 - recall: 0.7796 - val_auc: 0.4615 - val_binary_accuracy: 0.2509 - val_f1: 0.1984 - val_loss: 0.7520 - val_prc_auc: 0.1014 - val_precision: 0.1131 - val_recall: 0.8095\n","Epoch 9/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5174 - binary_accuracy: 0.5278 - f1: 0.6296 - loss: 0.6962 - prc_auc: 0.4881 - precision: 0.5128 - recall: 0.8159\n","Epoch 9: Validation Metrics:\n","loss: 0.690893828868866\n","val_binary_accuracy: 0.303636372089386\n","val_precision: 0.12790697813034058\n","val_recall: 0.8730158805847168\n","val_auc: 0.5185456871986389\n","val_prc_auc: 0.11424729228019714\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.5192 - binary_accuracy: 0.5289 - f1: 0.6305 - loss: 0.6959 - prc_auc: 0.4901 - precision: 0.5138 - recall: 0.8164 - val_auc: 0.5185 - val_binary_accuracy: 0.3036 - val_f1: 0.2231 - val_loss: 0.7416 - val_prc_auc: 0.1142 - val_precision: 0.1279 - val_recall: 0.8730\n","Epoch 10/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.5884 - binary_accuracy: 0.5717 - f1: 0.6662 - loss: 0.6874 - prc_auc: 0.5361 - precision: 0.5406 - recall: 0.8687\n","Epoch 10: Validation Metrics:\n","loss: 0.6821736097335815\n","val_binary_accuracy: 0.34727272391319275\n","val_precision: 0.12814070284366608\n","val_recall: 0.8095238208770752\n","val_auc: 0.5761383175849915\n","val_prc_auc: 0.13220006227493286\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.5900 - binary_accuracy: 0.5728 - f1: 0.6670 - loss: 0.6871 - prc_auc: 0.5380 - precision: 0.5416 - recall: 0.8688 - val_auc: 0.5761 - val_binary_accuracy: 0.3473 - val_f1: 0.2213 - val_loss: 0.7316 - val_prc_auc: 0.1322 - val_precision: 0.1281 - val_recall: 0.8095\n","Epoch 11/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6485 - binary_accuracy: 0.6158 - f1: 0.6910 - loss: 0.6789 - prc_auc: 0.5846 - precision: 0.5717 - recall: 0.8736\n","Epoch 11: Validation Metrics:\n","loss: 0.6737610697746277\n","val_binary_accuracy: 0.4000000059604645\n","val_precision: 0.1342465728521347\n","val_recall: 0.7777777910232544\n","val_auc: 0.6176460981369019\n","val_prc_auc: 0.15576884150505066\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.6500 - binary_accuracy: 0.6169 - f1: 0.6920 - loss: 0.6786 - prc_auc: 0.5864 - precision: 0.5728 - recall: 0.8742 - val_auc: 0.6176 - val_binary_accuracy: 0.4000 - val_f1: 0.2290 - val_loss: 0.7219 - val_prc_auc: 0.1558 - val_precision: 0.1342 - val_recall: 0.7778\n","Epoch 12/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.6951 - binary_accuracy: 0.6466 - f1: 0.7102 - loss: 0.6707 - prc_auc: 0.6258 - precision: 0.5950 - recall: 0.8811\n","Epoch 12: Validation Metrics:\n","loss: 0.6656442284584045\n","val_binary_accuracy: 0.45818182826042175\n","val_precision: 0.14501510560512543\n","val_recall: 0.761904776096344\n","val_auc: 0.6520973443984985\n","val_prc_auc: 0.20465874671936035\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.6964 - binary_accuracy: 0.6477 - f1: 0.7111 - loss: 0.6704 - prc_auc: 0.6277 - precision: 0.5961 - recall: 0.8816 - val_auc: 0.6521 - val_binary_accuracy: 0.4582 - val_f1: 0.2437 - val_loss: 0.7125 - val_prc_auc: 0.2047 - val_precision: 0.1450 - val_recall: 0.7619\n","Epoch 13/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7307 - binary_accuracy: 0.6749 - f1: 0.7252 - loss: 0.6628 - prc_auc: 0.6652 - precision: 0.6207 - recall: 0.8724\n","Epoch 13: Validation Metrics:\n","loss: 0.6578111052513123\n","val_binary_accuracy: 0.5018181800842285\n","val_precision: 0.15181517601013184\n","val_recall: 0.7301587462425232\n","val_auc: 0.6758254766464233\n","val_prc_auc: 0.27444249391555786\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.7317 - binary_accuracy: 0.6756 - f1: 0.7259 - loss: 0.6625 - prc_auc: 0.6671 - precision: 0.6215 - recall: 0.8729 - val_auc: 0.6758 - val_binary_accuracy: 0.5018 - val_f1: 0.2514 - val_loss: 0.7035 - val_prc_auc: 0.2744 - val_precision: 0.1518 - val_recall: 0.7302\n","Epoch 14/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7539 - binary_accuracy: 0.6973 - f1: 0.7357 - loss: 0.6551 - prc_auc: 0.6897 - precision: 0.6441 - recall: 0.8580\n","Epoch 14: Validation Metrics:\n","loss: 0.6502499580383301\n","val_binary_accuracy: 0.5436363816261292\n","val_precision: 0.16428571939468384\n","val_recall: 0.7301587462425232\n","val_auc: 0.691421389579773\n","val_prc_auc: 0.31611815094947815\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.7548 - binary_accuracy: 0.6979 - f1: 0.7364 - loss: 0.6549 - prc_auc: 0.6916 - precision: 0.6448 - recall: 0.8585 - val_auc: 0.6914 - val_binary_accuracy: 0.5436 - val_f1: 0.2682 - val_loss: 0.6947 - val_prc_auc: 0.3161 - val_precision: 0.1643 - val_recall: 0.7302\n","Epoch 15/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7745 - binary_accuracy: 0.7157 - f1: 0.7456 - loss: 0.6477 - prc_auc: 0.7258 - precision: 0.6653 - recall: 0.8482\n","Epoch 15: Validation Metrics:\n","loss: 0.6429504156112671\n","val_binary_accuracy: 0.5763636231422424\n","val_precision: 0.17557251453399658\n","val_recall: 0.7301587462425232\n","val_auc: 0.7054040431976318\n","val_prc_auc: 0.3353208899497986\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.7752 - binary_accuracy: 0.7163 - f1: 0.7462 - loss: 0.6475 - prc_auc: 0.7274 - precision: 0.6660 - recall: 0.8489 - val_auc: 0.7054 - val_binary_accuracy: 0.5764 - val_f1: 0.2831 - val_loss: 0.6862 - val_prc_auc: 0.3353 - val_precision: 0.1756 - val_recall: 0.7302\n","Epoch 16/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.7901 - binary_accuracy: 0.7301 - f1: 0.7550 - loss: 0.6406 - prc_auc: 0.7497 - precision: 0.6813 - recall: 0.8470\n","Epoch 16: Validation Metrics:\n","loss: 0.6359023451805115\n","val_binary_accuracy: 0.6036363840103149\n","val_precision: 0.18367347121238708\n","val_recall: 0.7142857313156128\n","val_auc: 0.7165835499763489\n","val_prc_auc: 0.34613364934921265\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.7908 - binary_accuracy: 0.7306 - f1: 0.7556 - loss: 0.6404 - prc_auc: 0.7511 - precision: 0.6820 - recall: 0.8474 - val_auc: 0.7166 - val_binary_accuracy: 0.6036 - val_f1: 0.2922 - val_loss: 0.6780 - val_prc_auc: 0.3461 - val_precision: 0.1837 - val_recall: 0.7143\n","Epoch 17/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8027 - binary_accuracy: 0.7438 - f1: 0.7641 - loss: 0.6337 - prc_auc: 0.7713 - precision: 0.6974 - recall: 0.8452\n","Epoch 17: Validation Metrics:\n","loss: 0.6290966272354126\n","val_binary_accuracy: 0.6290909051895142\n","val_precision: 0.19213974475860596\n","val_recall: 0.6984127163887024\n","val_auc: 0.7235748767852783\n","val_prc_auc: 0.370382159948349\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.8032 - binary_accuracy: 0.7442 - f1: 0.7647 - loss: 0.6335 - prc_auc: 0.7724 - precision: 0.6981 - recall: 0.8456 - val_auc: 0.7236 - val_binary_accuracy: 0.6291 - val_f1: 0.3014 - val_loss: 0.6701 - val_prc_auc: 0.3704 - val_precision: 0.1921 - val_recall: 0.6984\n","Epoch 18/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8129 - binary_accuracy: 0.7493 - f1: 0.7663 - loss: 0.6271 - prc_auc: 0.7862 - precision: 0.7066 - recall: 0.8371\n","Epoch 18: Validation Metrics:\n","loss: 0.6225242018699646\n","val_binary_accuracy: 0.6472727060317993\n","val_precision: 0.2009132355451584\n","val_recall: 0.6984127163887024\n","val_auc: 0.7306965589523315\n","val_prc_auc: 0.3856481611728668\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.8135 - binary_accuracy: 0.7496 - f1: 0.7668 - loss: 0.6268 - prc_auc: 0.7872 - precision: 0.7071 - recall: 0.8377 - val_auc: 0.7307 - val_binary_accuracy: 0.6473 - val_f1: 0.3121 - val_loss: 0.6624 - val_prc_auc: 0.3856 - val_precision: 0.2009 - val_recall: 0.6984\n","Epoch 19/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8210 - binary_accuracy: 0.7595 - f1: 0.7751 - loss: 0.6207 - prc_auc: 0.7962 - precision: 0.7185 - recall: 0.8417\n","Epoch 19: Validation Metrics:\n","loss: 0.616176962852478\n","val_binary_accuracy: 0.6690909266471863\n","val_precision: 0.21256038546562195\n","val_recall: 0.6984127163887024\n","val_auc: 0.7367100119590759\n","val_prc_auc: 0.4058123826980591\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - auc: 0.8214 - binary_accuracy: 0.7595 - f1: 0.7753 - loss: 0.6204 - prc_auc: 0.7971 - precision: 0.7186 - recall: 0.8419 - val_auc: 0.7367 - val_binary_accuracy: 0.6691 - val_f1: 0.3259 - val_loss: 0.6550 - val_prc_auc: 0.4058 - val_precision: 0.2126 - val_recall: 0.6984\n","Epoch 20/20\n","\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - auc: 0.8274 - binary_accuracy: 0.7637 - f1: 0.7774 - loss: 0.6145 - prc_auc: 0.8079 - precision: 0.7251 - recall: 0.8380\n","Epoch 20: Validation Metrics:\n","loss: 0.6100462675094604\n","val_binary_accuracy: 0.6854545474052429\n","val_precision: 0.21938775479793549\n","val_recall: 0.682539701461792\n","val_auc: 0.7408004999160767\n","val_prc_auc: 0.41887423396110535\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - auc: 0.8278 - binary_accuracy: 0.7637 - f1: 0.7776 - loss: 0.6142 - prc_auc: 0.8087 - precision: 0.7253 - recall: 0.8382 - val_auc: 0.7408 - val_binary_accuracy: 0.6855 - val_f1: 0.3320 - val_loss: 0.6478 - val_prc_auc: 0.4189 - val_precision: 0.2194 - val_recall: 0.6825\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 244ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 196ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 202ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 199ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 201ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step\n","\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 200ms/step\n","[[0 1 0 ... 0 0 0]\n"," [1 1 1 ... 0 0 0]\n"," [1 1 1 ... 0 0 0]\n"," ...\n"," [0 0 1 ... 1 1 0]\n"," [1 0 0 ... 0 0 1]\n"," [1 1 1 ... 0 0 0]]\n"]}],"source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250212_001142_5_tags_1_epoch'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_model=True,\n","    threshold=0.5,\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_20250213_130009'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eef705b716734bacb445376997654d8d","4cf6fc3b13d64ed8aa34bd4763cc9c11","63c72af89cb14b87b88860b973aa5243","912c4b6db067476d87af5c5d802c4943","31c08fd343ad41559cb0744b1eaa22c8","3fc83e9a02a647008f99a0c17a347ee8","4ccac6ae3c3a4db9bd475f4ce4b55b66","f678440da3ae46dca9225d896f990a3e","2374aba250f04cb5be0d929ae8e07464","d4dd3f5d8e3c4342a04e57380748aed9","31b577f0e79f44dd8f9c54eed25f6dfd","acfcfafe3fb94317a8d43273f542c50c","cbe5fdfbee654d0aa521be50906fddcb","69c6f86d7f724fc2bcd048613436678a","5cf423aaa1e94961b5e44a622d87bfa8","6d669423c11742a6934d6df2579e5934","e9cd8cb24d174422838d3543b1a6a3fe","16b5ae78379a44f1b5eed38cb0f61f08","714726935e694313bb4e765f6949c5cb","66cad93025194165b8158c8d58530e11","01e0a0e9fbff42838af906d2197109ac","2767ab58f6dd477f9e25e5acc84b41b4","0b50b12e8bdc4a6f87291d3f56f5cc0f","734b1d88ce014e8484b7b1573aba0d2e","c57b1636ccb14110b805d772d7b16e45","ac7fddb25c7f4d9b8e4cadefc9685ecd","3d01d5ddf71a49c7832668c9c1ccd6f6","ea2813552007403bbc0c5fff3eccf447","97f658f8348d421dacf62063e3be8c40","5265419ea91748819c588c3a52627916","4398f43a163f4d1ea602f9064cede2a7","7e119dc3a215446c84619a558019114a","86f3ddb6f1484e729c721e7452181eb7","286838ce72234b48b79e2de39c28925f","4bbdd7a947474abebf1d2466fb48fc0c","831e9f3c2f9b4461b1947ec4369c4f9d","6a5b30b4e6614519913a99a39d455f02","0931b8f0de704ac78a31e81cad910f82","74f6cb2789f84ab88f4f5c7e7aed10fd","e2b0140c24434afa9191dc1aa7c3c0d0","939f846da76e418ebc71b231a9b8e49d","7f6501a104224d958542cd3bb3b40b92","a64cad17e6224f7cb8f738ca800b4663","67efb3a779f64d7dbf9542c9b7371268"]},"id":"1NV-8lk7Q1b0","executionInfo":{"status":"ok","timestamp":1739453518114,"user_tz":-120,"elapsed":1000786,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"0b302b8c-d387-4754-c679-a5cc8c164b7a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef705b716734bacb445376997654d8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acfcfafe3fb94317a8d43273f542c50c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b50b12e8bdc4a6f87291d3f56f5cc0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286838ce72234b48b79e2de39c28925f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.3190 - binary_accuracy: 0.3588 - f1: 0.2571 - loss: 0.7216 - prc_auc: 0.3941 - precision: 0.3143 - recall: 0.2176\n","Epoch 1: Validation Metrics:\n","loss: 0.7180153131484985\n","val_binary_accuracy: 0.42300885915756226\n","val_precision: 0.20984455943107605\n","val_recall: 0.1892523318529129\n","val_auc: 0.33965036273002625\n","val_prc_auc: 0.2833983302116394\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 229ms/step - auc: 0.3192 - binary_accuracy: 0.3589 - f1: 0.2571 - loss: 0.7216 - prc_auc: 0.3941 - precision: 0.3143 - recall: 0.2176 - val_auc: 0.3397 - val_binary_accuracy: 0.4230 - val_f1: 0.1990 - val_loss: 0.7067 - val_prc_auc: 0.2834 - val_precision: 0.2098 - val_recall: 0.1893\n","Epoch 2/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.3416 - binary_accuracy: 0.3711 - f1: 0.2711 - loss: 0.7167 - prc_auc: 0.4044 - precision: 0.3316 - recall: 0.2293\n","Epoch 2: Validation Metrics:\n","loss: 0.7117483615875244\n","val_binary_accuracy: 0.44601771235466003\n","val_precision: 0.23947368562221527\n","val_recall: 0.21261681616306305\n","val_auc: 0.380962610244751\n","val_prc_auc: 0.2990378737449646\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.3419 - binary_accuracy: 0.3712 - f1: 0.2712 - loss: 0.7167 - prc_auc: 0.4044 - precision: 0.3317 - recall: 0.2294 - val_auc: 0.3810 - val_binary_accuracy: 0.4460 - val_f1: 0.2252 - val_loss: 0.7001 - val_prc_auc: 0.2990 - val_precision: 0.2395 - val_recall: 0.2126\n","Epoch 3/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.4120 - binary_accuracy: 0.4184 - f1: 0.3418 - loss: 0.7054 - prc_auc: 0.4435 - precision: 0.4042 - recall: 0.2962\n","Epoch 3: Validation Metrics:\n","loss: 0.699637234210968\n","val_binary_accuracy: 0.49734511971473694\n","val_precision: 0.3341232240200043\n","val_recall: 0.329439252614975\n","val_auc: 0.48127514123916626\n","val_prc_auc: 0.3569432199001312\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.4125 - binary_accuracy: 0.4187 - f1: 0.3422 - loss: 0.7053 - prc_auc: 0.4437 - precision: 0.4046 - recall: 0.2965 - val_auc: 0.4813 - val_binary_accuracy: 0.4973 - val_f1: 0.3318 - val_loss: 0.6903 - val_prc_auc: 0.3569 - val_precision: 0.3341 - val_recall: 0.3294\n","Epoch 4/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.5515 - binary_accuracy: 0.5249 - f1: 0.4848 - loss: 0.6899 - prc_auc: 0.5556 - precision: 0.5424 - recall: 0.4383\n","Epoch 4: Validation Metrics:\n","loss: 0.6849215030670166\n","val_binary_accuracy: 0.6088495850563049\n","val_precision: 0.4830096960067749\n","val_recall: 0.4649532735347748\n","val_auc: 0.5950338840484619\n","val_prc_auc: 0.4604935348033905\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.5519 - binary_accuracy: 0.5252 - f1: 0.4851 - loss: 0.6899 - prc_auc: 0.5559 - precision: 0.5428 - recall: 0.4386 - val_auc: 0.5950 - val_binary_accuracy: 0.6088 - val_f1: 0.4738 - val_loss: 0.6808 - val_prc_auc: 0.4605 - val_precision: 0.4830 - val_recall: 0.4650\n","Epoch 5/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.6685 - binary_accuracy: 0.6381 - f1: 0.6099 - loss: 0.6753 - prc_auc: 0.6663 - precision: 0.6768 - recall: 0.5551\n","Epoch 5: Validation Metrics:\n","loss: 0.6712936162948608\n","val_binary_accuracy: 0.665486752986908\n","val_precision: 0.559808611869812\n","val_recall: 0.5467289686203003\n","val_auc: 0.6607123613357544\n","val_prc_auc: 0.5354011654853821\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.6686 - binary_accuracy: 0.6382 - f1: 0.6100 - loss: 0.6752 - prc_auc: 0.6664 - precision: 0.6769 - recall: 0.5552 - val_auc: 0.6607 - val_binary_accuracy: 0.6655 - val_f1: 0.5532 - val_loss: 0.6723 - val_prc_auc: 0.5354 - val_precision: 0.5598 - val_recall: 0.5467\n","Epoch 6/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7297 - binary_accuracy: 0.6885 - f1: 0.6719 - loss: 0.6620 - prc_auc: 0.7288 - precision: 0.7248 - recall: 0.6263\n","Epoch 6: Validation Metrics:\n","loss: 0.658940851688385\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.5657015442848206\n","val_recall: 0.5934579372406006\n","val_auc: 0.6977627277374268\n","val_prc_auc: 0.5785953998565674\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7297 - binary_accuracy: 0.6885 - f1: 0.6718 - loss: 0.6620 - prc_auc: 0.7289 - precision: 0.7247 - recall: 0.6263 - val_auc: 0.6978 - val_binary_accuracy: 0.6735 - val_f1: 0.5792 - val_loss: 0.6648 - val_prc_auc: 0.5786 - val_precision: 0.5657 - val_recall: 0.5935\n","Epoch 7/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7614 - binary_accuracy: 0.7069 - f1: 0.6985 - loss: 0.6500 - prc_auc: 0.7594 - precision: 0.7346 - recall: 0.6659\n","Epoch 7: Validation Metrics:\n","loss: 0.6477516293525696\n","val_binary_accuracy: 0.6725663542747498\n","val_precision: 0.5611814260482788\n","val_recall: 0.6214953064918518\n","val_auc: 0.7160333395004272\n","val_prc_auc: 0.5986671447753906\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7614 - binary_accuracy: 0.7070 - f1: 0.6984 - loss: 0.6500 - prc_auc: 0.7594 - precision: 0.7345 - recall: 0.6659 - val_auc: 0.7160 - val_binary_accuracy: 0.6726 - val_f1: 0.5898 - val_loss: 0.6581 - val_prc_auc: 0.5987 - val_precision: 0.5612 - val_recall: 0.6215\n","Epoch 8/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7780 - binary_accuracy: 0.7164 - f1: 0.7135 - loss: 0.6391 - prc_auc: 0.7758 - precision: 0.7354 - recall: 0.6932\n","Epoch 8: Validation Metrics:\n","loss: 0.6376234889030457\n","val_binary_accuracy: 0.6761062145233154\n","val_precision: 0.5640496015548706\n","val_recall: 0.6378504633903503\n","val_auc: 0.7260215282440186\n","val_prc_auc: 0.6106086373329163\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7780 - binary_accuracy: 0.7164 - f1: 0.7135 - loss: 0.6391 - prc_auc: 0.7758 - precision: 0.7353 - recall: 0.6931 - val_auc: 0.7260 - val_binary_accuracy: 0.6761 - val_f1: 0.5987 - val_loss: 0.6522 - val_prc_auc: 0.6106 - val_precision: 0.5640 - val_recall: 0.6379\n","Epoch 9/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7866 - binary_accuracy: 0.7193 - f1: 0.7196 - loss: 0.6292 - prc_auc: 0.7859 - precision: 0.7331 - recall: 0.7069\n","Epoch 9: Validation Metrics:\n","loss: 0.6284626126289368\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.5682281255722046\n","val_recall: 0.6518691778182983\n","val_auc: 0.7334085702896118\n","val_prc_auc: 0.6163607239723206\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.7866 - binary_accuracy: 0.7192 - f1: 0.7195 - loss: 0.6292 - prc_auc: 0.7859 - precision: 0.7330 - recall: 0.7068 - val_auc: 0.7334 - val_binary_accuracy: 0.6805 - val_f1: 0.6072 - val_loss: 0.6470 - val_prc_auc: 0.6164 - val_precision: 0.5682 - val_recall: 0.6519\n","Epoch 10/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.7928 - binary_accuracy: 0.7266 - f1: 0.7284 - loss: 0.6203 - prc_auc: 0.7927 - precision: 0.7379 - recall: 0.7196\n","Epoch 10: Validation Metrics:\n","loss: 0.6201814413070679\n","val_binary_accuracy: 0.6849557757377625\n","val_precision: 0.5720000267028809\n","val_recall: 0.6682242751121521\n","val_auc: 0.7372376918792725\n","val_prc_auc: 0.6228439807891846\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 95ms/step - auc: 0.7928 - binary_accuracy: 0.7265 - f1: 0.7284 - loss: 0.6203 - prc_auc: 0.7927 - precision: 0.7378 - recall: 0.7196 - val_auc: 0.7372 - val_binary_accuracy: 0.6850 - val_f1: 0.6164 - val_loss: 0.6425 - val_prc_auc: 0.6228 - val_precision: 0.5720 - val_recall: 0.6682\n","Epoch 11/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7960 - binary_accuracy: 0.7276 - f1: 0.7300 - loss: 0.6123 - prc_auc: 0.7968 - precision: 0.7379 - recall: 0.7226\n","Epoch 11: Validation Metrics:\n","loss: 0.6126992702484131\n","val_binary_accuracy: 0.6876106262207031\n","val_precision: 0.5730994343757629\n","val_recall: 0.6869158744812012\n","val_auc: 0.739738941192627\n","val_prc_auc: 0.6253068447113037\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7959 - binary_accuracy: 0.7276 - f1: 0.7300 - loss: 0.6123 - prc_auc: 0.7968 - precision: 0.7378 - recall: 0.7226 - val_auc: 0.7397 - val_binary_accuracy: 0.6876 - val_f1: 0.6249 - val_loss: 0.6385 - val_prc_auc: 0.6253 - val_precision: 0.5731 - val_recall: 0.6869\n","Epoch 12/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7986 - binary_accuracy: 0.7248 - f1: 0.7294 - loss: 0.6050 - prc_auc: 0.8002 - precision: 0.7317 - recall: 0.7275\n","Epoch 12: Validation Metrics:\n","loss: 0.6059417724609375\n","val_binary_accuracy: 0.6831858158111572\n","val_precision: 0.5670498013496399\n","val_recall: 0.6915887594223022\n","val_auc: 0.7418057322502136\n","val_prc_auc: 0.6262223720550537\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7986 - binary_accuracy: 0.7248 - f1: 0.7293 - loss: 0.6050 - prc_auc: 0.8002 - precision: 0.7316 - recall: 0.7275 - val_auc: 0.7418 - val_binary_accuracy: 0.6832 - val_f1: 0.6232 - val_loss: 0.6350 - val_prc_auc: 0.6262 - val_precision: 0.5670 - val_recall: 0.6916\n","Epoch 13/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8002 - binary_accuracy: 0.7262 - f1: 0.7305 - loss: 0.5984 - prc_auc: 0.8026 - precision: 0.7337 - recall: 0.7277\n","Epoch 13: Validation Metrics:\n","loss: 0.5998410582542419\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.5640535354614258\n","val_recall: 0.6892523169517517\n","val_auc: 0.7432103157043457\n","val_prc_auc: 0.6293630599975586\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8001 - binary_accuracy: 0.7262 - f1: 0.7304 - loss: 0.5984 - prc_auc: 0.8025 - precision: 0.7336 - recall: 0.7277 - val_auc: 0.7432 - val_binary_accuracy: 0.6805 - val_f1: 0.6204 - val_loss: 0.6320 - val_prc_auc: 0.6294 - val_precision: 0.5641 - val_recall: 0.6893\n","Epoch 14/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8015 - binary_accuracy: 0.7295 - f1: 0.7343 - loss: 0.5925 - prc_auc: 0.8053 - precision: 0.7359 - recall: 0.7332\n","Epoch 14: Validation Metrics:\n","loss: 0.5943341851234436\n","val_binary_accuracy: 0.6787610650062561\n","val_precision: 0.5616698265075684\n","val_recall: 0.6915887594223022\n","val_auc: 0.7445483803749084\n","val_prc_auc: 0.6304680705070496\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8015 - binary_accuracy: 0.7295 - f1: 0.7342 - loss: 0.5925 - prc_auc: 0.8053 - precision: 0.7357 - recall: 0.7332 - val_auc: 0.7445 - val_binary_accuracy: 0.6788 - val_f1: 0.6199 - val_loss: 0.6294 - val_prc_auc: 0.6305 - val_precision: 0.5617 - val_recall: 0.6916\n","Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - auc: 0.6429 - binary_accuracy: 0.5891 - f1: 0.5276 - loss: 0.6793 - prc_auc: 0.5816 - precision: 0.6196 - recall: 0.4602\n","Epoch 1: Validation Metrics:\n","loss: 0.6774201393127441\n","val_binary_accuracy: 0.6221238970756531\n","val_precision: 0.4975961446762085\n","val_recall: 0.4870588183403015\n","val_auc: 0.6540275812149048\n","val_prc_auc: 0.48605775833129883\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 233ms/step - auc: 0.6430 - binary_accuracy: 0.5893 - f1: 0.5278 - loss: 0.6793 - prc_auc: 0.5817 - precision: 0.6198 - recall: 0.4604 - val_auc: 0.6540 - val_binary_accuracy: 0.6221 - val_f1: 0.4923 - val_loss: 0.6706 - val_prc_auc: 0.4861 - val_precision: 0.4976 - val_recall: 0.4871\n","Epoch 2/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6959 - binary_accuracy: 0.6464 - f1: 0.6205 - loss: 0.6726 - prc_auc: 0.6431 - precision: 0.6676 - recall: 0.5802\n","Epoch 2: Validation Metrics:\n","loss: 0.6684916019439697\n","val_binary_accuracy: 0.6628318428993225\n","val_precision: 0.5440000295639038\n","val_recall: 0.6399999856948853\n","val_auc: 0.7116696238517761\n","val_prc_auc: 0.5575727224349976\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.6965 - binary_accuracy: 0.6469 - f1: 0.6212 - loss: 0.6726 - prc_auc: 0.6438 - precision: 0.6680 - recall: 0.5811 - val_auc: 0.7117 - val_binary_accuracy: 0.6628 - val_f1: 0.5881 - val_loss: 0.6636 - val_prc_auc: 0.5576 - val_precision: 0.5440 - val_recall: 0.6400\n","Epoch 3/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7779 - binary_accuracy: 0.7228 - f1: 0.7295 - loss: 0.6581 - prc_auc: 0.7392 - precision: 0.7114 - recall: 0.7491\n","Epoch 3: Validation Metrics:\n","loss: 0.6519293785095215\n","val_binary_accuracy: 0.6938053369522095\n","val_precision: 0.5719490051269531\n","val_recall: 0.7388235330581665\n","val_auc: 0.7512807846069336\n","val_prc_auc: 0.611114501953125\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7783 - binary_accuracy: 0.7231 - f1: 0.7299 - loss: 0.6580 - prc_auc: 0.7399 - precision: 0.7117 - recall: 0.7495 - val_auc: 0.7513 - val_binary_accuracy: 0.6938 - val_f1: 0.6448 - val_loss: 0.6535 - val_prc_auc: 0.6111 - val_precision: 0.5719 - val_recall: 0.7388\n","Epoch 4/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8196 - binary_accuracy: 0.7551 - f1: 0.7675 - loss: 0.6392 - prc_auc: 0.7961 - precision: 0.7295 - recall: 0.8099\n","Epoch 4: Validation Metrics:\n","loss: 0.6326497197151184\n","val_binary_accuracy: 0.6858407258987427\n","val_precision: 0.5607638955116272\n","val_recall: 0.7599999904632568\n","val_auc: 0.7653616666793823\n","val_prc_auc: 0.634652316570282\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - auc: 0.8199 - binary_accuracy: 0.7554 - f1: 0.7678 - loss: 0.6391 - prc_auc: 0.7965 - precision: 0.7298 - recall: 0.8103 - val_auc: 0.7654 - val_binary_accuracy: 0.6858 - val_f1: 0.6454 - val_loss: 0.6443 - val_prc_auc: 0.6347 - val_precision: 0.5608 - val_recall: 0.7600\n","Epoch 5/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8366 - binary_accuracy: 0.7654 - f1: 0.7816 - loss: 0.6222 - prc_auc: 0.8236 - precision: 0.7304 - recall: 0.8410\n","Epoch 5: Validation Metrics:\n","loss: 0.6155169606208801\n","val_binary_accuracy: 0.6929203271865845\n","val_precision: 0.564784049987793\n","val_recall: 0.800000011920929\n","val_auc: 0.7719398736953735\n","val_prc_auc: 0.649455189704895\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8369 - binary_accuracy: 0.7656 - f1: 0.7818 - loss: 0.6221 - prc_auc: 0.8238 - precision: 0.7305 - recall: 0.8412 - val_auc: 0.7719 - val_binary_accuracy: 0.6929 - val_f1: 0.6621 - val_loss: 0.6367 - val_prc_auc: 0.6495 - val_precision: 0.5648 - val_recall: 0.8000\n","Epoch 6/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8439 - binary_accuracy: 0.7687 - f1: 0.7876 - loss: 0.6073 - prc_auc: 0.8359 - precision: 0.7274 - recall: 0.8593\n","Epoch 6: Validation Metrics:\n","loss: 0.6005369424819946\n","val_binary_accuracy: 0.6938053369522095\n","val_precision: 0.5650741457939148\n","val_recall: 0.8070588111877441\n","val_auc: 0.7745248079299927\n","val_prc_auc: 0.652750551700592\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8441 - binary_accuracy: 0.7689 - f1: 0.7878 - loss: 0.6072 - prc_auc: 0.8360 - precision: 0.7275 - recall: 0.8594 - val_auc: 0.7745 - val_binary_accuracy: 0.6938 - val_f1: 0.6647 - val_loss: 0.6303 - val_prc_auc: 0.6528 - val_precision: 0.5651 - val_recall: 0.8071\n","Epoch 7/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - auc: 0.8473 - binary_accuracy: 0.7735 - f1: 0.7934 - loss: 0.5944 - prc_auc: 0.8413 - precision: 0.7287 - recall: 0.8712\n","Epoch 7: Validation Metrics:\n","loss: 0.5874219536781311\n","val_binary_accuracy: 0.6946902871131897\n","val_precision: 0.5651465654373169\n","val_recall: 0.8164705634117126\n","val_auc: 0.7763270735740662\n","val_prc_auc: 0.6536524295806885\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8475 - binary_accuracy: 0.7736 - f1: 0.7935 - loss: 0.5943 - prc_auc: 0.8415 - precision: 0.7288 - recall: 0.8713 - val_auc: 0.7763 - val_binary_accuracy: 0.6947 - val_f1: 0.6679 - val_loss: 0.6250 - val_prc_auc: 0.6537 - val_precision: 0.5651 - val_recall: 0.8165\n","Epoch 8/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8499 - binary_accuracy: 0.7716 - f1: 0.7924 - loss: 0.5831 - prc_auc: 0.8439 - precision: 0.7257 - recall: 0.8731\n","Epoch 8: Validation Metrics:\n","loss: 0.5759287476539612\n","val_binary_accuracy: 0.6946902871131897\n","val_precision: 0.5645161271095276\n","val_recall: 0.8235294222831726\n","val_auc: 0.7773249745368958\n","val_prc_auc: 0.6557286381721497\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - auc: 0.8501 - binary_accuracy: 0.7717 - f1: 0.7925 - loss: 0.5830 - prc_auc: 0.8440 - precision: 0.7258 - recall: 0.8732 - val_auc: 0.7773 - val_binary_accuracy: 0.6947 - val_f1: 0.6699 - val_loss: 0.6207 - val_prc_auc: 0.6557 - val_precision: 0.5645 - val_recall: 0.8235\n","Epoch 9/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8514 - binary_accuracy: 0.7714 - f1: 0.7923 - loss: 0.5733 - prc_auc: 0.8458 - precision: 0.7251 - recall: 0.8738\n","Epoch 9: Validation Metrics:\n","loss: 0.5658488869667053\n","val_binary_accuracy: 0.6938053369522095\n","val_precision: 0.5634028911590576\n","val_recall: 0.8258823752403259\n","val_auc: 0.7772783041000366\n","val_prc_auc: 0.652920663356781\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - auc: 0.8516 - binary_accuracy: 0.7714 - f1: 0.7924 - loss: 0.5731 - prc_auc: 0.8459 - precision: 0.7252 - recall: 0.8739 - val_auc: 0.7773 - val_binary_accuracy: 0.6938 - val_f1: 0.6698 - val_loss: 0.6171 - val_prc_auc: 0.6529 - val_precision: 0.5634 - val_recall: 0.8259\n","Epoch 10/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8522 - binary_accuracy: 0.7700 - f1: 0.7912 - loss: 0.5647 - prc_auc: 0.8471 - precision: 0.7237 - recall: 0.8731\n","Epoch 10: Validation Metrics:\n","loss: 0.5570003986358643\n","val_binary_accuracy: 0.6920353770256042\n","val_precision: 0.5616000294685364\n","val_recall: 0.8258823752403259\n","val_auc: 0.7773450016975403\n","val_prc_auc: 0.655565083026886\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8523 - binary_accuracy: 0.7701 - f1: 0.7913 - loss: 0.5645 - prc_auc: 0.8473 - precision: 0.7238 - recall: 0.8732 - val_auc: 0.7773 - val_binary_accuracy: 0.6920 - val_f1: 0.6686 - val_loss: 0.6143 - val_prc_auc: 0.6556 - val_precision: 0.5616 - val_recall: 0.8259\n","Epoch 11/20\n","\u001b[1m106/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8524 - binary_accuracy: 0.7707 - f1: 0.7920 - loss: 0.5572 - prc_auc: 0.8472 - precision: 0.7239 - recall: 0.8748\n","Epoch 11: Validation Metrics:\n","loss: 0.5492262244224548\n","val_binary_accuracy: 0.691150426864624\n","val_precision: 0.5607028603553772\n","val_recall: 0.8258823752403259\n","val_auc: 0.7774701714515686\n","val_prc_auc: 0.6554083824157715\n","\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8525 - binary_accuracy: 0.7707 - f1: 0.7921 - loss: 0.5570 - prc_auc: 0.8474 - precision: 0.7240 - recall: 0.8749 - val_auc: 0.7775 - val_binary_accuracy: 0.6912 - val_f1: 0.6679 - val_loss: 0.6120 - val_prc_auc: 0.6554 - val_precision: 0.5607 - val_recall: 0.8259\n","Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - auc: 0.3754 - binary_accuracy: 0.4209 - f1: 0.3671 - loss: 0.7114 - prc_auc: 0.3989 - precision: 0.3982 - recall: 0.3408\n","Epoch 1: Validation Metrics:\n","loss: 0.707805871963501\n","val_binary_accuracy: 0.4929203391075134\n","val_precision: 0.34381139278411865\n","val_recall: 0.4227053225040436\n","val_auc: 0.44154995679855347\n","val_prc_auc: 0.32037925720214844\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 243ms/step - auc: 0.3757 - binary_accuracy: 0.4212 - f1: 0.3674 - loss: 0.7114 - prc_auc: 0.3990 - precision: 0.3985 - recall: 0.3411 - val_auc: 0.4415 - val_binary_accuracy: 0.4929 - val_f1: 0.3792 - val_loss: 0.7025 - val_prc_auc: 0.3204 - val_precision: 0.3438 - val_recall: 0.4227\n","Epoch 2/20\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4164 - binary_accuracy: 0.4646 - f1: 0.4415 - loss: 0.7063 - prc_auc: 0.4176 - precision: 0.4546 - recall: 0.4293\n","Epoch 2: Validation Metrics:\n","loss: 0.7012673020362854\n","val_binary_accuracy: 0.5247787833213806\n","val_precision: 0.3891891837120056\n","val_recall: 0.52173912525177\n","val_auc: 0.5025098919868469\n","val_prc_auc: 0.35328784584999084\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.4168 - binary_accuracy: 0.4649 - f1: 0.4419 - loss: 0.7063 - prc_auc: 0.4179 - precision: 0.4550 - recall: 0.4297 - val_auc: 0.5025 - val_binary_accuracy: 0.5248 - val_f1: 0.4458 - val_loss: 0.6967 - val_prc_auc: 0.3533 - val_precision: 0.3892 - val_recall: 0.5217\n","Epoch 3/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5134 - binary_accuracy: 0.5258 - f1: 0.5394 - loss: 0.6947 - prc_auc: 0.4737 - precision: 0.5176 - recall: 0.5632\n","Epoch 3: Validation Metrics:\n","loss: 0.6886734962463379\n","val_binary_accuracy: 0.5486725568771362\n","val_precision: 0.41808873414993286\n","val_recall: 0.5917874574661255\n","val_auc: 0.5988432168960571\n","val_prc_auc: 0.43019723892211914\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.5144 - binary_accuracy: 0.5264 - f1: 0.5400 - loss: 0.6946 - prc_auc: 0.4745 - precision: 0.5183 - recall: 0.5637 - val_auc: 0.5988 - val_binary_accuracy: 0.5487 - val_f1: 0.4900 - val_loss: 0.6880 - val_prc_auc: 0.4302 - val_precision: 0.4181 - val_recall: 0.5918\n","Epoch 4/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6416 - binary_accuracy: 0.5998 - f1: 0.6252 - loss: 0.6786 - prc_auc: 0.5927 - precision: 0.5807 - recall: 0.6774\n","Epoch 4: Validation Metrics:\n","loss: 0.6730489730834961\n","val_binary_accuracy: 0.5840708017349243\n","val_precision: 0.4533333480358124\n","val_recall: 0.6570048332214355\n","val_auc: 0.662650465965271\n","val_prc_auc: 0.5132244229316711\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.6423 - binary_accuracy: 0.6002 - f1: 0.6255 - loss: 0.6785 - prc_auc: 0.5935 - precision: 0.5812 - recall: 0.6775 - val_auc: 0.6627 - val_binary_accuracy: 0.5841 - val_f1: 0.5365 - val_loss: 0.6793 - val_prc_auc: 0.5132 - val_precision: 0.4533 - val_recall: 0.6570\n","Epoch 5/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7265 - binary_accuracy: 0.6474 - f1: 0.6686 - loss: 0.6630 - prc_auc: 0.6913 - precision: 0.6230 - recall: 0.7218\n","Epoch 5: Validation Metrics:\n","loss: 0.6584267020225525\n","val_binary_accuracy: 0.6150442361831665\n","val_precision: 0.4829268157482147\n","val_recall: 0.717391312122345\n","val_auc: 0.6989092826843262\n","val_prc_auc: 0.5553380250930786\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7269 - binary_accuracy: 0.6478 - f1: 0.6690 - loss: 0.6629 - prc_auc: 0.6916 - precision: 0.6234 - recall: 0.7220 - val_auc: 0.6989 - val_binary_accuracy: 0.6150 - val_f1: 0.5773 - val_loss: 0.6715 - val_prc_auc: 0.5553 - val_precision: 0.4829 - val_recall: 0.7174\n","Epoch 6/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7719 - binary_accuracy: 0.6808 - f1: 0.7021 - loss: 0.6488 - prc_auc: 0.7346 - precision: 0.6498 - recall: 0.7638\n","Epoch 6: Validation Metrics:\n","loss: 0.6450790762901306\n","val_binary_accuracy: 0.6415929198265076\n","val_precision: 0.5073409676551819\n","val_recall: 0.751207709312439\n","val_auc: 0.7199163436889648\n","val_prc_auc: 0.57940274477005\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7720 - binary_accuracy: 0.6811 - f1: 0.7024 - loss: 0.6487 - prc_auc: 0.7347 - precision: 0.6502 - recall: 0.7640 - val_auc: 0.7199 - val_binary_accuracy: 0.6416 - val_f1: 0.6056 - val_loss: 0.6645 - val_prc_auc: 0.5794 - val_precision: 0.5073 - val_recall: 0.7512\n","Epoch 7/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7972 - binary_accuracy: 0.7129 - f1: 0.7350 - loss: 0.6358 - prc_auc: 0.7586 - precision: 0.6739 - recall: 0.8086\n","Epoch 7: Validation Metrics:\n","loss: 0.632880687713623\n","val_binary_accuracy: 0.6601769924163818\n","val_precision: 0.5242718458175659\n","val_recall: 0.782608687877655\n","val_auc: 0.7346621751785278\n","val_prc_auc: 0.5976018905639648\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.7972 - binary_accuracy: 0.7131 - f1: 0.7351 - loss: 0.6357 - prc_auc: 0.7586 - precision: 0.6741 - recall: 0.8086 - val_auc: 0.7347 - val_binary_accuracy: 0.6602 - val_f1: 0.6279 - val_loss: 0.6582 - val_prc_auc: 0.5976 - val_precision: 0.5243 - val_recall: 0.7826\n","Epoch 8/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8111 - binary_accuracy: 0.7315 - f1: 0.7545 - loss: 0.6239 - prc_auc: 0.7711 - precision: 0.6864 - recall: 0.8379\n","Epoch 8: Validation Metrics:\n","loss: 0.6217226386070251\n","val_binary_accuracy: 0.6681416034698486\n","val_precision: 0.5317073464393616\n","val_recall: 0.7898550629615784\n","val_auc: 0.7422831058502197\n","val_prc_auc: 0.6045092940330505\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8110 - binary_accuracy: 0.7316 - f1: 0.7546 - loss: 0.6238 - prc_auc: 0.7710 - precision: 0.6867 - recall: 0.8377 - val_auc: 0.7423 - val_binary_accuracy: 0.6681 - val_f1: 0.6356 - val_loss: 0.6525 - val_prc_auc: 0.6045 - val_precision: 0.5317 - val_recall: 0.7899\n","Epoch 9/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8201 - binary_accuracy: 0.7473 - f1: 0.7704 - loss: 0.6130 - prc_auc: 0.7787 - precision: 0.6975 - recall: 0.8607\n","Epoch 9: Validation Metrics:\n","loss: 0.6115077137947083\n","val_binary_accuracy: 0.6663717031478882\n","val_precision: 0.5296000242233276\n","val_recall: 0.7995169162750244\n","val_auc: 0.7486404776573181\n","val_prc_auc: 0.6099453568458557\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8200 - binary_accuracy: 0.7474 - f1: 0.7704 - loss: 0.6129 - prc_auc: 0.7787 - precision: 0.6977 - recall: 0.8604 - val_auc: 0.7486 - val_binary_accuracy: 0.6664 - val_f1: 0.6372 - val_loss: 0.6475 - val_prc_auc: 0.6099 - val_precision: 0.5296 - val_recall: 0.7995\n","Epoch 10/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8273 - binary_accuracy: 0.7593 - f1: 0.7817 - loss: 0.6030 - prc_auc: 0.7869 - precision: 0.7069 - recall: 0.8746\n","Epoch 10: Validation Metrics:\n","loss: 0.6021484732627869\n","val_binary_accuracy: 0.6663717031478882\n","val_precision: 0.5296950340270996\n","val_recall: 0.7971014380455017\n","val_auc: 0.7539740800857544\n","val_prc_auc: 0.6169572472572327\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8272 - binary_accuracy: 0.7593 - f1: 0.7816 - loss: 0.6029 - prc_auc: 0.7868 - precision: 0.7071 - recall: 0.8743 - val_auc: 0.7540 - val_binary_accuracy: 0.6664 - val_f1: 0.6365 - val_loss: 0.6430 - val_prc_auc: 0.6170 - val_precision: 0.5297 - val_recall: 0.7971\n","Epoch 11/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8317 - binary_accuracy: 0.7671 - f1: 0.7884 - loss: 0.5938 - prc_auc: 0.7910 - precision: 0.7135 - recall: 0.8812\n","Epoch 11: Validation Metrics:\n","loss: 0.5935656428337097\n","val_binary_accuracy: 0.67345130443573\n","val_precision: 0.5363489389419556\n","val_recall: 0.8019323945045471\n","val_auc: 0.7570204138755798\n","val_prc_auc: 0.6205307841300964\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8316 - binary_accuracy: 0.7670 - f1: 0.7883 - loss: 0.5938 - prc_auc: 0.7909 - precision: 0.7136 - recall: 0.8809 - val_auc: 0.7570 - val_binary_accuracy: 0.6735 - val_f1: 0.6428 - val_loss: 0.6389 - val_prc_auc: 0.6205 - val_precision: 0.5363 - val_recall: 0.8019\n","Epoch 12/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8351 - binary_accuracy: 0.7692 - f1: 0.7911 - loss: 0.5854 - prc_auc: 0.7941 - precision: 0.7141 - recall: 0.8870\n","Epoch 12: Validation Metrics:\n","loss: 0.5856879353523254\n","val_binary_accuracy: 0.6752212643623352\n","val_precision: 0.5382114052772522\n","val_recall: 0.7995169162750244\n","val_auc: 0.7591760754585266\n","val_prc_auc: 0.6217126846313477\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8350 - binary_accuracy: 0.7691 - f1: 0.7910 - loss: 0.5854 - prc_auc: 0.7940 - precision: 0.7142 - recall: 0.8866 - val_auc: 0.7592 - val_binary_accuracy: 0.6752 - val_f1: 0.6433 - val_loss: 0.6353 - val_prc_auc: 0.6217 - val_precision: 0.5382 - val_recall: 0.7995\n","Epoch 13/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8380 - binary_accuracy: 0.7721 - f1: 0.7938 - loss: 0.5776 - prc_auc: 0.7966 - precision: 0.7165 - recall: 0.8900\n","Epoch 13: Validation Metrics:\n","loss: 0.578450620174408\n","val_binary_accuracy: 0.6778761148452759\n","val_precision: 0.5404530763626099\n","val_recall: 0.8067632913589478\n","val_auc: 0.7616438269615173\n","val_prc_auc: 0.6244738101959229\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8379 - binary_accuracy: 0.7720 - f1: 0.7937 - loss: 0.5776 - prc_auc: 0.7965 - precision: 0.7166 - recall: 0.8896 - val_auc: 0.7616 - val_binary_accuracy: 0.6779 - val_f1: 0.6473 - val_loss: 0.6320 - val_prc_auc: 0.6245 - val_precision: 0.5405 - val_recall: 0.8068\n","Epoch 14/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8408 - binary_accuracy: 0.7710 - f1: 0.7929 - loss: 0.5705 - prc_auc: 0.8010 - precision: 0.7153 - recall: 0.8897\n","Epoch 14: Validation Metrics:\n","loss: 0.5717952847480774\n","val_binary_accuracy: 0.6778761148452759\n","val_precision: 0.5401929020881653\n","val_recall: 0.8115941882133484\n","val_auc: 0.7635329961776733\n","val_prc_auc: 0.6255835294723511\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8406 - binary_accuracy: 0.7709 - f1: 0.7928 - loss: 0.5705 - prc_auc: 0.8009 - precision: 0.7154 - recall: 0.8894 - val_auc: 0.7635 - val_binary_accuracy: 0.6779 - val_f1: 0.6486 - val_loss: 0.6291 - val_prc_auc: 0.6256 - val_precision: 0.5402 - val_recall: 0.8116\n","Epoch 15/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8427 - binary_accuracy: 0.7751 - f1: 0.7968 - loss: 0.5639 - prc_auc: 0.8043 - precision: 0.7183 - recall: 0.8950\n","Epoch 15: Validation Metrics:\n","loss: 0.5656690001487732\n","val_binary_accuracy: 0.6805309653282166\n","val_precision: 0.5425361394882202\n","val_recall: 0.8164251446723938\n","val_auc: 0.7651742100715637\n","val_prc_auc: 0.6275582313537598\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8425 - binary_accuracy: 0.7750 - f1: 0.7968 - loss: 0.5640 - prc_auc: 0.8042 - precision: 0.7184 - recall: 0.8947 - val_auc: 0.7652 - val_binary_accuracy: 0.6805 - val_f1: 0.6519 - val_loss: 0.6265 - val_prc_auc: 0.6276 - val_precision: 0.5425 - val_recall: 0.8164\n","Epoch 16/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8441 - binary_accuracy: 0.7771 - f1: 0.7988 - loss: 0.5579 - prc_auc: 0.8067 - precision: 0.7198 - recall: 0.8974\n","Epoch 16: Validation Metrics:\n","loss: 0.5600243210792542\n","val_binary_accuracy: 0.682300865650177\n","val_precision: 0.544283390045166\n","val_recall: 0.8164251446723938\n","val_auc: 0.7662284970283508\n","val_prc_auc: 0.6280864477157593\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.8439 - binary_accuracy: 0.7770 - f1: 0.7987 - loss: 0.5579 - prc_auc: 0.8066 - precision: 0.7199 - recall: 0.8971 - val_auc: 0.7662 - val_binary_accuracy: 0.6823 - val_f1: 0.6531 - val_loss: 0.6241 - val_prc_auc: 0.6281 - val_precision: 0.5443 - val_recall: 0.8164\n","Epoch 17/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8453 - binary_accuracy: 0.7798 - f1: 0.8008 - loss: 0.5523 - prc_auc: 0.8080 - precision: 0.7226 - recall: 0.8983\n","Epoch 17: Validation Metrics:\n","loss: 0.554818332195282\n","val_binary_accuracy: 0.6849557757377625\n","val_precision: 0.5467742085456848\n","val_recall: 0.8188405632972717\n","val_auc: 0.7673518657684326\n","val_prc_auc: 0.6292511224746704\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - auc: 0.8451 - binary_accuracy: 0.7797 - f1: 0.8007 - loss: 0.5523 - prc_auc: 0.8079 - precision: 0.7227 - recall: 0.8980 - val_auc: 0.7674 - val_binary_accuracy: 0.6850 - val_f1: 0.6557 - val_loss: 0.6220 - val_prc_auc: 0.6293 - val_precision: 0.5468 - val_recall: 0.8188\n","Epoch 18/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8465 - binary_accuracy: 0.7832 - f1: 0.8036 - loss: 0.5471 - prc_auc: 0.8090 - precision: 0.7257 - recall: 0.9004\n","Epoch 18: Validation Metrics:\n","loss: 0.5500116944313049\n","val_binary_accuracy: 0.682300865650177\n","val_precision: 0.5441412329673767\n","val_recall: 0.8188405632972717\n","val_auc: 0.7682778835296631\n","val_prc_auc: 0.6289846301078796\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8463 - binary_accuracy: 0.7830 - f1: 0.8034 - loss: 0.5472 - prc_auc: 0.8089 - precision: 0.7257 - recall: 0.9001 - val_auc: 0.7683 - val_binary_accuracy: 0.6823 - val_f1: 0.6538 - val_loss: 0.6201 - val_prc_auc: 0.6290 - val_precision: 0.5441 - val_recall: 0.8188\n","Epoch 19/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8470 - binary_accuracy: 0.7851 - f1: 0.8050 - loss: 0.5424 - prc_auc: 0.8095 - precision: 0.7279 - recall: 0.9007\n","Epoch 19: Validation Metrics:\n","loss: 0.545569896697998\n","val_binary_accuracy: 0.6796460151672363\n","val_precision: 0.5418006181716919\n","val_recall: 0.8140096664428711\n","val_auc: 0.7690992951393127\n","val_prc_auc: 0.630178689956665\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8468 - binary_accuracy: 0.7849 - f1: 0.8049 - loss: 0.5424 - prc_auc: 0.8093 - precision: 0.7279 - recall: 0.9004 - val_auc: 0.7691 - val_binary_accuracy: 0.6796 - val_f1: 0.6506 - val_loss: 0.6184 - val_prc_auc: 0.6302 - val_precision: 0.5418 - val_recall: 0.8140\n","Epoch 20/20\n","\u001b[1m103/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8479 - binary_accuracy: 0.7861 - f1: 0.8057 - loss: 0.5380 - prc_auc: 0.8113 - precision: 0.7290 - recall: 0.9007\n","Epoch 20: Validation Metrics:\n","loss: 0.5414609313011169\n","val_binary_accuracy: 0.6814159154891968\n","val_precision: 0.5435484051704407\n","val_recall: 0.8140096664428711\n","val_auc: 0.769878625869751\n","val_prc_auc: 0.6302231550216675\n","\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - auc: 0.8477 - binary_accuracy: 0.7859 - f1: 0.8056 - loss: 0.5380 - prc_auc: 0.8112 - precision: 0.7290 - recall: 0.9004 - val_auc: 0.7699 - val_binary_accuracy: 0.6814 - val_f1: 0.6518 - val_loss: 0.6169 - val_prc_auc: 0.6302 - val_precision: 0.5435 - val_recall: 0.8140\n","Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927ms/step - auc: 0.3050 - binary_accuracy: 0.3735 - f1: 0.4647 - loss: 0.7066 - prc_auc: 0.3914 - precision: 0.4078 - recall: 0.5409\n","Epoch 1: Validation Metrics:\n","loss: 0.7069916725158691\n","val_binary_accuracy: 0.3371681272983551\n","val_precision: 0.24225029349327087\n","val_recall: 0.70333331823349\n","val_auc: 0.393263041973114\n","val_prc_auc: 0.2153453826904297\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - auc: 0.3048 - binary_accuracy: 0.3736 - f1: 0.4648 - loss: 0.7066 - prc_auc: 0.3912 - precision: 0.4078 - recall: 0.5412 - val_auc: 0.3933 - val_binary_accuracy: 0.3372 - val_f1: 0.3604 - val_loss: 0.7092 - val_prc_auc: 0.2153 - val_precision: 0.2423 - val_recall: 0.7033\n","Epoch 2/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.3260 - binary_accuracy: 0.3903 - f1: 0.4815 - loss: 0.7040 - prc_auc: 0.4002 - precision: 0.4211 - recall: 0.5628\n","Epoch 2: Validation Metrics:\n","loss: 0.7036089897155762\n","val_binary_accuracy: 0.3610619604587555\n","val_precision: 0.25407925248146057\n","val_recall: 0.7266666889190674\n","val_auc: 0.4475060701370239\n","val_prc_auc: 0.24009904265403748\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.3259 - binary_accuracy: 0.3904 - f1: 0.4818 - loss: 0.7040 - prc_auc: 0.4000 - precision: 0.4212 - recall: 0.5633 - val_auc: 0.4475 - val_binary_accuracy: 0.3611 - val_f1: 0.3765 - val_loss: 0.7042 - val_prc_auc: 0.2401 - val_precision: 0.2541 - val_recall: 0.7267\n","Epoch 3/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4035 - binary_accuracy: 0.4315 - f1: 0.5152 - loss: 0.6982 - prc_auc: 0.4386 - precision: 0.4515 - recall: 0.6005\n","Epoch 3: Validation Metrics:\n","loss: 0.6969813704490662\n","val_binary_accuracy: 0.4486725628376007\n","val_precision: 0.2888889014720917\n","val_recall: 0.7366666793823242\n","val_auc: 0.580638587474823\n","val_prc_auc: 0.31685671210289\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.4042 - binary_accuracy: 0.4318 - f1: 0.5156 - loss: 0.6982 - prc_auc: 0.4389 - precision: 0.4517 - recall: 0.6010 - val_auc: 0.5806 - val_binary_accuracy: 0.4487 - val_f1: 0.4150 - val_loss: 0.6961 - val_prc_auc: 0.3169 - val_precision: 0.2889 - val_recall: 0.7367\n","Epoch 4/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5931 - binary_accuracy: 0.5521 - f1: 0.6028 - loss: 0.6895 - prc_auc: 0.5893 - precision: 0.5448 - recall: 0.6748\n","Epoch 4: Validation Metrics:\n","loss: 0.6875065565109253\n","val_binary_accuracy: 0.6292035579681396\n","val_precision: 0.3875236213207245\n","val_recall: 0.6833333373069763\n","val_auc: 0.6921426057815552\n","val_prc_auc: 0.4555202126502991\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.5941 - binary_accuracy: 0.5529 - f1: 0.6034 - loss: 0.6894 - prc_auc: 0.5900 - precision: 0.5455 - recall: 0.6754 - val_auc: 0.6921 - val_binary_accuracy: 0.6292 - val_f1: 0.4946 - val_loss: 0.6857 - val_prc_auc: 0.4555 - val_precision: 0.3875 - val_recall: 0.6833\n","Epoch 5/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7482 - binary_accuracy: 0.6831 - f1: 0.6944 - loss: 0.6788 - prc_auc: 0.7446 - precision: 0.6759 - recall: 0.7147\n","Epoch 5: Validation Metrics:\n","loss: 0.6766427159309387\n","val_binary_accuracy: 0.6902654767036438\n","val_precision: 0.440191388130188\n","val_recall: 0.6133333444595337\n","val_auc: 0.7229839563369751\n","val_prc_auc: 0.49280834197998047\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.7484 - binary_accuracy: 0.6834 - f1: 0.6946 - loss: 0.6788 - prc_auc: 0.7445 - precision: 0.6763 - recall: 0.7145 - val_auc: 0.7230 - val_binary_accuracy: 0.6903 - val_f1: 0.5125 - val_loss: 0.6753 - val_prc_auc: 0.4928 - val_precision: 0.4402 - val_recall: 0.6133\n","Epoch 6/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7869 - binary_accuracy: 0.7189 - f1: 0.7185 - loss: 0.6685 - prc_auc: 0.7876 - precision: 0.7245 - recall: 0.7132\n","Epoch 6: Validation Metrics:\n","loss: 0.6663872599601746\n","val_binary_accuracy: 0.7088495492935181\n","val_precision: 0.46133333444595337\n","val_recall: 0.5766666531562805\n","val_auc: 0.7311184406280518\n","val_prc_auc: 0.4998084008693695\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.7869 - binary_accuracy: 0.7190 - f1: 0.7184 - loss: 0.6685 - prc_auc: 0.7872 - precision: 0.7246 - recall: 0.7128 - val_auc: 0.7311 - val_binary_accuracy: 0.7088 - val_f1: 0.5126 - val_loss: 0.6658 - val_prc_auc: 0.4998 - val_precision: 0.4613 - val_recall: 0.5767\n","Epoch 7/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7951 - binary_accuracy: 0.7261 - f1: 0.7184 - loss: 0.6590 - prc_auc: 0.7977 - precision: 0.7443 - recall: 0.6946\n","Epoch 7: Validation Metrics:\n","loss: 0.6568752527236938\n","val_binary_accuracy: 0.7168141603469849\n","val_precision: 0.4722222089767456\n","val_recall: 0.5666666626930237\n","val_auc: 0.7342570424079895\n","val_prc_auc: 0.5009839534759521\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.7951 - binary_accuracy: 0.7261 - f1: 0.7183 - loss: 0.6589 - prc_auc: 0.7973 - precision: 0.7443 - recall: 0.6943 - val_auc: 0.7343 - val_binary_accuracy: 0.7168 - val_f1: 0.5152 - val_loss: 0.6569 - val_prc_auc: 0.5010 - val_precision: 0.4722 - val_recall: 0.5667\n","Epoch 8/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7994 - binary_accuracy: 0.7259 - f1: 0.7141 - loss: 0.6501 - prc_auc: 0.8013 - precision: 0.7515 - recall: 0.6804\n","Epoch 8: Validation Metrics:\n","loss: 0.6480470895767212\n","val_binary_accuracy: 0.7203539609909058\n","val_precision: 0.47752809524536133\n","val_recall: 0.5666666626930237\n","val_auc: 0.7345181107521057\n","val_prc_auc: 0.499582976102829\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.7994 - binary_accuracy: 0.7258 - f1: 0.7140 - loss: 0.6501 - prc_auc: 0.8009 - precision: 0.7514 - recall: 0.6802 - val_auc: 0.7345 - val_binary_accuracy: 0.7204 - val_f1: 0.5183 - val_loss: 0.6488 - val_prc_auc: 0.4996 - val_precision: 0.4775 - val_recall: 0.5667\n","Epoch 9/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7994 - binary_accuracy: 0.7272 - f1: 0.7148 - loss: 0.6419 - prc_auc: 0.8034 - precision: 0.7543 - recall: 0.6793\n","Epoch 9: Validation Metrics:\n","loss: 0.6398512125015259\n","val_binary_accuracy: 0.722123920917511\n","val_precision: 0.4801136255264282\n","val_recall: 0.5633333325386047\n","val_auc: 0.7349839210510254\n","val_prc_auc: 0.5012908577919006\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.7994 - binary_accuracy: 0.7272 - f1: 0.7147 - loss: 0.6419 - prc_auc: 0.8029 - precision: 0.7542 - recall: 0.6792 - val_auc: 0.7350 - val_binary_accuracy: 0.7221 - val_f1: 0.5184 - val_loss: 0.6414 - val_prc_auc: 0.5013 - val_precision: 0.4801 - val_recall: 0.5633\n","Epoch 10/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8011 - binary_accuracy: 0.7265 - f1: 0.7124 - loss: 0.6343 - prc_auc: 0.8060 - precision: 0.7565 - recall: 0.6733\n","Epoch 10: Validation Metrics:\n","loss: 0.6322416067123413\n","val_binary_accuracy: 0.721238911151886\n","val_precision: 0.47863247990608215\n","val_recall: 0.5600000023841858\n","val_auc: 0.7347710728645325\n","val_prc_auc: 0.49917247891426086\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.8011 - binary_accuracy: 0.7265 - f1: 0.7124 - loss: 0.6342 - prc_auc: 0.8055 - precision: 0.7565 - recall: 0.6732 - val_auc: 0.7348 - val_binary_accuracy: 0.7212 - val_f1: 0.5161 - val_loss: 0.6345 - val_prc_auc: 0.4992 - val_precision: 0.4786 - val_recall: 0.5600\n","Epoch 11/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.8016 - binary_accuracy: 0.7274 - f1: 0.7130 - loss: 0.6272 - prc_auc: 0.8066 - precision: 0.7582 - recall: 0.6730\n","Epoch 11: Validation Metrics:\n","loss: 0.6251760125160217\n","val_binary_accuracy: 0.721238911151886\n","val_precision: 0.4785100221633911\n","val_recall: 0.5566666722297668\n","val_auc: 0.7363253235816956\n","val_prc_auc: 0.5008561611175537\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - auc: 0.8016 - binary_accuracy: 0.7274 - f1: 0.7129 - loss: 0.6271 - prc_auc: 0.8062 - precision: 0.7582 - recall: 0.6729 - val_auc: 0.7363 - val_binary_accuracy: 0.7212 - val_f1: 0.5146 - val_loss: 0.6281 - val_prc_auc: 0.5009 - val_precision: 0.4785 - val_recall: 0.5567\n","Epoch 12/20\n","\u001b[1m75/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.8022 - binary_accuracy: 0.7306 - f1: 0.7156 - loss: 0.6206 - prc_auc: 0.8081 - precision: 0.7633 - recall: 0.6737\n","Epoch 12: Validation Metrics:\n","loss: 0.6186152100563049\n","val_binary_accuracy: 0.722123920917511\n","val_precision: 0.47999998927116394\n","val_recall: 0.5600000023841858\n","val_auc: 0.7353694438934326\n","val_prc_auc: 0.501164436340332\n","\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - auc: 0.8022 - binary_accuracy: 0.7305 - f1: 0.7155 - loss: 0.6206 - prc_auc: 0.8077 - precision: 0.7632 - recall: 0.6735 - val_auc: 0.7354 - val_binary_accuracy: 0.7221 - val_f1: 0.5169 - val_loss: 0.6223 - val_prc_auc: 0.5012 - val_precision: 0.4800 - val_recall: 0.5600\n","Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFMPNetModel.\n","\n","All the layers of TFMPNetModel were initialized from the model checkpoint at /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/02_Transformer_Models/transformer_model_20250213_130009.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - auc: 0.4533 - binary_accuracy: 0.4825 - f1: 0.4988 - loss: 0.7012 - prc_auc: 0.4710 - precision: 0.4849 - recall: 0.5161\n","Epoch 1: Validation Metrics:\n","loss: 0.7008937001228333\n","val_binary_accuracy: 0.4716814160346985\n","val_precision: 0.20941558480262756\n","val_recall: 0.5397489666938782\n","val_auc: 0.5069735050201416\n","val_prc_auc: 0.21978329122066498\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 372ms/step - auc: 0.4533 - binary_accuracy: 0.4823 - f1: 0.4986 - loss: 0.7012 - prc_auc: 0.4712 - precision: 0.4847 - recall: 0.5159 - val_auc: 0.5070 - val_binary_accuracy: 0.4717 - val_f1: 0.3018 - val_loss: 0.6990 - val_prc_auc: 0.2198 - val_precision: 0.2094 - val_recall: 0.5397\n","Epoch 2/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.4644 - binary_accuracy: 0.4871 - f1: 0.4998 - loss: 0.6997 - prc_auc: 0.4801 - precision: 0.4889 - recall: 0.5136\n","Epoch 2: Validation Metrics:\n","loss: 0.6989997029304504\n","val_binary_accuracy: 0.4831858277320862\n","val_precision: 0.21297836303710938\n","val_recall: 0.5355648398399353\n","val_auc: 0.522667407989502\n","val_prc_auc: 0.2333867847919464\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.4645 - binary_accuracy: 0.4870 - f1: 0.4997 - loss: 0.6997 - prc_auc: 0.4804 - precision: 0.4888 - recall: 0.5134 - val_auc: 0.5227 - val_binary_accuracy: 0.4832 - val_f1: 0.3048 - val_loss: 0.6949 - val_prc_auc: 0.2334 - val_precision: 0.2130 - val_recall: 0.5356\n","Epoch 3/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.4936 - binary_accuracy: 0.4948 - f1: 0.5061 - loss: 0.6963 - prc_auc: 0.5108 - precision: 0.4963 - recall: 0.5184\n","Epoch 3: Validation Metrics:\n","loss: 0.6952217817306519\n","val_binary_accuracy: 0.5106194615364075\n","val_precision: 0.21762590110301971\n","val_recall: 0.5062761306762695\n","val_auc: 0.547203779220581\n","val_prc_auc: 0.26446571946144104\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - auc: 0.4937 - binary_accuracy: 0.4947 - f1: 0.5060 - loss: 0.6963 - prc_auc: 0.5113 - precision: 0.4961 - recall: 0.5182 - val_auc: 0.5472 - val_binary_accuracy: 0.5106 - val_f1: 0.3044 - val_loss: 0.6883 - val_prc_auc: 0.2645 - val_precision: 0.2176 - val_recall: 0.5063\n","Epoch 4/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.5340 - binary_accuracy: 0.5224 - f1: 0.5185 - loss: 0.6912 - prc_auc: 0.5676 - precision: 0.5236 - recall: 0.5149\n","Epoch 4: Validation Metrics:\n","loss: 0.6897481083869934\n","val_binary_accuracy: 0.5716814398765564\n","val_precision: 0.23880596458911896\n","val_recall: 0.4686192572116852\n","val_auc: 0.5741539001464844\n","val_prc_auc: 0.3288809061050415\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - auc: 0.5342 - binary_accuracy: 0.5223 - f1: 0.5183 - loss: 0.6912 - prc_auc: 0.5681 - precision: 0.5235 - recall: 0.5147 - val_auc: 0.5742 - val_binary_accuracy: 0.5717 - val_f1: 0.3164 - val_loss: 0.6794 - val_prc_auc: 0.3289 - val_precision: 0.2388 - val_recall: 0.4686\n","Epoch 5/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.5843 - binary_accuracy: 0.5545 - f1: 0.5168 - loss: 0.6845 - prc_auc: 0.6381 - precision: 0.5646 - recall: 0.4773\n","Epoch 5: Validation Metrics:\n","loss: 0.6828556656837463\n","val_binary_accuracy: 0.7123894095420837\n","val_precision: 0.34859153628349304\n","val_recall: 0.4142259359359741\n","val_auc: 0.6027687788009644\n","val_prc_auc: 0.3808801770210266\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.5845 - binary_accuracy: 0.5547 - f1: 0.5169 - loss: 0.6845 - prc_auc: 0.6385 - precision: 0.5649 - recall: 0.4773 - val_auc: 0.6028 - val_binary_accuracy: 0.7124 - val_f1: 0.3786 - val_loss: 0.6687 - val_prc_auc: 0.3809 - val_precision: 0.3486 - val_recall: 0.4142\n","Epoch 6/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.6340 - binary_accuracy: 0.6339 - f1: 0.5524 - loss: 0.6770 - prc_auc: 0.6936 - precision: 0.7104 - recall: 0.4525\n","Epoch 6: Validation Metrics:\n","loss: 0.675370454788208\n","val_binary_accuracy: 0.7831858396530151\n","val_precision: 0.48148149251937866\n","val_recall: 0.3263598382472992\n","val_auc: 0.6334239840507507\n","val_prc_auc: 0.4175662100315094\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - auc: 0.6342 - binary_accuracy: 0.6341 - f1: 0.5524 - loss: 0.6769 - prc_auc: 0.6938 - precision: 0.7110 - recall: 0.4523 - val_auc: 0.6334 - val_binary_accuracy: 0.7832 - val_f1: 0.3890 - val_loss: 0.6582 - val_prc_auc: 0.4176 - val_precision: 0.4815 - val_recall: 0.3264\n","Epoch 7/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.6819 - binary_accuracy: 0.6539 - f1: 0.5363 - loss: 0.6698 - prc_auc: 0.7361 - precision: 0.8121 - recall: 0.4005\n","Epoch 7: Validation Metrics:\n","loss: 0.6683750748634338\n","val_binary_accuracy: 0.7911504507064819\n","val_precision: 0.5118110179901123\n","val_recall: 0.27196651697158813\n","val_auc: 0.6547765135765076\n","val_prc_auc: 0.43200281262397766\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.6820 - binary_accuracy: 0.6540 - f1: 0.5364 - loss: 0.6697 - prc_auc: 0.7362 - precision: 0.8125 - recall: 0.4005 - val_auc: 0.6548 - val_binary_accuracy: 0.7912 - val_f1: 0.3552 - val_loss: 0.6484 - val_prc_auc: 0.4320 - val_precision: 0.5118 - val_recall: 0.2720\n","Epoch 8/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - auc: 0.7226 - binary_accuracy: 0.6574 - f1: 0.5262 - loss: 0.6631 - prc_auc: 0.7676 - precision: 0.8513 - recall: 0.3809\n","Epoch 8: Validation Metrics:\n","loss: 0.6619291305541992\n","val_binary_accuracy: 0.7938053011894226\n","val_precision: 0.5245901346206665\n","val_recall: 0.26778241991996765\n","val_auc: 0.6707967519760132\n","val_prc_auc: 0.4456080198287964\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - auc: 0.7227 - binary_accuracy: 0.6576 - f1: 0.5265 - loss: 0.6631 - prc_auc: 0.7676 - precision: 0.8516 - recall: 0.3811 - val_auc: 0.6708 - val_binary_accuracy: 0.7938 - val_f1: 0.3546 - val_loss: 0.6393 - val_prc_auc: 0.4456 - val_precision: 0.5246 - val_recall: 0.2678\n","Epoch 9/20\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - auc: 0.7502 - binary_accuracy: 0.6564 - f1: 0.5174 - loss: 0.6570 - prc_auc: 0.7882 - precision: 0.8668 - recall: 0.3690\n","Epoch 9: Validation Metrics:\n","loss: 0.6559860110282898\n","val_binary_accuracy: 0.7938053011894226\n","val_precision: 0.523809552192688\n","val_recall: 0.2761506140232086\n","val_auc: 0.6775026321411133\n","val_prc_auc: 0.4472590386867523\n","\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - auc: 0.7502 - binary_accuracy: 0.6565 - f1: 0.5177 - loss: 0.6570 - prc_auc: 0.7882 - precision: 0.8669 - recall: 0.3693 - val_auc: 0.6775 - val_binary_accuracy: 0.7938 - val_f1: 0.3616 - val_loss: 0.6308 - val_prc_auc: 0.4473 - val_precision: 0.5238 - val_recall: 0.2762\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 623ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 426ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 422ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 421ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 419ms/step\n","[[0 0 1 1 0]\n"," [0 1 0 1 0]\n"," [1 0 1 0 0]\n"," ...\n"," [1 0 1 0 0]\n"," [0 1 0 0 0]\n"," [1 1 0 0 0]]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0607fc3d5ee2416ea523bd5cce0e8c80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ff464abd8f4c98bcacb672569a8dc6","placeholder":"​","style":"IPY_MODEL_824bdcb736db49b0b01e101f3d4bbe32","value":"tokenizer.json: 100%"}},"0e0b5259abee4a00b2aed377427faebc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"115fb8c0adf84e5687cdfecaddc7fc88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a2a9545b11644b6a7c683c3baa92760","placeholder":"​","style":"IPY_MODEL_54739fd4f13d4b128a24de6e70c503f3","value":" 466k/466k [00:00&lt;00:00, 10.7MB/s]"}},"143f3f72648947628be426536c54165a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"156e7b3dc5c74377abf997088f5d5039":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0b5259abee4a00b2aed377427faebc","placeholder":"​","style":"IPY_MODEL_b1298a3565b24588878eab99a2f778d2","value":" 532M/532M [00:11&lt;00:00, 34.3MB/s]"}},"15ff464abd8f4c98bcacb672569a8dc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1872502f5bbf42d1827f773b9bcd37f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18c24b0b760a4b5e8dfcbace68fd7469":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1969c0b6db9c4f47b22607038a7b1a79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224fb6448d974adc8c89a7e5d92893f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"229551aa84fd4c7787adcc867eabba53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25c1221c444c4c6e81dc25e8ab06143f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c6bd7e97ea2414aac33c456b046e873":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a75a543c4a414a9e98646af48b6bbe80","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c77a74539b4a4ca7a56aae18c674362e","value":239}},"31789b2281b447e9a533802256b73e32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"359a25604e64401bba227185ae1c76c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36965743912a4bbc83a05b3c55b9e544":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37822c1dea7c4066891fe9dc2bfad9de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0607fc3d5ee2416ea523bd5cce0e8c80","IPY_MODEL_4b42397cb6fa4f13a52fcdfc4e7d7095","IPY_MODEL_115fb8c0adf84e5687cdfecaddc7fc88"],"layout":"IPY_MODEL_b469b0c304d84cbe9467cc76204428c5"}},"3a0217664365498e81c1375d11696089":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42f47dbea5d44dff9749627569b344e3","placeholder":"​","style":"IPY_MODEL_afd7b77b1b5e41b9aa344ef3d4af6eee","value":" 438M/438M [00:01&lt;00:00, 238MB/s]"}},"40fb4eea828a47eebde3deffb34eccaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d465a2294ac346fcaeb1e40f905431ed","placeholder":"​","style":"IPY_MODEL_e8217faab1a64813989a48f3bc71980e","value":"model.safetensors: 100%"}},"42f3658a4ec241fc93c783ee84caa9cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f47dbea5d44dff9749627569b344e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4549d9c099ab48e88afcbb1d8f4c789d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4905559eaa5b40779fa2d579308ddeb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baa06b0ec2d34d02b113f8503fddc216","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d441459d1c884b52b9772285b2fd17f0","value":363}},"4b42397cb6fa4f13a52fcdfc4e7d7095":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbca1f857e064aeeabac2f8eac9c9ba7","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae0bdf64c6fe474ba4b361a10d3406ab","value":466021}},"4bdb5352724c40eb9d493cb1efd743d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae478ac2bfec4d3694f2550a6e7d28e8","placeholder":"​","style":"IPY_MODEL_1969c0b6db9c4f47b22607038a7b1a79","value":" 232k/232k [00:00&lt;00:00, 4.81MB/s]"}},"4dc6ae2f526f4653a54c0c07381768db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6812d035d701491cb605814f86bcbb3e","placeholder":"​","style":"IPY_MODEL_4549d9c099ab48e88afcbb1d8f4c789d","value":"vocab.txt: 100%"}},"54739fd4f13d4b128a24de6e70c503f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a2a9545b11644b6a7c683c3baa92760":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c535e651f1c4adcbaa60791742af937":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e547717c224c02981da5a4ff0462a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_810f6376fd9e4b4589f1d76bdbbba698","IPY_MODEL_65b9b5ea95334da8a0519f61e9dd4c8b","IPY_MODEL_3a0217664365498e81c1375d11696089"],"layout":"IPY_MODEL_a763decf210b4bb19269b66251f8ff6f"}},"65b9b5ea95334da8a0519f61e9dd4c8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b654486cb19443ec88cba4f74f18da7b","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ece2b16bff0d42e1a080df7ff743a59d","value":437971872}},"67b0ded56d4342698ab40156896dbef3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6812d035d701491cb605814f86bcbb3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c28c29db2b54a68809be4927f2e6561":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31789b2281b447e9a533802256b73e32","max":531998632,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffa3a842b49943ba8fffe30c63b7e803","value":531998632}},"6dd438058253463ab15a65ad8f33192f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b0ded56d4342698ab40156896dbef3","placeholder":"​","style":"IPY_MODEL_da87376fe355463386e1bcae2d6146d4","value":" 239/239 [00:00&lt;00:00, 21.9kB/s]"}},"76c7ede6ff5e462a8312821bad1a8202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dc6ae2f526f4653a54c0c07381768db","IPY_MODEL_c42874edb92e43cca983af83dc96420b","IPY_MODEL_4bdb5352724c40eb9d493cb1efd743d1"],"layout":"IPY_MODEL_d4da583e676f4d08a7e4356e6c19f394"}},"7ee763e22b064a0fbcf9b42ccf97b9ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40fb4eea828a47eebde3deffb34eccaf","IPY_MODEL_6c28c29db2b54a68809be4927f2e6561","IPY_MODEL_156e7b3dc5c74377abf997088f5d5039"],"layout":"IPY_MODEL_143f3f72648947628be426536c54165a"}},"810f6376fd9e4b4589f1d76bdbbba698":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36965743912a4bbc83a05b3c55b9e544","placeholder":"​","style":"IPY_MODEL_fcb2b70818dd4586bc146ccf99f08869","value":"model.safetensors: 100%"}},"824bdcb736db49b0b01e101f3d4bbe32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ef25127aea24b65aed075efbf782bd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa274429fd264ada9935779eaa1ca354","placeholder":"​","style":"IPY_MODEL_faaa9d56430f4cd1854b1775bc3172ba","value":"tokenizer_config.json: 100%"}},"9c4cd35bd3c64007a9744c871f60f686":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a75a543c4a414a9e98646af48b6bbe80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a763decf210b4bb19269b66251f8ff6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76d43f7e247423d8bd0267409172ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ef25127aea24b65aed075efbf782bd9","IPY_MODEL_4905559eaa5b40779fa2d579308ddeb3","IPY_MODEL_ec09a2d650af46328f1be4ad121ed09f"],"layout":"IPY_MODEL_42f3658a4ec241fc93c783ee84caa9cf"}},"aa274429fd264ada9935779eaa1ca354":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0bdf64c6fe474ba4b361a10d3406ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae139a3cd6614bdb8b13997dfa0926c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25c1221c444c4c6e81dc25e8ab06143f","placeholder":"​","style":"IPY_MODEL_359a25604e64401bba227185ae1c76c6","value":"config.json: 100%"}},"ae478ac2bfec4d3694f2550a6e7d28e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd7b77b1b5e41b9aa344ef3d4af6eee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1298a3565b24588878eab99a2f778d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ae715e675d45c2957a160069ac7d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2026bb57acb43ccabb5254e5a74b4d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c24b0b760a4b5e8dfcbace68fd7469","placeholder":"​","style":"IPY_MODEL_f9642ec2fd524b17a5a1ce5f4f5c1ee1","value":" 571/571 [00:00&lt;00:00, 52.1kB/s]"}},"b469b0c304d84cbe9467cc76204428c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b654486cb19443ec88cba4f74f18da7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa06b0ec2d34d02b113f8503fddc216":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb1e5270d0b4d76ad75e7f33f15895a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c42874edb92e43cca983af83dc96420b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_224fb6448d974adc8c89a7e5d92893f2","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca45baf4c67c4a679a7300e9fb6e18d3","value":231536}},"c77a74539b4a4ca7a56aae18c674362e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca45baf4c67c4a679a7300e9fb6e18d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd6805a6b4bc490bb3dabb61504ab8e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fed591da0d304c0f8b320ff464c5666c","IPY_MODEL_2c6bd7e97ea2414aac33c456b046e873","IPY_MODEL_6dd438058253463ab15a65ad8f33192f"],"layout":"IPY_MODEL_1872502f5bbf42d1827f773b9bcd37f6"}},"d441459d1c884b52b9772285b2fd17f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d465a2294ac346fcaeb1e40f905431ed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4da583e676f4d08a7e4356e6c19f394":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da87376fe355463386e1bcae2d6146d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbca1f857e064aeeabac2f8eac9c9ba7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2efb55c88a44d24941853097ec4a60d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3067982ccdd4f4b9e25d084782b196b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2efb55c88a44d24941853097ec4a60d","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcb1e5270d0b4d76ad75e7f33f15895a","value":571}},"e8217faab1a64813989a48f3bc71980e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec09a2d650af46328f1be4ad121ed09f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c4cd35bd3c64007a9744c871f60f686","placeholder":"​","style":"IPY_MODEL_b1ae715e675d45c2957a160069ac7d08","value":" 363/363 [00:00&lt;00:00, 31.3kB/s]"}},"ece2b16bff0d42e1a080df7ff743a59d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eee4ebb41d904ad7a3084540c6b2f33a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f394cc47b76c424ea50f39894d33a95e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae139a3cd6614bdb8b13997dfa0926c7","IPY_MODEL_e3067982ccdd4f4b9e25d084782b196b","IPY_MODEL_b2026bb57acb43ccabb5254e5a74b4d6"],"layout":"IPY_MODEL_5c535e651f1c4adcbaa60791742af937"}},"f9642ec2fd524b17a5a1ce5f4f5c1ee1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faaa9d56430f4cd1854b1775bc3172ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcb2b70818dd4586bc146ccf99f08869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fed591da0d304c0f8b320ff464c5666c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eee4ebb41d904ad7a3084540c6b2f33a","placeholder":"​","style":"IPY_MODEL_229551aa84fd4c7787adcc867eabba53","value":"special_tokens_map.json: 100%"}},"ffa3a842b49943ba8fffe30c63b7e803":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b361cf0ce9374064aa7938cc9b15e4e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b67268cfe5294e178e7be8458255eb62","IPY_MODEL_7e6858d2eadf40d7aa6d6c842f2afd8c","IPY_MODEL_256d9fcf09da45788be85c3c25348db8"],"layout":"IPY_MODEL_4ddcca862b9c48ae82197f7cdfb7099c"}},"b67268cfe5294e178e7be8458255eb62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f42fcf20762492491d69e415321a306","placeholder":"​","style":"IPY_MODEL_cdabfde45a224cb9adb3b993173f0a3f","value":"tokenizer_config.json: 100%"}},"7e6858d2eadf40d7aa6d6c842f2afd8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e90e780dda3463ab27f64320bb226ff","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f79b7d8cb52d4ff1be035420abdb7196","value":363}},"256d9fcf09da45788be85c3c25348db8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d85bf9d77cc4419aa0606b14db8a32ea","placeholder":"​","style":"IPY_MODEL_4bbd2452df8d41759de0c6bfeccbfe93","value":" 363/363 [00:00&lt;00:00, 31.8kB/s]"}},"4ddcca862b9c48ae82197f7cdfb7099c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f42fcf20762492491d69e415321a306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdabfde45a224cb9adb3b993173f0a3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e90e780dda3463ab27f64320bb226ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79b7d8cb52d4ff1be035420abdb7196":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d85bf9d77cc4419aa0606b14db8a32ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bbd2452df8d41759de0c6bfeccbfe93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e563e9ec02840feb90612f39de4b7d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4c63e2d86be4549b464172ecc2e004e","IPY_MODEL_991583a89eee442180772986547417cb","IPY_MODEL_df11c069a37e41c7b98355044dd8109f"],"layout":"IPY_MODEL_691b471245dc43308eac46dbd52ca334"}},"f4c63e2d86be4549b464172ecc2e004e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6d81c66eea2492eb7177b94adf09672","placeholder":"​","style":"IPY_MODEL_aba4939b96bd4c718f6b71b123c6f03e","value":"vocab.txt: 100%"}},"991583a89eee442180772986547417cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_157ea918b15a4a30bf6249c6b1970533","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19c5a7db7dfe45b984bfae1b3c1ee27c","value":231536}},"df11c069a37e41c7b98355044dd8109f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7618d494162146ddb99ff2dae9a4d687","placeholder":"​","style":"IPY_MODEL_478b91e0bbb8497b9b8b0b2cc4d6f995","value":" 232k/232k [00:00&lt;00:00, 3.81MB/s]"}},"691b471245dc43308eac46dbd52ca334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6d81c66eea2492eb7177b94adf09672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba4939b96bd4c718f6b71b123c6f03e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"157ea918b15a4a30bf6249c6b1970533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c5a7db7dfe45b984bfae1b3c1ee27c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7618d494162146ddb99ff2dae9a4d687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"478b91e0bbb8497b9b8b0b2cc4d6f995":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83aa0bcfb54b4bc38ce253300cbea3d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70aa03d216854021805e201ceb94d60c","IPY_MODEL_26cbe4f973944b8c98b9f338e0d71367","IPY_MODEL_e0472d0757b64c389181e3334d010d21"],"layout":"IPY_MODEL_0ee7d537d2ca4d309f80c421191a58b4"}},"70aa03d216854021805e201ceb94d60c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5a3a383ba534407aa55b5941c02dcfd","placeholder":"​","style":"IPY_MODEL_2a696e45e9014ed487a374615d84dde2","value":"tokenizer.json: 100%"}},"26cbe4f973944b8c98b9f338e0d71367":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_433a0c4eaaab4a59884aa823e8d2ac8a","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1945cea97c34c348f301eba555ff20b","value":466021}},"e0472d0757b64c389181e3334d010d21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf02c37119b44e98e816bf94785ef15","placeholder":"​","style":"IPY_MODEL_7200f30d527b47cab255bc71c2c81d3a","value":" 466k/466k [00:00&lt;00:00, 9.78MB/s]"}},"0ee7d537d2ca4d309f80c421191a58b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a3a383ba534407aa55b5941c02dcfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a696e45e9014ed487a374615d84dde2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"433a0c4eaaab4a59884aa823e8d2ac8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1945cea97c34c348f301eba555ff20b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baf02c37119b44e98e816bf94785ef15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7200f30d527b47cab255bc71c2c81d3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a6b9b9721d8470a9661512cfd9ae8f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74704115a3c1452cbb85ac80a3d302aa","IPY_MODEL_cac0e8396c814053a5041253392a8920","IPY_MODEL_4649bd4895344e9eb5f2b65872abcbb2"],"layout":"IPY_MODEL_a0500a7dd92c44a6b5b56351c3f179ef"}},"74704115a3c1452cbb85ac80a3d302aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f35ca5c74142f9a180694289dbbf26","placeholder":"​","style":"IPY_MODEL_794213dc30e94259846ffa89cc8d23dc","value":"special_tokens_map.json: 100%"}},"cac0e8396c814053a5041253392a8920":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2d735dcd7d5494ba19f102383261fda","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a7dcc8f57034486ba0bcfef999943ff","value":239}},"4649bd4895344e9eb5f2b65872abcbb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a1a47bfd54f4cea8c0b3fa9871c0d47","placeholder":"​","style":"IPY_MODEL_3c518b50a2294c269d0f2f305e3128b8","value":" 239/239 [00:00&lt;00:00, 24.3kB/s]"}},"a0500a7dd92c44a6b5b56351c3f179ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f35ca5c74142f9a180694289dbbf26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"794213dc30e94259846ffa89cc8d23dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2d735dcd7d5494ba19f102383261fda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a7dcc8f57034486ba0bcfef999943ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a1a47bfd54f4cea8c0b3fa9871c0d47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c518b50a2294c269d0f2f305e3128b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff00d044eee7455ea055d41eecd46ab6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4623dc4774e45e99eb5d906536f882b","IPY_MODEL_243b4f0208734ba6be91003e326fc874","IPY_MODEL_4dcae359e96247749b629688fc6065cf"],"layout":"IPY_MODEL_6c0aa329098a4233b3d6822c2792c75a"}},"e4623dc4774e45e99eb5d906536f882b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e90fa6acfeb4b20832f109feb3a137b","placeholder":"​","style":"IPY_MODEL_b98fa389be82430189b91a2d50a3bc6b","value":"tokenizer_config.json: 100%"}},"243b4f0208734ba6be91003e326fc874":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_038bfdc607c44422996247e0a7c80c7f","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c2572a8315c477e930ab36657fbdc6c","value":363}},"4dcae359e96247749b629688fc6065cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d21ebc03335849e4a623c2f70f33c436","placeholder":"​","style":"IPY_MODEL_4d61888ae34040d2970cae8992193349","value":" 363/363 [00:00&lt;00:00, 30.9kB/s]"}},"6c0aa329098a4233b3d6822c2792c75a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e90fa6acfeb4b20832f109feb3a137b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b98fa389be82430189b91a2d50a3bc6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"038bfdc607c44422996247e0a7c80c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c2572a8315c477e930ab36657fbdc6c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d21ebc03335849e4a623c2f70f33c436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d61888ae34040d2970cae8992193349":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7310631e936e4d30905352dddeaaf3a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2f3918e10ad48dbb18b1414bb6a763d","IPY_MODEL_77ffd8c6b54b4b94a751e3c029a47929","IPY_MODEL_a138ab49a06b46a3b08d2a8de4e356f9"],"layout":"IPY_MODEL_8802fedd0dcc45de9fa4bf229ee13e57"}},"f2f3918e10ad48dbb18b1414bb6a763d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acee79ded0d048e7a4a7e61d8d5fcbb9","placeholder":"​","style":"IPY_MODEL_9f9ff5ef33e64dc294553b2a45401527","value":"vocab.txt: 100%"}},"77ffd8c6b54b4b94a751e3c029a47929":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55e058e23ca45e082bcd554ede43d07","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3130d2ce8b1140aea1118882ad271c52","value":231536}},"a138ab49a06b46a3b08d2a8de4e356f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8b72c52050b4ca79810c9db1428d6f4","placeholder":"​","style":"IPY_MODEL_9cb87ef2725b486c866e52817ad87a70","value":" 232k/232k [00:00&lt;00:00, 1.09MB/s]"}},"8802fedd0dcc45de9fa4bf229ee13e57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acee79ded0d048e7a4a7e61d8d5fcbb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f9ff5ef33e64dc294553b2a45401527":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55e058e23ca45e082bcd554ede43d07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3130d2ce8b1140aea1118882ad271c52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8b72c52050b4ca79810c9db1428d6f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb87ef2725b486c866e52817ad87a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17f1416261a6443ebc9ed153b23aed98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e067ebc1f9040aba9ee4f8c99bcf8bd","IPY_MODEL_5dea9b4c9d7c496e86572882bbe10964","IPY_MODEL_234238bbba354162ac750bbbce732618"],"layout":"IPY_MODEL_0a3f83ff78d147f098b02924c1e0c091"}},"4e067ebc1f9040aba9ee4f8c99bcf8bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1f8d84742be4a8697093f49cad6bae8","placeholder":"​","style":"IPY_MODEL_f81a6633681448e1ac84321a66bbb6b5","value":"tokenizer.json: 100%"}},"5dea9b4c9d7c496e86572882bbe10964":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7219e14cf440458db316c07e379851b9","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6f664f6320c4118976538aa49194248","value":466021}},"234238bbba354162ac750bbbce732618":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c84f86f60e954463861dd9d42d3cdf22","placeholder":"​","style":"IPY_MODEL_2af7ae8034a14f97a6803d663b06e52a","value":" 466k/466k [00:00&lt;00:00, 2.16MB/s]"}},"0a3f83ff78d147f098b02924c1e0c091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f8d84742be4a8697093f49cad6bae8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81a6633681448e1ac84321a66bbb6b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7219e14cf440458db316c07e379851b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f664f6320c4118976538aa49194248":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c84f86f60e954463861dd9d42d3cdf22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af7ae8034a14f97a6803d663b06e52a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47152a9d9de34707bbc4a68b68cf7166":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a11be7fdedec40aeb32091d9c2c713be","IPY_MODEL_6df8d4fd5c074ce09445cff6ad686673","IPY_MODEL_f31c72a72de04a069831b6c02625ca06"],"layout":"IPY_MODEL_d6126bb4b55f49afb2f94cbcb556cc0b"}},"a11be7fdedec40aeb32091d9c2c713be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_371dbed25d214ff0b3417747d1aa4e81","placeholder":"​","style":"IPY_MODEL_3886fa525b2644289609e3747d63a4c1","value":"special_tokens_map.json: 100%"}},"6df8d4fd5c074ce09445cff6ad686673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c25daf2859aa460a917a10ce3f34853c","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3907f247e98e442ab9e2a2a46e395eb0","value":239}},"f31c72a72de04a069831b6c02625ca06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36524922e0b64f84b71f2781e2c6f53e","placeholder":"​","style":"IPY_MODEL_a9a647e054d8445cad1f2a69ea095578","value":" 239/239 [00:00&lt;00:00, 24.1kB/s]"}},"d6126bb4b55f49afb2f94cbcb556cc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"371dbed25d214ff0b3417747d1aa4e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3886fa525b2644289609e3747d63a4c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c25daf2859aa460a917a10ce3f34853c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3907f247e98e442ab9e2a2a46e395eb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36524922e0b64f84b71f2781e2c6f53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a647e054d8445cad1f2a69ea095578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1b5444741424aa1bd4cf73d2e1bca2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09444536f2e045c1b8b390b46ff6d36e","IPY_MODEL_08c43396b31e4d728eecb18166a1f66e","IPY_MODEL_7f71604621644558a5fa465fbdff813f"],"layout":"IPY_MODEL_bdaf413f40584191ae09dc49ef208636"}},"09444536f2e045c1b8b390b46ff6d36e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f97f8a1179694d1fbd138eb2dcceb9d5","placeholder":"​","style":"IPY_MODEL_a8d7395ad5714703a6dd62b1f4d1bfad","value":"config.json: 100%"}},"08c43396b31e4d728eecb18166a1f66e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bc9ec3005e74495b44cb0840bf5d1b6","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e5995b871784c78ad5b439719f3c6a4","value":571}},"7f71604621644558a5fa465fbdff813f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed26481f215848ffa1e82c536081d689","placeholder":"​","style":"IPY_MODEL_8c62f13468194098a4572e0c6390aeef","value":" 571/571 [00:00&lt;00:00, 47.7kB/s]"}},"bdaf413f40584191ae09dc49ef208636":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f97f8a1179694d1fbd138eb2dcceb9d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d7395ad5714703a6dd62b1f4d1bfad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bc9ec3005e74495b44cb0840bf5d1b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e5995b871784c78ad5b439719f3c6a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed26481f215848ffa1e82c536081d689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c62f13468194098a4572e0c6390aeef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"562910b86fa74e20af9b21cf2f09e7f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5611117a53fe4ffaa67849d0379f508f","IPY_MODEL_65d11ecfca704cbab78369971eb08c80","IPY_MODEL_a2c1afbf99804724a5f91bced120db0e"],"layout":"IPY_MODEL_13776de58fd84ca095568a9ae79eaa26"}},"5611117a53fe4ffaa67849d0379f508f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a405c677ddc749cf898d2acd2c70b99a","placeholder":"​","style":"IPY_MODEL_e757bcb54f1a4aeda214a66c201e748d","value":"model.safetensors: 100%"}},"65d11ecfca704cbab78369971eb08c80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3fa9a374c34fab9237b3eafab125bc","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92176040c4a8454ba5e067d0d37d3d99","value":437971872}},"a2c1afbf99804724a5f91bced120db0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2059f92c2260492a86e28c8e3a0e09e2","placeholder":"​","style":"IPY_MODEL_9859bbf180be43708e8c1c71be103e29","value":" 438M/438M [00:02&lt;00:00, 146MB/s]"}},"13776de58fd84ca095568a9ae79eaa26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a405c677ddc749cf898d2acd2c70b99a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e757bcb54f1a4aeda214a66c201e748d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f3fa9a374c34fab9237b3eafab125bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92176040c4a8454ba5e067d0d37d3d99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2059f92c2260492a86e28c8e3a0e09e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9859bbf180be43708e8c1c71be103e29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2a54679043643f68269b2d8ad325c3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc9364505b6c443494b603c7e27f2d19","IPY_MODEL_abe186e84b6140488498f0940e250db9","IPY_MODEL_b0552d257afb4692a3f84de4c967370e"],"layout":"IPY_MODEL_133a16070bb7494287c0792cd67250ce"}},"bc9364505b6c443494b603c7e27f2d19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_484926a3e41543898f72e0c016a4a513","placeholder":"​","style":"IPY_MODEL_8444187c6dae4aaaafcfb9e53edb1d25","value":"tokenizer_config.json: 100%"}},"abe186e84b6140488498f0940e250db9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c5592426e394682b4e9aec25403fc38","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_deb44b2aa2294007b257810c5c997b80","value":363}},"b0552d257afb4692a3f84de4c967370e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eb658645d45477ebc4ee20df2c43b67","placeholder":"​","style":"IPY_MODEL_c9650c8176d843a2ad281acc4b180fc0","value":" 363/363 [00:00&lt;00:00, 30.6kB/s]"}},"133a16070bb7494287c0792cd67250ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"484926a3e41543898f72e0c016a4a513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8444187c6dae4aaaafcfb9e53edb1d25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c5592426e394682b4e9aec25403fc38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"deb44b2aa2294007b257810c5c997b80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2eb658645d45477ebc4ee20df2c43b67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9650c8176d843a2ad281acc4b180fc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f701f39595b043868f6e52e3f6d5e760":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1ab64b6ff584b7aa5af520862882e4e","IPY_MODEL_e16204a6c2e4435fb5286996b488c2e8","IPY_MODEL_4b8c43d558fe46248bde5eadd416d232"],"layout":"IPY_MODEL_0be3a124385a4ed2b90810911ebf173b"}},"e1ab64b6ff584b7aa5af520862882e4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19b22bdae129416fa79f01ef9f8bc964","placeholder":"​","style":"IPY_MODEL_4a7216014d524fd8aa62afbea6b6fe74","value":"vocab.txt: 100%"}},"e16204a6c2e4435fb5286996b488c2e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5f59559e88648f4a877a7e05e161293","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2478ce03d7d4489f98cd4d18275dd1d4","value":231536}},"4b8c43d558fe46248bde5eadd416d232":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2e2f2f051c426e8dfb29ad618e834f","placeholder":"​","style":"IPY_MODEL_08169399262b4a0a93bd3930045d3431","value":" 232k/232k [00:00&lt;00:00, 543kB/s]"}},"0be3a124385a4ed2b90810911ebf173b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19b22bdae129416fa79f01ef9f8bc964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a7216014d524fd8aa62afbea6b6fe74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5f59559e88648f4a877a7e05e161293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2478ce03d7d4489f98cd4d18275dd1d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d2e2f2f051c426e8dfb29ad618e834f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08169399262b4a0a93bd3930045d3431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3baf556aa20d418d95267dc1f1551c65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95926958240e4d7fbef3cc6153cf0906","IPY_MODEL_39d64098196745a7b00c30bf274b065e","IPY_MODEL_48c137ff745844b384bedb2d4c4f2fa4"],"layout":"IPY_MODEL_7c2ec8cd9006466b8a9c70b98427bd88"}},"95926958240e4d7fbef3cc6153cf0906":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_900da647c45342ec81dac0b16ea40066","placeholder":"​","style":"IPY_MODEL_e4af78b8a56a46dca2be92e0da07e545","value":"tokenizer.json: 100%"}},"39d64098196745a7b00c30bf274b065e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_909e47768399479391bc2f6575cfdece","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48b1051c6e294ffd9c7fb70c0a8d1a30","value":466021}},"48c137ff745844b384bedb2d4c4f2fa4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d6d81bab9c243efa0707d4d28885e62","placeholder":"​","style":"IPY_MODEL_5bbf6b096a5241439d9d6bd1be9e8946","value":" 466k/466k [00:00&lt;00:00, 17.2MB/s]"}},"7c2ec8cd9006466b8a9c70b98427bd88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900da647c45342ec81dac0b16ea40066":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4af78b8a56a46dca2be92e0da07e545":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"909e47768399479391bc2f6575cfdece":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b1051c6e294ffd9c7fb70c0a8d1a30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d6d81bab9c243efa0707d4d28885e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bbf6b096a5241439d9d6bd1be9e8946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45d4fb2451224b9499451f2b81296627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d712c9016a0a40198c3d9b73deaa4cd8","IPY_MODEL_680275bf22ba4f90980e26f623b9a82a","IPY_MODEL_55e28e6c13174d87920164e39d2d73ed"],"layout":"IPY_MODEL_07524f7dfac24d2083f3a20f7d55c2d6"}},"d712c9016a0a40198c3d9b73deaa4cd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbedd28d8652417e8f30f0a2b3befe95","placeholder":"​","style":"IPY_MODEL_d35efd465346414c97055d8c41186809","value":"special_tokens_map.json: 100%"}},"680275bf22ba4f90980e26f623b9a82a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed889d9041f0435e9648011de965de4d","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbf7e3396ade4aa88c4d95d22a6ccea1","value":239}},"55e28e6c13174d87920164e39d2d73ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2a3036e2e854b5d80f410e4b8e1e5ea","placeholder":"​","style":"IPY_MODEL_497f26fa4c7b48bcb7339ebf73e6691f","value":" 239/239 [00:00&lt;00:00, 17.6kB/s]"}},"07524f7dfac24d2083f3a20f7d55c2d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbedd28d8652417e8f30f0a2b3befe95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35efd465346414c97055d8c41186809":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed889d9041f0435e9648011de965de4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbf7e3396ade4aa88c4d95d22a6ccea1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2a3036e2e854b5d80f410e4b8e1e5ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497f26fa4c7b48bcb7339ebf73e6691f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73fda70a2019495a888606f5955d1fb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c710696ffce64366bef6fb606954ad94","IPY_MODEL_f582f748a0fe4538b32af77b2e465553","IPY_MODEL_43dcddd37ff44da59b105377129ced86"],"layout":"IPY_MODEL_449e9bf86c974947b03a0e0a3b9e6999"}},"c710696ffce64366bef6fb606954ad94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b13b8188e25345b29c202cb4715d53f9","placeholder":"​","style":"IPY_MODEL_8687342b4c39418c80bd7bf9e28d1e3d","value":"config.json: 100%"}},"f582f748a0fe4538b32af77b2e465553":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4c71aae1552409a94bb0b007cf483d1","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61fd6f7faa6f4b26af2c7335feb6ddae","value":571}},"43dcddd37ff44da59b105377129ced86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78366280fac94821ad51b9a3eade571a","placeholder":"​","style":"IPY_MODEL_dfd7605f59524501a571c1aace81c9ca","value":" 571/571 [00:00&lt;00:00, 61.2kB/s]"}},"449e9bf86c974947b03a0e0a3b9e6999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b13b8188e25345b29c202cb4715d53f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8687342b4c39418c80bd7bf9e28d1e3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4c71aae1552409a94bb0b007cf483d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61fd6f7faa6f4b26af2c7335feb6ddae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78366280fac94821ad51b9a3eade571a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfd7605f59524501a571c1aace81c9ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5458308ec6d444499c89e58027ae115c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6a6d47516f24a8e9d2c629599cbe303","IPY_MODEL_fe5d54d3861f4fbcb5e35a4b2c8c85de","IPY_MODEL_9a5906ffca4b4b81a93f84d51b36bfec"],"layout":"IPY_MODEL_9983ffde2c0a49b585a69beeaa39d370"}},"d6a6d47516f24a8e9d2c629599cbe303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d61cb10c43f434b8eba3b8ed0fe3524","placeholder":"​","style":"IPY_MODEL_c168a00564d74d62a6e3de42d022b943","value":"model.safetensors: 100%"}},"fe5d54d3861f4fbcb5e35a4b2c8c85de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_479c53b24aeb43a6b85e2992a607cee8","max":437971872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfbbdcc5a8924669a24075ddc33e274d","value":437971872}},"9a5906ffca4b4b81a93f84d51b36bfec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d345ba95e024f16815f539189db4a0e","placeholder":"​","style":"IPY_MODEL_a45f9a7fd9904aa3bb659e7b4e63300d","value":" 438M/438M [00:01&lt;00:00, 245MB/s]"}},"9983ffde2c0a49b585a69beeaa39d370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d61cb10c43f434b8eba3b8ed0fe3524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c168a00564d74d62a6e3de42d022b943":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"479c53b24aeb43a6b85e2992a607cee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfbbdcc5a8924669a24075ddc33e274d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d345ba95e024f16815f539189db4a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a45f9a7fd9904aa3bb659e7b4e63300d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1ef7465bdad4aa99e46b17336eb08bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec374b14f56e46e0a12d176b661b7986","IPY_MODEL_1fbfb85eaf35478e8876053ea46861ef","IPY_MODEL_fd2972deaf514423a63ea6e455612f42"],"layout":"IPY_MODEL_1c3c89caa70341958d09fb76c9a02d25"}},"ec374b14f56e46e0a12d176b661b7986":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49b483d2bdb24ba8b75f8c4ddb29eb96","placeholder":"​","style":"IPY_MODEL_13e239216c1f4ed9b9e29f3062cafd23","value":"tokenizer_config.json: 100%"}},"1fbfb85eaf35478e8876053ea46861ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70004a06f3f44d4880a2401202605a7","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf6107f827f148f7b88f7580eeb76331","value":363}},"fd2972deaf514423a63ea6e455612f42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5227f1d168c4a9fa524fe9690186985","placeholder":"​","style":"IPY_MODEL_64c9a91ff67540578251537b14ea0c42","value":" 363/363 [00:00&lt;00:00, 28.1kB/s]"}},"1c3c89caa70341958d09fb76c9a02d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49b483d2bdb24ba8b75f8c4ddb29eb96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e239216c1f4ed9b9e29f3062cafd23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d70004a06f3f44d4880a2401202605a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6107f827f148f7b88f7580eeb76331":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5227f1d168c4a9fa524fe9690186985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64c9a91ff67540578251537b14ea0c42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"528852e7c28c4539ae814ee12bec9a5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b4fe054152843d3b5bf40890a69b0e8","IPY_MODEL_38f5bfa80dff411283a14e914eb4c212","IPY_MODEL_e72957fb8b1c4c1ba5c557149476ffba"],"layout":"IPY_MODEL_ba6b5689165b4ee68cdf5f747ee7bfc6"}},"7b4fe054152843d3b5bf40890a69b0e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41cdddf3ec1c44d295665064e03f9c82","placeholder":"​","style":"IPY_MODEL_dae4dc5507834152b503b21a7294793d","value":"vocab.txt: 100%"}},"38f5bfa80dff411283a14e914eb4c212":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28767b17f89b41ccab96269746c5a949","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d410bbf89d97443c846bbb5e29fa5920","value":231536}},"e72957fb8b1c4c1ba5c557149476ffba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f9bc5968394f2f969c36228a8ae094","placeholder":"​","style":"IPY_MODEL_4eb9985bac2048188b8aecbb7befbcca","value":" 232k/232k [00:00&lt;00:00, 5.12MB/s]"}},"ba6b5689165b4ee68cdf5f747ee7bfc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41cdddf3ec1c44d295665064e03f9c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dae4dc5507834152b503b21a7294793d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28767b17f89b41ccab96269746c5a949":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d410bbf89d97443c846bbb5e29fa5920":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5f9bc5968394f2f969c36228a8ae094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb9985bac2048188b8aecbb7befbcca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fbc7def9aaf4662b0eb6c52805e27ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9de72624690c418c99d2fe2954d13d3e","IPY_MODEL_f0463927ebb5462094c1b48308884630","IPY_MODEL_5304ffe53dc540a6986de63e64a5218c"],"layout":"IPY_MODEL_6de7169200ff45b1b44745f91c1cdace"}},"9de72624690c418c99d2fe2954d13d3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_783892bb23614a64abae935239a54e55","placeholder":"​","style":"IPY_MODEL_730d3341411f4068b2258229d107a765","value":"tokenizer.json: 100%"}},"f0463927ebb5462094c1b48308884630":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e0c347fda0241cdac38388706d7ffb5","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12f673dce58c4f56bd4c2536bcfbb933","value":466021}},"5304ffe53dc540a6986de63e64a5218c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f03273e0d985492398b877e3b72151cb","placeholder":"​","style":"IPY_MODEL_f84624339e094415af1dd2c649cab8a8","value":" 466k/466k [00:00&lt;00:00, 18.0MB/s]"}},"6de7169200ff45b1b44745f91c1cdace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783892bb23614a64abae935239a54e55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"730d3341411f4068b2258229d107a765":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e0c347fda0241cdac38388706d7ffb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12f673dce58c4f56bd4c2536bcfbb933":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f03273e0d985492398b877e3b72151cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f84624339e094415af1dd2c649cab8a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2321b55a4bdf4166bdd7f7f788e4e4fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5334023429d041b28ff6b914e1ac495c","IPY_MODEL_746dbc44be264efa8af352ab9ea58b52","IPY_MODEL_bc6626908ad64eddb830291dc8a6a938"],"layout":"IPY_MODEL_3298a9c5ebef44f4a8b7c26d1b8dd674"}},"5334023429d041b28ff6b914e1ac495c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b11c034c25c4441afe80ec2bdc815ca","placeholder":"​","style":"IPY_MODEL_b4f21e89d648425a89cb71552aa8c03f","value":"special_tokens_map.json: 100%"}},"746dbc44be264efa8af352ab9ea58b52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68bac3bc6a2e4fdc8d6fba3d6ba01623","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2f42d2f245e4af5a8ae87119af57704","value":239}},"bc6626908ad64eddb830291dc8a6a938":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d773a0c9d864fe6a635573983decf2f","placeholder":"​","style":"IPY_MODEL_790249b25d794f458612532abde61263","value":" 239/239 [00:00&lt;00:00, 21.5kB/s]"}},"3298a9c5ebef44f4a8b7c26d1b8dd674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b11c034c25c4441afe80ec2bdc815ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4f21e89d648425a89cb71552aa8c03f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68bac3bc6a2e4fdc8d6fba3d6ba01623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f42d2f245e4af5a8ae87119af57704":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d773a0c9d864fe6a635573983decf2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"790249b25d794f458612532abde61263":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eef705b716734bacb445376997654d8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cf6fc3b13d64ed8aa34bd4763cc9c11","IPY_MODEL_63c72af89cb14b87b88860b973aa5243","IPY_MODEL_912c4b6db067476d87af5c5d802c4943"],"layout":"IPY_MODEL_31c08fd343ad41559cb0744b1eaa22c8"}},"4cf6fc3b13d64ed8aa34bd4763cc9c11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fc83e9a02a647008f99a0c17a347ee8","placeholder":"​","style":"IPY_MODEL_4ccac6ae3c3a4db9bd475f4ce4b55b66","value":"tokenizer_config.json: 100%"}},"63c72af89cb14b87b88860b973aa5243":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f678440da3ae46dca9225d896f990a3e","max":363,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2374aba250f04cb5be0d929ae8e07464","value":363}},"912c4b6db067476d87af5c5d802c4943":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4dd3f5d8e3c4342a04e57380748aed9","placeholder":"​","style":"IPY_MODEL_31b577f0e79f44dd8f9c54eed25f6dfd","value":" 363/363 [00:00&lt;00:00, 28.2kB/s]"}},"31c08fd343ad41559cb0744b1eaa22c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc83e9a02a647008f99a0c17a347ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ccac6ae3c3a4db9bd475f4ce4b55b66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f678440da3ae46dca9225d896f990a3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2374aba250f04cb5be0d929ae8e07464":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4dd3f5d8e3c4342a04e57380748aed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31b577f0e79f44dd8f9c54eed25f6dfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acfcfafe3fb94317a8d43273f542c50c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbe5fdfbee654d0aa521be50906fddcb","IPY_MODEL_69c6f86d7f724fc2bcd048613436678a","IPY_MODEL_5cf423aaa1e94961b5e44a622d87bfa8"],"layout":"IPY_MODEL_6d669423c11742a6934d6df2579e5934"}},"cbe5fdfbee654d0aa521be50906fddcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9cd8cb24d174422838d3543b1a6a3fe","placeholder":"​","style":"IPY_MODEL_16b5ae78379a44f1b5eed38cb0f61f08","value":"vocab.txt: 100%"}},"69c6f86d7f724fc2bcd048613436678a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_714726935e694313bb4e765f6949c5cb","max":231536,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66cad93025194165b8158c8d58530e11","value":231536}},"5cf423aaa1e94961b5e44a622d87bfa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01e0a0e9fbff42838af906d2197109ac","placeholder":"​","style":"IPY_MODEL_2767ab58f6dd477f9e25e5acc84b41b4","value":" 232k/232k [00:00&lt;00:00, 549kB/s]"}},"6d669423c11742a6934d6df2579e5934":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9cd8cb24d174422838d3543b1a6a3fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16b5ae78379a44f1b5eed38cb0f61f08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"714726935e694313bb4e765f6949c5cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66cad93025194165b8158c8d58530e11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01e0a0e9fbff42838af906d2197109ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2767ab58f6dd477f9e25e5acc84b41b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b50b12e8bdc4a6f87291d3f56f5cc0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_734b1d88ce014e8484b7b1573aba0d2e","IPY_MODEL_c57b1636ccb14110b805d772d7b16e45","IPY_MODEL_ac7fddb25c7f4d9b8e4cadefc9685ecd"],"layout":"IPY_MODEL_3d01d5ddf71a49c7832668c9c1ccd6f6"}},"734b1d88ce014e8484b7b1573aba0d2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea2813552007403bbc0c5fff3eccf447","placeholder":"​","style":"IPY_MODEL_97f658f8348d421dacf62063e3be8c40","value":"tokenizer.json: 100%"}},"c57b1636ccb14110b805d772d7b16e45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5265419ea91748819c588c3a52627916","max":466021,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4398f43a163f4d1ea602f9064cede2a7","value":466021}},"ac7fddb25c7f4d9b8e4cadefc9685ecd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e119dc3a215446c84619a558019114a","placeholder":"​","style":"IPY_MODEL_86f3ddb6f1484e729c721e7452181eb7","value":" 466k/466k [00:00&lt;00:00, 2.13MB/s]"}},"3d01d5ddf71a49c7832668c9c1ccd6f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea2813552007403bbc0c5fff3eccf447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f658f8348d421dacf62063e3be8c40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5265419ea91748819c588c3a52627916":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4398f43a163f4d1ea602f9064cede2a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e119dc3a215446c84619a558019114a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86f3ddb6f1484e729c721e7452181eb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286838ce72234b48b79e2de39c28925f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bbdd7a947474abebf1d2466fb48fc0c","IPY_MODEL_831e9f3c2f9b4461b1947ec4369c4f9d","IPY_MODEL_6a5b30b4e6614519913a99a39d455f02"],"layout":"IPY_MODEL_0931b8f0de704ac78a31e81cad910f82"}},"4bbdd7a947474abebf1d2466fb48fc0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74f6cb2789f84ab88f4f5c7e7aed10fd","placeholder":"​","style":"IPY_MODEL_e2b0140c24434afa9191dc1aa7c3c0d0","value":"special_tokens_map.json: 100%"}},"831e9f3c2f9b4461b1947ec4369c4f9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_939f846da76e418ebc71b231a9b8e49d","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f6501a104224d958542cd3bb3b40b92","value":239}},"6a5b30b4e6614519913a99a39d455f02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a64cad17e6224f7cb8f738ca800b4663","placeholder":"​","style":"IPY_MODEL_67efb3a779f64d7dbf9542c9b7371268","value":" 239/239 [00:00&lt;00:00, 22.1kB/s]"}},"0931b8f0de704ac78a31e81cad910f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f6cb2789f84ab88f4f5c7e7aed10fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2b0140c24434afa9191dc1aa7c3c0d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"939f846da76e418ebc71b231a9b8e49d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f6501a104224d958542cd3bb3b40b92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a64cad17e6224f7cb8f738ca800b4663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67efb3a779f64d7dbf9542c9b7371268":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}