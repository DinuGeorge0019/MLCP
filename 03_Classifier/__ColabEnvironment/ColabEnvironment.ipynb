{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22173,"status":"ok","timestamp":1740865968671,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"xe8Eih0hHc2-","outputId":"c4ff889a-3eb3-4b46-c6b7-28fcdea2d223"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1587,"status":"ok","timestamp":1740865970249,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"YmNUmwcdHc3B","outputId":"e84abfbc-239d-4182-ebe7-d16f29d39cc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3126,"status":"ok","timestamp":1740865973378,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"qIIAqc0VIDm4","outputId":"c3969f8c-63d5-4fd1-c4b5-deed6824bd94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n","Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n"]}],"source":["# install dependencies\n","\n","!pip install scikit-multilearn"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1740865973406,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"T2lmJ49jGPJE","outputId":"e68cbd9a-ebaf-4830-c97c-519414d27773"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3170,"status":"ok","timestamp":1740865976578,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"7T7YDX_3GPJE","outputId":"684bec1e-ed01-4145-d816-3f67fb21e219"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"markdown","source":["1. START DOMAIN ADAPTATION"],"metadata":{"id":"xRHELeWOU15Q"}},{"cell_type":"markdown","source":["1.1. DOMAIN ADAPTATION ON OUR DATASET"],"metadata":{"id":"y311Be0zZ711"}},{"cell_type":"markdown","source":["1.1.1 Domain adaptation for top N subset on our dataset using augumentation (DA models dataset from paper)"],"metadata":{"id":"rrBcOUD6VIs5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRO_Vzk2MtcV"},"outputs":[],"source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'TOP_{NUMBER_OF_TAGS}_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"]},{"cell_type":"markdown","source":["1.1.2. Domain adaptation for top N subset on our dataset without using augumentation (Basic DA models dataset from paper)"],"metadata":{"id":"ZWRTRsxoVNgH"}},{"cell_type":"code","source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'TOP_{NUMBER_OF_TAGS}_BASIC_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"],"metadata":{"id":"-qRh79wVV1qA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.1. DOMAIN ADAPTATION ON KIM ET. ALL DATASET"],"metadata":{"id":"_ZTkqCnUaPFY"}},{"cell_type":"markdown","source":["1.2.1. Domain adaptation for top N subset on Kim et. all dataset using augumentation (DA models dataset from paper)"],"metadata":{"id":"2OmINYWPWyFn"}},{"cell_type":"code","source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"],"metadata":{"id":"6h0hoXRQVFe8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.2.2. Domain adaptation for top N subset on Kim et. all dataset without using augumentation (Basic DA models dataset from paper)"],"metadata":{"id":"vHlNmBEUVEMn"}},{"cell_type":"code","source":["##################\n","# IMPORTANT: change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import NLITransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","nli_transformer_wrapper = NLITransformerWrapper('sentence-transformers/all-mpnet-base-v2')\n","nli_transformer_wrapper.train_model(\n","    train_dataset_path= CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_BASIC_NLI_TRAINING_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=16\n",")\n"],"metadata":{"id":"CaaZnQw6W5YZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. START CHAIN CLASSIFIER EXPERIEMNTS"],"metadata":{"id":"iplTslnBXEjH"}},{"cell_type":"markdown","source":["2.1. Start Chain Classifier experiments using Gausinan Naive Bayes (paper presented experiements)"],"metadata":{"id":"OQmyezRIabba"}},{"cell_type":"markdown","source":["2.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"vhcpt0a9as3L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxccKR9-LaVM"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_base_top_5')\n","    )\n"]},{"cell_type":"markdown","source":["2.1.2 Our Dataset without domain adapted model (Base / Basic train models)"],"metadata":{"id":"tseRnIGRbQqE"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    )\n"],"metadata":{"id":"BnlbaWoMbhUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.1.3 Kim et. all dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"Fnc4tPXLcmUk"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    outside_dataset=True\n","    )\n"],"metadata":{"id":"eYXOTZL_cqD3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.1.4 Kim et. all dataset without domain adapted model (Base / Basic train models)"],"metadata":{"id":"DVngfrjic4fH"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    estimator_name='GaussianNB',\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    outside_dataset=True\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYjmgLh8c-u7","executionInfo":{"status":"ok","timestamp":1740866479558,"user_tz":-120,"elapsed":43561,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"7acae547-0e92-49c8-ed1d-2d3a75fa0bdc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded transformer model: sentence-transformers/all-mpnet-base-v2\n","Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 141/141 [00:32<00:00,  4.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using GPU\n"]},{"output_type":"stream","name":"stderr","text":["Encoding problem statements: 100%|██████████| 34/34 [00:07<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Benchmarking estimator model: GaussianNB\n"]}]},{"cell_type":"markdown","source":["2.2. Run all Chain Classifier Experients (not present in the paper)"],"metadata":{"id":"Kz3iVYHsdQfW"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","from app_src import DecisionTreeEvaluator\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_estimators(\n","    encoder_batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    transformer_name='sentence-transformers/all-mpnet-base-v2',\n","    outside_dataset=False  # Comment to change to True to change to Kim. et all dataset\n","    )\n"],"metadata":{"id":"bf539_VjeDLI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. START ONE VS ALL model EXPERIEMNTS"],"metadata":{"id":"PTJXyT36eZvq"}},{"cell_type":"markdown","source":["3.1. Experiemnts on Our Dataset"],"metadata":{"id":"ooWvGWrNjvLw"}},{"cell_type":"markdown","source":["3.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"Qn_1hWp0fbKI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E67PUmrfEy0H"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","source":["3.1.2. Our Dataset training without domain adaptation (Basic Train)"],"metadata":{"id":"InniuOcdiw7Q"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"SWK7yUbui-7h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.1.3. Our Dataset without without any training OnveVsAll (Base)"],"metadata":{"id":"Ff-jfLrsgNwM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NV-8lk7Q1b0"},"outputs":[],"source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"]},{"cell_type":"markdown","source":["3.2. Experiemnts on Kim et. all Dataset"],"metadata":{"id":"IdIqbYQFjaeQ"}},{"cell_type":"markdown","source":["3.2.1 Kim et. all Dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"c7BxWIB_k-xi"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"azBnzDcwlFBV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.2.2. Kim et. all Dataset training without domain adaptation (Basic Train)"],"metadata":{"id":"CF7LEQwWmPig"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"fV0oihUamY14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.2.3. Kim et. all Dataset without without any training OnveVsAll (Base)"],"metadata":{"id":"YyTSB97Omgpq"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIPLL9QVm0Y3","executionInfo":{"status":"ok","timestamp":1740866256391,"user_tz":-120,"elapsed":119964,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"9e9304f5-1d33-4784-aaee-12575989591f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and evaluating model: sentence-transformers/all-mpnet-base-v2\n","Starting training for label: 0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 1\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 2\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 3\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Starting training for label: 4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 618ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 422ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 433ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 425ms/step\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 425ms/step\n","[[0 1 1 1 1]\n"," [0 1 1 0 0]\n"," [1 1 1 0 1]\n"," ...\n"," [0 0 1 0 0]\n"," [0 1 0 1 1]\n"," [0 1 1 1 0]]\n"]}]},{"cell_type":"markdown","source":["3.2.4 Kim et. all Dataset - All base experiments from Table 5."],"metadata":{"id":"_Kfum1lam51i"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import OneVsAllTransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = OneVsAllTransformerEvaluator()\n","transformer_evaluator.evaluate_base_models(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"QhOjjloZnBHq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. SINGLE MODEL CLASSIFIER EXPERIEMNTS"],"metadata":{"id":"N6PeLmKrnZU3"}},{"cell_type":"markdown","source":["4.1. Experiemnts on Our Dataset"],"metadata":{"id":"Z9gHGmI0nhFB"}},{"cell_type":"markdown","source":["4.1.1 Our Dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"ff6394xgo722"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"Q6na0mMFnhUq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.1.2. Our Dataset training without domain adaptation (Basic Train)"],"metadata":{"id":"4x4ibT_tp6Tj"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"W5P7W9KgqgTh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.1.3. Our Dataset without without any training OnveVsAll (Base)"],"metadata":{"id":"oJ3IZ1qsqDlp"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"nuZq6aorqwXP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.2. Experiemnts on Kim et. all Dataset"],"metadata":{"id":"Jc6i4ThcqKs4"}},{"cell_type":"markdown","source":["4.2.1 Kim et. all Dataset with domain adapted model (DA / Basic DA models)"],"metadata":{"id":"f64q3HnDqNdm"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","# 2. Change the transformer_model_path to the corresponding domain adapted model path\n","# 3. If you want to replicate Basic DA experiments just replace transformer_model_path to a Basic DA pretrained model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    transformer_model_path=os.path.join(CONFIG[\"TRANSFORMER_SAVE_PATH_ROOT\"], 'transformer_model_top_5'),\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"sbvU_DmEq6zC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.2.2. Kim et. all Dataset training without domain adaptation (Basic Train)"],"metadata":{"id":"HHw_BGmwqQeS"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"rfGARVY5rAYF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4.2.3. Kim et. all Dataset without without any training OnveVsAll (Base)"],"metadata":{"id":"cUP3hlh9qTv2"}},{"cell_type":"code","source":["##################\n","# IMPORTANT:\n","# 1. Change NUMBER_OF_TAGS to select the dataset subset for which you are training the model\n","##################\n","\n","# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_base_model(\n","    epochs=20,\n","    batch_size=32,\n","    number_of_tags=NUMBER_OF_TAGS,\n","    model='sentence-transformers/all-mpnet-base-v2',\n","    train_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    test_dataset_path=CONFIG[f'OUTSIDE_TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH']\n","  )\n"],"metadata":{"id":"k_0r97Yfp6aG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":0}