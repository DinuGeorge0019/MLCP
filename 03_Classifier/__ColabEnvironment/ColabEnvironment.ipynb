{"cells":[{"cell_type":"markdown","metadata":{"id":"Jx_pafU4toh5"},"source":["For google colab environment"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3692,"status":"ok","timestamp":1738517340848,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"xe8Eih0hHc2-","outputId":"e2823f3e-6e27-4522-9682-db00c3a36dd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1738517340849,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"YmNUmwcdHc3B","outputId":"bf3417cc-eceb-4c88-a72b-52bdedb42375"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\n"]}],"source":["cd \"/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/__ColabEnvironment\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2161,"status":"ok","timestamp":1738517343008,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"qIIAqc0VIDm4","outputId":"f32bac47-6e1b-48f6-97f2-a34a618be25d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"]}],"source":["# install dependencies\n","\n","# !pip install catboost\n","!pip install scikit-multilearn\n","# !pip install sentence-transformers\n","# !pip install --upgrade tensorflow-addons\n","# !pip install dask[dataframe]\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1738517343008,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"T2lmJ49jGPJE","outputId":"11f3d596-3121-40fe-e646-0a583a78b3c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier\n"]}],"source":["import sys\n","import os\n","\n","# Add the parent directory of app_config to the Python path\n","sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n","print(os.path.abspath(os.path.join(os.getcwd(), '..')))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1738517343008,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"7T7YDX_3GPJE","outputId":"df09df69-b2bb-4e0d-c76c-b86929a1b249"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Othercomputers/ASUS Main/MLCP\n"]}],"source":["from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","print(CONFIG['BASE_DIR'])"]},{"cell_type":"markdown","metadata":{"id":"-d7Bz7antoh8"},"source":["Start code here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18177,"status":"ok","timestamp":1738429201620,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"vnQee3H_Hc3B","outputId":"aad7f8b6-c5e9-47b7-ceeb-cafd1d4763b4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n","[[-0.8101385  -0.16610806  0.6887159  ...  0.44352567 -0.5091756\n","   0.8196503 ]\n"," [-0.7800876  -0.18304415  0.65481484 ...  0.4226258  -0.53926814\n","   0.8172223 ]\n"," [-0.7563645  -0.13678594  0.6978225  ...  0.42069024 -0.50592023\n","   0.7682986 ]]\n"]}],"source":["from app_src import CustomEncoder\n","\n","encoder = CustomEncoder(\"bert-base-uncased\")\n","data = [\"This is a test\", \"This is another test\", \"This is a third test\"]\n","\n","encodded_sentence = encoder.encode_problem_statement(data)\n","print(encodded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":435,"status":"error","timestamp":1738429262170,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"AL8NTNOKHc3C","outputId":"4c2b8ed2-e82d-4bbf-a4bd-f7c3b1f70aaa"},"outputs":[{"ename":"TypeError","evalue":"ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-97d0783496a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifierChainWrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierChainWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ClassifierChainWrapper.__init__() takes 2 positional arguments but 4 were given"]}],"source":["from app_src import ClassifierChainWrapper\n","from sklearn.ensemble import RandomForestClassifier\n","\n","classifierChainWrapper = ClassifierChainWrapper(RandomForestClassifier(), \"bert-base-uncased\", 5)\n","classifierChainWrapper.fit()\n","metrics_results = classifierChainWrapper.predict()\n","\n","for metric_name, metric_value in metrics_results.items():\n","    print(f\"{metric_name}: {metric_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":966},"executionInfo":{"elapsed":374215,"status":"error","timestamp":1738434464825,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"2V2DZ5O5wpXk","outputId":"bfb4f9ab-0f0b-4ab9-fe51-4358121bb989"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking encoder model: sentence-transformers/all-mpnet-base-v2\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 140/140 [03:21<00:00,  1.44s/it]\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFMPNetModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Using GPU\n"]},{"name":"stderr","output_type":"stream","text":["Encoding problem statements: 100%|██████████| 39/39 [01:21<00:00,  2.10s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Benchmarking estimator model: LogisticRegression\n","Benchmarking estimator model: KNeighborsClassifier\n","Benchmarking estimator model: DecisionTreeClassifier\n","Benchmarking estimator model: GaussianNB\n","Benchmarking estimator model: RandomForestClassifier\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f48c8ed72720>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecisionTreeEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecisionTreeEvaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/DecisionTreeEvaluator.py\u001b[0m in \u001b[0;36mbenchmark_models\u001b[0;34m(self, encoder_batch_size, number_of_tags, validation)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mmetrics_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifierChainWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Othercomputers/ASUS Main/MLCP/03_Classifier/app_src/ClassifierChainWrapper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_problem_statements, train_tags, validation_problem_statements, validation_tags)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_problem_statements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_problem_statements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_problem_statements_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, order)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[0m\u001b[1;32m    155\u001b[0m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[1;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from app_src import DecisionTreeEvaluator\n","\n","decisionTreeEvaluator = DecisionTreeEvaluator()\n","decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=5)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=10)\n","# decisionTreeEvaluator.benchmark_models(encoder_batch_size=32, number_of_tags=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4154,"status":"ok","timestamp":1738441980041,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"UMkaJZsOBid0","outputId":"607490d9-83ea-4484-8a63-e7bc11428d7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.18.0\n","CUDA version: 12.5.1\n","CUDNN version: 9\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","build_info = tf.sysconfig.get_build_info()\n","print(\"CUDA version:\", build_info.get(\"cuda_version\", \"Unknown\"))\n","print(\"CUDNN version:\", build_info.get(\"cudnn_version\", \"Unknown\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194040,"status":"ok","timestamp":1738444782534,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"_DhP3q-Htoh9","outputId":"98be28bf-4ead-4803-a8ca-79b3fd84ff7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n","GPU details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - auc: 0.4989 - binary_accuracy: 0.5410 - label_wise_accuracy: 0.5658 - label_wise_f1_score: 0.2792 - label_wise_macro_f1: 0.3096 - loss: 0.7119 - prc_auc: 0.3117 - precision: 0.3172 - recall: 0.3973 - subset_accuracy: 0.0409 - subset_f1: 0.3366 - subset_precision: 0.2985 - subset_recall: 0.3944\n","Epoch 1: Validation Metrics:\n","loss: 0.6944112777709961\n","val_label_wise_f1_score: [0.15384611 0.49999997 0.         0.         0.24999999]\n","val_label_wise_accuracy: [0.65625 0.8125  0.59375 0.78125 0.4375 ]\n","val_binary_accuracy: 0.6274999976158142\n","val_precision: 0.33170732855796814\n","val_recall: 0.17989417910575867\n","val_label_wise_macro_f1: 0.1877191960811615\n","val_subset_accuracy: 0.05416666716337204\n","val_subset_precision: 0.21840278804302216\n","val_subset_recall: 0.16968749463558197\n","val_subset_f1: 0.18850629031658173\n","val_auc: 0.516687273979187\n","val_prc_auc: 0.3235663175582886\n","\n","Epoch 1: val_loss improved from inf to 0.65696, saving model to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Sentence_Transformer_Models/sentence_transformer_model_20250201_211152.keras\n","\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 1s/step - auc: 0.4990 - binary_accuracy: 0.5412 - label_wise_accuracy: 0.5665 - label_wise_f1_score: 0.2785 - label_wise_macro_f1: 0.3094 - loss: 0.7118 - prc_auc: 0.3118 - precision: 0.3172 - recall: 0.3968 - subset_accuracy: 0.0410 - subset_f1: 0.3363 - subset_precision: 0.2984 - subset_recall: 0.3939 - val_auc: 0.5167 - val_binary_accuracy: 0.6275 - val_label_wise_accuracy: 0.6562 - val_label_wise_f1_score: 0.1808 - val_label_wise_macro_f1: 0.1877 - val_loss: 0.6570 - val_prc_auc: 0.3236 - val_precision: 0.3317 - val_recall: 0.1799 - val_subset_accuracy: 0.0542 - val_subset_f1: 0.1885 - val_subset_precision: 0.2184 - val_subset_recall: 0.1697\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Sentence_Transformer_Models/sentence_transformer_model_20250201_211152.keras\n"]}],"source":["import os\n","import tensorflow as tf\n","\n","# Check if GPU is available and print details\n","if tf.config.experimental.list_physical_devices('GPU'):\n","    print(\"GPU is available\")\n","    print(\"GPU details:\", tf.config.list_physical_devices('GPU'))\n","else:\n","    print(\"GPU not available, using CPU\")\n","\n","# # If GPU is available, try setting memory growth\n","# gpus = tf.config.list_physical_devices('GPU')\n","# if gpus:\n","#     try:\n","#         # Currently, memory growth needs to be the same across GPUs\n","#         for gpu in gpus:\n","#             tf.config.experimental.set_memory_growth(gpu, True)\n","#         logical_gpus = tf.config.list_logical_devices('GPU')\n","#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#     except RuntimeError as e:\n","#         # Memory growth must be set before GPUs have been initialized\n","#         print('Error')\n","#         print(e)\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"bert-base-uncased\", NUMBER_OF_TAGS)\n","sentenceTransformerWrapper.train_model(\n","    train_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TRAINING_DATASET_PATH'],\n","    val_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_VALIDATION_DATASET_PATH'],\n","    epochs=1,\n","    batch_size=32\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56218,"status":"ok","timestamp":1738444904763,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"},"user_tz":-120},"id":"Pd4K7EOOtoh9","outputId":"a10b0a17-a24d-43c7-9197-a5d8045ea1fb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/serialization_lib.py:730: UserWarning: Model 'sentence_transformer_encoder_model_4' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n","  instance.build_from_config(build_config)\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adamw', because it has 2 variables whereas the saved optimizer has 6 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded from /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Sentence_Transformer_Models/sentence_transformer_model_20250201_211152.keras\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - auc: 0.5075 - binary_accuracy: 0.5221 - label_wise_accuracy: 0.5250 - label_wise_f1_score: 0.2534 - label_wise_macro_f1: 0.2499 - loss: 0.7648 - prc_auc: 0.3238 - precision: 0.3184 - recall: 0.4299 - subset_accuracy: 0.0302 - subset_f1: 0.3636 - subset_precision: 0.3176 - subset_recall: 0.4276\n","Evaluation Metrics:\n","Loss: 0.7654196619987488\n","Label F1 Scores: [0.4137931  0.         0.5641025  0.31578943 0.        ]\n","Label Accuracies: [0.46875 0.625   0.46875 0.1875  0.875  ]\n","Accuracy: 0.5249999761581421\n","Precision: 0.31938159465789795\n","Recall: 0.43886011838912964\n","F1 Score: 0.25330957770347595\n","Subset Accuracy: 0.027960525825619698\n","Subset Precision: 0.3192160725593567\n","Subset Recall: 0.4399808645248413\n","Subset F1: 0.3689383566379547\n","AUC: 0.5071903467178345\n","PRC AUC: 0.3139888048171997\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Loss': 0.7654196619987488,\n"," 'Label F1 Scores': array([0.4137931 , 0.        , 0.5641025 , 0.31578943, 0.        ],\n","       dtype=float32),\n"," 'Label Accuracies': array([0.46875, 0.625  , 0.46875, 0.1875 , 0.875  ], dtype=float32),\n"," 'Accuracy': 0.5249999761581421,\n"," 'Precision': 0.31938159465789795,\n"," 'Recall': 0.43886011838912964,\n"," 'F1 Score': 0.25330957770347595,\n"," 'Subset Accuracy': 0.027960525825619698,\n"," 'Subset Precision': 0.3192160725593567,\n"," 'Subset Recall': 0.4399808645248413,\n"," 'Subset F1': 0.3689383566379547,\n"," 'AUC': 0.5071903467178345,\n"," 'PRC AUC': 0.3139888048171997}"]},"metadata":{},"execution_count":11}],"source":["import os\n","\n","# local application/library specific imports\n","from app_src import SentenceTransformerWrapper\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","NUMBER_OF_TAGS = 5\n","\n","sentenceTransformerWrapper = SentenceTransformerWrapper(\"bert-base-uncased\", NUMBER_OF_TAGS)\n","\n","\n","sentenceTransformerWrapper.benchmark_model(\n","    test_dataset_path=CONFIG[f'TOP_{NUMBER_OF_TAGS}_TESTING_DATASET_PATH'],\n","    batch_size=32,\n","    model_path= os.path.join(CONFIG[\"MODEL_SAVE_PATH_ROOT\"], 'sentence_transformer_model_20250202_153543.keras'),\n","    )"]},{"cell_type":"code","source":["# local application/library specific imports\n","from app_src import TransformerEvaluator\n","from app_config import AppConfig\n","\n","# define configuration proxy\n","configProxy = AppConfig()\n","CONFIG = configProxy.return_config()\n","\n","transformer_evaluator = TransformerEvaluator()\n","transformer_evaluator.evaluate_models(\n","    epochs=1,\n","    batch_size=32,\n","    number_of_tags=5,\n","    train_model=True,\n","    threshold=0.5\n","  )\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["67560ef4f02f43bdb433b1bb38ea5c04","d68e50ede9844127ae43a615ecb56c6a","9634c984d2dd423ab0d0ffd7fdf9ebb9","c0c8c151258d4dea985565dbbc0aa067","6da354f7873847b19222bb1c3eb56808","4d52acee814045a797322bf0360d6a5c","9f4bcfb128a14b3ca7503df7dc32643a","8b71a762fa234f92818d34cd5ff3cc8a","d078c40d40224f378552c77c6cdc5f0d","687e7f8903fe4baaaae9a79bb471285a","bc80fb1a87ce4bdd865fbfd196298cef","335d1f6919b2421d80dadf9befd96432","a78c091c1f9d4fbf8b48baf12a271ffd","7180d8f314354147b783683ba5539262","76aea744d69a4856b09a9cfd678c6667","8e4fc9aeb3164aedaea28566e0aec0ba","c4ed6e0ba3724beca4f39c0d918da3db","e1f02f0002bf409580c3974866b34188","2e109a2531a84ecfb4450c0007d998fd","d047b21385ae4223b2400c9da94bdf65","d8fbf2454d844b2586bd977d358c0ef0","2cecb1744314441f82d94f644875f8ac","0841bbe229dd44dbb91bdd4db6d94cbf","13b94edf6a3b43a3989bd0bb7bc22b23","fdbfa9748bfb4be7bcc2b36ee47f409f","4e6516b754b04402aff6c8a626009ac5","0b4faccf730446e99417a431f5134220","1a2fc9f11abd4fe7904428c428b479be","2c8e682d40824f9d8f5055852ed55da5","81d3a3b652a5454fac89093db2c315ae","00e226600b834ba18f82d53b192607ff","7080c77beae54505ae212b78bed7bf31","2b324cc0a01145998f09e32c41dd721c","5595718fe92e4f61b8c0b104e89bbd3b","9ef2ed7e98544f0fb680dcf6e4dd2a75","65f88d0ad7314ab6a5651da79e71d930","875d48234ba94a4ab61e2ee2bff238a8","719f69dcf52e465d96d91dff93cfad98","7d76e7cebcb24b798fa80ed0d64dcaaa","dd446b90f8f44210a9accd49769bd4a0","aa5ba90eea204a8081eee9dfbbeb1b16","ea0e1c3d0dc942b391a9f6e6516f375d","73fe20fb642d49ccbff5dbad1c33cb8c","8920a1a836fc414fa2ac5b8769080e12"]},"id":"mCcdWL_XfxIG","executionInfo":{"status":"ok","timestamp":1738517698596,"user_tz":-120,"elapsed":353458,"user":{"displayName":"Dinu Ion George","userId":"14034259797438922081"}},"outputId":"f37fb705-f304-45b0-a14a-82fb38cb9c9f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Training and evaluating model: microsoft/deberta-v3-base\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67560ef4f02f43bdb433b1bb38ea5c04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/736M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"335d1f6919b2421d80dadf9befd96432"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFDebertaV2Model.\n","\n","All the layers of TFDebertaV2Model were initialized from the model checkpoint at microsoft/deberta-v3-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2Model for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0841bbe229dd44dbb91bdd4db6d94cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5595718fe92e4f61b8c0b104e89bbd3b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - auc: 0.5326 - binary_accuracy: 0.5517 - label_wise_accuracy: 0.5527 - label_wise_f1_score: 0.2340 - label_wise_macro_f1: 0.2326 - loss: 0.7286 - prc_auc: 0.4071 - precision: 0.4164 - recall: 0.4367 - subset_accuracy: 0.0715 - subset_f1: 0.4211 - subset_precision: 0.4164 - subset_recall: 0.4281\n","Epoch 1: Validation Metrics:\n","loss: 0.7173011898994446\n","val_label_wise_f1_score: [0.6938775  0.39999998 0.         0.         0.        ]\n","val_label_wise_accuracy: [0.53125 0.25    0.71875 0.53125 0.71875]\n","val_binary_accuracy: 0.5422794222831726\n","val_precision: 0.4126838147640228\n","val_recall: 0.42559242248535156\n","val_label_wise_macro_f1: 0.2318522334098816\n","val_subset_accuracy: 0.07352941483259201\n","val_subset_precision: 0.4126838147640228\n","val_subset_recall: 0.41813725233078003\n","val_subset_f1: 0.41475462913513184\n","val_auc: 0.5095677375793457\n","val_prc_auc: 0.39973726868629456\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 1s/step - auc: 0.5326 - binary_accuracy: 0.5517 - label_wise_accuracy: 0.5527 - label_wise_f1_score: 0.2339 - label_wise_macro_f1: 0.2326 - loss: 0.7285 - prc_auc: 0.4071 - precision: 0.4164 - recall: 0.4367 - subset_accuracy: 0.0714 - subset_f1: 0.4211 - subset_precision: 0.4164 - subset_recall: 0.4281 - val_auc: 0.5096 - val_binary_accuracy: 0.5423 - val_label_wise_accuracy: 0.5500 - val_label_wise_f1_score: 0.2188 - val_label_wise_macro_f1: 0.2319 - val_loss: 0.7044 - val_prc_auc: 0.3997 - val_precision: 0.4127 - val_recall: 0.4256 - val_subset_accuracy: 0.0735 - val_subset_f1: 0.4148 - val_subset_precision: 0.4127 - val_subset_recall: 0.4181\n","Model saved to /content/drive/Othercomputers/ASUS Main/MLCP/05_MODELS/01_Sentence_Transformer_Models/sentence_transformer_model_20250202_172914.keras\n","Using the trained model\n","\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - auc: 0.5671 - binary_accuracy: 0.5699 - label_wise_accuracy: 0.5669 - label_wise_f1_score: 0.2437 - label_wise_macro_f1: 0.2459 - loss: 0.6801 - prc_auc: 0.4395 - precision: 0.4484 - recall: 0.4612 - subset_accuracy: 0.0703 - subset_f1: 0.4546 - subset_precision: 0.4484 - subset_recall: 0.4622\n","Evaluation Metrics:\n","Loss: 0.684823751449585\n","Label F1 Scores: [0.6086956 0.6938775 0.        0.        0.       ]\n","Label Accuracies: [0.4375  0.53125 0.53125 0.6875  0.8125 ]\n","Accuracy: 0.5661337375640869\n","Precision: 0.442950576543808\n","Recall: 0.4563833773136139\n","F1 Score: 0.24332481622695923\n","Subset Accuracy: 0.075581394135952\n","Subset Precision: 0.442950576543808\n","Subset Recall: 0.4543846547603607\n","Subset F1: 0.4478779733181\n","AUC: 0.5542804598808289\n","PRC AUC: 0.4325554370880127\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"widgets":{"application/vnd.jupyter.widget-state+json":{"67560ef4f02f43bdb433b1bb38ea5c04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d68e50ede9844127ae43a615ecb56c6a","IPY_MODEL_9634c984d2dd423ab0d0ffd7fdf9ebb9","IPY_MODEL_c0c8c151258d4dea985565dbbc0aa067"],"layout":"IPY_MODEL_6da354f7873847b19222bb1c3eb56808"}},"d68e50ede9844127ae43a615ecb56c6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d52acee814045a797322bf0360d6a5c","placeholder":"​","style":"IPY_MODEL_9f4bcfb128a14b3ca7503df7dc32643a","value":"config.json: 100%"}},"9634c984d2dd423ab0d0ffd7fdf9ebb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b71a762fa234f92818d34cd5ff3cc8a","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d078c40d40224f378552c77c6cdc5f0d","value":579}},"c0c8c151258d4dea985565dbbc0aa067":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_687e7f8903fe4baaaae9a79bb471285a","placeholder":"​","style":"IPY_MODEL_bc80fb1a87ce4bdd865fbfd196298cef","value":" 579/579 [00:00&lt;00:00, 43.6kB/s]"}},"6da354f7873847b19222bb1c3eb56808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d52acee814045a797322bf0360d6a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f4bcfb128a14b3ca7503df7dc32643a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b71a762fa234f92818d34cd5ff3cc8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d078c40d40224f378552c77c6cdc5f0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"687e7f8903fe4baaaae9a79bb471285a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc80fb1a87ce4bdd865fbfd196298cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"335d1f6919b2421d80dadf9befd96432":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a78c091c1f9d4fbf8b48baf12a271ffd","IPY_MODEL_7180d8f314354147b783683ba5539262","IPY_MODEL_76aea744d69a4856b09a9cfd678c6667"],"layout":"IPY_MODEL_8e4fc9aeb3164aedaea28566e0aec0ba"}},"a78c091c1f9d4fbf8b48baf12a271ffd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4ed6e0ba3724beca4f39c0d918da3db","placeholder":"​","style":"IPY_MODEL_e1f02f0002bf409580c3974866b34188","value":"tf_model.h5: 100%"}},"7180d8f314354147b783683ba5539262":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e109a2531a84ecfb4450c0007d998fd","max":735589384,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d047b21385ae4223b2400c9da94bdf65","value":735589384}},"76aea744d69a4856b09a9cfd678c6667":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8fbf2454d844b2586bd977d358c0ef0","placeholder":"​","style":"IPY_MODEL_2cecb1744314441f82d94f644875f8ac","value":" 736M/736M [00:34&lt;00:00, 22.8MB/s]"}},"8e4fc9aeb3164aedaea28566e0aec0ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ed6e0ba3724beca4f39c0d918da3db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f02f0002bf409580c3974866b34188":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e109a2531a84ecfb4450c0007d998fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d047b21385ae4223b2400c9da94bdf65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8fbf2454d844b2586bd977d358c0ef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cecb1744314441f82d94f644875f8ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0841bbe229dd44dbb91bdd4db6d94cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13b94edf6a3b43a3989bd0bb7bc22b23","IPY_MODEL_fdbfa9748bfb4be7bcc2b36ee47f409f","IPY_MODEL_4e6516b754b04402aff6c8a626009ac5"],"layout":"IPY_MODEL_0b4faccf730446e99417a431f5134220"}},"13b94edf6a3b43a3989bd0bb7bc22b23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a2fc9f11abd4fe7904428c428b479be","placeholder":"​","style":"IPY_MODEL_2c8e682d40824f9d8f5055852ed55da5","value":"tokenizer_config.json: 100%"}},"fdbfa9748bfb4be7bcc2b36ee47f409f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d3a3b652a5454fac89093db2c315ae","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00e226600b834ba18f82d53b192607ff","value":52}},"4e6516b754b04402aff6c8a626009ac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7080c77beae54505ae212b78bed7bf31","placeholder":"​","style":"IPY_MODEL_2b324cc0a01145998f09e32c41dd721c","value":" 52.0/52.0 [00:00&lt;00:00, 4.25kB/s]"}},"0b4faccf730446e99417a431f5134220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a2fc9f11abd4fe7904428c428b479be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c8e682d40824f9d8f5055852ed55da5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81d3a3b652a5454fac89093db2c315ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00e226600b834ba18f82d53b192607ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7080c77beae54505ae212b78bed7bf31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b324cc0a01145998f09e32c41dd721c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5595718fe92e4f61b8c0b104e89bbd3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ef2ed7e98544f0fb680dcf6e4dd2a75","IPY_MODEL_65f88d0ad7314ab6a5651da79e71d930","IPY_MODEL_875d48234ba94a4ab61e2ee2bff238a8"],"layout":"IPY_MODEL_719f69dcf52e465d96d91dff93cfad98"}},"9ef2ed7e98544f0fb680dcf6e4dd2a75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d76e7cebcb24b798fa80ed0d64dcaaa","placeholder":"​","style":"IPY_MODEL_dd446b90f8f44210a9accd49769bd4a0","value":"spm.model: 100%"}},"65f88d0ad7314ab6a5651da79e71d930":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa5ba90eea204a8081eee9dfbbeb1b16","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea0e1c3d0dc942b391a9f6e6516f375d","value":2464616}},"875d48234ba94a4ab61e2ee2bff238a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73fe20fb642d49ccbff5dbad1c33cb8c","placeholder":"​","style":"IPY_MODEL_8920a1a836fc414fa2ac5b8769080e12","value":" 2.46M/2.46M [00:00&lt;00:00, 131MB/s]"}},"719f69dcf52e465d96d91dff93cfad98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d76e7cebcb24b798fa80ed0d64dcaaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd446b90f8f44210a9accd49769bd4a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa5ba90eea204a8081eee9dfbbeb1b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea0e1c3d0dc942b391a9f6e6516f375d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73fe20fb642d49ccbff5dbad1c33cb8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8920a1a836fc414fa2ac5b8769080e12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}